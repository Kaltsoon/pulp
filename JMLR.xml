<?xml version="1.0" encoding="UTF-8" standalone="no"?><articles><Article><id>1</id><title>Learning with Mixtures of Trees</title><author>Marina Meila, Michael I. Jordan</author><abstract>
This paper describes the mixtures-of-trees model, a probabilistic 
model for discrete multidimensional domains.  Mixtures-of-trees 
generalize the probabilistic trees of Chow and Liu (1968) in a 
different and complementary direction to that of Bayesian networks.
We present efficient algorithms for learning mixtures-of-trees 
models in maximum likelihood and Bayesian frameworks. 
We also discuss additional efficiencies that can be obtained 
when data are &amp;quot;sparse,&amp;quot; and we present data structures and 
algorithms that exploit such sparseness.  Experimental results 
demonstrate the performance of the model for both density 
estimation and classification. We also discuss the sense in 
which tree-based classifiers perform an implicit form of feature 
selection, and demonstrate a resulting insensitivity to irrelevant 
attributes.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/meila00a/meila00a.pdf</url></Article><Article><id>2</id><title>Dependency Networks for Inference, Collaborative Filtering, and Data Visualization</title><author>David Heckerman, David Maxwell Chickering, Christopher Meek, Robert Rounthwaite, Carl Kadie</author><abstract>
We describe a graphical model for probabilistic relationships--an
alternative to the Bayesian network--called a dependency network.  The
graph of a dependency network, unlike a Bayesian network, is
potentially cyclic.  The probability component of a dependency
network, like a Bayesian network, is a set of conditional
distributions, one for each node given its parents.  We identify
several basic properties of this representation and describe a
computationally efficient procedure for learning the graph and
probability components from data.  We describe the application of this
representation to probabilistic inference, collaborative filtering
(the task of predicting preferences), and the visualization of acausal
predictive relationships.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/heckerman00a/heckerman00a.pdf</url></Article><Article><id>3</id><title>Learning Evaluation Functions to Improve Optimization by Local Search</title><author>Justin Boyan, Andrew W. Moore</author><abstract>
  This paper describes algorithms that learn to improve search
  performance on large-scale optimization tasks.  The main algorithm,
  STAGE, works by learning an evaluation function that predicts the
  outcome of a local search algorithm, such as hillclimbing or
  Walksat, from features of states visited during search.  The
  learned evaluation function is then used to bias future search
  trajectories toward better optima on the same problem.  Another
  algorithm, X-STAGE, transfers previously learned evaluation
  functions to new, similar optimization problems.  Empirical results
  are provided on seven large-scale optimization domains: bin-packing,
  channel routing, Bayesian network structure-finding, radiotherapy
  treatment planning, cartogram design, Boolean satisfiability, and
  Boggle board setup.


&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/boyan00a/boyan00a.pdf</url></Article><Article><id>4</id><title>Reducing Multiclass to Binary: A Unifying Approach for Margin Classifiers</title><author>Erin L. Allwein, Robert E. Schapire, Yoram Singer</author><abstract>
We present a unifying framework for studying the solution of
multiclass categorization problems by reducing them to multiple binary
problems that are then solved using a margin-based binary learning
algorithm.  The proposed framework unifies some of the most popular
approaches in which each class is compared against all others, or in
which all pairs of classes are compared to each other, or in which
output codes with error-correcting properties are used.  We propose a
general method for combining the classifiers generated on the binary
problems, and we prove a general empirical &lt;em&gt;multiclass&lt;/em&gt; loss
bound given the empirical loss of the individual &lt;em&gt;binary&lt;/em&gt; learning
algorithms.  The scheme and the corresponding bounds apply to many
popular classification learning algorithms including support-vector
machines, AdaBoost, regression, logistic regression and decision-tree
algorithms.  We also give a multiclass generalization error analysis
for general output codes with AdaBoost as the binary learner.
Experimental results with SVM and AdaBoost show that our scheme
provides a viable alternative to the most commonly used multiclass
algorithms.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/allwein00a/allwein00a.pdf</url></Article><Article><id>5</id><title>SVMTorch: Support Vector Machines for Large-Scale Regression Problems</title><author>Ronan Collobert, Samy Bengio</author><abstract>
Support Vector Machines (SVMs) for regression problems are trained by solving&#13;
a quadratic optimization problem which needs on the order of l square&#13;
memory and time resources to solve, where l is the number of training&#13;
examples. In this paper, we propose a decomposition algorithm, &#13;
SVMTorch (available at &lt;a target=_new href=http://www.idiap.ch/learning/SVMTorch.html&gt;http://www.idiap.ch/learning/SVMTorch.html&lt;/a&gt;), which is &#13;
similar to SVM-Light proposed by Joachims (1999) for classification problems, &#13;
but adapted to regression problems. &#13;
With this algorithm, one can now efficiently solve&#13;
large-scale regression problems (more than 20000 examples). &#13;
Comparisons with Nodelib, another publicly available&#13;
SVM algorithm for large-scale regression problems&#13;
from Flake and Lawrence (2000) yielded significant time improvements.&#13;
Finally, based on a recent paper from Lin (2000), we show that a &#13;
convergence proof exists for our algorithm.&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/collobert01a/collobert01a.pdf</url></Article><Article><id>6</id><title>Lagrangian Support Vector Machines</title><author>O. L. Mangasarian, David R. Musicant</author><abstract>
An implicit Lagrangian for the dual of a simple reformulation of the
standard quadratic program of a linear support vector machine is
proposed.  This leads to the minimization of an unconstrained
differentiable convex function in a space of dimensionality equal to
the number of classified points.  This problem is solvable by an
extremely simple linearly convergent Lagrangian support vector machine
(LSVM) algorithm. LSVM requires the inversion at the outset of a
single matrix of the order of the much smaller dimensionality of the
original input space plus one. The full algorithm is given in this
paper in 11 lines of MATLAB code without any special optimization
tools such as linear or quadratic programming solvers. This LSVM code
can be used "as is" to solve classification problems with millions of
points. For example, 2 million points in 10 dimensional input space
were classified by a linear surface in 82 minutes on a Pentium III 500
MHz notebook with 384 megabytes of memory (and additional swap space),
and in 7 minutes on a 250 MHz UltraSPARC II processor with 2 gigabytes
of memory.  Other standard classification test problems were also
solved.  Nonlinear kernel classification can also be solved by LSVM.
Although it does not scale up to very large problems, it can handle
any positive semidefinite kernel and is guaranteed to converge. A
short MATLAB code is also given for nonlinear kernels and tested on a
number of problems.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/mangasarian01a/mangasarian01a.pdf</url></Article><Article><id>7</id><title>Regularized Principal Manifolds</title><author>Alexander J. Smola, Sebastian Mika, Bernhard Sch&amp;ouml;lkopf, Robert C. Williamson</author><abstract>
Many settings of unsupervised learning can be viewed as
quantization problems - the minimization of the expected quantization
error subject to some restrictions. This allows the use of tools such as
regularization from the theory of (supervised) risk minimization for
unsupervised learning. This setting turns out to be closely related to
principal curves, the generative topographic map, and robust coding.
    
We explore this connection in two ways: (1) we propose an algorithm for
finding principal manifolds that can be regularized in a variety of ways;
and (2) we derive uniform convergence bounds and hence bounds on the
learning rates of the algorithm. In particular, we give bounds on the
covering numbers which allows us to obtain nearly optimal learning rates
for certain types of regularization operators. Experimental results
demonstrate the feasibility of the approach.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/smola01a/smola01a.pdf</url></Article><Article><id>8</id><title>Sparse Bayesian Learning and the Relevance Vector Machine</title><author>Michael E. Tipping</author><abstract>
  This paper introduces a general Bayesian framework for obtaining
  sparse solutions to regression and classification tasks
  utilising models linear in the parameters. Although this framework
  is fully general, we illustrate our approach with a particular
  specialisation that we denote the 'relevance vector machine' (RVM),
  a model of identical functional form to the popular and
  state-of-the-art 'support vector machine' (SVM). We demonstrate that
  by exploiting a probabilistic Bayesian learning framework, we can
  derive accurate prediction models which typically utilise
  dramatically fewer basis functions than a comparable SVM while
  offering a number of additional advantages. These include the
  benefits of probabilistic predictions, automatic estimation of
  'nuisance' parameters, and the facility to utilise arbitrary basis
  functions (e.g. non-'Mercer' kernels).
  &lt;p&gt;
  We detail the Bayesian framework and associated learning algorithm
  for the RVM, and give some illustrative examples of its application
  along with some comparative benchmarks. We offer some explanation
  for the exceptional degree of sparsity obtained, and discuss and
  demonstrate some of the advantageous features, and potential
  extensions, of Bayesian relevance learning.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/tipping01a/tipping01a.pdf</url></Article><Article><id>9</id><title>Bayes Point Machines</title><author>Ralf Herbrich, Thore Graepel, Colin Campbell</author><abstract>
Kernel-classifiers comprise a powerful class of non-linear decision
functions for binary classification. The support vector machine is an
example of a learning algorithm for kernel classifiers that singles
out the consistent classifier with the largest margin, i.e. minimal
real-valued output on the training sample, within the set of
consistent hypotheses, the so-called &lt;i&gt;version space&lt;/i&gt;. We suggest
the &lt;i&gt;Bayes point machine&lt;/i&gt; as a well-founded improvement which
approximates the Bayes-optimal decision by the centre of mass of
version space. We present two algorithms to stochastically approximate
the centre of mass of version space: a billiard sampling algorithm and
a sampling algorithm based on the well known perceptron algorithm. It
is shown how both algorithms can be extended to allow for
soft-boundaries in order to admit training errors.  Experimentally, we
find that - for the zero training error case - Bayes point
machines consistently outperform support vector machines on both
surrogate data and real-world benchmark data sets. In the
soft-boundary/soft-margin case, the improvement over support vector
machines is shown to be reduced. Finally, we demonstrate that the
real-valued output of single Bayes points on novel test points is a
valid &lt;i&gt;confidence&lt;/i&gt; measure and leads to a steady decrease in
generalisation error when used as a rejection criterion.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf</url></Article><Article><id>10</id><title>Tracking the Best Linear Predictor</title><author>Mark Herbster, Manfred K. Warmuth</author><abstract>
In most on-line learning research the total on-line loss of the&#13;
algorithm is compared to the total loss of the best off-line predictor&#13;
&lt;i&gt;u&lt;/i&gt; from a comparison class of predictors.  We call such bounds &#13;
&lt;i&gt;static bounds&lt;/i&gt;.  The interesting feature of these bounds is that they&#13;
hold for an arbitrary sequence of examples.  Recently some work has&#13;
been done where the predictor &lt;i&gt;u&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt; at each trial &lt;i&gt;t&lt;/i&gt; is allowed to&#13;
change with time, and the total on-line loss of the algorithm is&#13;
compared to the sum of the losses of &lt;i&gt;u&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt; at each trial plus the&#13;
total "cost" for shifting to successive predictors.  This is to&#13;
model situations in which the examples change over time, and different&#13;
predictors from the comparison class are best for different segments&#13;
of the sequence of examples.  We call such bounds &lt;i&gt;shifting&#13;
bounds&lt;/i&gt;.  They hold for arbitrary sequences of examples and arbitrary&#13;
sequences of predictors.&#13;
&lt;p&gt;&#13;
Naturally shifting bounds are much harder to prove.  The only known&#13;
bounds are for the case when the comparison class consists of a&#13;
sequences of experts or boolean disjunctions. In this paper we develop&#13;
the methodology for lifting known static bounds to the shifting case.&#13;
In particular we obtain bounds when the comparison class consists of&#13;
linear neurons (linear combinations of experts).  Our essential&#13;
technique is to &lt;i&gt;project&lt;/i&gt; the hypothesis of the static algorithm&#13;
at the end of each trial into a suitably chosen convex region.  This&#13;
keeps the hypothesis of the algorithm well-behaved and the static&#13;
bounds can be converted to shifting bounds.&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/herbster01a/herbster01a.pdf</url></Article><Article><id>11</id><title>Prior Knowledge and Preferential Structures in Gradient Descent Learning Algorithms</title><author>Robert E. Mahony, Robert C. Williamson</author><abstract>
A family of gradient descent algorithms for learning linear
functions in an online setting is considered.  The family
includes the classical LMS algorithm as well as new variants such
as the Exponentiated Gradient (EG) algorithm due to Kivinen and
Warmuth.  The algorithms are based on prior distributions defined
on the weight space.  Techniques from differential geometry are
used to develop the algorithms as gradient descent iterations
with respect to the natural gradient in the Riemannian structure
induced by the prior distribution.  The proposed framework
subsumes the notion of "link-functions".
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume1/mahony01a/mahony01a.pdf</url></Article><Article><id>12</id><title>On the Size of Convex Hulls of Small Sets</title><author>Shahar Mendelson</author><abstract>
We investigate two different notions of "size" which appear&#13;
naturally in Statistical Learning Theory. We present quantitative&#13;
estimates on the &lt;i&gt;fat-shattering dimension&lt;/i&gt; and on the&#13;
covering numbers of convex hulls of sets of functions, given the&#13;
necessary data on the original sets. The proofs we present are&#13;
relatively simple since they do not require extensive background&#13;
in convex geometry.&#13;
&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/mendelson01a/mendelson01a.pdf</url></Article><Article><id>13</id><title>Graph-Based Hierarchical Conceptual Clustering</title><author>Istvan Jonyer, Diane J. Cook, Lawrence B. Holder</author><abstract>
Hierarchical conceptual clustering has proven to be a useful, although under-explored, data mining &#13;
technique.  A graph-based representation of structural information combined with a substructure &#13;
discovery technique has been shown to be successful in knowledge discovery.  The SUBDUE &#13;
substructure discovery system provides one such combination of approaches. This work presents &#13;
SUBDUE and the development of its clustering functionalities.  Several examples are used to &#13;
illustrate the validity of the approach both in structured and unstructured domains, as well as to &#13;
compare SUBDUE to the Cobweb clustering algorithm. We also develop a new metric for &#13;
comparing structurally-defined clusterings. Results show that SUBDUE successfully discovers &#13;
hierarchical clusterings in both structured and unstructured data.&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/jonyer01a/jonyer01a.pdf</url></Article><Article><id>14</id><title>Support Vector Machine Active Learning with Applications to Text Classification</title><author>Simon Tong, Daphne Koller</author><abstract>
Support vector machines have met with significant success in numerous
real-world learning tasks.  However, like most machine learning
algorithms, they are generally applied using a randomly selected
training set classified in advance.  In many settings, we also have
the option of using &lt;em&gt;pool-based active learning&lt;/em&gt;. Instead of using
a randomly selected training set, the learner has access to a pool of
unlabeled instances and can request the labels for some number of
them. We introduce a new algorithm for performing active learning
with support vector machines, i.e., an algorithm for choosing which
instances to request next. We provide a theoretical motivation for the
algorithm using the notion of a &lt;em&gt;version space&lt;/em&gt;.  We present
experimental results showing that employing our active learning method
can significantly reduce the need for labeled training instances in
both the standard inductive and transductive settings.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/tong01a/tong01a.pdf</url></Article><Article><id>15</id><title>On the Influence of the Kernel on the Consistency of Support Vector Machines</title><author>Ingo Steinwart</author><abstract>
In this article we study the generalization abilities&#13;
of several classifiers of support vector machine (SVM) type using a certain class&#13;
of kernels that we call universal. It is shown that the soft margin algorithms with universal kernels&#13;
are consistent for&#13;
a large class of classification problems including some kind of noisy tasks provided that the &#13;
regularization parameter is chosen well. In particular we derive a simple&#13;
sufficient condition for this parameter in the case of Gaussian RBF kernels.&#13;
On the one hand our considerations are based on an investigation of an &#13;
approximation property---the so-called universality---of the used kernels &#13;
that ensures that all continuous functions can be approximated by certain kernel expressions.&#13;
This approximation property&#13;
also gives a new insight into the role of kernels in these and other&#13;
algorithms. On the other hand the results are achieved by a precise study of the&#13;
underlying optimization problems of the classifiers.&#13;
Furthermore, we show consistency for the maximal margin classifier as well as for the soft margin SVM's&#13;
in the presence of large margins. In this case it turns out that also constant regularization parameters&#13;
ensure consistency for the soft margin SVM's. Finally we prove that even for simple, noise free &#13;
classification problems SVM's with polynomial kernels can behave arbitrarily badly.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/steinwart01a/steinwart01a.pdf</url></Article><Article><id>16</id><title>Kernel Partial Least Squares Regression in Reproducing Kernel Hilbert Space</title><author>Roman Rosipal, Leonard J. Trejo</author><abstract>
A family of regularized least squares regression models in a Reproducing Kernel Hilbert Space is extended by the kernel partial least squares (PLS) regression model. Similar to principal components regression (PCR), PLS is a method based on the projection of input (explanatory) variables to the latent variables (components). However, in contrast to PCR, PLS creates the components by modeling the relationship between input and output variables while maintaining most of the information in the input variables. PLS is useful in situations where the number of explanatory variables exceeds the number of observations and/or a high level of multicollinearity among those variables is assumed. Motivated by this fact we will provide a kernel PLS algorithm for construction of nonlinear regression models in possibly high-dimensional feature spaces.

We give the theoretical description of the kernel PLS algorithm and we experimentally compare the algorithm with the existing kernel PCR and kernel ridge regression techniques. We will demonstrate that on the data sets employed kernel PLS achieves the same results as kernel PCR but uses significantly fewer, qualitatively different components.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/rosipal01a/rosipal01a.pdf</url></Article><Article><id>17</id><title>Support Vector Clustering</title><author>Asa Ben-Hur, David Horn, Hava T. Siegelmann, Vladimir Vapnik</author><abstract>
We present a novel clustering method
using the approach of support vector machines.
Data points are mapped by means of a Gaussian kernel
to a high dimensional feature space, where we search for the minimal
enclosing sphere.
This sphere, when mapped back to data space, can separate
into several components, each enclosing a separate cluster of points.
We present a simple algorithm for identifying these clusters.
The width of the Gaussian kernel controls the scale at which the data
is probed while the soft margin constant helps coping with outliers and overlapping clusters.
The structure of a dataset is explored by varying the two
parameters, maintaining a minimal number of support vectors
to assure smooth cluster boundaries.
We demonstrate the performance of our algorithm on several datasets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/horn01a/horn01a.pdf</url></Article><Article><id>18</id><title>Support Vector Clustering</title><author>Asa Ben-Hur, David Horn, Hava T. Siegelmann, Vladimir Vapnik</author><abstract>
We present a novel clustering method
using the approach of support vector machines.
Data points are mapped by means of a Gaussian kernel
to a high dimensional feature space, where we search for the minimal
enclosing sphere.
This sphere, when mapped back to data space, can separate
into several components, each enclosing a separate cluster of points.
We present a simple algorithm for identifying these clusters.
The width of the Gaussian kernel controls the scale at which the data
is probed while the soft margin constant helps coping with outliers and overlapping clusters.
The structure of a dataset is explored by varying the two
parameters, maintaining a minimal number of support vectors
to assure smooth cluster boundaries.
We demonstrate the performance of our algorithm on several datasets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/horn01a/rev1/horn01ar1.pdf</url></Article><Article><id>19</id><title>One-Class SVMs for Document Classification</title><author>Larry M. Manevitz, Malik Yousef</author><abstract>
We implemented versions of the SVM appropriate for &lt;i&gt;one-class&lt;/i&gt; classification
in the context of information retrieval.    The experiments were conducted on
the standard &lt;i&gt;Reuters&lt;/i&gt; data set.  

For the SVM implementation we used both a version of Schoelkopf et al.
and a somewhat different version of one-class
SVM based on identifying "outlier" data as representative of the second-class.
We report on experiments with different kernels for both of these 
implementations and with different representations of the data, including
binary vectors, tf-idf representation and a modification called "Hadamard"
representation.
Then we compared it with one-class versions of the algorithms
prototype (Rocchio), nearest neighbor, naive Bayes,
and finally a natural one-class neural network classification 
method based on "bottleneck" compression generated filters.

The SVM approach as represented by Schoelkopf was superior to all 
the methods except the neural network one, where it was, although
occasionally worse, essentially comparable.    However, the SVM methods
turned out to be quite sensitive to the choice of representation and
kernel in ways which are not well understood; therefore, for the time being
leaving the neural network approach as the most robust.





&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/manevitz01a/manevitz01a.pdf</url></Article><Article><id>20</id><title>Uniform Object Generation for Optimizing One-class Classifiers</title><author>David M.J. Tax, Robert P.W. Duin</author><abstract>
In one-class classification, one class of data, called the target
class, has to be distinguished from the rest of the feature space.  It
is assumed that only examples of the target class are available.  This
classifier has to be constructed such that objects not originating from the
target set, by definition outlier objects, are not classified as target
objects.  In previous research the support vector data description (SVDD) is
proposed to solve the problem of one-class classification. It models a
hypersphere around the target set, and by the introduction of kernel
functions, more flexible descriptions are obtained.  In the original
optimization of the SVDD, two parameters have to be given beforehand by the
user. To automatically optimize the values for these parameters, the error on
both the target and outlier data has to be estimated. Because no outlier
examples are available, we propose a method for generating artificial
outliers, uniformly distributed in a hypersphere. An (relative) efficient
estimate for the volume covered by the one-class classifiers is obtained, and
so an estimate for the outlier error.  Results are shown for artificial data
and for real world data.


&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/tax01a/tax01a.pdf</url></Article><Article><id>21</id><title>A Generalized Kernel Approach to Dissimilarity-based Classification</title><author>Elzbieta Pekalska, Pavel Paclik, Robert P.W. Duin</author><abstract>
Usually, objects to be classified are represented by features. 
In this paper, we discuss an alternative object representation based on
dissimilarity values. If such distances separate the classes well,
the nearest neighbor method offers a good solution. However, dissimilarities 
used in practice are usually far from ideal and the performance of the 
nearest neighbor rule suffers from its sensitivity to noisy examples. 
We show that other, more global classification techniques are preferable 
to the nearest neighbor rule, in such cases.

For classification purposes, two different ways of using generalized 
dissimilarity kernels are considered. In the first one, distances 
are isometrically embedded in a pseudo-Euclidean space and the classification 
task is performed there. In the second approach, classifiers are built 
directly on distance kernels. Both approaches are described theoretically 
and then compared using experiments with different dissimilarity measures 
and datasets including degraded data simulating the problem of missing values.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/pekalska01a/pekalska01a.pdf</url></Article><Article><id>22</id><title>A Generalized Kernel Approach to Dissimilarity-based Classification</title><author>Elzbieta Pekalska, Pavel Paclik, Robert P.W. Duin</author><abstract>
&lt;p&gt;
Usually, objects to be classified are represented by features. 
In this paper, we discuss an alternative object representation based on
dissimilarity values. If such distances separate the classes well,
the nearest neighbor method offers a good solution. However, dissimilarities 
used in practice are usually far from ideal and the performance of the 
nearest neighbor rule suffers from its sensitivity to noisy examples. 
We show that other, more global classification techniques are preferable 
to the nearest neighbor rule, in such cases.
&lt;/p&gt;
&lt;p&gt;
For classification purposes, two different ways of using generalized 
dissimilarity kernels are considered. In the first one, distances 
are isometrically embedded in a pseudo-Euclidean space and the classification 
task is performed there. In the second approach, classifiers are built 
directly on distance kernels. Both approaches are described theoretically 
and then compared using experiments with different dissimilarity measures 
and datasets including degraded data simulating the problem of missing values.
&lt;/p&gt;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/pekalska01a/rev1/pekalska01ar1.pdf</url></Article><Article><id>23</id><title>A New Approximate Maximal Margin Classification Algorithm</title><author>Claudio Gentile</author><abstract>
A new incremental learning algorithm is described which 
approximates the maximal margin hyperplane w.r.t. norm &lt;i&gt;p &amp;ge; 2&lt;/i&gt; for 
a set of linearly separable data.
Our algorithm, called ALMA_&lt;i&gt;p&lt;/i&gt; (Approximate Large Margin algorithm w.r.t. norm &lt;i&gt;p&lt;/i&gt;),
takes &lt;i&gt;O( (p-1) / (&amp;alpha;&lt;sup&gt;2&lt;/sup&gt; &amp;gamma;&lt;sup&gt;2&lt;/sup&gt; ) )&lt;/i&gt;
corrections to separate the data with &lt;i&gt;p&lt;/i&gt;-norm margin larger than &lt;i&gt;(1-&amp;alpha;)&amp;gamma;&lt;/i&gt;,
where &lt;i&gt;g&lt;/i&gt; is the (normalized) &lt;i&gt;p&lt;/i&gt;-norm margin of the data.
ALMA_&lt;i&gt;p&lt;/i&gt; avoids quadratic (or higher-order) programming methods. It is
very easy to implement and is as fast as on-line algorithms, such as
Rosenblatt's Perceptron algorithm.
We performed extensive experiments on both real-world and artificial datasets.
We compared ALMA_2 (i.e., ALMA_&lt;i&gt;p&lt;/i&gt; with &lt;i&gt;p = 2&lt;/i&gt;) to standard 
Support vector Machines (SVM) and to 
two incremental algorithms: the Perceptron algorithm and Li and Long's ROMMA.
The accuracy levels achieved by ALMA_2 are superior to those
achieved by the Perceptron algorithm and ROMMA, but slightly inferior to 
SVM's. On the other hand, ALMA_2 is quite faster and easier 
to implement than standard SVM training algorithms.
When learning sparse target vectors, ALMA_&lt;i&gt;p&lt;/i&gt; with &lt;i&gt;p &gt; 2&lt;/i&gt; largely 
outperforms Perceptron-like algorithms, such as ALMA_2.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/gentile01a/gentile01a.pdf</url></Article><Article><id>24</id><title>Efficient SVM Training Using Low-Rank Kernel Representations</title><author>Shai Fine, Katya Scheinberg</author><abstract>
SVM training is a convex optimization problem
which scales with the training set size rather than the feature space 
dimension. 
While this is usually considered to be a desired quality, 
in large scale problems it may cause training to be impractical.
The common techniques to handle this difficulty basically build a solution
by solving a sequence of small scale subproblems. 
Our current effort is concentrated on the rank  of the kernel matrix as a
source for further enhancement of the training procedure. We first show that
 for a low rank kernel matrix it is possible to design a better
interior point  method (IPM) in terms of storage requirements
as well as computational complexity. We then  suggest an efficient
use of a known factorization technique to approximate a given kernel matrix
by a low rank matrix, which in turn will be used to feed the optimizer.
Finally, we derive an upper bound on the change in the 
objective function
value based on the approximation error and the number of active constraints
(support vectors). This bound is general in the sense that it holds 
regardless of the approximation method.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/fine01a/fine01a.pdf</url></Article><Article><id>25</id><title>On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines</title><author>Koby Crammer, Yoram Singer</author><abstract>
In this paper we describe the algorithmic implementation of multiclass kernel-based vector machines.  Our starting point is a generalized notion of the margin to multiclass problems.  Using this notion we cast multiclass categorization problems as a constrained optimization problem with a quadratic objective function.  Unlike most of previous approaches which typically decompose a multiclass problem into multiple independent binary classification tasks, our notion of margin yields a direct method for training multiclass predictors.  By using the dual of the optimization problem we are able to incorporate kernels with a compact set of constraints and decompose the dual problem into multiple optimization problems of reduced size.  We describe an efficient fixed-point algorithm for solving the reduced optimization problems and prove its convergence.  We then discuss technical details that yield significant running time improvements for large datasets.  Finally, we describe various experiments with our approach comparing it to previously studied kernel-based methods.  Our experiments indicate that for multiclass problems we attain state-of-the-art accuracy.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/crammer01a/crammer01a.pdf</url></Article><Article><id>26</id><title>Exact Simplification of Support Vector Solutions</title><author>Tom Downs, Kevin E. Gates, Annette Masters</author><abstract>
This paper demonstrates that standard algorithms for training support vector machines generally produce solutions with a greater number of support vectors than are strictly necessary. An algorithm is presented that allows unnecessary support vectors to be recognized and eliminated while leaving the solution otherwise unchanged. The algorithm is applied to a variety of benchmark data sets (for both classification and regression) and in most cases the procedure leads to a reduction in the number of support vectors. In some cases the reduction is substantial.&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/downs01a/downs01a.pdf</url></Article><Article><id>27</id><title>Classes of Kernels for Machine Learning: A Statistics Perspective</title><author>Marc G. Genton</author><abstract>
In this paper, we present classes of kernels for machine learning from a statistics perspective. Indeed, kernels are positive definite functions and thus also covariances. After discussing key properties of kernels, as well as a new formula to construct kernels, we present several important classes of kernels: anisotropic stationary kernels, isotropic stationary kernels, compactly supported kernels, locally stationary kernels, nonstationary kernels, and separable nonstationary kernels. Compactly supported kernels and separable nonstationary kernels are of prime interest because they provide a computational reduction for kernel-based methods. We describe the spectral representation of the various classes of kernels and conclude with a discussion on the characterization of nonlinear maps that reduce nonstationary kernels to either stationarity or local stationarity.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/genton01a/genton01a.pdf</url></Article><Article><id>28</id><title>Recommender Systems Using Linear Classifiers</title><author>Tong Zhang, Vijay S. Iyengar</author><abstract>
Recommender systems
use historical data on user preferences and other available
data on users (for example, demographics) and items (for example, taxonomy)
to predict items a new user might like.  Applications of these methods include
recommending items for purchase and personalizing the
browsing experience on a web-site.
Collaborative filtering methods have focused on using just the
history of user preferences to make the recommendations.
These methods have been categorized as &lt;i&gt;memory-based&lt;/i&gt; if they operate
over the entire data to make predictions and as &lt;i&gt;model-based&lt;/i&gt; if
they use the data to build a model which is then used for predictions.
In this paper, we propose the use of linear classifiers in a
model-based recommender system.
We compare our method with another model-based method using
decision trees and with
memory-based methods using data from various domains.
Our experimental results indicate that these linear models
are well suited for this application.
They outperform a commonly proposed
memory-based method in accuracy and also
have a better tradeoff between off-line and on-line computational requirements.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/zhang02a/zhang02a.pdf</url></Article><Article><id>29</id><title>Machine Learning with Data Dependent Hypothesis Classes</title><author>Adam Cannon, J. Mark Ettinger, Don Hush, Clint Scovel</author><abstract>
We extend the VC theory of statistical learning to
data dependent spaces of classifiers.
This theory can be viewed as a decomposition
of classifier design into two components;
the first component is a restriction to a data dependent
hypothesis class
and the second is empirical risk minimization
within that class.
We define a measure of complexity for
data dependent hypothesis classes and
provide data dependent versions of
bounds on error deviance and estimation error.
We also provide
a structural risk minimization procedure
over data dependent hierarchies and prove consistency.
We use this theory to provide a framework for
studying the trade-offs between performance and
computational complexity in classifier design.
As a consequence we obtain
a new family of classifiers with dimension independent
performance bounds and efficient learning procedures.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/cannon02a/cannon02a.pdf</url></Article><Article><id>30</id><title>On Using Extended Statistical Queries to Avoid Membership Queries</title><author>Nader H. Bshouty, Vitaly Feldman</author><abstract>
The Kushilevitz-Mansour (KM) algorithm is an algorithm that finds all the
"large" Fourier coefficients of a Boolean function. It is the main tool for
learning decision trees and DNF expressions in the PAC model with respect to
the uniform distribution. The algorithm requires access to the membership
query (MQ) oracle. The access is often unavailable in learning applications
and thus the KM algorithm cannot be used. We significantly weaken this
requirement by producing an analogue of the KM algorithm that uses extended
statistical queries (SQ) (SQs in which the expectation is taken with respect
to a distribution given by a learning algorithm). We restrict a set of
distributions that a learning algorithm may use for its statistical queries
to be a set of product distributions with each bit being 1 with probability
&lt;i&gt;rho&lt;/i&gt;, 1/2 or 1-&lt;i&gt;rho&lt;/i&gt; for a constant 1/2 &gt; &lt;i&gt;rho&lt;/i&gt; &gt; 0 (we denote the resulting
model by SQ-&lt;i&gt;D&lt;/i&gt;&lt;sub&gt;&lt;i&gt;rho&lt;/i&gt;&lt;/sub&gt;). Our analogue finds all the "large" Fourier coefficients
of degree lower than &lt;i&gt;c&lt;/i&gt;log(&lt;i&gt;n&lt;/i&gt;) (we call it the &lt;i&gt;Bounded Sieve&lt;/i&gt; (BS)). We use BS
to learn decision trees and by adapting Freund's boosting technique we give
an algorithm that learns DNF in SQ-&lt;i&gt;D&lt;/i&gt;&lt;sub&gt;&lt;i&gt;rho&lt;/i&gt;&lt;/sub&gt;. An important property of the model
is that its algorithms can be simulated by MQs with persistent noise. With
some modifications BS can also be simulated by MQs with product attribute
noise (i.e., for a query &lt;i&gt;x&lt;/i&gt; oracle changes every bit of &lt;i&gt;x&lt;/i&gt; with some constant
probability and calculates the value of the target function at the resulting
point) and classification noise. This implies learnability of decision trees
and weak learnability of DNF with this non-trivial noise. In the second part
of this paper we develop a characterization for learnability with these
extended statistical queries. We show that our characterization when applied
to SQ-&lt;i&gt;D&lt;/i&gt;&lt;sub&gt;&lt;i&gt;rho&lt;/i&gt;&lt;/sub&gt; is tight in terms of learning parity functions. We extend the
result given by Blum et al. by proving that there is a class learnable in
the PAC model with random classification noise and not learnable in
SQ-&lt;i&gt;D&lt;/i&gt;&lt;sub&gt;&lt;i&gt;rho&lt;/i&gt;&lt;/sub&gt;.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/bshouty02a/bshouty02a.pdf</url></Article><Article><id>31</id><title>The Learning-Curve Sampling Method Applied to Model-Based Clustering</title><author>Christopher Meek, Bo Thiesson, David Heckerman</author><abstract>
We examine the learning-curve sampling method, an approach for
applying machine-learning algorithms to large data sets. The
approach is based on the observation that the computational cost
of learning a model increases as a function of the sample size of
the training data, whereas the accuracy of a model has
diminishing improvements as a function of sample size. Thus, the
learning-curve sampling method monitors the increasing costs and
performance as larger and larger amounts of data are used for
training, and terminates learning when future costs outweigh
future benefits.  In this paper, we formalize the learning-curve
sampling method and its associated cost-benefit tradeoff in terms
of decision theory.  In addition, we describe the application of
the learning-curve sampling method to the task of model-based
clustering via the expectation-maximization (EM) algorithm. In
experiments on three real data sets, we show that the
learning-curve sampling method produces models that are nearly as
accurate as those trained on complete data sets, but with
dramatically reduced learning times.  Finally, we describe an
extension of the basic learning-curve approach for model-based
clustering that results in an additional speedup. This extension is
based on the observation that the shape of the learning curve for
a given model and data set is roughly independent of the number
of EM iterations used during training. Thus, we run EM for only a
few iterations to decide how many cases to use for training, and
then run EM to full convergence once the number of cases is
selected.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/meek02a/meek02a.pdf</url></Article><Article><id>32</id><title>Text Classification using String Kernels</title><author>Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, Chris Watkins</author><abstract>
We propose a novel approach for categorizing text documents based on
the use of a special kernel. The kernel is
an inner product in the feature space generated by all subsequences of
length &lt;em&gt;k&lt;/em&gt;. A subsequence is any ordered sequence of &lt;em&gt;k&lt;/em&gt; characters
occurring in the text though not necessarily contiguously. The subsequences
are weighted by an exponentially decaying factor of their full length in the
text, hence emphasising those occurrences that are close to contiguous. A
direct computation of this feature vector would involve a prohibitive amount
of computation even for modest values of &lt;em&gt;k&lt;/em&gt;, since the dimension of the
feature space grows exponentially with &lt;em&gt;k&lt;/em&gt;. The paper describes how despite
this fact the inner product can be efficiently evaluated by a dynamic
programming technique. 

Experimental comparisons of the
performance of the kernel compared with a standard word feature space
kernel (Joachims, 1998) show positive results on modestly sized datasets.
The case of contiguous subsequences is also considered for comparison
with the subsequences kernel with different decay factors.
For larger documents and datasets the paper introduces an approximation 
technique that is shown to deliver good approximations efficiently for large
datasets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/lodhi02a/lodhi02a.pdf</url></Article><Article><id>33</id><title>Learning Equivalence Classes of Bayesian-Network Structures</title><author>David Maxwell Chickering</author><abstract>
Two Bayesian-network structures are said to be &lt;em&gt;
equivalent&lt;/em&gt; if the set of distributions that can be represented with
one of those structures is identical to the set of distributions that
can be represented with the other. Many scoring criteria that are used
to learn Bayesian-network structures from data are &lt;em&gt; score
equivalent&lt;/em&gt;; that is, these criteria do not distinguish among networks
that are equivalent. In this paper, we consider using a score
equivalent criterion in conjunction with a heuristic search algorithm
to perform model selection or model averaging. We argue that it is
often appropriate to search among equivalence classes of network
structures as opposed to the more common approach of searching among
individual Bayesian-network structures. We describe a convenient
graphical representation for an equivalence class of structures, and
introduce a set of operators that can be applied to that
representation by a search algorithm to move among equivalence
classes. We show that our equivalence-class operators can be scored
locally, and thus share the computational efficiency of traditional
operators defined for individual structures. We show experimentally
that a greedy model-selection algorithm using our representation
yields slightly higher-scoring structures than the traditional
approach without any additional time overhead, and we argue that more
sophisticated search algorithms are likely to benefit much more.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/chickering02a/chickering02a.pdf</url></Article><Article><id>34</id><title>Stability and Generalization</title><author>Olivier Bousquet, Andr&amp;eacute; Elisseeff</author><abstract>
We define notions of stability for learning algorithms and show how to use these notions to derive generalization error bounds based on the empirical error and the leave-one-out error. The methods we use can be applied in the regression framework as well as in the classification one when the classifier is obtained by thresholding a real-valued function. We study the stability properties of large classes of learning algorithms such as regularization based algorithms. In particular we focus on Hilbert space regularization and Kullback-Leibler regularization. We demonstrate how to apply the results to SVM for regression and classification.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/bousquet02a/bousquet02a.pdf</url></Article><Article><id>35</id><title>Covering Number Bounds of Certain Regularized Linear Function Classes</title><author>Tong Zhang</author><abstract>
  Recently, sample complexity bounds have been derived for problems involving 
  linear functions such as neural networks and support vector machines.
  In many of  these theoretical studies, the concept of covering numbers 
  played an important role. It is thus useful to study covering numbers
  for linear function classes.
  In this paper, we investigate two closely related methods to derive upper 
  bounds on these  covering numbers. 
  The first method, already employed
  in some earlier studies, relies on the so-called Maurey's lemma; 
  the second method uses
  techniques from the  mistake bound framework in online learning.
  We compare results from these two methods, as well as their consequences in
  some learning formulations.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/zhang02b/zhang02b.pdf</url></Article><Article><id>36</id><title>Introduction to Special Issue on Machine Learning Approaches to Shallow Parsing</title><author>James Hammerton, Miles Osborne, Susan Armstrong, Walter Daelemans</author><abstract>
This article introduces the problem of partial or shallow parsing
(assigning partial syntactic structure to sentences) and explains why
it is an important natural language processing (NLP) task. The
complexity of the task makes Machine Learning an attractive option in
comparison to the handcrafting of rules. On the other hand, because of the
same task complexity, shallow parsing makes an excellent benchmark
problem for evaluating machine learning algorithms. We sketch the
origins of shallow parsing as a specific task for machine learning of
language, and introduce the articles accepted for this special issue,
a representative sample of current research in this area. Finally,
future directions for machine learning of shallow parsing are
suggested. 
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/hammerton02a/hammerton02a.pdf</url></Article><Article><id>37</id><title>Memory-Based Shallow Parsing</title><author>Erik F. Tjong Kim Sang</author><abstract>
We present memory-based learning approaches to shallow parsing 
and apply these to five tasks: base noun phrase identification, 
arbitrary base phrase recognition, clause detection, noun phrase 
parsing and full parsing. We use feature selection techniques and 
system combination methods for improving the performance of the 
memory-based learner.  Our approach is evaluated on standard data 
sets and the results are compared with that of other systems. 
This reveals that our approach works well for base phrase 
identification while its application towards recognizing embedded 
structures leaves some room for improvement.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/tks02a/tks02a.pdf</url></Article><Article><id>38</id><title>Shallow Parsing using Specialized HMMs</title><author>Antonio Molina, Ferran Pla</author><abstract>
We present a unified technique to solve different shallow parsing tasks as a
tagging problem using a Hidden Markov Model-based approach (HMM). This technique consists of the
incorporation of the relevant information for each task into the models. To do
this, the training corpus is transformed to take into account this
information. In this way, no change is necessary for either the training or
tagging process, so it allows for the use of a standard HMM approach. Taking
into account this information, we
construct a Specialized HMM which gives more complete contextual models. 
We have tested our system on chunking and clause identification tasks using
different specialization criteria. The results obtained are in line with the
results reported for most of the relevant state-of-the-art
approaches. 
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/molina02a/molina02a.pdf</url></Article><Article><id>39</id><title>Text Chunking based on a Generalization of Winnow</title><author>Tong Zhang, Fred Damerau, David Johnson</author><abstract>
  This paper describes a text chunking system based on 
  a generalization of the Winnow algorithm. We propose
  a general statistical model for text chunking which we then convert
  into a classification problem. We argue that the Winnow family of
  algorithms is particularly suitable for solving classification
  problems arising from NLP applications, due to their robustness to
  irrelevant features.
  However in theory, Winnow may not converge for linearly non-separable data. 
  To remedy this problem, we employ a generalization of the original Winnow
  method. 
  An additional advantage of the new algorithm is that it provides reliable 
  confidence estimates for its classification predictions. This property
  is required in our statistical modeling approach.
  We show that our system achieves state of the art performance in 
  text chunking with less computational cost then previous systems.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/zhang02c/zhang02c.pdf</url></Article><Article><id>40</id><title>Shallow Parsing with PoS Taggers and Linguistic Features</title><author>Be&amp;aacute;ta Megyesi</author><abstract>
Three data-driven publicly available part-of-speech taggers are applied to shallow parsing of Swedish texts. The phrase structure is represented by nine types of phrases in a hierarchical structure containing labels for every constituent type the token belongs to in the parse tree. The encoding is based on the concatenation of the phrase tags on the path from lowest to higher nodes. Various linguistic features are used in learning; the taggers are trained on the basis of lexical information only, part-of-speech only, and a combination of both, to predict the phrase structure of the tokens with or without part-of-speech. Special attention is directed to the taggers' sensitivity to different types of linguistic information included in learning, as well as the taggers' sensitivity to the size and the various types of training data sets. The method can be easily transferred to other languages. 
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/megyesi02a/megyesi02a.pdf</url></Article><Article><id>41</id><title>Learning Rules and Their Exceptions</title><author>Herv&amp;eacute; D&amp;eacute;jean</author><abstract>
We present in this article a top-down inductive system, ALLiS, for learning linguistic structures.
Two difficulties came up during the development of the system: the presence of a significant amount of noise in the data and the presence of exceptions linguistically motivated.
It is then a challenge for an inductive system to learn rules from this kind of data.
This leads us to add a specific mechanism, &lt;b&gt;refinement&lt;/b&gt;, which enables learning rules and their exceptions.
In the first part of this article we evaluate the usefulness of this device and show that it  improves results when learning linguistic structures.

In the second part, we explore how to improve the efficiency of the system by using prior knowledge.
Since Natural Language is a strongly structured object, it may be important to investigate whether linguistic knowledge can help to make natural language learning more efficiently and accurately.
This article presents some experiments demonstrating that linguistic knowledge improves learning.
The system has been applied to the shared task of the CoNLL'00 workshop.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/dejean02a/dejean02a.pdf</url></Article><Article><id>42</id><title>Shallow Parsing using Noisy and Non-Stationary Training Material</title><author>Miles Osborne</author><abstract>
Shallow parsers are usually assumed to be trained on &lt;it&gt;noise-free&lt;/it&gt;
material, drawn from the same distribution as the testing
material. However, when either the training set is &lt;it&gt;noisy&lt;/it&gt; or else
drawn from a &lt;it&gt;different&lt;/it&gt; distributions,
performance may be degraded.  Using the parsed Wall Street Journal, we 
investigate the performance of four shallow parsers (maximum entropy,
memory-based learning, N-grams and ensemble learning)  trained using 
various types of artificially noisy material.  Our first set of results show that shallow parsers
are surprisingly robust to synthetic noise, with performance gradually
decreasing as the rate of noise increases.  Further
results show that no single shallow parser performs best in all noise
situations. Final results show that simple, parser-specific extensions
can improve noise-tolerance.
Our second set of results addresses the question of whether naturally
occurring disfluencies undermines performance more than does a change
in distribution.  Results using the parsed Switchboard corpus suggest 
that, although naturally
occurring disfluencies might harm performance, differences in
distribution between the training set and the testing set are more
significant. 
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/osborne02a/osborne02a.pdf</url></Article><Article><id>43</id><title>Round Robin Classification</title><author>Johannes F&amp;uuml;rnkranz</author><abstract>
  In this paper, we discuss round robin classification (aka pairwise
  classification), a technique for handling multi-class problems with
  binary classifiers by learning one classifier for each pair of
  classes. We present an empirical evaluation of the method,
  implemented as a wrapper around the Ripper rule learning
  algorithm, on 20 multi-class datasets from the UCI database
  repository.  Our results show that the technique is very likely to
  improve Ripper's classification accuracy without having a high risk
  of decreasing it.
  More importantly, we give a general theoretical analysis of the
  complexity of the approach and show that its run-time complexity is
  below that of the commonly used one-against-all technique. These
  theoretical results are not restricted to rule learning but are also
  of interest to other communities where pairwise classification has
  recently received some attention.
  Furthermore, we investigate its properties as a general ensemble
  technique and show that round robin classification with C5.0 may
  improve C5.0's performance on multi-class problems. However, this
  improvement does not reach the performance increase of boosting, and
  a combination of boosting and round robin classification does not
  produce any gain over conventional boosting.
  Finally, we show that the performance of round robin classification
  can be further improved by a straight-forward integration with
  bagging.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume2/fuernkranz02a/fuernkranz02a.pdf</url></Article><Article><id>44</id><title>Kernel Independent Component Analysis</title><author>Francis R. Bach, Michael I. Jordan</author><abstract>
We present a class of algorithms for independent component&#13;
analysis (ICA) which use contrast functions based on canonical&#13;
correlations in a reproducing kernel Hilbert space.  On the one&#13;
hand, we show that our contrast functions are related to mutual&#13;
information and have desirable mathematical properties as measures&#13;
of statistical dependence. On the other hand, building on recent&#13;
developments in kernel methods, we show that these criteria and&#13;
their derivatives can be computed efficiently. Minimizing these&#13;
criteria leads to flexible and robust algorithms for ICA. We&#13;
illustrate with simulations involving a wide variety of source&#13;
distributions, showing that our algorithms outperform many of the&#13;
presently known algorithms.&#13;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bach02a/bach02a.pdf</url></Article><Article><id>45</id><title>Learning Monotone DNF from a Teacher that Almost Does Not Answer Membership Queries</title><author>Nader H. Bshouty, Nadav Eiron</author><abstract>
We present results concerning the learning of Monotone DNF (MDNF) from
Incomplete Membership Queries and Equivalence Queries. Our main result
is a new algorithm that allows efficient learning of MDNF using
Equivalence Queries and Incomplete Membership Queries with probability
of &lt;i&gt;p&lt;/i&gt;=1-1/poly&lt;i&gt;&lt;/i&gt;(&lt;i&gt;n,t&lt;/i&gt;) of failing.  Our algorithm is expected to
make
&lt;p&gt;
&lt;center&gt;&lt;i&gt;O&lt;/i&gt;((&lt;i&gt;tn/&lt;/i&gt;(1-&lt;i&gt;p&lt;/i&gt;))&lt;sup&gt;2&lt;/sup&gt;)&lt;/center&gt;
&lt;p&gt;
queries, when learning a MDNF formula with &lt;i&gt;t&lt;/i&gt; terms over &lt;i&gt;n&lt;/i&gt;
variables. Note that this is polynomial for any failure probability
&lt;i&gt;p&lt;/i&gt;=1-1/poly(&lt;i&gt;n,t&lt;/i&gt;).  The algorithm's running time is also
polynomial in &lt;i&gt;t,n,&lt;/i&gt; and 1/(1-&lt;i&gt;p&lt;/i&gt;). In a sense this is the best
possible, as learning with &lt;i&gt;p&lt;/i&gt;=1-1/&lt;i&gt;w&lt;/i&gt;(poly(&lt;i&gt;n,t&lt;/i&gt;)) would
imply learning MDNF, and thus also DNF, from equivalence queries
alone.
&lt;p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bshouty02a/bshouty02a.pdf</url></Article><Article><id>46</id><title>On the Convergence of Optimistic Policy Iteration</title><author>John N. Tsitsiklis</author><abstract>
We consider  a finite-state Markov decision problem and
establish the convergence of a special case of
optimistic policy iteration that involves Monte Carlo estimation
of &lt;i&gt;Q&lt;/i&gt;-values, in conjunction with greedy  policy selection.
We provide convergence results for a number of algorithmic variations,
including one that
involves temporal difference learning (bootstrapping) instead of Monte Carlo
estimation. We also indicate some extensions that either fail or are unlikely
to go through.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/tsitsiklis02a/tsitsiklis02a.pdf</url></Article><Article><id>47</id><title>Data-dependent margin-based generalization bounds for classification</title><author>Andr&amp;aacute;s Antos, Bal&amp;aacute;zs K&amp;eacute;gl, Tam&amp;aacute;s Linder, G&amp;aacute;bor Lugosi</author><abstract>
We derive new margin-based inequalities for the probability of error
of classifiers. The main feature of these bounds is that they can be
calculated using the training data and therefore may be effectively
used for model selection purposes. In particular, the bounds involve
empirical complexities measured on the training data (such as the
empirical fat-shattering dimension) as opposed to their worst-case
counterparts traditionally used in such analyses. Also, our  bounds
appear to be sharper and more general than recent results involving
empirical complexity measures.  In addition, we develop an
alternative data-based bound for the generalization error of classes
of convex combinations of classifiers involving an empirical
complexity measure that is easier to compute than the empirical
covering number or fat-shattering dimension.  We also show examples of
efficient computation of the new bounds.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/antos02a/antos02a.pdf</url></Article><Article><id>48</id><title>Variational Learning of Clusters of Undercomplete Nonsymmetric Independent Components</title><author>Kwokleung Chan, Te-Won Lee, Terrence J. Sejnowski</author><abstract>
We apply a variational method to automatically determine the number of
mixtures of independent components in high-dimensional datasets, in which the
sources may be nonsymmetrically distributed.  The data are modeled by clusters
where each cluster is described as a linear mixture of independent factors.
The variational Bayesian method yields an accurate density model for the
observed data without overfitting problems.  This allows the dimensionality of
the data to be identified for each cluster.  The new method was successfully
applied to a difficult real-world medical dataset for diagnosing glaucoma.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/chan02a/chan02a.pdf</url></Article><Article><id>49</id><title>Learning Precise Timing with LSTM Recurrent Networks</title><author>Felix A. Gers, Nicol N. Schraudolph, J&amp;uuml;rgen Schmidhuber</author><abstract>
The temporal distance between events conveys information essential
for numerous sequential tasks such as motor control and rhythm detection.
While Hidden Markov Models tend to ignore this information, recurrent
neural networks (RNNs) can in principle learn to make use of it.
We focus on Long Short-Term Memory (LSTM) because it has been shown
to outperform other RNNs on tasks involving long time lags.
We find that LSTM augmented by "peephole connections"
from its internal cells to its multiplicative gates can learn the fine
distinction between sequences of spikes spaced either 50 or 49
time steps apart without the help of any short training exemplars.
Without external resets or teacher forcing,
our LSTM variant also learns to generate
stable streams of precisely timed spikes and other highly nonlinear
periodic patterns.  This makes LSTM a promising approach for
tasks that require the accurate measurement or generation of
time intervals.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf</url></Article><Article><id>50</id><title>&amp;epsilon;-MDPs: Learning in Varying Environments</title><author>Istv&amp;aacute;n Szita, B&amp;aacute;lint Tak&amp;aacute;cs, Andr&amp;aacute;s L&amp;ouml;rincz</author><abstract>
In this paper &amp;epsilon;-MDP-models are introduced and convergence
theorems are proven using the generalized MDP framework of
Szepesvari and Littman. Using this model family, we show that
Q-learning is capable of finding near-optimal policies in varying
environments. The potential of this new family of MDP models is
illustrated via a reinforcement learning algorithm called
&lt;i&gt;event-learning&lt;/i&gt; which separates the optimization of decision
making from the controller. We show that event-learning augmented
by a particular controller, which gives rise to an &amp;epsilon;-MDP, enables
near optimal performance even if considerable and sudden changes
may occur in the environment. Illustrations are provided on the
two-segment pendulum problem.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/szita02a/szita02a.pdf</url></Article><Article><id>51</id><title>Algorithmic Luckiness</title><author>Ralf Herbrich, Robert C. Williamson</author><abstract>
Classical statistical learning theory studies the generalisation
performance of machine learning algorithms rather indirectly. One
of the main detours is that algorithms are studied in terms of the
hypothesis class that they draw their hypotheses from. In this paper,
motivated by the luckiness framework of Shawe-Taylor et al. (1998), we
study learning algorithms more directly and in a way that allows us
to exploit the serendipity of the training sample. The main difference
to previous approaches lies in the complexity measure; rather than
covering all hypotheses in a given hypothesis space it is only necessary
to cover the functions which could have been learned using the fixed
learning algorithm. We show how the resulting framework relates to
the VC, luckiness and compression frameworks. Finally, we present
an application of this framework to the maximum margin algorithm for
linear classifiers which results in a bound that exploits the margin,
the sparsity of the resultant weight vector, and the degree of clustering
of the training data in feature space.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/herbrich02a/herbrich02a.pdf</url></Article><Article><id>52</id><title>R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning</title><author>Ronen I. Brafman, Moshe Tennenholtz</author><abstract>
R-MAX is a very simple model-based reinforcement learning
  algorithm which can attain near-optimal average reward in polynomial
  time. In R-MAX, the agent always maintains a complete, but possibly
  inaccurate model of its environment and acts based on the optimal
  policy derived from this model. The model is initialized in an
  optimistic fashion: all actions in all states return the maximal
  possible reward (hence the name). During execution, it is updated
  based on the agent's observations. R-MAX improves upon several
  previous algorithms: (1) It is simpler and more general than Kearns
  and Singh's E^3 algorithm, covering zero-sum stochastic
  games.  (2) It has a built-in mechanism for resolving 
  the exploration vs. exploitation dilemma. (3) It formally
  justifies the ``optimism under uncertainty'' bias used in many RL 
  algorithms.
  (4) It is simpler, more general, and more efficient than Brafman
  and Tennenholtz's LSG algorithm for learning in single controller
  stochastic games. (5) It generalizes the algorithm by Monderer and 
  Tennenholtz for learning in repeated games. 
  (6) It is the only algorithm for learning in repeated games, to date, which
  is provably efficient, considerably improving and simplifying previous
  algorithms by  Banos and by Megiddo.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/brafman02a/brafman02a.pdf</url></Article><Article><id>53</id><title>PAC-Bayesian Generalisation Error Bounds for Gaussian Process Classification</title><author>Matthias Seeger</author><abstract>
Approximate Bayesian Gaussian process (GP) classification techniques are
powerful non-parametric learning methods, similar in appearance and performance
to support vector machines. Based on simple probabilistic models, they render
interpretable results and can be embedded in Bayesian frameworks for model
selection, feature selection, etc. In this paper, by applying the PAC-Bayesian
theorem of McAllester (1999a), we prove distribution-free generalisation
error bounds for a wide range of approximate Bayesian GP classification
techniques. We also provide a new and much simplified proof for this powerful
theorem, making use of the concept of convex duality which is a backbone of
many machine learning techniques. We instantiate and test our bounds for two
particular GPC techniques, including a recent sparse method which circumvents
the unfavourable scaling of standard GP algorithms. As is shown in experiments
on a real-world task, the bounds can be very tight for moderate training
sample sizes. To the best of our knowledge, these results provide the tightest
known distribution-free error bounds for approximate Bayesian GPC methods,
giving a strong learning-theoretical justification for the use of these
techniques.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/seeger02a/seeger02a.pdf</url></Article><Article><id>54</id><title>On Online Learning of Decision Lists</title><author>Ziv Nevo, Ran El-Yaniv</author><abstract>
A fundamental open problem in computational learning theory is
whether there is an attribute efficient learning algorithm for the
concept class of decision lists (Rivest, 1987; Blum, 1996). We consider a
weaker problem, where the concept class is restricted to decision
lists with &lt;i&gt;D&lt;/i&gt; alternations.  For this class, we present a novel
online algorithm that achieves a mistake bound of
&lt;i&gt;O&lt;/i&gt;(&lt;i&gt;r&lt;/i&gt;&lt;sup&gt;&lt;i&gt;D&lt;/i&gt;&lt;/sup&gt;/log &lt;i&gt;n&lt;/i&gt;),
where &lt;i&gt;r&lt;/i&gt; is the number of relevant variables, and &lt;i&gt;n&lt;/i&gt; is the
total number of variables.  The algorithm can be viewed as a
strict generalization of the famous Winnow algorithm by
Littlestone (1988), and improves the &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;r&lt;/i&gt;^(2&lt;i&gt;D&lt;/i&gt;)/log &lt;i&gt;n&lt;/i&gt;) mistake
bound of Balanced Winnow.  Our bound is stronger than a similar
PAC-learning result of Dhagat and Hellerstein (1994).  A combination of our
algorithm with the algorithm suggested by Rivest (1987) might
achieve even better bounds.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/nevo02a/nevo02a.pdf</url></Article><Article><id>55</id><title>Minimal Kernel Classifiers</title><author>Glenn M. Fung, Olvi L. Mangasarian, Alexander J. Smola</author><abstract>
A finite concave minimization algorithm is proposed for constructing
kernel classifiers that use a minimal number of data points 
both in generating and characterizing a classifier.
The algorithm is theoretically justified on the basis 
of linear programming perturbation theory and a leave-one-out
error bound as well as effective computational results
on seven real world datasets.  A nonlinear rectangular kernel
is generated by systematically utilizing
as few of the data as possible both in training &lt;i&gt;and&lt;/i&gt; in
characterizing a nonlinear separating surface. 
This can result in substantial reduction in kernel data-dependence
(over 94% in six of the seven public datasets tested on) and with test
set correctness equal to that obtained by using a 
conventional support vector machine classifier that depends on many more data points. This 
reduction in data dependence results in a much faster classifier that 
requires less storage.
To eliminate data points, the proposed approach
makes use of a novel loss function, the "pound" function ()&lt;sub&gt;#&lt;/sub&gt;, which
is a linear combination of the 1-norm and the step function that measures
both the magnitude and the presence of any error.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/fung02a/fung02a.pdf</url></Article><Article><id>56</id><title>The Subspace Information Criterion for Infinite Dimensional Hypothesis Spaces</title><author>Masashi Sugiyama, Klaus-Robert M&amp;uuml;ller</author><abstract>
  A central problem in learning is selection of an appropriate model.  This is
  typically done by estimating the &lt;i&gt;unknown&lt;/i&gt; generalization errors of a
  set of models to be selected from and then choosing the model with minimal
  generalization error estimate.  In this article, we discuss the problem of
  model selection and generalization error estimation in the context of kernel
  regression models,
  e.g., kernel ridge regression, kernel
  subset regression or Gaussian process regression.

  Previously, a non-asymptotic generalization error estimator called the
  subspace information criterion (SIC) was proposed, that could be
  successfully applied to &lt;i&gt;finite&lt;/i&gt; dimensional subspace models.  SIC is an unbiased
  estimator of the generalization error for the finite sample case under the
  conditions that the learning target function belongs to a specified
  reproducing kernel Hilbert space (RKHS) &lt;i&gt;H&lt;/i&gt; and the reproducing kernels
  centered on training sample points span the whole space &lt;i&gt;H&lt;/i&gt;.
  These conditions hold only if dim &lt;i&gt;H &lt; l&lt;/i&gt;, where &lt;i&gt;l &lt; infinity&lt;/i&gt;
  is the number of training examples. Therefore, SIC could be applied only to finite
  dimensional RKHSs.

  In this paper, we extend the range of applicability of SIC, and show that
  even if the reproducing kernels centered on training sample points
  do not span the whole space &lt;i&gt;H&lt;/i&gt;,
  SIC is an unbiased estimator of an essential part of the
  generalization error.  
  Our extension allows the use of any RKHSs including
  &lt;i&gt;infinite&lt;/i&gt; dimensional ones, i.e.,
  richer function classes commonly used in
  Gaussian processes, support vector machines or boosting.  We further show
  that when the kernel matrix is invertible, SIC can be expressed in a much simpler form,
  making its computation highly efficient.  In computer simulations on ridge
  parameter selection with real and artificial data sets, SIC is compared
  favorably with other standard model selection techniques for instance
  leave-one-out cross-validation or an empirical Bayesian method.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/sugiyama02a/sugiyama02a.pdf</url></Article><Article><id>57</id><title>Tracking a Small Set of Experts by Mixing Past Posteriors</title><author>Olivier Bousquet, Manfred K. Warmuth</author><abstract>
In this paper, we examine on-line learning problems in which the target
concept is allowed to change over time. In each trial a master algorithm
receives predictions from a large set of &lt;i&gt;n&lt;/i&gt; experts. Its goal is to predict
almost as well as the best sequence of such experts chosen off-line by
partitioning the training sequence into &lt;i&gt;k&lt;/i&gt;+1 sections and then choosing
the best expert for each section. We build on methods developed by
Herbster and Warmuth and consider an open problem posed by
Freund where the experts in the best partition are from a small
pool of size &lt;i&gt;m&lt;/i&gt;.
Since &lt;i&gt;k&lt;/i&gt; &gt;&gt; &lt;i&gt;m&lt;/i&gt;, the best expert shifts back and forth
between the experts of the small pool.
We propose algorithms that solve
this open problem by mixing the past posteriors maintained by the master
algorithm. We relate the number of bits needed for encoding the best
partition to the loss bounds of the algorithms. 
Instead of paying log &lt;i&gt;n&lt;/i&gt; for
choosing the best expert in each section we first pay log (&lt;i&gt;n&lt;/i&gt; choose &lt;i&gt;m&lt;/i&gt;)
bits in the bounds for identifying the pool of &lt;i&gt;m&lt;/i&gt; experts 
and then log &lt;i&gt;m&lt;/i&gt; bits per new section. 
In the bounds we also pay twice for encoding the
boundaries of the sections.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bousquet02b/bousquet02b.pdf</url></Article><Article><id>58</id><title>Using Confidence Bounds for Exploitation-Exploration Trade-offs</title><author>Peter Auer</author><abstract>
We show how a standard tool from statistics --- namely confidence
bounds --- can be used to elegantly deal with situations which exhibit
an exploitation-exploration trade-off. Our technique for designing and
analyzing algorithms for such situations is general and can be applied
when an algorithm has to make exploitation-versus-exploration
decisions based on uncertain information provided by a random process.
&lt;p&gt; We apply our technique to two models with such an
exploitation-exploration trade-off.  For the adversarial bandit
problem with shifting our new algorithm suffers only
&lt;i&gt;O&lt;/i&gt;((&lt;i&gt;ST&lt;/i&gt;)&lt;sup&gt;1/2&lt;/sup&gt;) regret &lt;i&gt;with high
probability&lt;/i&gt; over &lt;i&gt;T&lt;/i&gt; trials with &lt;i&gt;S&lt;/i&gt; shifts.  Such a
regret bound was previously known only &lt;i&gt;in expectation&lt;/i&gt;.  The
second model we consider is associative reinforcement learning with
linear value functions. For this model our technique improves the
regret from &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;T&lt;/i&gt;&lt;sup&gt;3/4&lt;/sup&gt;) to &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;T&lt;/i&gt;&lt;sup&gt;1/2&lt;/sup&gt;).
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/auer02a/auer02a.pdf</url></Article><Article><id>59</id><title>Efficient Algorithms for Universal Portfolios</title><author>Adam Kalai, Santosh Vempala</author><abstract>
A constant rebalanced portfolio is an investment strategy that keeps 
the same distribution of wealth among a set of stocks from day to day. 
There has been much work on Cover's Universal algorithm, which 
is competitive with the best constant rebalanced portfolio determined 
in hindsight (Cover, 1991, Helmbold et al, 1998, Blum and Kalai, 1999,
Foster and Vohra, 1999, Vovk, 1998, Cover and Ordentlich, 1996a,
Cover, 1996c).
While this algorithm has good performance guarantees, all known 
implementations are exponential in the number of stocks, restricting 
the number of stocks used in 
experiments (Helmbold et al, 1998, Cover and Ordentlich, 1996a,
Ordentlich and Cover, 1996b, Cover, 1996c, Blum and Kalai, 1999).  We present an 
efficient implementation of the Universal algorithm that is 
based on non-uniform random walks that are rapidly mixing (Applegate
and Kannan, 1991, Lovasz and Simonovits, 1992, Frieze and Kannan, 1999).
This same implementation also works for 
non-financial applications of 
the Universal algorithm, such as data compression (Cover, 1996c) and language 
modeling (Chen et al, 1999). 
 
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/kalai02a/kalai02a.pdf</url></Article><Article><id>60</id><title>Limitations of Learning Via Embeddings in Euclidean Half Spaces</title><author>Shai Ben-David, Nadav Eiron, Hans Ulrich Simon</author><abstract>
The notion of embedding a class of dichotomies in a class of linear
half spaces is central to the support vector machines paradigm.
We examine the question of determining the minimal Euclidean dimension
and the maximal margin that can be obtained when the embedded class
has a finite VC dimension.
&lt;p&gt;
We show that an overwhelming majority of the family of finite concept
classes of any constant VC dimension  cannot be embedded in
low-dimensional half spaces. (In fact, we show that the Euclidean
dimension must be almost as high as the size of the instance space.)
We strengthen this result even further by showing that an overwhelming
majority of the family of finite concept classes of any constant VC
dimension  cannot be embedded in half spaces (of arbitrarily high
Euclidean dimension) with a large margin. (In fact, the margin cannot
be substantially larger than the margin achieved by the trivial
embedding.) Furthermore, these bounds are robust in the sense that
allowing each image half space to err on
a small fraction of the instances does not imply a significant
weakening of these dimension and margin bounds.
&lt;p&gt;
Our results indicate that any universal learning machine, which
transforms data into the Euclidean space and then applies linear (or 
large margin) classification, cannot  enjoy any meaningful
generalization guarantees that are based on either VC dimension or
margins considerations.  This failure of generalization bounds applies
even to classes for which "straight forward" empirical risk minimization
does enjoy meaningful generalization guarantees.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bendavid02a/bendavid02a.pdf</url></Article><Article><id>61</id><title>Rademacher and Gaussian Complexities: Risk Bounds and Structural Results</title><author>Peter L. Bartlett, Shahar Mendelson</author><abstract>
    We investigate the use of certain data-dependent estimates
    of the complexity of a function class, called Rademacher and
    Gaussian complexities. In a decision theoretic setting, we
    prove general risk bounds in terms of these complexities. We
    consider function classes that can be expressed as combinations
    of functions from basis classes and show how the Rademacher and
    Gaussian complexities of such a function class can be bounded in
    terms of the complexity of the basis classes. We give examples
    of the application of these techniques in finding data-dependent
    risk bounds for decision trees, neural networks and support
    vector machines.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf</url></Article><Article><id>62</id><title>On Boosting with Polynomially Bounded Distributions</title><author>Nader H. Bshouty, Dmitry Gavinsky</author><abstract>
We construct a framework which allows an
algorithm to turn the distributions produced by some boosting
algorithms into polynomially smooth distributions (w.r.t. the PAC
oracle's distribution), 
with minimal performance loss.

Further, we explore the case of Freund and Schapire's &lt;i&gt;AdaBoost&lt;/i&gt; algorithm,
bounding its distributions to polynomially smooth.  The main advantage
of &lt;i&gt;AdaBoost&lt;/i&gt; over other boosting techniques is that it is adaptive, i.e.,
it is able to take advantage of weak hypotheses that are more accurate
than it was assumed a priori.  We show that the feature of
adaptiveness is preserved and improved by our technique.

Our scheme allows the execution of &lt;i&gt;AdaBoost&lt;/i&gt; in the on-line boosting mode (i.e.,
to perform boosting "by filtering").  Executed this way (and
possessing the quality of smoothness), now &lt;i&gt;AdaBoost&lt;/i&gt; may be efficiently
applied to a wider range of learning problems than before.

In particular, we demonstrate &lt;i&gt;AdaBoost&lt;/i&gt;'s application to the task of
&lt;i&gt;DNF learning using membership queries&lt;/i&gt;.  This application results
in an algorithm that chooses the number of boosting iterations
adaptively, and, consequently, adaptively chooses the size of the
produced final hypothesis.  This answers affirmatively a question
posed by Jackson.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bshouty02b/bshouty02b.pdf</url></Article><Article><id>63</id><title>Optimal Structure Identification With Greedy Search</title><author>David Maxwell Chickering</author><abstract>
In this paper we prove the so-called "Meek Conjecture". In
particular, we show that if a DAG &lt;i&gt;H&lt;/i&gt; is an independence map of
another DAG &lt;i&gt;G&lt;/i&gt;, then there exists a finite sequence of edge
additions and covered edge reversals in &lt;i&gt;G&lt;/i&gt; such that (1) after each
edge modification &lt;i&gt;H&lt;/i&gt; remains an independence map of &lt;i&gt;G&lt;/i&gt; and (2)
after all modifications &lt;i&gt;G&lt;/i&gt; =&lt;i&gt;H&lt;/i&gt;. As shown by Meek (1997), this
result has an important consequence for Bayesian approaches to
learning Bayesian networks from data: in the limit of large sample
size, there exists a two-phase &lt;i&gt;greedy&lt;/i&gt; search algorithm
that---when applied to a particular sparsely-connected search
space---provably identifies a perfect map of the generative
distribution if that perfect map is a DAG. We provide a new
implementation of the search space, using equivalence classes as
states, for which all operators used in the greedy search can be
scored efficiently using &lt;i&gt;local&lt;/i&gt; functions of the nodes in the
domain. Finally, using both synthetic and real-world datasets, we
demonstrate that the two-phase greedy approach leads to good solutions
when learning with finite sample sizes.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/chickering02b/chickering02b.pdf</url></Article><Article><id>64</id><title>A Robust Minimax Approach to Classification</title><author>Gert R.G. Lanckriet, Laurent El Ghaoui, Chiranjib Bhattacharyya, Michael I. Jordan</author><abstract>
When constructing a classifier, the probability of correct
classification of future data points should be maximized. We
consider a binary classification problem where the mean and
covariance matrix of each class are assumed to be known. No
further assumptions are made with respect to the class-conditional
distributions. Misclassification probabilities are then controlled
in a worst-case setting: that is, under all possible choices of
class-conditional densities with given mean and covariance matrix,
we &lt;i&gt;mini&lt;/i&gt;mize the worst-case (&lt;i&gt;max&lt;/i&gt;imum) probability of
misclassification of future data points. For a linear decision
boundary, this desideratum is translated in a very direct way into
a (convex) second order cone optimization problem, with complexity
similar to a support vector machine problem. The minimax problem
can be interpreted geometrically as minimizing the maximum of the
Mahalanobis distances to the two classes.  We address the issue of
robustness with respect to estimation errors (in the means and
covariances of the classes) via a simple modification of the input
data. We also show how to exploit Mercer kernels in this setting
to obtain nonlinear decision boundaries, yielding a classifier
which proves to be competitive with current methods, including
support vector machines. An important feature of this method is
that a worst-case bound on the probability of misclassification of
future data is always obtained explicitly.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/lanckriet02a/lanckriet02a.pdf</url></Article><Article><id>65</id><title>Cluster Ensembles --- A Knowledge Reuse Framework for Combining Multiple Partitions</title><author>Alexander Strehl, Joydeep Ghosh</author><abstract>
This paper introduces the problem of combining multiple partitionings
of a set of objects into a single consolidated clustering &lt;i&gt;without&lt;/i&gt; accessing the features or algorithms that determined these
partitionings.  We first identify several application scenarios for
the resultant 'knowledge reuse' framework that we call &lt;i&gt;cluster ensembles&lt;/i&gt;.
The cluster ensemble problem is then formalized as a combinatorial
optimization problem in terms of shared mutual information.  In
addition to a direct maximization approach, we propose three effective
and efficient techniques for obtaining high-quality combiners
(consensus functions).  The first combiner induces a similarity
measure from the partitionings and then reclusters the objects.  The
second combiner is based on hypergraph partitioning. The third one
collapses groups of clusters into meta-clusters which then compete for
each object to determine the combined clustering.  Due to the low
computational costs of our techniques, it is quite feasible to use a
supra-consensus function that evaluates all three approaches against
the objective function and picks the best solution for a given
situation.
We evaluate the effectiveness of cluster ensembles in three
qualitatively different application scenarios: (i) where the original
clusters were formed based on non-identical sets of features, (ii)
where the original clustering algorithms worked on non-identical sets
of objects, and (iii) where a common data-set is used and the main
purpose of combining multiple clusterings is to improve the quality and
robustness of the solution.  Promising results are obtained in all
three situations for synthetic as well as real data-sets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/strehl02a/strehl02a.pdf</url></Article><Article><id>66</id><title>Efficient Algorithms for Decision Tree Cross-validation</title><author>Hendrik Blockeel, Jan Struyf</author><abstract>
Cross-validation is a useful and generally applicable technique
often employed in machine learning, including decision
tree induction.  An important disadvantage of straightforward implementation
of the technique is its computational overhead.  In this paper 
we show that, for decision trees, the computational overhead of 
cross-validation can be reduced significantly by integrating the
cross-validation with the normal decision tree induction process.
We discuss how existing decision tree algorithms can be adapted to this
aim, and provide an analysis of the speedups these adaptations
may yield.  We identify a number of parameters that influence the obtainable
speedups, and validate and refine our analysis with experiments 
on a variety of data sets with two different implementations.  Besides 
cross-validation, we also briefly explore the usefulness of these techniques
for bagging.  We conclude with some guidelines concerning when these
optimizations should be considered.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/blockeel02a/blockeel02a.pdf</url></Article><Article><id>67</id><title>Multiple-Instance Learning of Real-Valued Data</title><author>Daniel R. Dooly, Qi Zhang, Sally A. Goldman, Robert A. Amar</author><abstract>
The multiple-instance learning model has received much attention
recently with a primary application area being that of drug activity
prediction. Most prior work on multiple-instance learning has been for
concept learning, yet for drug activity
prediction, the label is a real-valued affinity measurement giving the
binding strength.  We present extensions of
&lt;i&gt;k&lt;/i&gt;-nearest neighbors (&lt;i&gt;k&lt;/i&gt;-NN), Citation-&lt;i&gt;k&lt;/i&gt;NN, and the diverse density algorithm for the real-valued
setting and study their performance on Boolean and
real-valued data.  We also provide a method for generating chemically
realistic artificial data.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/dooly02a/dooly02a.pdf</url></Article><Article><id>68</id><title>Learning Probabilistic Models of Link Structure</title><author>Lisa Getoor, Nir Friedman, Daphne Koller, Benjamin Taskar</author><abstract>
Most real-world data is heterogeneous and richly interconnected.
Examples include the Web, hypertext, bibliometric data and
social networks.
In contrast, most
statistical learning methods work with "flat" data representations,
forcing us to convert our data into a form that loses much of the
link structure.
The recently introduced framework of
&lt;i&gt;probabilistic relational models&lt;/i&gt; (PRMs) embraces the object-relational
nature of structured data by capturing  probabilistic interactions 
between attributes of related entities.  In this paper, we
extend this framework by modeling interactions between the attributes
and the link structure itself.  
An advantage of our approach is a unified generative model for
both content and relational structure.
We propose two mechanisms for
representing a probabilistic distribution over link structures:
&lt;i&gt;reference uncertainty&lt;/i&gt; and &lt;i&gt;existence uncertainty&lt;/i&gt;.  We describe the appropriate conditions for
using each model and present learning algorithms for each.  We present
experimental results showing that the learned models can be used to
predict link structure and, moreover, the observed link
structure can be used to provide better predictions for the attributes
in the model.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/getoor02a/getoor02a.pdf</url></Article><Article><id>69</id><title>The Representational Power of Discrete Bayesian Networks</title><author>Charles X. Ling, Huajie Zhang</author><abstract>
One of the most important fundamental properties of Bayesian networks 
is the representational power, 
reflecting what kind of functions 
they can or cannot represent. In this 
paper, we establish an association between the structural complexity of 
Bayesian networks and their representational power. We use the maximum 
number of nodes' parents as the measure 
for the structural complexity of Bayesian networks,
and the maximum XOR 
contained in a target function as the measure for the function complexity.
A representational upper bound is established
and proved. Roughly speaking, 
discrete Bayesian networks with each node having at most &lt;i&gt;k&lt;/i&gt; parents 
cannot represent any function containing (&lt;i&gt;k&lt;/i&gt;+1)-XORs.  
Our theoretical results help us to gain
a deeper understanding on the capacities and 
limitations of Bayesian networks. 

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/ling02a/ling02a.pdf</url></Article><Article><id>70</id><title>The Set Covering Machine</title><author>Mario Marchand, John Shawe-Taylor</author><abstract>
We extend the classical algorithms of Valiant and Haussler for
learning compact conjunctions and disjunctions of Boolean
attributes to allow features that are constructed from the data
and to allow a trade-off between accuracy and complexity. The
result is a general-purpose learning machine, suitable for
practical learning tasks, that we call the &lt;i&gt;set covering
machine&lt;/i&gt;. We present a version of the set covering machine that
uses &lt;i&gt;data-dependent balls&lt;/i&gt; for its set of features and
compare its performance with the support vector machine. By
extending a technique pioneered by Littlestone and Warmuth, we
bound its generalization error as a function of the amount of data
compression it achieves during training. In experiments with
real-world learning tasks, the bound is shown to be extremely
tight and to provide an effective guide for model selection.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/marchand02a/marchand02a.pdf</url></Article><Article><id>71</id><title>Coupled Clustering: A Method for Detecting Structural Correspondence</title><author>Zvika Marx, Ido Dagan, Joachim M. Buhmann, Eli Shamir</author><abstract>
This paper proposes a new paradigm and a computational framework for revealing equivalencies (analogies) between sub-structures of distinct composite systems that are initially represented by unstructured data sets.  For this purpose, we introduce and investigate a variant of traditional data clustering, termed &lt;i&gt;coupled clustering&lt;/i&gt;, which outputs a configuration of corresponding subsets of two such representative sets.  We apply our method to synthetic as well as textual data.  Its achievements in detecting topical correspondences between textual corpora are evaluated through comparison to performance of human experts.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/marx02a/marx02a.pdf</url></Article><Article><id>72</id><title>Some Greedy Learning Algorithms for Sparse Regression and Classification with Mercer Kernels</title><author>Prasanth B. Nair, Arindam Choudhury, Andy J. Keane</author><abstract>
We present greedy learning algorithms for building sparse nonlinear regression 
and classification models from observational data using Mercer kernels. 
Our objective is to develop efficient numerical schemes for reducing the 
training and runtime complexities of kernel-based algorithms applied to large
datasets. In the spirit of Natarajan's greedy algorithm (Natarajan, 1995),
we iteratively minimize the &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;$ loss function subject to a 
specified constraint on the degree of sparsity required of the final model or 
till a specified stopping criterion is reached.
 We discuss various greedy criteria for basis 
selection and numerical schemes for improving the robustness and 
computational efficiency. Subsequently, algorithms  based on residual 
minimization and thin QR factorization are presented 
for constructing sparse regression and classification models. During the
course of the incremental model construction, the algorithms are terminated
using model selection principles such as 
the minimum descriptive length (MDL) and Akaike's information
criterion (AIC). Finally, experimental results on
benchmark data are presented to demonstrate the competitiveness 
of the algorithms developed in this paper.


&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/nair02a/nair02a.pdf</url></Article><Article><id>73</id><title>Lyapunov Design for Safe Reinforcement Learning</title><author>Theodore J. Perkins, Andrew G. Barto</author><abstract>
Lyapunov design methods are used widely in control engineering to
design controllers that achieve qualitative objectives, such as
stabilizing a system or maintaining a system's state in a desired
operating range. We propose a method for constructing safe, reliable
reinforcement learning agents based on Lyapunov design principles. In
our approach, an agent learns to control a system by switching among a
number of given, base-level controllers. These controllers are
designed using Lyapunov domain knowledge so that &lt;i&gt;any&lt;/i&gt; switching
policy is safe and enjoys basic performance guarantees. Our approach
thus ensures qualitatively satisfactory agent behavior for virtually
any reinforcement learning algorithm and at all times, including while
the agent is learning and taking exploratory actions. We demonstrate
the process of designing safe agents for four different control
problems. In simulation experiments, we find that our theoretically
motivated designs also enjoy a number of practical benefits, including
reasonable performance initially and throughout learning, and
accelerated learning.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/perkins02a/perkins02a.pdf</url></Article><Article><id>74</id><title>Finding the Most Interesting Patterns in a Database Quickly by Using Sequential Sampling</title><author>Tobias Scheffer, Stefan Wrobel</author><abstract>
Many discovery problems, &lt;i&gt;e&lt;/i&gt;.&lt;i&gt;g&lt;/i&gt;. subgroup or association rule discovery, can
naturally be cast as &lt;i&gt;n&lt;/i&gt;-best hypotheses problems where the goal is to find
the &lt;i&gt;n&lt;/i&gt; hypotheses from a given hypothesis space that score best according to
a certain utility function.  We present a sampling algorithm that solves this
problem by issuing a small number of database queries while guaranteeing
precise bounds on the confidence and quality of solutions.  Known sampling
approaches have treated single hypothesis selection problems, assuming that
the utility is the average (over the examples) of some function --- which is
not the case for many frequently used utility functions. We show that our
algorithm works for all utilities that can be estimated with bounded error. We
provide these error bounds and resulting worst-case sample bounds for some of
the most frequently used utilities, and prove that there is no sampling
algorithm for a popular class of utility functions that cannot be estimated
with bounded error.  The algorithm is sequential in the sense that it starts
to return (or discard) hypotheses that already seem to be particularly good
(or bad) after a few examples.  Thus, the algorithm is almost always faster than
its worst-case bounds.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/scheffer02a/scheffer02a.pdf</url></Article><Article><id>75</id><title>Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem</title><author>Marc Sebban, Richard Nock, St&amp;eacute;phane Lallich</author><abstract>
So far, boosting has been used to improve the quality of moderately accurate learning algorithms, by
weighting and combining many of their &lt;i&gt;weak&lt;/i&gt; hypotheses into a final classifier with theoretically
high accuracy. In a recent work (Sebban, Nock and Lallich, 2001), we have attempted to adapt boosting
properties to data reduction techniques. In this particular context, the objective was not only to improve
the success rate, but also to reduce the time and space complexities due to the storage requirements of
some costly learning algorithms, such as nearest-neighbor
classifiers. In that framework, each &lt;i&gt;weak&lt;/i&gt; hypothesis, which is usually built and weighted from the learning set, is replaced by a
single learning instance. The weight given by boosting defines in that case the relevance of the instance,
and a statistical test allows one to decide whether it can be discarded without damaging further classification
tasks. In Sebban, Nock and Lallich (2001), we addressed problems with two classes. It is the aim of the
present paper to relax the class constraint, and extend our contribution to multiclass problems. Beyond
data reduction, experimental results are also provided on twenty-three datasets, showing the benefits that
our boosting-derived weighting rule brings to weighted nearest neighbor classifiers.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/sebban02a/sebban02a.pdf</url></Article><Article><id>76</id><title>Learning to Construct Fast Signal Processing Implementations</title><author>Bryan Singer, Manuela Veloso</author><abstract>
A single signal processing algorithm can be represented by many
mathematically equivalent formulas.  However, when these formulas are
implemented in code and run on real machines, they have very different
runtimes.  Unfortunately, it is extremely difficult to model this broad
performance range.  Further, the space of formulas for real signal
transforms is so large that it is impossible to search it exhaustively
for fast implementations.  We approach this search question as a control
learning problem.  We present a new method for learning to &lt;i&gt;generate
fast formulas&lt;/i&gt;, allowing us to intelligently search through only the
most promising formulas.  Our approach incorporates signal processing
knowledge, hardware features, and formula performance data to learn to
construct fast formulas.  Our method learns from performance data for a
few formulas of one size and then can construct formulas that will have
the fastest runtimes possible across many sizes.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/singer02a/singer02a.pdf</url></Article><Article><id>77</id><title>Policy Search using Paired Comparisons</title><author>Malcolm J. A. Strens, Andrew W. Moore</author><abstract>
Direct policy search is a practical way to solve reinforcement
learning (RL) problems involving continuous state and action
spaces. The goal becomes finding policy parameters that maximize a
noisy objective function. The Pegasus method converts this
stochastic optimization problem into a deterministic one, by using
fixed start states and fixed random number sequences for comparing
policies (Ng and Jordan, 2000). We evaluate Pegasus, and new paired
comparison methods, using the mountain car problem, and a
difficult pursuer-evader problem. We conclude that: (i) paired
tests can improve performance of optimization procedures; (ii)
several methods are available to reduce the 'overfitting' effect
found with Pegasus; (iii) adapting the number of trials used for
each comparison yields faster learning; (iv) pairing also helps
&lt;i&gt;stochastic&lt;/i&gt; search methods such as differential evolution.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/strens02a/strens02a.pdf</url></Article><Article><id>78</id><title>Ultraconservative Online Algorithms for Multiclass Problems</title><author>Koby Crammer, Yoram Singer</author><abstract>
In this paper we study a paradigm to generalize online classification
algorithms for binary classification problems to multiclass problems.
The particular hypotheses we investigate maintain one prototype vector
per class. Given an input instance, a multiclass hypothesis computes a
similarity-score between each prototype and the input instance and sets
the predicted label to be the index of the prototype achieving the highest
similarity. To design and analyze the learning algorithms in this paper we
introduce the notion of &lt;i&gt;ultraconservativeness&lt;/i&gt;. Ultraconservative
algorithms are algorithms that update only the prototypes attaining
similarity-scores which are higher than the score of the correct label's
prototype. We start by describing a family of additive ultraconservative
algorithms where each algorithm in the family updates its prototypes by
finding a feasible solution for a set of linear constraints that depend on
the instantaneous similarity-scores.  We then discuss a specific online
algorithm that seeks a set of prototypes which have a small norm. The
resulting algorithm, which we term MIRA (for Margin Infused Relaxed
Algorithm) is ultraconservative as well. We derive mistake bounds
for all the algorithms and provide further analysis of MIRA using a
generalized notion of the margin for multiclass problems. We discuss
the form the algorithms take in the binary case and show that all the
algorithms from the first family reduce to the Perceptron algorithm while
MIRA provides a new Perceptron-like algorithm with a margin-dependent
learning rate.  We then return to multiclass problems and describe an
analogous multiplicative family of algorithms with corresponding mistake
bounds. We end the formal part by deriving and analyzing a multiclass
version of Li and Long's ROMMA algorithm. We conclude with a discussion
of experimental results that demonstrate the merits of our algorithms.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/crammer03a/crammer03a.pdf</url></Article><Article><id>79</id><title>Latent Dirichlet Allocation</title><author>David M. Blei, Andrew Y. Ng, Michael I. Jordan</author><abstract>
  We describe &lt;i&gt;latent Dirichlet allocation&lt;/i&gt; (LDA), a generative
  probabilistic model for collections of discrete data such as text
  corpora.  LDA is a three-level hierarchical Bayesian model, in which
  each item of a collection is modeled as a finite mixture over an
  underlying set of topics.  Each topic is, in turn, modeled as an
  infinite mixture over an underlying set of topic probabilities.  In
  the context of text modeling, the topic probabilities provide an
  explicit representation of a document.  We present efficient
  approximate inference techniques based on variational methods and an
  EM algorithm for empirical Bayes parameter estimation.  We report
  results in document modeling, text classification, and collaborative
  filtering, comparing to a mixture of unigrams model and the
  probabilistic LSI model.

&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf</url></Article><Article><id>80</id><title>A Family of Additive Online Algorithms for Category Ranking</title><author>Koby Crammer, Yoram Singer</author><abstract>
We describe a new family of topic-ranking algorithms for multi-labeled
documents. The motivation for the algorithms stem from recent advances
in online learning algorithms. The algorithms are simple to implement
and are also time and memory efficient. We provide a unified analysis
of the family of algorithms in the mistake bound model. We then discuss
experiments with the proposed family of topic-ranking algorithms on the
Reuters-21578 corpus and the new corpus released by Reuters in 2000.
On both corpora, the algorithms we present achieve
state-of-the-art
results and outperforms topic-ranking adaptations of Rocchio's algorithm
and of the Perceptron algorithm.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/crammer03b/crammer03b.pdf</url></Article><Article><id>81</id><title>Word-Sequence Kernels</title><author>Nicola Cancedda, Eric Gaussier, Cyril Goutte, Jean-Michel Renders</author><abstract>
We address the problem of categorising documents using
kernel-based methods such as Support Vector Machines. Since the
work of Joachims (1998), there is ample experimental evidence
that SVM using the standard word frequencies as features yield
state-of-the-art performance on a number of benchmark problems.
Recently, Lodhi et al. (2002) proposed the use of &lt;i&gt;string
kernels&lt;/i&gt;, a novel way of computing document similarity based of
matching non-consecutive subsequences of characters. In this
article, we propose the use of this technique with sequences of
&lt;i&gt;words&lt;/i&gt; rather than characters. This approach has several
advantages, in particular it is more efficient computationally and
it ties in closely with standard linguistic pre-processing
techniques. We present some extensions to sequence kernels dealing
with symbol-dependent and match-dependent decay factors, and
present empirical evaluations of these extensions on the
Reuters-21578 datasets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/cancedda03a/cancedda03a.pdf</url></Article><Article><id>82</id><title>Kernel Methods for Relation Extraction</title><author>Dmitry Zelenko, Chinatsu Aone, Anthony Richardella</author><abstract>
We present an application of kernel methods to extracting
relations from unstructured natural language sources.
We introduce kernels defined over shallow parse representations of text, and
design efficient algorithms for computing the kernels. We
use the devised kernels in conjunction with Support Vector
Machine and Voted Perceptron learning algorithms for the
task of extracting &lt;tt&gt;person-affiliation&lt;/tt&gt; and
&lt;tt&gt;organization-location&lt;/tt&gt; relations from text. We
experimentally evaluate the proposed methods and compare
them with feature-based learning algorithms, with promising
results.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/zelenko03a/zelenko03a.pdf</url></Article><Article><id>83</id><title>Matching Words and Pictures</title><author>Kobus Barnard, Pinar Duygulu, David Forsyth, Nando de Freitas,David M. Blei, Michael I. Jordan</author><abstract>
We present a new approach for modeling multi-modal data sets,
focusing on the specific case of segmented images with associated
text. Learning the joint distribution of image regions and words
has many applications. We consider in detail predicting words
associated with whole images (auto-annotation) and corresponding
to particular image regions (region naming). Auto-annotation might
help organize and access large collections of images. Region
naming is a model of object recognition as a process of
translating image regions to words, much as one might translate
from one language to another. Learning the relationships between
image regions and semantic correlates (words) is an interesting
example of multi-modal data mining, particularly because it is
typically hard to apply data mining techniques to collections of
images.  We develop a number of models for the joint distribution
of image regions and words, including several which explicitly
learn the correspondence between regions and words. We study
multi-modal and correspondence extensions to Hofmann's
hierarchical clustering/aspect model, a translation model adapted
from statistical machine translation (Brown et al.), and a
multi-modal extension to mixture of latent Dirichlet allocation
(MoM-LDA). All models are assessed using a large collection of
annotated images of real scenes. We study in depth the difficult
problem of measuring performance. For the annotation task, we look
at prediction performance on held out data. We present three
alternative measures, oriented toward different types of task.
Measuring the performance of correspondence methods is harder,
because one must determine whether a word has been placed on the
right region of an image. We can use annotation performance as a
proxy measure, but accurate measurement requires hand labeled
data, and thus must occur on a smaller scale. We show results
using both an annotation proxy, and manually labeled data.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/barnard03a/barnard03a.pdf</url></Article><Article><id>84</id><title>A Neural Probabilistic Language Model</title><author>Yoshua Bengio, R&amp;eacute;jean Ducharme, Pascal Vincent, Christian Jauvin</author><abstract>
A goal of statistical language modeling is to learn the joint
probability function of sequences of words in a language. This is
intrinsically difficult because of the &lt;b&gt;curse of dimensionality&lt;/b&gt;:
a word sequence on which the model will be tested is likely to be
different from all the word sequences seen during training.
Traditional but very successful approaches based on n-grams obtain
generalization by concatenating very short overlapping
sequences seen in the training
set.  We propose to fight the curse of dimensionality by
&lt;b&gt;learning a distributed representation for words&lt;/b&gt; which allows each
training sentence to inform the model about an exponential number of
semantically neighboring sentences.  The model learns simultaneously
(1) a distributed representation for each word along with (2) the
probability function for word sequences, expressed in terms of these
representations. Generalization is obtained because a sequence of
words that has never been seen before gets high probability if it is
made of words that are similar (in the sense of having a nearby
representation) to words forming an already seen sentence. Training
such large models (with millions of parameters) within a reasonable
time is itself a significant challenge.  We report on experiments
using neural networks for the probability function, showing on two
text corpora that the proposed approach significantly improves on
state-of-the-art n-gram models, and that the proposed approach
allows to take advantage of longer contexts.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf</url></Article><Article><id>85</id><title>An Introduction to Variable and Feature Selection</title><author>Isabelle Guyon, Andr&amp;eacute; Elisseeff</author><abstract>
Variable and feature selection have become the focus of much
research in areas of application for which datasets with tens or
hundreds of thousands of variables are available. These areas
include text processing of internet documents, gene expression
array analysis, and combinatorial chemistry. The objective of
variable selection is three-fold: improving the prediction
performance of the predictors, providing faster and more
cost-effective predictors, and providing a better understanding of
the underlying process that generated the data. The contributions
of this special issue cover a wide range of aspects of such
problems: providing a better definition of the objective function,
feature construction, feature ranking, multivariate feature
selection, efficient search methods, and feature validity
assessment methods.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/guyon03a/guyon03a.pdf</url></Article><Article><id>86</id><title>Distributional Word Clusters vs. Words for Text Categorization</title><author>Ron Bekkerman, Ran El-Yaniv, Naftali Tishby, and Yoad Winter</author><abstract>
We study an approach to text categorization that combines
distributional clustering of words and a Support Vector Machine
(SVM) classifier. This word-cluster representation is computed
using the recently introduced &lt;i&gt;Information Bottleneck&lt;/i&gt; method,
which generates a compact and efficient representation of
documents. When combined with the classification power of the SVM,
this method yields high performance in text categorization. This
novel combination of SVM with word-cluster representation is
compared with SVM-based categorization using the simpler
bag-of-words (BOW) representation. The comparison is performed
over three known datasets. On one of these datasets (the 20
Newsgroups) the method based on word clusters significantly
outperforms the word-based representation in terms of
categorization accuracy or representation efficiency. On the two
other sets (Reuters-21578 and WebKB) the word-based representation
slightly outperforms the word-cluster representation. We
investigate the potential reasons for this behavior and relate it
to structural differences between the datasets.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bekkerman03a/bekkerman03a.pdf</url></Article><Article><id>87</id><title>Extensions to Metric-Based Model Selection</title><author>Yoshua Bengio, Nicolas Chapados</author><abstract>
Metric-based methods have recently been introduced for model selection and regularization, often yielding very
significant improvements over the alternatives tried (including cross-validation). All these methods require unlabeled data
over which to compare functions and detect gross differences in behavior away from the training points. We introduce three
new extensions of the metric model selection methods and apply them to feature selection.  The first extension takes
advantage of the particular case of time-series data in which the task involves prediction with a horizon &lt;i&gt;h&lt;/i&gt;. The idea is
to use at &lt;i&gt;t&lt;/i&gt; the &lt;i&gt;h&lt;/i&gt; unlabeled examples that precede &lt;i&gt;t&lt;/i&gt; for model selection.  The second extension takes advantage of the
different error distributions of cross-validation and the metric methods: cross-validation tends to have a larger variance
and is unbiased. A hybrid combining the two model selection methods is rarely beaten by any of the two methods.  The third
extension deals with the case when unlabeled data is not available at all, using an estimated input density.  Experiments
are described to study these extensions in the context of capacity control and feature subset selection.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bengio03b/bengio03b.pdf</url></Article><Article><id>88</id><title>Dimensionality Reduction via Sparse Support Vector Machines</title><author>Jinbo Bi, Kristin Bennett, Mark Embrechts, Curt Breneman, Minghu Song</author><abstract>
We describe a methodology for performing variable ranking and
selection using support vector machines (SVMs).   The method
constructs a series of sparse linear SVMs to generate linear
models that can generalize well, and uses a subset of nonzero
weighted variables found by the linear models to produce a final
nonlinear model. The method exploits the fact that a linear SVM
(no kernels) with &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm regularization inherently performs
variable selection as a side-effect of minimizing capacity of the
SVM model. The distribution of the linear model weights provides a
mechanism for ranking and interpreting the effects of variables.
Starplots are used to visualize the magnitude and variance of the
 weights for each variable.  We illustrate the effectiveness of
the methodology on synthetic data, benchmark problems, and
challenging regression problems in drug design. This method can
dramatically reduce the number of variables and outperforms SVMs
trained using all attributes and using the attributes selected
according to correlation coefficients. The visualization of the
resulting models is useful for understanding the role of
underlying variables.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/bi03a/bi03a.pdf</url></Article><Article><id>89</id><title>Benefitting from the Variables that Variable Selection Discards</title><author>Rich Caruana, Virginia R. de Sa</author><abstract>
&lt;p&gt;
In supervised learning variable selection is used to find a subset
of the available inputs that accurately predict the output.  This
paper shows that some of the variables that variable selection
discards can beneficially be used as extra outputs for inductive
transfer.  Using discarded input variables as extra outputs forces
the model to learn mappings from the  variables that were selected
as inputs to these extra outputs.  Inductive transfer makes what
is learned by these mappings available to the model that is being
trained on the main output, often resulting in improved
performance on that main output.
&lt;/p&gt;
&lt;p&gt;
We present three synthetic problems (two regression problems and one
classification problem) where performance improves if some variables
discarded by variable selection are used as extra outputs.  We then
apply variable selection to two real problems (DNA splice-junction and
pneumonia risk prediction) and demonstrate the same effect: using some
of the discarded input variables as extra outputs yields somewhat better
performance on both of these problems than can be achieved by variable
selection alone.  This new approach enhances the benefit of variable
selection by allowing the learner to benefit from variables that would
otherwise have been discarded by variable selection, but without
suffering the loss in performance that occurs when these variables are
used as inputs.
&lt;/p&gt;
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/caruana03a/caruana03a.pdf</url></Article><Article><id>90</id><title>A Divisive Information-Theoretic Feature Clustering Algorithm for Text Classification</title><author>Inderjit S. Dhillon, Subramanyam Mallela, Rahul Kumar</author><abstract>
High dimensionality of text can be a deterrent in applying
complex learners such as Support Vector Machines to the task of text
classification. Feature clustering is a powerful alternative to feature selection
for reducing the dimensionality of text data. In this paper we propose a new
information-theoretic divisive algorithm for feature/word clustering and
apply it to text classification.
Existing techniques for such "distributional clustering" of words are
agglomerative in nature and result
in (i) sub-optimal word clusters and (ii) high computational cost.
In order to explicitly capture the optimality of word clusters in
an information theoretic framework, we first derive a global
criterion for feature clustering. We then present a fast, divisive
algorithm that monotonically decreases this objective function value.
We show that our algorithm
minimizes the "within-cluster Jensen-Shannon divergence" while
simultaneously maximizing the "between-cluster Jensen-Shannon divergence".
In comparison to the previously proposed agglomerative strategies our
divisive algorithm is much faster and achieves comparable or higher classification
accuracies. We further show that feature clustering is an
effective technique for building smaller class models in hierarchical
classification. We present detailed experimental results
using Naive Bayes and Support Vector Machines
on the 20Newsgroups data set and a 3-level hierarchy of HTML
documents collected from the Open Directory project (www.dmoz.org).
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/dhillon03a/dhillon03a.pdf</url></Article><Article><id>91</id><title>An Extensive Empirical Study of Feature Selection Metrics for Text Classification</title><author>George Forman</author><abstract>
Machine learning for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization.  In text domains, effective feature selection is essential to make the learning task efficient and more accurate.  This paper presents an empirical comparison of twelve feature selection methods (e.g. Information Gain) evaluated on a benchmark of 229 text classification problem instances that were gathered from Reuters, TREC, OHSUMED, etc.  The results are analyzed from multiple goal perspectives-accuracy, F-measure, precision, and recall-since each is appropriate in different situations.
	The results reveal that a new feature selection metric we call 'Bi-Normal Separation' (BNS), outperformed the others by a substantial margin in most situations.  This margin widened in tasks with high class skew, which is rampant in text classification problems and is particularly challenging for induction algorithms.
	A new evaluation methodology is offered that focuses on the needs of the data mining practitioner faced with a single dataset who seeks to choose one (or a pair of) metrics that are most &lt;i&gt;likely&lt;/i&gt; to yield the best performance.  From this perspective, BNS was the top single choice for all goals except precision, for which Information Gain yielded the best result most often.  This analysis also revealed, for example, that Information Gain and Chi-Squared have correlated failures, and so they work poorly together.  When choosing optimal pairs of metrics for each of the four performance goals, BNS is consistently a member of the pair---e.g., for greatest recall, the pair BNS + F1-measure yielded the best performance on the greatest number of tasks by a considerable margin.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/forman03a/forman03a.pdf</url></Article><Article><id>92</id><title>Sufficient Dimensionality Reduction</title><author>Amir Globerson, Naftali Tishby</author><abstract>
Dimensionality reduction of empirical co-occurrence data
 is a fundamental problem in unsupervised learning. It is also a well
 studied problem in statistics known as the analysis of
 cross-classified data.
 One principled approach to this problem is to represent the data in
 low dimension with minimal loss of (mutual) information
 contained in the original data. In this paper we introduce an
 information theoretic nonlinear method for finding such a most informative
 dimension reduction.
 In contrast with previously introduced clustering based approaches,
 here we  extract &lt;i&gt;continuous feature functions&lt;/i&gt; directly from the
 co-occurrence matrix. In a sense, we automatically extract functions
 of the variables that serve as approximate sufficient statistics for
 a sample of one variable about the other one.
 Our method is different from dimensionality reduction methods which are based
 on a specific, sometimes arbitrary, metric or embedding.
 Another interpretation of our method is as
 generalized - multi-dimensional - non-linear regression, where rather than
 fitting one regression function through two dimensional data, we
 extract &lt;i&gt;d&lt;/i&gt;-regression functions whose expectation values capture the
 information among the variables. It thus presents a new learning
 paradigm that unifies aspects from both supervised and unsupervised
 learning. The resulting dimension reduction can be described by two
 conjugate d-dimensional differential manifolds that are coupled through
 Maximum Entropy &lt;i&gt;I&lt;/i&gt;-projections. The Riemannian metrics of these manifolds
 are determined by the observed expectation values of our extracted features.
Following this geometric interpretation we present an iterative
information projection algorithm for finding such features
and prove its convergence. Our algorithm is similar to the method of
"association analysis" in statistics, though the feature extraction
context as well as the information theoretic and geometric
interpretation are new.
The algorithm is illustrated by
various synthetic co-occurrence data. It is then demonstrated for
text categorization and information retrieval and proves effective
in selecting a small set of features, often improving
 performance over the original  feature set.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/globerson03a/globerson03a.pdf</url></Article><Article><id>93</id><title>Grafting: Fast, Incremental Feature Selection by Gradient Descent in Function Space</title><author>Simon Perkins, Kevin Lacker, James Theiler</author><abstract>
We present a novel and flexible approach to the problem of feature
selection, called &lt;i&gt;grafting&lt;/i&gt;. Rather than considering feature
selection as separate from learning, grafting treats the selection of
suitable features as an integral part of learning a predictor in a
regularized learning framework. To make this regularized learning
process sufficiently fast for large scale problems, grafting operates
in an incremental iterative fashion, gradually building up a feature
set while training a predictor model using gradient descent. At each
iteration, a fast gradient-based heuristic is used to quickly assess
which feature is most likely to improve the existing model, that
feature is then added to the model, and the model is incrementally
optimized using gradient descent. The algorithm scales linearly with
the number of data points and at most quadratically with the number of
features. Grafting can be used with a variety of predictor model
classes, both linear and non-linear, and can be used for both
classification and regression. Experiments are reported here on a
variant of grafting for classification, using both linear and
non-linear models, and using a logistic regression-inspired loss
function. Results on a variety of synthetic and real world data sets
are presented. Finally the relationship between grafting, stagewise
additive modelling, and boosting is explored.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/perkins03a/perkins03a.pdf</url></Article><Article><id>94</id><title>Variable Selection Using SVM-based Criteria</title><author>Alain Rakotomamonjy</author><abstract>
We propose new methods to evaluate variable subset relevance with
a view to variable selection. Relevance criteria are derived from
Support Vector Machines and are based on  weight vector
||&lt;b&gt;w&lt;/b&gt;||&lt;sup&gt;2&lt;/sup&gt; or  generalization error bounds sensitivity with
respect to a variable. Experiments on linear and non-linear toy
problems and real-world datasets have been carried out to assess
the effectiveness of these criteria. Results show that the
criterion based on weight vector derivative  achieves good results
and performs consistently well over the datasets we used.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/rakotomamonjy03a/rakotomamonjy03a.pdf</url></Article><Article><id>95</id><title>Overfitting in Making Comparisons Between Variable Selection Methods</title><author>Juha Reunanen</author><abstract>
This paper addresses a common methodological flaw in the comparison of
variable selection methods. A practical approach to guide the search
or the selection process is to compute cross-validation performance
estimates of the different variable subsets. Used with computationally
intensive search algorithms, these estimates may overfit and yield
biased predictions. Therefore, they cannot be used reliably to compare
two selection methods, as is shown by the empirical results of this
paper. Instead, like in other instances of the model selection
problem, independent test sets should be used for determining the
final performance. The claims made in the literature about the
superiority of more exhaustive search algorithms over simpler ones are
also revisited, and some of them infirmed.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/reunanen03a/reunanen03a.pdf</url></Article><Article><id>96</id><title>MLPs (Mono-Layer Polynomials and Multi-Layer Perceptrons) for Nonlinear Modeling</title><author>Isabelle Rivals, L&amp;eacute;on Personnaz</author><abstract>
This paper presents a model selection procedure which stresses the importance of the classic polynomial models as tools for evaluating the complexity of a given modeling problem, and for removing non-significant input variables. If the complexity of the problem makes a neural network necessary, the selection among neural candidates can be performed in two phases. In an additive phase, the most important one, candidate neural networks with an increasing number of hidden neurons are trained. The addition of hidden neurons is stopped when the effect of the round-off errors becomes significant, so that, for instance, confidence intervals cannot be accurately estimated. This phase leads to a set of approved candidate networks. In a subsequent subtractive phase, a selection among approved networks is performed using statistical Fisher tests. The series of tests starts from a possibly too large unbiased network (the full network), and ends with the smallest unbiased network whose input variables and hidden neurons all have a significant contribution to the regression estimate. This method was successfully tested against the real-world regression problems proposed at the NIPS2000 Unlabeled Data Supervised Learning Competition; two of them are included here as illustrative examples.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/rivals03a/rivals03a.pdf</url></Article><Article><id>97</id><title>Ranking a Random Feature for Variable and Feature Selection</title><author>Herv&amp;eacute; Stoppiglia, G&amp;eacute;rard Dreyfus, R&amp;eacute;mi Dubois, Yacine Oussar</author><abstract>
We describe a feature selection method that can be applied directly to
models that are linear with respect to their parameters, and indirectly to
others. It is independent of the target machine. It is closely related to
classical statistical hypothesis tests, but it is more intuitive, hence more
suitable for use by engineers who are not statistics experts. Furthermore,
some assumptions of classical tests are relaxed. The method has been used
successfully in a number of applications that are briefly described.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/stoppiglia03a/stoppiglia03a.pdf</url></Article><Article><id>98</id><title>Feature Extraction by Non-Parametric Mutual Information Maximization</title><author>Kari Torkkola</author><abstract>
We present a method for learning discriminative feature transforms
using as criterion the mutual information between class labels and
transformed features. Instead of a commonly used mutual
information measure based on Kullback-Leibler divergence, we use a
quadratic divergence measure, which allows us to make an efficient
non-parametric implementation and requires no prior assumptions
about class densities. In addition to linear transforms, we also
discuss nonlinear transforms that are implemented as radial basis
function networks. Extensions to reduce the computational
complexity are also presented, and a comparison to greedy feature
selection is made.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/torkkola03a/torkkola03a.pdf</url></Article><Article><id>99</id><title>Use of the Zero-Norm with Linear Models and Kernel Methods</title><author>Jason Weston, Andr&amp;eacute; Elisseeff, Bernhard Sch&amp;ouml;lkopf, Mike Tipping</author><abstract>
We explore the use of the so-called  zero-norm of the
parameters of linear models in learning.  Minimization of such a
quantity  has many uses in a machine learning context: for
variable or feature selection, minimizing training error and
ensuring sparsity in solutions. We derive a simple but practical
method for achieving these goals and discuss its relationship to
existing techniques of minimizing the  zero-norm.
The method boils down to implementing
a simple modification of vanilla SVM, namely via
an iterative multiplicative rescaling of the training data.
Applications we investigate which aid our discussion include
variable and feature selection on biological microarray data,
and multicategory classification.
&lt;p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume3/weston03a/weston03a.pdf</url>
<Article><id>100</id><title>On Nearest-Neighbor Error-Correcting Output Codes with Application to All-Pairs Multiclass Support Vector Machines</title><author>Aldebaro Klautau, Nikola Jevti&amp;#263;, Alon Orlitsky</author><abstract>A common way of constructing a multiclass classifier is by
combining the outputs of several binary ones, according to an
error-correcting output code (ECOC) scheme. The combination is
typically done via a simple nearest-neighbor rule that finds the
class that is closest in some sense to the outputs of the binary
classifiers. For these nearest-neighbor ECOCs, we improve existing
bounds on the error rate of the multiclass classifier given the
average binary distance. The new bounds provide insight into the
one-versus-rest and all-pairs matrices, which are compared through
experiments with standard datasets. The results also show why
&lt;i&gt;elimination&lt;/i&gt; (also known as DAGSVM) and Hamming decoding
often achieve the same accuracy.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/klautau03a/klautau03a.pdf</url></Article><Article><id>101</id><title>FINkNN: A Fuzzy Interval Number k-Nearest Neighbor Classifier for Prediction of Sugar Production from Populations of Samples</title><author>Vassilios Petridis, Vassilis G. Kaburlasos</author><abstract>This work introduces &lt;i&gt;FINkNN&lt;/i&gt;, a k-nearest-neighbor classifier operating over the metric lattice of
conventional interval-supported convex fuzzy sets. We show that for problems involving
populations of measurements, data can be represented by fuzzy interval numbers (FINs) and we
present an algorithm for constructing FINs from such populations. We then present a lattice-theoretic
metric distance between FINs with arbitrary-shaped
membership functions, which forms
the basis for &lt;i&gt;FINkNN&lt;/i&gt;'s similarity measurements. We apply &lt;i&gt;FINkNN&lt;/i&gt; to the task of predicting
annual sugar production based on populations of measurements supplied by Hellenic Sugar
Industry. We show that &lt;i&gt;FINkNN&lt;/i&gt; improves prediction accuracy on this task, and discuss the
broader scope and potential utility of these techniques.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/petridis03a/petridis03a.pdf</url></Article><Article><id>102</id><title>Designing Committees of Models through Deliberate Weighting of Data Points</title><author>Stefan W. Christensen, Ian Sinclair, Philippa A. S. Reed</author><abstract>&lt;p&gt;
In the adaptive derivation of mathematical models from data, each data point should contribute with a weight reflecting the amount of confidence one has in it. When no additional information for data confidence is available, all the data points should be considered equal, and are also generally given the same weight. In the formation of committees of models, however, this is often not the case and the data points may exercise unequal, even random, influence over the committee formation.
&lt;/p&gt;
&lt;p&gt;
In this paper, a principled approach to committee design is presented.  The construction of a committee design matrix is detailed through which each data point will contribute to the committee formation with a fixed weight, while contributing with different individual weights to the derivation of the different constituent models, thus encouraging model diversity whilst not biasing the committee inadvertently towards any particular data points. Not distinctly an algorithm, it is instead a framework within which several different committee approaches may be realised.
&lt;/p&gt;
&lt;p&gt;
Whereas the focus in the paper lies entirely on regression, the principles discussed extend readily to classification.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/christensen03a/christensen03a.pdf</url></Article><Article><id>103</id><title>The em Algorithm for Kernel Matrix Completion with Auxiliary Data</title><author>Koji Tsuda, Shotaro Akaho, Kiyoshi Asai</author><abstract>In biological data, it is often the case that observed data are
available only for a subset of samples.  When a kernel matrix is
derived from such data, we have to leave the entries for unavailable
samples as missing. In this paper, the missing entries are completed
by exploiting an auxiliary kernel matrix derived from another
information source.  The parametric model of kernel matrices is
created as a set of spectral variants of the auxiliary kernel matrix,
and the missing entries are estimated by fitting this model to the
existing entries.  For model fitting, we adopt the &lt;i&gt;em&lt;/i&gt; algorithm
(distinguished from the EM algorithm of Dempster et al., 1977) based
on the information geometry of positive definite matrices.  We will
report promising results on bacteria clustering experiments using two
marker sequences: 16S and gyrB.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/tsuda03a/tsuda03a.pdf</url></Article><Article><id>104</id><title>Task Clustering and Gating for Bayesian Multitask Learning</title><author>Bart Bakker, Tom Heskes</author><abstract>&lt;p&gt;
Modeling a collection of similar regression or classification tasks can 
be improved by making the tasks 'learn from each other'. In machine learning, 
this subject is approached through 'multitask learning', where parallel tasks
are modeled as multiple outputs of the same network. In multilevel
analysis this is generally implemented through the mixed-effects
linear model where a distinction is made between 'fixed effects', which
are the same for all tasks, and 'random effects', which may vary
between tasks. In the present article we will adopt
a Bayesian approach in which some of the model parameters are 
shared (the same for all tasks) and others more loosely connected through
a joint prior distribution that can be learned from the data. We seek
in this way to combine the best parts of both the statistical
multilevel approach and the neural network machinery.
&lt;/p&gt;
&lt;p&gt;
The standard assumption expressed in both approaches is that each 
task can learn equally well from any other task. In this article we extend 
the model by allowing more differentiation in the similarities between tasks.
One such extension is to make the prior
mean depend on higher-level task characteristics. More unsupervised
clustering of tasks is obtained if we go from a single Gaussian prior
to a mixture of Gaussians. This can be further generalized to a
mixture of experts architecture with the gates depending on 
task characteristics.
&lt;/p&gt;
&lt;p&gt;
All three extensions are demonstrated through application both on an
artificial data set and on two real-world problems, one a school
problem and the other involving single-copy newspaper sales. 
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/bakker03a/bakker03a.pdf</url></Article><Article><id>105</id><title>Optimally-Smooth Adaptive Boosting and Application to Agnostic Learning</title><author>Dmitry Gavinsky</author><abstract>&lt;p&gt;
We describe a new boosting algorithm that is the first such algorithm to be
  both smooth and adaptive.
  These two features make possible performance improvements for many
  learning tasks whose solutions use a boosting technique.
&lt;/p&gt;
&lt;p&gt;
  The boosting approach was originally suggested for the standard PAC model;
  we analyze possible applications of boosting in the context of agnostic
  learning, which is more realistic than the PAC model.
  We derive a lower bound for the final error achievable by boosting in the
  agnostic model and show that our algorithm actually achieves that accuracy
  (within a constant factor).
&lt;/p&gt;
&lt;p&gt;
  We note that the idea of applying boosting in the agnostic model
  was first suggested by Ben-David, Long and Mansour (2001) and the solution they give
  is improved in the present paper.
  The accuracy we achieve is exponentially better with respect to the standard
  agnostic accuracy parameter &amp;beta;.
&lt;/p&gt;
&lt;p&gt;
  We also describe the construction of a boosting "tandem" whose asymptotic
  number of iterations is the lowest possible (in both &amp;gamma; and &amp;epsilon;
  and whose smoothness is optimal in terms of &lt;i&gt;&amp;#213;&lt;/i&gt;(&amp;#183;).
  This allows adaptively solving problems whose solution is based on smooth
  boosting (like noise tolerant boosting and DNF membership learning), while
  preserving the original (non-adaptive) solution's complexity.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/gavinsky03a/gavinsky03a.pdf</url></Article><Article><id>106</id><title>Think Globally, Fit Locally: Unsupervised Learning of Low Dimensional Manifolds</title><author>Lawrence K. Saul, Sam T. Roweis</author><abstract>The problem of dimensionality reduction arises in many fields of
information processing, including machine learning, data compression,
scientific visualization, pattern recognition, and neural computation.
Here we describe locally linear embedding (LLE), an unsupervised
learning algorithm that computes low dimensional, neighborhood
preserving embeddings of high dimensional data.  The data, assumed to
be sampled from an underlying manifold, are mapped 
into a single global coordinate
system of lower dimensionality.  The mapping is derived from the
symmetries of locally linear reconstructions, and the actual
computation of the embedding reduces to a sparse eigenvalue problem.
Notably, the optimizations in LLE---though capable of generating
highly nonlinear embeddings---are simple to implement, and they do not
involve local minima.  In this paper, we 
describe the implementation of the algorithm
in detail and discuss several extensions that enhance its performance.
We present results of the algorithm applied to data sampled from
known manifolds, as well as to collections of images of
faces, lips, and handwritten digits.  These examples
are used to provide extensive illustrations of
the algorithm's performance---both successes and failures---and 
to relate the algorithm to previous and ongoing work in 
nonlinear dimensionality reduction.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/saul03a/saul03a.pdf</url></Article><Article><id>107</id><title>On the Proper Learning of Axis-Parallel Concepts</title><author>Nader H. Bshouty, Lynn Burroughs</author><abstract>
&lt;p&gt;
We study the proper learnability of axis-parallel concept classes
in the PAC-learning and exact-learning models.
These classes include union of boxes, DNF, 
decision trees and multivariate polynomials.
&lt;/p&gt;
&lt;p&gt;
For &lt;i&gt;constant&lt;/i&gt;-dimensional axis-parallel concepts &lt;i&gt;C&lt;/i&gt; we show 
that the following problems have time complexities that are 
within a polynomial factor of each other.
&lt;ol&gt;
&lt;li&gt;
&lt;i&gt;C&lt;/i&gt; is &amp;alpha;-properly exactly learnable 
(with hypotheses of size
at most &amp;alpha; times the target size)
from membership and equivalence queries.
&lt;li&gt;
&lt;i&gt;C&lt;/i&gt; is &amp;alpha;-properly PAC learnable (without membership queries)
under any product distribution.
&lt;li&gt;
There is an &amp;alpha;-approximation algorithm 
for the MINEQUI&lt;i&gt;C&lt;/i&gt; problem (given a &lt;i&gt;g&lt;/i&gt; &amp;isin; &lt;i&gt;C&lt;/i&gt;
find a minimal size &lt;i&gt;f&lt;/i&gt; &amp;isin; &lt;i&gt;C&lt;/i&gt; that is logically equivalent to
&lt;i&gt;g&lt;/i&gt;).
&lt;/ol&gt;
&lt;/p&gt;
&lt;p&gt;
In particular, if one has polynomial time complexity, they all do.
Using this we give the first proper-learning algorithm
of constant-dimensional decision trees and
the first negative results in proper learning from membership
and equivalence queries for many classes.
&lt;/p&gt;
For axis-parallel concepts over a nonconstant dimension we show that 
with the equivalence oracle (1) &amp;rArr; (3). We use this to 
show that (binary) decision trees are not properly learnable in 
polynomial time (assuming P &amp;ne; NP) and DNF is not 
&lt;i&gt;s&lt;/i&gt;&lt;sup&gt;&amp;epsilon;&lt;/sup&gt;-properly learnable (&amp;epsilon; &lt; 1) in polynomial 
time even with an NP-oracle (assuming &amp;Sigma;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;&lt;i&gt;P&lt;/i&gt;&lt;/sup&gt;
  &amp;ne; &lt;i&gt;P&lt;/i&gt;&lt;sup&gt;&lt;i&gt;NP&lt;/i&gt;&lt;/sup&gt;).
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/bshouty03a/bshouty03a.pdf</url></Article><Article><id>108</id><title>Bottom-Up Relational Learning of Pattern Matching Rules for Information Extraction</title><author>Mary Elaine Califf, Raymond J. Mooney</author><abstract>
&lt;p&gt;
Information extraction is a form of shallow text processing that locates a
specified set of relevant items in a natural-language document. Systems for
this task require significant domain-specific knowledge and are time-consuming
and difficult to build by hand, making them a good application for machine
learning.  We present an algorithm, RAPIER, that uses pairs of
sample documents and filled templates to induce pattern-match rules that
directly extract fillers for the slots in the template.  RAPIER is a
bottom-up learning algorithm that incorporates techniques from several
inductive logic programming systems.  We have 
implemented the algorithm in a system that allows patterns to have
constraints on the words, part-of-speech tags, and semantic classes
present in the filler and the surrounding text.  We present encouraging
experimental results on two domains.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/califf03a/califf03a.pdf</url></Article><Article><id>109</id><title>Tree Induction vs. Logistic Regression: A Learning-Curve Analysis</title><author>Claudia Perlich, Foster Provost, Jeffrey S. Simonoff</author><abstract>
Tree induction and logistic regression are two standard,
off-the-shelf methods for building models for classification.  We
present a large-scale experimental comparison of logistic regression
and tree induction, assessing classification accuracy and the quality
of rankings based on class-membership probabilities.  We use a
learning-curve analysis to examine the relationship of these measures
to the size of the training set.  The results of the study show
several things.  (1) Contrary to some prior observations,
logistic regression does not generally outperform tree induction.  (2)
More specifically, and not surprisingly, logistic regression is better
for smaller training sets and tree induction for larger data sets.
Importantly, this often holds for training sets drawn from the same
domain (that is, the learning curves cross), so conclusions about
induction-algorithm superiority on a given domain must be based on an
analysis of the learning curves. (3) Contrary to conventional wisdom,
tree induction is effective at producing probability-based rankings,
although apparently comparatively less so for a given training-set
size than at making classifications.  Finally, (4) the domains on
which tree induction and logistic regression are ultimately preferable
can be characterized surprisingly well by a simple measure of
the separability of signal from noise.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/perlich03a/perlich03a.pdf</url></Article><Article><id>110</id><title>Learning Probabilistic Models: An Expected Utility Maximization Approach</title><author>Craig Friedman, Sven Sandow</author><abstract>We consider the problem of learning a probabilistic model from the viewpoint of an expected utility maximizing decision maker/investor who would use the model to make decisions (bets), which result in well defined payoffs.
In our new approach, we seek good out-of-sample model performance by
      considering a one-parameter family of Pareto optimal models,
      which we define in terms of consistency with the training data
      and consistency with a prior (benchmark) model. We measure the
      former by means of the large-sample distribution of a vector of
      sample-averaged features, and the latter by means of a
      generalized relative entropy.
We express each Pareto optimal model as the solution of a strictly convex optimization problem and its strictly concave (and tractable) dual.  Each dual problem is a regularized maximization of expected utility over a well-defined family of functions.
Each Pareto optimal model is robust: maximizing worst-case outperformance relative to the benchmark model.
Finally, we select the Pareto optimal model with maximum (out-of-sample) expected utility.
We show that our method reduces to the minimum relative entropy method if and only if the utility function is a member of a three-parameter logarithmic family.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/friedman03a/friedman03a.pdf</url></Article><Article><id>111</id><title>Combining Knowledge from Different Sources in Causal Probabilistic Models</title><author>Marek J. Druzdzel, Francisco J. D&amp;iacute;ez</author><abstract>Building probabilistic and decision-theoretic models requires a
considerable knowledge engineering effort in which the most
daunting task is obtaining the numerical parameters. Authors of
Bayesian networks usually combine various sources of information,
such as textbooks, statistical reports, databases, and expert
judgement. In this paper, we demonstrate the risks of such a
combination, even when this knowledge encompasses such seemingly
population-independent characteristics as sensitivity and
specificity of medical symptoms. We show that the criteria ``do
not combine knowledge from different sources'' or ``use only data
from the setting in which the model will be used'' are neither
necessary nor sufficient to guarantee the correctness of the
model. Instead, we offer graphical criteria for determining when
knowledge from different sources can be safely combined into the
general population model. We also offer a method for building
subpopulation models. The analysis performed in this paper and the
criteria we propose may be useful in such fields  as knowledge
engineering, epidemiology, machine learning, and statistical
meta-analysis.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/druzdzel03a/druzdzel03a.pdf</url></Article><Article><id>112</id><title>Preference Elicitation via Theory Refinement</title><author>Peter Haddawy, Vu Ha, Angelo Restificar, Benjamin Geisler, John Miyamoto</author><abstract>We present an approach to elicitation of user preference models in which assumptions can be used
to guide but not constrain the elicitation process. We demonstrate that when domain knowledge is
available, even in the form of weak and somewhat inaccurate assumptions, significantly less data
is required to build an accurate model of user preferences than when no domain knowledge is
provided. This approach is based on the KBANN (Knowledge-Based Artificial Neural Network)
algorithm pioneered by Shavlik and Towell (1989). We demonstrate this
approach through two examples, one involves preferences under certainty, and the other involves
preferences under uncertainty. In the case of certainty, we show how to encode assumptions
concerning preferential independence and monotonicity in a KBANN network, which can be trained
using a variety of preferential information including simple binary classification. In the case of
uncertainty, we show how to construct a KBANN network that encodes certain types of dominance
relations and attitude toward risk. The resulting network can be trained using answers to standard
gamble questions and can be used as an approximate representation of a person's preferences. We
empirically evaluate our claims by comparing the KBANN networks with simple backpropagation
artificial neural networks in terms of learning rate and accuracy. For the case of uncertainty,
the answers to standard gamble questions used in the experiment are taken from an actual medical
data set first used by Miyamoto and Eraker (1988). In the case of
certainty, we define a measure to which a set of preferences violate a domain theory, and examine
the robustness of the KBANN network as this measure of domain theory violation varies.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/haddawy03a/haddawy03a.pdf</url></Article><Article><id>113</id><title>Fusion of Domain Knowledge with Data for Structural Learning in Object Oriented Domains</title><author>Helge Langseth, Thomas D. Nielsen</author><abstract>&lt;p&gt;
  When constructing a Bayesian network, it can be advantageous to
  employ structural learning algorithms to combine knowledge
  captured in databases with prior information provided by domain
  experts. Unfortunately, conventional learning algorithms do not
  easily incorporate prior information, if this information is too
  vague to be encoded as properties that are local to families of
  variables. For instance, conventional algorithms do not exploit
  prior information about repetitive structures, which are often found
  in object oriented domains such as computer networks, large
  pedigrees and genetic analysis.
&lt;/p&gt;
&lt;p&gt;
  In this paper we propose a method for doing structural
  learning in object oriented domains. It is demonstrated that this
  method is more efficient than conventional algorithms in such
  domains, and it is argued that the method supports a natural approach for
  expressing and incorporating prior information provided by
  domain experts.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/langseth03a/langseth03a.pdf</url></Article><Article><id>114</id><title>An Empirical Study of the Use of Relevance Information in Inductive Logic Programming</title><author>Ashwin Srinivasan, Ross D. King, Michael E. Bain</author><abstract>Inductive Logic Programming (ILP) systems construct models
for data using domain-specific background information.
When using these systems, it is typically assumed that
sufficient human expertise is at hand to rule out
irrelevant background information. Such irrelevant information can, and
typically does, hinder an ILP system's search for good models.
Here, we provide evidence that if expertise
is available that can provide a partial-ordering
on sets of background predicates in terms of
relevance to the analysis task, then this can be used to good effect by
an ILP system. In particular, using data from biochemical domains,
we investigate an incremental strategy of including sets of predicates
in decreasing order of relevance. Results obtained suggest that:
(a) the incremental approach identifies, in substantially less time,
a model that is comparable in predictive accuracy to that
obtained with all background information in place; and
(b) the incremental approach using the relevance ordering performs
better than one that does not (that is, one that adds sets
of predicates randomly).
For a practitioner concerned with use of ILP,
the implication of these findings are two-fold:
(1) when not all background information can be used
at once (either due to limitations of the ILP system, or
the nature of the domain) expert assessment of the relevance
of background predicates can assist substantially
in the construction of good models; and
(2) good "first-cut" results can be obtained quickly by a simple exclusion of
information known to be less relevant.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/srinivasan03a/srinivasan03a.pdf</url></Article><Article><id>115</id><title>An Empirical Study of the Use of Relevance Information in Inductive Logic Programming</title><author>Ashwin Srinivasan, Ross D. King, Michael E. Bain</author><abstract>
Inductive Logic Programming (ILP) systems construct models
for data using domain-specific background information.
When using these systems, it is typically assumed that
sufficient human expertise is at hand to rule out
irrelevant background information. Such irrelevant information can, and
typically does, hinder an ILP system's search for good models.
Here, we provide evidence that if expertise
is available that can provide a partial-ordering
on sets of background predicates in terms of
relevance to the analysis task, then this can be used to good effect by
an ILP system. In particular, using data from biochemical domains,
we investigate an incremental strategy of including sets of predicates
in decreasing order of relevance. Results obtained suggest that:
(a) the incremental approach identifies, in substantially less time,
a model that is comparable in predictive accuracy to that
obtained with all background information in place; and
(b) the incremental approach using the relevance ordering performs
better than one that does not (that is, one that adds sets
of predicates randomly).
For a practitioner concerned with use of ILP,
the implication of these findings are two-fold:
(1) when not all background information can be used
at once (either due to limitations of the ILP system, or
the nature of the domain) expert assessment of the relevance
of background predicates can assist substantially
in the construction of good models; and
(2) good "first-cut" results can be obtained quickly by a simple exclusion of
information known to be less relevant.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/srinivasan03a/rev1/srinivasan03ar1.pdf</url></Article><Article><id>116</id><title>Learning Behavior-Selection by Emotions and Cognition in a Multi-Goal Robot Task</title><author>Sandra Clara Gadanho</author><abstract>&lt;p&gt;
  The existence of emotion and cognition as two interacting systems,
  both with important roles in decision-making, has been recently
  advocated by neurophysiological research
  (LeDoux, 1998, Damasio, 1994.  Following that idea, this paper
  presents the ALEC agent architecture which has both emotive and
  cognitive learning, as well as emotive and cognitive decision-making
  capabilities to adapt to real-world environments.  These two
  learning mechanisms embody very different properties which can be
  related to those of natural emotion and cognition systems.
&lt;/p&gt;
&lt;p&gt;
  The reported experiments test ALEC  within a simulated autonomous
  robot which learns to perform a multi-goal and multi-step survival
  task when faced with real world conditions, namely continuous time
  and space, noisy sensors and unreliable actuators.  Experimental
  results show that both systems contribute positively to the
  learning performance of the agent.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/gadanho03a/gadanho03a.pdf</url></Article><Article><id>117</id><title>ILP: A Short Look Back and a Longer Look Forward</title><author>David Page, Ashwin Srinivasan</author><abstract>Inductive logic programming (ILP) is built on a foundation laid by
research in machine learning and computational logic.
Armed with this strong foundation, ILP has been applied
to important and interesting problems in the life sciences, 
engineering and the arts.
This paper begins by briefly reviewing some example applications, in order
to illustrate the benefits of ILP.
In turn, the applications have brought
into focus the need for more research into specific topics.
We enumerate and elaborate five of these: (1) novel search methods;
(2) incorporation of explicit probabilities; (3) incorporation
of special-purpose reasoners; (4) parallel execution using
commodity components; and (5) enhanced human interaction.
It is our hypothesis that progress in each of these areas
can greatly improve the contributions that can be made with ILP;
and that, with assistance from research workers in other areas,
significant progress in each of these areas is possible.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/page03a/page03a.pdf</url></Article><Article><id>118</id><title>Relational Learning as Search in a Critical Region</title><author>Marco Botta, Attilio Giordana, Lorenza Saitta, Mich&amp;egrave;le Sebag</author><abstract>Machine learning strongly relies on the covering test to assess whether&#13;
a candidate hypothesis covers training examples. &#13;
The present paper investigates learning relational concepts &#13;
from examples, termed &lt;em&gt;relational learning&lt;/em&gt; or &lt;em&gt;inductive logic&#13;
programming&lt;/em&gt;. In particular, it investigates the chances of success&#13;
and the computational cost of relational learning, which appears to be severely&#13;
affected by the presence of a phase transition in the covering test.&#13;
To this aim, three up-to-date relational learners &#13;
have been applied to a wide range of artificial, fully relational&#13;
learning problems.&#13;
A first experimental observation is that &#13;
the phase transition behaves as an attractor &#13;
for relational learning; no matter which region the learning &#13;
problem belongs to,&#13;
all three learners produce hypotheses lying within or close to the phase&#13;
transition region.&#13;
Second, a &lt;em&gt;failure region&lt;/em&gt; appears. All three learners fail to learn any &#13;
accurate hypothesis in this region. &#13;
Quite surprisingly, the probability of failure does not &#13;
systematically increase with the size of the underlying target concept: &#13;
under some circumstances, &#13;
longer concepts may be easier to accurately approximate &#13;
than shorter ones. Some  interpretations for these findings are proposed and discussed.&#13;
&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/botta03a/botta03a.pdf</url></Article><Article><id>119</id><title>Query Transformations for Improving the Efficiency of ILP Systems</title><author>V&amp;iacute;tor Santos Costa, Ashwin Srinivasan, Rui Camacho, Hendrik Blockeel, Bart Demoen, Gerda Janssens, Jan Struyf, Henk Vandecasteele, Wim Van Laer</author><abstract>Relatively simple transformations can speed up the execution of
queries for data mining considerably.  While some ILP systems use such
transformations, relatively little is known about them or
how they relate to each other.  This paper describes a number of such transformations.
Not all of them are novel, but there have been no studies comparing their
efficacy.  The main contributions of the
paper are: (a) it clarifies the relationship between the transformations;
(b) it contains an empirical study of what can be gained by applying the transformations;
and (c) it provides some guidance on the kinds of problems that are likely to
benefit from the transformations.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/costa03a/costa03a.pdf</url></Article><Article><id>120</id><title>Learning Semantic Lexicons from a Part-of-Speech and Semantically Tagged Corpus Using Inductive Logic Programming</title><author>Vincent Claveau, Pascale S&amp;eacute;billot, C&amp;eacute;cile Fabre, Pierrette Bouillon</author><abstract>This paper describes an inductive logic programming learning method designed to
acquire from a corpus specific Noun-Verb (N-V) pairs---relevant in information
retrieval applications to perform index expansion---in
order to build up semantic lexicons based on Pustejovsky's generative lexicon
(GL) principles (Pustejovsky, 1995). In one of the components of this lexical model,
called the &lt;em&gt;qualia structure&lt;/em&gt;, words are described in terms of semantic
roles. For example, the &lt;em&gt;telic&lt;/em&gt; role indicates the purpose or function of
an item (&lt;em&gt;cut&lt;/em&gt; for &lt;em&gt;knife&lt;/em&gt;), the agentive role its creation mode
(&lt;em&gt;build&lt;/em&gt; for &lt;em&gt;house&lt;/em&gt;), etc. The qualia structure of a noun is
mainly made up of verbal associations, encoding relational information. The
learning method enables us to
automatically extract, from a morpho-syntactically and semantically tagged
corpus, N-V pairs whose elements are linked by one of the semantic relations
defined in the qualia structure in GL. It also infers rules explaining what in
the surrounding context distinguishes such pairs from others also
found in sentences of the corpus but which are not relevant. Stress is put here on the
learning efficiency that is required to be able to deal with all the available
contextual information, and to produce linguistically meaningful rules.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/claveau03a/claveau03a.pdf</url></Article><Article><id>121</id><title>On Inclusion-Driven Learning of Bayesian Networks</title><author>Robert Castelo, Tom&amp;aacute;s Kocka</author><abstract>&lt;p&gt;
Two or more Bayesian network structures are Markov equivalent when the
corresponding acyclic digraphs encode the same set of conditional
independencies. Therefore, the search space of Bayesian network structures may
be organized in equivalence classes, where each of them represents a
different set of conditional independencies. The collection of sets of
conditional independencies obeys a partial order, the so-called "inclusion
order."
&lt;/p&gt;
&lt;p&gt;
This paper discusses in depth the role that the inclusion order plays in
learning the structure of Bayesian networks. In particular, this role involves
the way a learning algorithm traverses the search space. We introduce a
condition for traversal operators, the &lt;em&gt;inclusion boundary condition&lt;/em&gt;,
which, when it is satisfied, guarantees that the search strategy can avoid
local maxima. This is proved under the assumptions that the data is sampled
from a probability distribution which is &lt;em&gt;faithful&lt;/em&gt; to an acyclic digraph,
and the length of the sample is unbounded.
&lt;/p&gt;
&lt;p&gt;
The previous discussion leads to the design of a new traversal operator and
two new learning algorithms in the context of heuristic search and the Markov
Chain Monte Carlo method. We carry out a set of experiments with synthetic and
real-world data that show empirically the benefit of striving for the
inclusion order when learning Bayesian networks from data.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/castelo03a/castelo03a.pdf</url></Article><Article><id>122</id><title>The Principled Design of Large-Scale Recursive Neural Network Architectures--DAG-RNNs and the Protein Structure Prediction Problem</title><author>Pierre Baldi, Gianluca Pollastri</author><abstract>We describe a general methodology for the design of large-scale recursive neural network architectures (DAG-RNNs) which comprises three fundamental steps: (1) representation of a given domain using suitable 
directed acyclic graphs (DAGs) to connect visible and hidden node variables; (2) parameterization of the relationship between each variable and its parent variables by feedforward neural networks; and (3) application of weight-sharing within appropriate subsets of DAG connections to capture stationarity and control model complexity. Here we use these principles to derive several &lt;em&gt;specific&lt;/em&gt; classes of DAG-RNN architectures based on lattices, trees, and other structured graphs. These architectures can process a wide range of data structures with variable sizes and dimensions. While the overall resulting models remain probabilistic, the internal deterministic dynamics allows efficient propagation of information, as well as training by gradient descent, 
in order to tackle large-scale problems. These methods are used here to derive
state-of-the-art predictors for protein structural features such as secondary structure (1D) and both fine- and coarse-grained contact maps
(2D). 
Extensions, relationships to graphical models, and implications for
    the design of neural architectures are briefly discussed. The
    protein prediction servers are available over the Web at:  &lt;a
                  target=_new href="http://www.igb.uci.edu/tools.htm"&gt;www.igb.uci.edu/tools.htm&lt;/a&gt;.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/baldi03a/baldi03a.pdf</url></Article><Article><id>123</id><title>Inducing Grammars from Sparse Data Sets: A Survey of Algorithms and Results</title><author>Orlando Cicchello, Stefan C. Kremer</author><abstract>This paper provides a comprehensive survey of the field of grammar induction 
applied to randomly generated languages using sparse example sets.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/cicchello03a/cicchello03a.pdf</url></Article><Article><id>124</id><title>Smooth Boosting and Learning with Malicious Noise</title><author>Rocco A. Servedio</author><abstract>We describe a new boosting algorithm which generates only smooth
distributions which do not assign too much weight to any single example.  
We show that this new boosting algorithm can be used to construct
efficient PAC learning algorithms which tolerate relatively high rates of
malicious noise.  In particular, we use the new smooth boosting algorithm
to construct malicious noise tolerant versions of the PAC-model &lt;i&gt;p&lt;/i&gt;-norm
linear threshold learning algorithms described by Servedio (2002).
The bounds on sample complexity and malicious noise tolerance of these new
PAC algorithms closely correspond to known bounds for the online &lt;i&gt;p&lt;/i&gt;-norm
algorithms of Grove, Littlestone and Schuurmans (1997)
and Gentile and Littlestone (1999).
As special cases of our new
algorithms we obtain linear threshold learning algorithms which match the
sample complexity and malicious noise tolerance of the online Perceptron
and Winnow algorithms.  Our analysis reveals an interesting connection
between boosting and noise tolerance in the PAC setting.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/servedio03a/servedio03a.pdf</url></Article><Article><id>125</id><title>Speedup Learning for Repair-based Search by Identifying Redundant Steps</title><author>Shaul Markovitch, Asaf Shatil</author><abstract>&lt;p&gt;Repair-based search algorithms start with an initial solution and
attempt to improve it by iteratively applying repair operators.
Such algorithms can often handle large-scale problems that may be
difficult for systematic search algorithms. Nevertheless, the
computational cost of solving such problems is still very high.
We observed that many of the repair steps applied by such
algorithms are redundant in the sense that they do not eventually
contribute to finding a solution. Such redundant steps are
particularly harmful in repair-based search, where each step
carries high cost due to the very high branching factor typically
associated with it.
&lt;/p&gt;
&lt;p&gt;
Accurately identifying and avoiding such redundant steps would
result in faster local search without harming the algorithm's
problem-solving ability. In this paper we propose a speedup
learning methodology for attaining this goal. It consists of the
following steps: defining the concept of a &lt;em&gt;redundant step&lt;/em&gt;;
acquiring this concept during off-line learning by analyzing
solution paths for training problems, tagging all the steps along
the paths according to the redundancy definition and using an
induction algorithm to infer a classifier based on the tagged
examples; and using the acquired classifier to filter out redundant
steps while solving unseen problems.
&lt;/p&gt;
&lt;p&gt;
Our algorithm was empirically tested on instances of real-world
employee timetabling problems (ETP). The problem solver to be
improved is based on one of the best methods for solving some
large ETP instances. Our results show a significant improvement
in speed for test problems that are similar to the given example
problems.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/markovitch03a/markovitch03a.pdf</url></Article><Article><id>126</id><title>Comparing Bayes Model Averaging and Stacking When Model Approximation Error Cannot be Ignored</title><author>Bertrand Clarke</author><abstract>&lt;p&gt;
We compare Bayes Model Averaging, BMA, to a non-Bayes form of model
averaging called stacking.  In stacking, the weights are no longer 
posterior probabilities of models; they are obtained by a 
technique based on cross-validation.  When the correct data generating 
model (DGM) is on the list of
models under consideration BMA is never worse than
stacking and often is demonstrably better, provided that
the noise level is of order commensurate with the coefficients and
explanatory variables.
Here, however, we focus on the case that the correct DGM is not 
on the model list and may not be well 
approximated by the elements on the model list.
&lt;/p&gt;
&lt;p&gt;
We give a sequence of computed examples by choosing model lists and 
DGM's to contrast the risk performance of stacking and BMA.  
In the first examples, the model 
lists are chosen to reflect geometric principles that should
give good performance.  In these cases, stacking typically outperforms 
BMA, sometimes by a wide margin. 
In the second set of examples we examine how stacking and BMA 
perform when the model list
includes all subsets of a set of potential predictors.
When we standardize the size of terms and coefficients in this
setting, we find that BMA 
outperforms stacking when the deviant terms in the DGM 'point' in 
directions accommodated by the model list but that when the deviant term
points outside the model list stacking seems to do better.
&lt;/p&gt;
&lt;p&gt;
Overall, our results suggest the stacking has better robustness
properties than BMA in the most important settings.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/clarke03a/clarke03a.pdf</url></Article><Article><id>127</id><title>Greedy Algorithms for Classification -- Consistency, Convergence Rates, and Adaptivity</title><author>Shie Mannor, Ron Meir, Tong Zhang</author><abstract>Many regression and classification algorithms proposed over the years can be described as greedy procedures for the stagewise&#13;
minimization of an appropriate cost function. Some examples&#13;
include additive models, matching pursuit, and boosting. In this&#13;
work we focus on the classification problem, for which many recent&#13;
algorithms have been proposed and applied successfully. For a&#13;
specific regularized form of greedy stagewise optimization, we&#13;
prove consistency of the approach under rather general conditions.&#13;
Focusing on specific classes of problems we provide conditions&#13;
under which our greedy procedure achieves the (nearly) minimax&#13;
rate of convergence, implying that the procedure cannot be&#13;
improved in a worst case setting. We also construct a fully&#13;
adaptive procedure, which, without knowing the smoothness&#13;
parameter of the decision boundary, converges at the same rate as&#13;
if the smoothness parameter were known.&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/mannor03a/mannor03a.pdf</url></Article><Article><id>128</id><title>Tree-Structured Neural Decoding</title><author>Christian d'Avignon, Donald Geman</author><abstract>We propose adaptive testing as a general mechanism for extracting
information about stimuli from spike trains.  Each test or question
corresponds to choosing a neuron and a time interval and checking for
a given number of spikes.  No assumptions are made about the
distribution of spikes or any other aspect of neural encoding.  The
chosen questions are those which most reduce the uncertainty about the
stimulus, as measured by entropy and estimated from stimulus-response
data.  Our experiments are based on accurate simulations of responses
to pure tones in the auditory nerve and are meant to illustrate the
ideas rather than investigate the auditory system.  The results cohere
nicely with well-understood encoding of amplitude and frequency in the
auditory nerve, suggesting that adaptive testing might provide a
powerful tool for investigating complex and poorly understood neural
structures.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/davignon03a/davignon03a.pdf</url></Article><Article><id>129</id><title>On the Performance of Kernel Classes</title><author>Shahar Mendelson</author><abstract>We present sharp bounds on the localized Rademacher averages of
the unit ball in a reproducing kernel Hilbert space in terms of
the eigenvalues of the integral operator associated with the
kernel. We use this result to estimate the performance of the
empirical minimization algorithm when the base class is the unit
ball of the reproducing kernel Hilbert space.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/mendelson03a/mendelson03a.pdf</url></Article><Article><id>130</id><title>Path Kernels and Multiplicative Updates</title><author>Eiji Takimoto, Manfred K. Warmuth</author><abstract>&lt;p&gt;Kernels are typically applied to linear algorithms
whose weight vector is a linear combination
of the feature vectors of the examples.
On-line versions of these algorithms are sometimes
called "additive updates" because they add a multiple of the last
feature vector to the current weight vector.
&lt;/p&gt;
&lt;p&gt;
In this paper we have found a way to use special convolution
kernels to efficiently implement "multiplicative" updates.
The kernels are defined by a directed graph.
Each edge contributes an input.
The inputs along a path form a product feature and
all such products build the feature vector associated
with the inputs.
We also have a set of probabilities on the edges so
that the outflow from each vertex is one.
We then discuss multiplicative updates on these
graphs where the prediction is essentially a kernel
computation and the update contributes a factor to each edge.
After adding the factors to the edges,
the total outflow out of each vertex is not
one any more. However some clever algorithms re-normalize
the weights on the paths so that the total
outflow out of each vertex is one again.
Finally, we show that if the digraph is built
from a regular expressions, then this can
be used for speeding
up the kernel and re-normalization computations.
&lt;/p&gt;
&lt;p&gt;
We reformulate a large number of multiplicative
update algorithms using path kernels
and characterize the applicability of our method.
The examples include
efficient algorithms for learning disjunctions
and a recent algorithm that predicts as well
as the best pruning of a series parallel digraphs.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/takimoto03a/takimoto03a.pdf</url></Article><Article><id>131</id><title>Tracking Linear-threshold Concepts with Winnow</title><author>Chris Mesterharm</author><abstract>  In this paper, we give a mistake-bound for learning arbitrary
  linear-threshold concepts that are allowed to change over time in
  the on-line model of learning.  We use a variation of the Winnow
  algorithm and show that the bounds for learning shifting
  linear-threshold functions have many of the same advantages that the
  traditional Winnow algorithm has on fixed concepts.  These benefits
  include a weak dependence on the number of irrelevant attributes,
  inexpensive runtime, and robust behavior against noise.  In fact, we
  show that the bound for tracking Winnow has even better performance
  with respect to irrelevant attributes.  Let &lt;i&gt;X&lt;/i&gt;&amp;isin;[0,1]&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; be an
  instance of the learning problem.  In the previous bounds, the
  number of mistakes depends on ln&lt;i&gt;n&lt;/i&gt;.  In this paper, the shifting
  concept bound depends on max ln(||&lt;i&gt;X&lt;/i&gt;||&lt;sub&gt;1&lt;/sub&gt;).  We show that
  this behavior is a result of certain parameter choices in the
  tracking version of Winnow, and we show how to use related
  parameters to get a similar mistake bound for the traditional
  fixed concept version of Winnow.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/mesterharm03a/mesterharm03a.pdf</url></Article><Article><id>132</id><title>Generalization Error Bounds for Bayesian Mixture Algorithms</title><author>Ron Meir, Tong Zhang</author><abstract>Bayesian approaches to learning and estimation have played a
significant role in the Statistics literature over many years.
While they are often provably optimal in a frequentist setting,
and lead to excellent performance in practical applications, there
have not been many precise characterizations of their performance
for finite sample sizes under general conditions. In this paper we
consider the class of Bayesian mixture algorithms, where an
estimator is formed by constructing a data-dependent mixture over
some hypothesis space. Similarly to what is observed in practice,
our results demonstrate that mixture approaches are particularly
robust, and allow for the construction of highly complex
estimators, while avoiding undesirable overfitting effects. Our
results, while being data-dependent in nature, are insensitive to
the underlying model assumptions, and apply whether or not these
hold. At a technical level, the approach applies to unbounded
functions, constrained only by certain moment conditions. Finally,
the bounds derived can be directly applied to non-Bayesian mixture
approaches such as Boosting and Bagging.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/meir03a/meir03a.pdf</url></Article><Article><id>133</id><title>On the Rate of Convergence of Regularized Boosting Classifiers</title><author>Gilles Blanchard, G&amp;aacute;bor Lugosi, Nicolas Vayatis</author><abstract>A regularized boosting method is introduced, for which regularization
is obtained through a penalization function. It is shown through
oracle inequalities that this method is model adaptive.  The rate of
convergence of the probability of misclassification is investigated.
It is shown that for
quite a large class of distributions, the probability of error
converges to the Bayes risk at a rate
faster than &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;-(&lt;i&gt;V&lt;/i&gt;+2)/(4(&lt;i&gt;V&lt;/i&gt;+1))&lt;/sup&gt; where &lt;i&gt;V&lt;/i&gt; is the VC dimension
of the "base" class whose elements are combined by boosting methods
to obtain an aggregated classifier.  The dimension-independent nature
of the rates may partially explain the good behavior of these methods
in practical problems. Under Tsybakov's noise condition the rate of
convergence is even faster. We investigate the conditions necessary to
obtain such rates for different base classes.  The special case of
boosting using decision stumps is studied in detail. We characterize
the class of classifiers realizable by aggregating decision stumps. It
is shown that some versions of boosting work especially well in
high-dimensional logistic additive models.  It appears that adding a
limited labelling noise to the training data may in certain cases
improve the convergence, as has been also suggested by other authors.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/blanchard03a/blanchard03a.pdf</url></Article><Article><id>134</id><title>Concentration Inequalities for the Missing Mass and for Histogram Rule Error</title><author>David McAllester, Luis Ortiz</author><abstract>This paper gives distribution-free concentration
inequalities for the missing mass and the error rate of histogram rules.
Negative association methods can be used to reduce these concentration
problems to concentration questions about independent sums.  Although
the sums are independent, they are highly heterogeneous.  Such
highly heterogeneous independent sums cannot be analyzed using standard
concentration inequalities such as Hoeffding's inequality, the
Angluin-Valiant bound, Bernstein's inequality, Bennett's inequality,
or McDiarmid's theorem.  The concentration inequality for histogram rule error
is motivated by the desire to construct a new class of bounds on the generalization
error of decision trees.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/mcallester03a/mcallester03a.pdf</url></Article><Article><id>135</id><title>Learning over Sets using Kernel Principal Angles</title><author>Lior Wolf, Amnon Shashua</author><abstract>&lt;p&gt;
We consider the problem of learning  with instances defined over a space of
sets of vectors. We derive a new positive definite kernel &lt;i&gt;f&lt;/i&gt;(&lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt;) defined over
pairs of matrices &lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt; based on the concept of principal angles between two
linear subspaces. We show that the principal angles can be recovered
using only inner-products between pairs of column vectors of the input
matrices thereby allowing the original column vectors of &lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt; to be
mapped onto arbitrarily high-dimensional feature spaces. 
&lt;/p&gt;
&lt;p&gt;
We demonstrate the usage of the matrix-based kernel function &lt;i&gt;f&lt;/i&gt;(&lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt;)
with experiments on two visual tasks. The first task 
is the discrimination of "irregular" motion trajectory of an individual or a
group of individuals in a video sequence. We use the SVM approach
using &lt;i&gt;f&lt;/i&gt;(&lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt;) where an input matrix
represents the motion trajectory of a group of individuals over a
certain (fixed) time frame. We show that the classification
(irregular versus regular) greatly outperforms the
conventional representation where all the trajectories form a single
vector. The second application is the visual recognition of faces from
input video sequences representing head motion and facial expressions
where &lt;i&gt;f&lt;/i&gt;(&lt;i&gt;A&lt;/i&gt;,&lt;i&gt;B&lt;/i&gt;) is used to compare two image sequences.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/wolf03a/wolf03a.pdf</url></Article><Article><id>136</id><title>An Efficient Boosting Algorithm for Combining Preferences</title><author>Yoav Freund, Raj Iyer, Robert E. Schapire, Yoram Singer</author><abstract>We study the problem of learning to accurately rank a set of objects
by combining a given collection of ranking or preference functions.
This problem of combining preferences arises in several applications,
such as that of combining the results of different search engines, or
the "collaborative-filtering" problem of ranking movies for a user
based on the movie rankings provided by other users.
In this work, we begin by presenting a formal framework for this
general problem.
We then describe and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine
learning.
We give theoretical results describing the algorithm's behavior both
on the training data, and on new test data not seen during training.
We also describe an efficient implementation of the
algorithm for a particular restricted but common case.
We next discuss two experiments we carried
out to assess the performance of RankBoost. In the first experiment,
we used the algorithm to combine different web search strategies, each of
which is a query expansion for a given domain.
The second experiment is a collaborative-filtering task
for making movie recommendations.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/freund03a/freund03a.pdf</url></Article><Article><id>137</id><title>Optimality of Universal Bayesian Sequence Prediction for General Loss and Alphabet</title><author>Marcus Hutter</author><abstract>Various optimality properties of universal sequence predictors
based on Bayes-mixtures in general, and Solomonoff's prediction
scheme in particular, will be studied.

The probability of observing &lt;i&gt;x&lt;/i&gt;&lt;sub&gt;&lt;i&gt;t&lt;/i&gt;&lt;/sub&gt; at time &lt;i&gt;t&lt;/i&gt;, given past
observations &lt;i&gt;x&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;...&lt;i&gt;x&lt;/i&gt;&lt;sub&gt;&lt;i&gt;t&lt;/i&gt;-1&lt;/sub&gt; can be computed with the chain rule
if the true generating distribution &amp;mu; of the sequences
&lt;i&gt;x&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;i&gt;x&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;i&gt;x&lt;/i&gt;&lt;sub&gt;3&lt;/sub&gt;.... is known. If &amp;mu; is unknown, but known to belong
to a countable or continuous class &amp;Mu; one can base ones
prediction on the Bayes-mixture &amp;xi; defined as a
&lt;i&gt;w&lt;/i&gt;&lt;sub&gt;&amp;nu;&lt;/sub&gt;-weighted sum or integral of distributions &amp;nu;
&amp;isin; &amp;Mu;. The
cumulative expected loss of the Bayes-optimal universal prediction
scheme based on &amp;xi; is shown to be close to the loss of the
Bayes-optimal, but infeasible prediction scheme based on &amp;mu;. We
show that the bounds are tight and that no other predictor can
lead to significantly smaller bounds.

Furthermore, for various performance measures, we show
Pareto-optimality of &amp;xi; and give an Occam's razor argument that
the choice &lt;i&gt;w&lt;/i&gt;&lt;sub&gt;&amp;nu;&lt;/sub&gt; &amp;sim 2&lt;sup&gt;-&lt;i&gt;K&lt;/i&gt;(&amp;nu;)&lt;/sup&gt; for the weights is optimal,
where &lt;i&gt;K&lt;/i&gt;(&amp;nu;) is the length of the shortest program describing
&amp;nu;.

The results are applied to games of chance, defined as a sequence
of bets, observations, and rewards.

The prediction schemes (and bounds) are compared to the popular
predictors based on expert advice.

Extensions to infinite alphabets, partial, delayed and
probabilistic prediction, classification, and more active systems
are briefly discussed.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/hutter03a/hutter03a.pdf</url></Article><Article><id>138</id><title>A Unified Framework for Model-based Clustering</title><author>Shi Zhong, Joydeep Ghosh</author><abstract>Model-based clustering techniques have been widely used and
have shown promising results in many applications involving complex data.
This paper presents a unified framework for probabilistic model-based
clustering based on a bipartite graph view of data and models
that highlights the commonalities and differences among existing
model-based clustering algorithms.
In this view, clusters are represented as probabilistic models in
a model space that is conceptually separate from the data space.
For partitional clustering, the view is conceptually similar
to the Expectation-Maximization (EM) algorithm.
For hierarchical clustering, the graph-based view helps to visualize
critical/important distinctions
between similarity-based approaches and model-based approaches.
The framework also suggests several useful variations of existing
clustering algorithms.
Two new variations---balanced model-based clustering and hybrid
model-based clustering---are discussed and empirically evaluated
on a variety of data types.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/zhong03a/zhong03a.pdf</url></Article><Article><id>139</id><title>Nash Q-Learning for General-Sum Stochastic Games</title><author>Junling Hu, Michael P. Wellman</author><abstract>We extend Q-learning to a noncooperative multiagent context, using the
framework of general-sum stochastic games.  A learning agent maintains
Q-functions over joint actions, and performs updates based on assuming
Nash equilibrium behavior over the current Q-values.  This learning
protocol provably converges given certain restrictions on the stage
games (defined by Q-values) that arise during learning.  Experiments with a pair of two-player
grid games suggest that such restrictions on the game structure are
not necessarily required.  
Stage games encountered during learning in both grid environments violate the conditions.
However, learning
consistently converges in the first grid game, which has a unique
equilibrium Q-function, but sometimes fails to converge in the
second, which has three different equilibrium Q-functions.
In a comparison of offline learning performance in
both games, we find agents are more likely to reach a joint optimal
path with Nash Q-learning than with a single-agent Q-learning
method.  When at least one agent adopts Nash Q-learning,
the performance of both agents is better than using single-agent
Q-learning.  We have also implemented an online version of Nash
Q-learning that balances exploration with exploitation,
yielding improved performance.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/hu03a/hu03a.pdf</url></Article><Article><id>140</id><title>Sparseness of Support Vector Machines</title><author>Ingo Steinwart</author><abstract>Support vector machines (SVMs) construct decision functions that are linear combinations
of kernel evaluations on the training set. The samples with non-vanishing coefficients
are called support vectors. In this work we establish lower (asymptotical)
bounds on the number of support vectors. On our way we prove several results
which are of great importance for the understanding of SVMs.
In particular, we describe to which "limit"
SVM decision functions tend, discuss the corresponding notion of convergence
and provide some results on the stability of SVMs using subdifferential calculus
in the associated reproducing kernel Hilbert space.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/steinwart03a/steinwart03a.pdf</url></Article><Article><id>141</id><title>Least-Squares Policy Iteration</title><author>Michail G. Lagoudakis, Ronald Parr</author><abstract>We propose a new approach to reinforcement learning for control
problems which combines value-function approximation with linear
architectures and approximate policy iteration. This new approach is
motivated by the least-squares temporal-difference learning algorithm
(LSTD) for prediction problems, which is known for its efficient use
of sample experiences compared to pure temporal-difference
algorithms. Heretofore, LSTD has not had a straightforward application
to control problems mainly because LSTD learns the state value
function of a fixed policy which cannot be used for action selection
and control without a model of the underlying process.  Our new
algorithm, least-squares policy iteration (LSPI), learns the
state-action value function which allows for action selection without
a model and for incremental policy improvement within a
policy-iteration framework. LSPI is a model-free, off-policy method
which can use efficiently (and reuse in each iteration) sample
experiences collected in any manner. By separating the
sample collection method, the choice of the linear approximation
architecture, and the solution method, LSPI allows for focused
attention on the distinct elements that contribute to practical
reinforcement learning.  LSPI is tested on the simple task of
balancing an inverted pendulum and the harder task of balancing and
riding a bicycle to a target location. In both cases, LSPI learns to
control the pendulum or the bicycle by merely observing a relatively
small number of trials where actions are selected randomly. LSPI is
also compared against &lt;i&gt;Q&lt;/i&gt;-learning (both with and without experience
replay) using the same value function architecture.  While LSPI
achieves good performance fairly consistently on the difficult bicycle
task, &lt;i&gt;Q&lt;/i&gt;-learning variants were rarely able to balance for more than
a small fraction of the time needed to reach the target location.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/lagoudakis03a/lagoudakis03a.pdf</url></Article><Article><id>142</id><title>An Approximate Analytical Approach to Resampling Averages</title><author>D&amp;ouml;rthe Malzahn, Manfred Opper</author><abstract>Using a novel reformulation, we develop a
framework to compute approximate resampling data averages
analytically. The method avoids multiple retraining of statistical models
on the samples. Our approach uses a combination of
the replica "trick" of statistical physics and the TAP approach for
approximate
Bayesian inference. We demonstrate our approach on regression with Gaussian
processes. A comparison with averages obtained by Monte-Carlo
sampling shows that our method achieves good accuracy.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/malzahn03a/malzahn03a.pdf</url></Article><Article><id>143</id><title>Dependence, Correlation and  Gaussianity in Independent Component Analysis</title><author>Jean-Fran&amp;ccedil;ois Cardoso</author><abstract>&lt;p&gt;  
  Independent component analysis (ICA) is the decomposition of a random vector in linear
  components which are "as independent as possible."  Here, "independence" should be understood
  in its strong statistical sense: it goes beyond (second-order) decorrelation and thus
  involves the non-Gaussianity of the data.

  The ideal measure of independence is the "mutual information" and is known to be related to
  the entropy of the components when the search for components is restricted to uncorrelated
  components.

  This paper explores the connections between mutual information, entropy and non-Gaussianity
  in a larger framework, without resorting to a somewhat arbitrary decorrelation constraint.  A
  key result is that the mutual information can be decomposed, under linear transforms, as the
  sum of two terms: one term expressing the decorrelation of the components and one expressing
  their non-Gaussianity.
&lt;/p&gt;
  &lt;p&gt;
  Our results extend the previous understanding of these connections and explain them in the
  light of information geometry.  We also describe the "local geometry" of ICA by re-expressing
  all our results via a Gram-Charlier expansion by which all quantities of interest are
  obtained in terms of cumulants.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/cardoso03a/cardoso03a.pdf</url></Article><Article><id>144</id><title>Beyond Independent Components: Trees and Clusters</title><author>Francis R. Bach, Michael I. Jordan</author><abstract>We present a generalization of independent component analysis&#13;
(ICA), where instead of looking for a linear transform that makes&#13;
the data components independent, we look for a transform that&#13;
makes the data components well fit by a tree-structured graphical&#13;
model.  This &lt;em&gt;tree-dependent component analysis (TCA)&lt;/em&gt;&#13;
provides a tractable and flexible approach to weakening the&#13;
assumption of independence in ICA.  In particular, TCA allows the&#13;
underlying graph to have multiple connected components, and thus&#13;
the method is able to find "clusters" of components such that&#13;
components are dependent within a cluster and independent between&#13;
clusters.  Finally, we make use of a notion of graphical models&#13;
for time series due to Brillinger (1996) to extend these ideas&#13;
to the temporal setting.  In particular, we are able to fit models&#13;
that incorporate tree-structured dependencies among multiple time&#13;
series.&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/bach03a/bach03a.pdf</url></Article><Article><id>145</id><title>Energy-Based Models for Sparse Overcomplete Representations</title><author>Yee Whye Teh, Max Welling, Simon Osindero, Geoffrey E. Hinton</author><abstract>We present a new way of extending independent components analysis
(ICA) to overcomplete representations. In contrast to the causal
generative extensions of ICA which maintain marginal independence of
&lt;em&gt;sources&lt;/em&gt;, we define &lt;em&gt;features&lt;/em&gt; as deterministic (linear)
functions of the inputs. This assumption results in marginal
&lt;em&gt;dependencies&lt;/em&gt; among the features, but &lt;em&gt;conditional
independence&lt;/em&gt; of the features given the inputs.  By assigning energies
to the features a probability distribution over the input states is
defined through the Boltzmann distribution. Free parameters of this
model are trained using the contrastive divergence objective (Hinton, 2002).  When the number of features is equal to the number
of input dimensions this energy-based model reduces to noiseless ICA
and we show experimentally that the proposed learning algorithm is
able to perform blind source separation on speech data. In additional
experiments we train overcomplete energy-based models to extract
features from various standard data-sets containing speech, natural
images, hand-written digits and faces.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/teh03a/teh03a.pdf</url></Article><Article><id>146</id><title>Blind Source Separation via Generalized Eigenvalue Decomposition</title><author>Lucas Parra, Paul Sajda</author><abstract>In this short note we highlight the fact that linear blind source separation can be formulated as a generalized eigenvalue 
decomposition under the assumptions of non-Gaussian, non-stationary, or non-white independent sources. The solution for the 
unmixing matrix is given by the generalized eigenvectors that simultaneously diagonalize the covariance matrix of the 
observations and an additional symmetric matrix whose form depends upon the particular assumptions. The method critically 
determines the mixture coefficients and is therefore not robust to estimation errors.  However it provides a rather general 
and unified solution that summarizes the conditions for successful blind source separation.  To demonstrate the method, which can be implemented in two lines of matlab code, we 
present results for artificial mixtures of speech and real mixtures of electroencephalography (EEG) data, showing that the 
same sources are recovered under the various assumptions.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/parra03a/parra03a.pdf</url></Article><Article><id>147</id><title>ICA Using Spacings Estimates of Entropy</title><author>Erik G. Learned-Miller, John W. Fisher III</author><abstract>This paper presents a new algorithm for the independent components&#13;
analysis (ICA) problem based on an efficient entropy estimator.  Like&#13;
many previous methods, this algorithm directly minimizes the measure&#13;
of departure from independence according to the estimated&#13;
Kullback-Leibler divergence between the joint distribution and the&#13;
product of the marginal distributions. We pair this approach with&#13;
efficient entropy estimators from the statistics literature. In&#13;
particular, the entropy estimator we use is consistent and exhibits&#13;
rapid convergence.  The algorithm based on this estimator is simple,&#13;
computationally efficient, intuitively appealing, and outperforms&#13;
other well known algorithms. In addition, the estimator's relative&#13;
insensitivity to outliers translates into superior performance by our&#13;
ICA algorithm on outlier tests. We present favorable comparisons to&#13;
the Kernel ICA, FAST-ICA, JADE, and extended Infomax algorithms in&#13;
extensive simulations. We also provide public domain source code for&#13;
our algorithms.&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/learned-miller03a/learned-miller03a.pdf</url></Article><Article><id>148</id><title>MISEP -- Linear and Nonlinear ICA Based on Mutual Information</title><author>Lu&amp;iacute;s B. Almeida</author><abstract>&lt;p&gt;&#13;
Linear Independent Components Analysis (ICA) has become an&#13;
important signal processing and data analysis technique, the&#13;
typical application being blind source separation in a wide range&#13;
of signals, such as biomedical, acoustical and astrophysical ones.&#13;
Nonlinear ICA is less developed, but has the potential to become&#13;
at least as powerful.&#13;
&lt;/p&gt;&#13;
&lt;p&gt;&#13;
This paper presents MISEP, an ICA technique for linear and&#13;
nonlinear mixtures, which is based on the minimization of the&#13;
mutual information of the estimated components. MISEP is a&#13;
generalization of the popular INFOMAX technique, which is extended&#13;
in two ways: (1) to deal with nonlinear mixtures, and (2) to be&#13;
able to adapt to the actual statistical distributions of the&#13;
sources, by dynamically estimating the nonlinearities to be used&#13;
at the outputs. The resulting MISEP method optimizes a network&#13;
with a specialized architecture, with a single objective function:&#13;
the output entropy.&#13;
&lt;/p&gt;&#13;
&lt;p&gt;&#13;
The paper also briefly discusses the issue of nonlinear source&#13;
separation. Examples of linear and nonlinear source separation&#13;
performed by MISEP are presented.&#13;
&lt;/p&gt;&#13;
&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/almeida03a/almeida03a.pdf</url></Article><Article><id>149</id><title>Blind Separation of Post-nonlinear Mixtures using Linearizing Transformations and Temporal Decorrelation</title><author>Andreas Ziehe, Motoaki Kawanabe, Stefan Harmeling, Klaus-Robert M&amp;uuml;ller</author><abstract>  We propose two methods that reduce the post-nonlinear blind
  source separation problem (PNL-BSS) to a linear BSS problem.  The
  first method is based on the concept of &lt;em&gt;maximal correlation&lt;/em&gt;:
  we apply the alternating conditional expectation (ACE) algorithm---a
  powerful technique from non-parametric statistics---to approximately invert
  the componentwise non-linear functions.
  The second method is a Gaussianizing transformation, which is
  motivated by the fact that linearly mixed signals before nonlinear
  transformation are approximately Gaussian distributed.  This
  heuristic, but simple and efficient procedure works as good as the
  ACE method.
  Using the framework provided by ACE, convergence can be proven.  The
  optimal transformations obtained by ACE coincide with the
  sought-after inverse functions of the nonlinearities.
  After equalizing the nonlinearities, temporal decorrelation separation (TDSEP)
  allows us to recover the source signals. Numerical simulations
  testing  "ACE-TD" and "Gauss-TD" on realistic examples are performed with
  excellent results.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/ziehe03a/ziehe03a.pdf</url></Article><Article><id>150</id><title>A Multiscale Framework For Blind Separation of Linearly Mixed Signals</title><author>Pavel Kisilev, Michael Zibulevsky, Yehoshua Y. Zeevi</author><abstract>We consider the problem of blind separation of unknown source signals or images from a given set of their linear mixtures. 
It was discovered recently that exploiting the sparsity of sources and their mixtures, once they are projected onto a proper 
space of sparse representation, improves the quality of separation. In this study we take advantage of the properties of 
multiscale transforms, such as wavelet packets, to decompose signals into sets of local features with various degrees of 
sparsity. We then study how the separation error is affected by the sparsity of decomposition coefficients, and by the 
misfit between the probabilistic model of these coefficients and their actual distribution. Our error estimator, based on 
the Taylor expansion of the quasi-ML function, is used in selection of the best subsets of coefficients and utilized, in 
turn, in further separation. The performance of the algorithm is evaluated by using noise-free and noisy data. Experiments 
with simulated signals, musical sounds and images, demonstrate significant improvement of separation quality over previously 
reported results.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/kisilev03a/kisilev03a.pdf</url></Article><Article><id>151</id><title>A Maximum Likelihood Approach to Single-channel Source Separation</title><author>Gil-Jin Jang, Te-Won Lee</author><abstract>This paper presents a new technique for achieving blind signal&#13;
separation when given only a single channel recording. The&#13;
main concept is based on exploiting &lt;em&gt;a priori&lt;/em&gt; sets of&#13;
time-domain basis functions learned by independent component&#13;
analysis (ICA) to the separation of mixed source signals&#13;
observed in a single channel. The inherent time structure of&#13;
sound sources is reflected in the ICA basis functions, which&#13;
encode the sources in a statistically efficient manner. We&#13;
derive a learning algorithm using a maximum likelihood&#13;
approach given the observed single channel data and sets of&#13;
basis functions. For each time point we infer the source&#13;
parameters and their contribution factors. This inference is&#13;
possible due to prior knowledge of the basis functions and the&#13;
associated coefficient densities. A flexible model for density&#13;
estimation allows accurate modeling of the observation and our&#13;
experimental results exhibit a high level of separation&#13;
performance for simulated mixtures as well as real environment&#13;
recordings employing mixtures of two different sources.&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/jang03a/jang03a.pdf</url></Article><Article><id>152</id><title>Statistical Dynamics of On-line Independent Component Analysis</title><author>Gleb Basalyga, Magnus Rattray</author><abstract>&#13;
The learning dynamics of on-line independent component analysis is analysed in the limit of large data dimension. We study a &#13;
simple Hebbian learning algorithm that can be used to separate out a small number of non-Gaussian components from a &#13;
high-dimensional data set. The de-mixing matrix parameters are confined to a Stiefel manifold of tall, orthogonal matrices &#13;
and we introduce a natural gradient variant of the algorithm which is appropriate to learning on this manifold. For large &#13;
input dimension the parameter trajectory of both algorithms passes through a sequence of unstable fixed points, each &#13;
described by a diffusion process in a polynomial potential. Choosing the learning rate too large increases the escape time &#13;
from each of these fixed points, effectively trapping the learning in a sub-optimal state.  In order to avoid these trapping &#13;
states a very low learning rate must be chosen during the learning transient, resulting in learning time-scales of &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;N&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;) &#13;
or &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;N&lt;/i&gt;&lt;sup&gt;3&lt;/sup&gt;) iterations where &lt;i&gt;N&lt;/i&gt; is the data dimension. Escape from each sub-optimal state results in a sequence of symmetry &#13;
breaking events as the algorithm learns each source in turn. This is in marked contrast to the learning dynamics displayed &#13;
by related on-line learning algorithms for multilayer neural networks and principal component analysis. Although the natural &#13;
gradient variant of the algorithm has nice asymptotic convergence properties, it has an equivalent transient dynamics to the &#13;
standard Hebbian algorithm.&#13;
&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/basalyga03a/basalyga03a.pdf</url></Article><Article><id>153</id><title>Blind Source Recovery: A Framework in the State Space</title><author>Khurram Waheed, Fathi M. Salem</author><abstract>Blind Source Recovery (BSR) denotes recovery of original
sources/signals from environments that may include convolution,
temporal variation, and even nonlinearity.  It also infers the
recovery of sources even in the absence of precise environment
identifiability.  This paper describes, in a comprehensive fashion, a
generalized BSR formulation achieved by the application of stochastic
optimization principles to the Kullback-Liebler divergence as a
performance functional subject to the constraints of the general
(i.e., nonlinear and time-varying) state space representation.  This
technique is used to derive update laws for nonlinear time-varying
dynamical systems, which are subsequently specialized to
time-invariant and linear systems.  Further, the state space demixing
network structures have been exploited to develop learning rules,
capable of handling most filtering paradigms, which can be
conveniently extended to nonlinear models.  In the special cases,
distinct linear state-space algorithms are presented for the minimum
phase and non-minimum phase mixing environment models.  Conventional
(FIR/IIR) filtering models are subsequently derived from this general
structure and are compared with material in the recent literature.
Illustrative simulation examples are presented to demonstrate the
&lt;em&gt;online&lt;/em&gt; adaptation capabilities of the developed algorithms.
Some of this reported work has also been implemented in dedicated
hardware/software platforms.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/waheed03a/waheed03a.pdf</url></Article><Article><id>154</id><title>Overlearning in Marginal Distribution-Based ICA: Analysis and Solutions</title><author>Jaakko S&amp;auml;rel&amp;auml, Ricardo Vig&amp;aacute;rio</author><abstract>  The present paper is written as a word of caution, with users of&#13;
  independent component analysis (ICA) in mind, to overlearning&#13;
  phenomena that are often observed.&lt;br&gt;&#13;
  We consider two types of overlearning, typical to high-order&#13;
  statistics based ICA.  These algorithms can be seen to maximise the&#13;
  negentropy of the source estimates.  The first kind of overlearning&#13;
  results in the generation of spike-like signals, if there are not&#13;
  enough samples in the data or there is a considerable amount of&#13;
  noise present.  It is argued that, if the data has power spectrum&#13;
  characterised by 1/&lt;i&gt;f&lt;/i&gt; curve, we face a more severe problem, which&#13;
  cannot be solved inside the strict ICA model. This overlearning is&#13;
  better characterised by bumps instead of spikes. Both overlearning&#13;
  types are demonstrated in the case of artificial signals as well as&#13;
  magnetoencephalograms (MEG). Several methods are suggested to&#13;
  circumvent both types, either by making the estimation of the ICA&#13;
  model more robust or by including further modelling of the data.&#13;
&#13;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/sarela03a/sarela03a.pdf</url></Article><Article><id>155</id><title>ICA for Watermarking Digital Images</title><author>St&amp;eacute;phane Bounkong, Bor&amp;eacute;mi Toch, David Saad, David Lowe</author><abstract>  We present a domain-independent ICA-based approach to watermarking.
  This approach can be used on images, music or video to embed either
  a robust or fragile watermark.
  In the case of robust watermarking, the method shows high
  information rate and robustness against malicious and non-malicious
  attacks, while keeping a low induced distortion.  The fragile
  watermarking scheme, on the other hand, shows high sensitivity to
  tampering attempts while keeping the requirement for high
  information rate and low distortion. The improved performance is
  achieved by employing a set of statistically independent sources
  (the independent components) as the feature space and principled
  statistical decoding methods. The performance of the suggested
  method is compared to other state of the art approaches. The paper
  focuses on applying the method to digitized images although the same
  approach can be used for other media, such as music or video.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/bounkong03a/bounkong03a.pdf</url></Article><Article><id>156</id><title>A Generative Model for Separating Illumination and Reflectance from Images</title><author>Inna Stainvas, David Lowe</author><abstract>&lt;p&gt;
It is well known that even slight changes in nonuniform illumination
lead to a large image variability  and are crucial  for
many visual tasks. This paper presents a new ICA related
probabilistic model where the number of sources exceeds the number of
sensors to  perform an image segmentation and  illumination removal, simultaneously.
We model illumination and reflectance in log space
by a generalized autoregressive process and Hidden Gaussian Markov random field, respectively.
&lt;/p&gt;
&lt;p&gt;
The model ability to deal with segmentation of illuminated images
is compared with a Canny edge detector and homomorphic filtering.
We apply the model to two problems: synthetic image segmentation and
sea surface pollution detection from intensity images.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume4/stainvas03a/stainvas03a.pdf</url></Article></Article><Article><id>158</id><title>Bias-Variance Analysis of Support Vector Machines for the Development of SVM-Based Ensemble Methods</title><author>Giorgio Valentini, Thomas G. Dietterich</author><abstract>
Bias-variance analysis provides a tool to study learning algorithms and can be used to properly design ensemble methods well tuned to the properties of a specific base learner. Indeed the effectiveness of ensemble methods critically depends on accuracy, diversity and learning characteristics of base learners. We present an extended experimental analysis of bias-variance decomposition of the error in Support Vector Machines (SVMs), considering Gaussian, polynomial and dot product kernels. A characterization of the error decomposition is provided, by means of the analysis of the relationships between bias, variance, kernel type and its parameters, offering insights into the way SVMs learn. The results show that the expected trade-off between bias and variance is sometimes observed, but more complex relationships can be detected, especially in Gaussian and polynomial kernels. We show that the bias-variance decomposition offers a rationale to develop ensemble methods using SVMs as base learners, and we outline two directions for developing SVM ensembles, exploiting the SVM bias characteristics and the bias-variance dependence on the kernel parameters.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/valentini04a/valentini04a.pdf</url></Article><Article><id>159</id><title>A Fast Algorithm for Joint Diagonalization with Non-orthogonal Transformations and its Application to Blind Source Separation
</title><author>
Andreas Ziehe, Pavel Laskov, Guido Nolte, Klaus-Robert M&amp;uuml;ller</author><abstract>
A new efficient algorithm is presented for joint diagonalization 
of several matrices. The algorithm is based on the Frobenius-norm
formulation of the joint diagonalization problem, and addresses
diagonalization with a general, non-orthogonal transformation. The
iterative scheme of the algorithm is based on a multiplicative
update which ensures the invertibility of the diagonalizer.  The
algorithm's efficiency stems from the special approximation of the
cost function resulting in a sparse, block-diagonal Hessian to be
used in the computation of the quasi-Newton update step.  Extensive
numerical simulations illustrate the performance of the algorithm
and provide a comparison to other leading diagonalization methods.
The results of such comparison demonstrate that the proposed
algorithm is a viable alternative to existing state-of-the-art joint
diagonalization algorithms.  The practical use of our algorithm is
shown for blind source separation problems.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/ziehe04a/ziehe04a.pdf</url></Article><Article><id>160</id><title>Feature Discovery in Non-Metric Pairwise Data
</title><author>
Julian Laub, Klaus-Robert M&amp;uuml;ller</author><abstract>
Pairwise proximity data, given as similarity or dissimilarity matrix, 
can violate metricity. This occurs either due to
noise, fallible estimates, or due to intrinsic non-metric features
such as they arise from human judgments. So far the problem of 
non-metric pairwise data has been tackled by essentially omitting 
the negative eigenvalues or shifting the spectrum of the associated 
(pseudo-)covariance matrix for a subsequent embedding. However, 
little attention has been paid to the negative part of the spectrum 
itself. In particular no answer was given to whether the directions 
associated to the negative eigenvalues would at all code variance other 
than noise related. We show by a simple, &lt;i&gt;exploratory&lt;/i&gt; analysis 
that the negative eigenvalues &lt;i&gt;can&lt;/i&gt; code for
relevant structure in the data, thus leading to the discovery of new
features, which were lost by conventional data analysis techniques.
The information hidden in the negative eigenvalue part of the
spectrum is illustrated and discussed for three data sets, namely USPS
handwritten digits, text-mining and  data from cognitive psychology. 
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/laub04a/laub04a.pdf</url></Article><Article><id>161</id><title>Probability Product Kernels
</title><author>
Tony Jebara, Risi Kondor, Andrew Howard</author><abstract>
The advantages of discriminative learning algorithms and kernel
machines are combined with generative modeling using a novel kernel
between distributions. In the probability product kernel, data points
in the input space are mapped to distributions over the sample space
and a general inner product is then evaluated as the integral of the
product of pairs of distributions. The kernel is straightforward to
evaluate for all exponential family models such as multinomials and
Gaussians and yields interesting nonlinear kernels. Furthermore, the
kernel is computable in closed form for latent distributions such as
mixture models, hidden Markov models and linear dynamical systems. For
intractable models, such as switching linear dynamical systems,
structured mean-field approximations can be brought to bear on the
kernel evaluation. For general distributions, even if an analytic
expression for the kernel is not feasible, we show a straightforward
sampling method to evaluate it. Thus, the kernel permits
discriminative learning methods, including support vector machines, to
exploit the properties, metrics and invariances of the generative
models we infer from each datum. Experiments are shown using
multinomial models for text, hidden Markov models for biological
data sets and linear dynamical systems for time series data.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/jebara04a/jebara04a.pdf</url></Article><Article><id>165</id><title>Boosting as a Regularized Path to a Maximum Margin Classifier
</title><author>
Saharon Rosset, Ji Zhu, Trevor Hastie</author><abstract>
In this paper we study boosting methods from a new perspective. We
build on recent work by Efron et al. to show that boosting
approximately (and in some cases exactly) minimizes its loss
criterion with an &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; constraint on the coefficient 
vector. This
helps understand the success of boosting with early stopping as
regularized fitting of the loss criterion. For the two most
commonly used criteria (exponential and binomial log-likelihood),
we further show that as the constraint is relaxed---or
equivalently as the boosting iterations proceed---the solution
converges (in the separable case) to an "&lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-optimal"
separating hyper-plane.  We prove that this &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-optimal
separating hyper-plane has the property of maximizing the minimal
&lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-margin of the training data, as defined in the boosting
literature. An interesting fundamental similarity between boosting
and kernel support vector machines emerges, as both can be
described as methods for regularized optimization in
high-dimensional predictor space, using a computational trick to
make the calculation practical, and converging to
margin-maximizing solutions. While this statement describes SVMs
exactly, it applies to boosting only approximately.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/rosset04a/rosset04a.pdf</url></Article><Article><id>170</id><title>No Unbiased Estimator of the Variance of K-Fold Cross-Validation
</title><author>
Yoshua Bengio, Yves Grandvalet</author><abstract>
Most machine learning researchers perform quantitative experiments 
to estimate generalization error and compare the performance of 
different algorithms (in particular, their proposed algorithm). In 
order to be able to draw statistically convincing conclusions, 
it is important  to estimate the uncertainty of such estimates.
This paper studies the very commonly used K-fold cross-validation 
estimator of generalization performance. The main theorem shows 
that there exists no universal (valid under all distributions) 
unbiased estimator of the variance of K-fold cross-validation. 
The analysis that accompanies this result is based on the 
eigen-decomposition of the covariance matrix of errors, which 
has only three different eigenvalues corresponding to three 
degrees of freedom of the matrix and three components of the 
total variance. This analysis helps to better understand the 
nature of the problem and how it can make naive estimators 
(that don't take into account the error correlations due to 
the overlap between training and test sets) grossly underestimate 
variance. This is confirmed by numerical experiments in which 
the three components of the variance are compared when the 
difficulty of the learning problem and the number of folds are varied.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/grandvalet04a/grandvalet04a.pdf</url></Article><Article><id>171</id><title>Selective Rademacher Penalization and Reduced Error Pruning of Decision Trees
</title><author>
Matti K&amp;#228;&amp;#228;ri&amp;#228;inen, Tuomo Malinen, Tapio Elomaa</author><abstract>
Rademacher penalization is a modern technique for obtaining
data-dependent bounds on the generalization error of classifiers.  It
appears to be limited to relatively simple hypothesis classes because of
computational complexity issues.  In this paper we, nevertheless, apply
Rademacher penalization to the in practice important hypothesis class of
unrestricted decision trees by considering the prunings of a given
decision tree rather than the tree growing phase.  This study
constitutes the first application of Rademacher penalization to  
hypothesis classes that have practical significance.  We present two 
variations of the approach, one in which the hypothesis class consists of 
all prunings of the initial tree and another in which only the prunings 
that are accurate on growing data are taken into account.  Moreover, we 
generalize the error-bounding approach from binary classification to 
multi-class situations.  Our empirical experiments indicate that the 
proposed new bounds outperform distribution-independent bounds for 
decision tree prunings and provide non-trivial error estimates on 
real-world data sets. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/kaariainen04a/kaariainen04a.pdf</url></Article><Article><id>172</id><title>Knowledge-Based Kernel Approximation
</title><author>
Olvi L. Mangasarian, Jude W. Shavlik, Edward W. Wild</author><abstract>
Prior knowledge, in the form of linear inequalities that need to be
satisfied over multiple polyhedral sets, is incorporated into a
function approximation generated by a linear combination of linear or
nonlinear kernels.  In addition, the approximation needs to satisfy
conventional conditions such as having given exact or inexact function
values at certain points.  Determining such an approximation leads to
a linear programming formulation. By using nonlinear kernels and
mapping the prior polyhedral knowledge in the input space to one
defined by the kernels, the prior knowledge translates into nonlinear
inequalities in the original input space. Through a number of
computational examples, including a real world breast cancer prognosis
dataset, it is shown that prior knowledge can significantly improve
function approximation.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/mangasarian04a/mangasarian04a.pdf</url></Article><Article><id>173</id><title>Support Vector Machine Soft Margin Classifiers: Error Analysis
</title><author>
Di-Rong Chen, Qiang Wu, Yiming Ying, Ding-Xuan Zhou</author><abstract>
The purpose of this paper is to provide a PAC error analysis for
the &lt;i&gt;q&lt;/i&gt;-norm soft margin classifier, a support vector machine
classification algorithm. It consists of two parts:
regularization error and sample error. While many techniques
are available for treating the sample error, much less is known
for the regularization error and the corresponding
approximation error for reproducing
kernel Hilbert spaces. We are mainly concerned about the
regularization error. It is estimated for general distributions
by a &lt;i&gt;K&lt;/i&gt;-functional in weighted &lt;i&gt;L&lt;sup&gt;q&lt;/sup&gt;&lt;/i&gt; spaces. For weakly
separable distributions (i.e., the margin may be zero)
satisfactory convergence rates are provided by means of separating functions.
A projection operator is introduced, which leads to
better sample error estimates especially for small complexity kernels.
The misclassification error is bounded
by the &lt;i&gt;V&lt;/i&gt;-risk associated with a general class of
loss functions &lt;i&gt;V&lt;/i&gt;. The difficulty of bounding the offset is overcome.
Polynomial kernels and Gaussian kernels are used to
demonstrate the main results.
The choice of the regularization parameter
plays an important role in our analysis.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/chen04b/chen04b.pdf</url></Article><Article><id>174</id><title>Model Averaging for Prediction with Discrete Bayesian Networks
</title><author>
Denver Dash, Gregory F. Cooper</author><abstract>
In this paper we consider the problem of
performing Bayesian model-averaging over a class of discrete
Bayesian network structures consistent with a partial ordering and
with bounded in-degree &lt;i&gt;k&lt;/i&gt;. We show that for &lt;i&gt;N&lt;/i&gt; nodes this class
contains in the worst-case at least &lt;img align=middle src=dash04a-omega.jpeg alt="omega eq"&gt;
distinct network structures, and yet model averaging
over these structures can be performed using &lt;img align=middle src=dash04a-bigo.jpeg alt="bigo eq"&gt;
operations. Furthermore we show that there exists a
single Bayesian network that defines a joint distribution over the
variables that is equivalent to model averaging over these
structures. Although constructing this network is computationally
prohibitive, we show that it can be approximated by a tractable
network, allowing approximate model-averaged probability
calculations to be performed in &lt;i&gt;O(N)&lt;/i&gt; time. Our result also
leads to an exact and linear-time solution to the problem of
averaging over the 2&lt;sup&gt;&lt;i&gt;N&lt;/i&gt;&lt;/sup&gt; possible feature sets in a naive Bayes
model, providing an exact Bayesian solution to the troublesome
feature-selection problem for naive Bayes classifiers. We
demonstrate the utility of these techniques in the context of
supervised classification, showing empirically that model
averaging consistently beats other generative
Bayesian-network-based models, even when the generating model is
not guaranteed to be a member of the class being averaged over. We
characterize the performance over several parameters on simulated
and real-world data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/dash04a/dash04a.pdf</url></Article><Article><id>175</id><title>Efficient Feature Selection via Analysis of Relevance and Redundancy
</title><author>
Lei Yu, Huan Liu</author><abstract>
Feature selection is applied to reduce the number of
features in many applications where data has hundreds or thousands
of features. Existing feature selection methods mainly focus on
finding relevant features. In this paper, we show that feature
relevance alone is insufficient for efficient feature selection of
high-dimensional data. We define feature redundancy and propose to
perform explicit redundancy analysis in feature selection. A new
framework is introduced that decouples relevance analysis and
redundancy analysis. We develop a correlation-based method for
relevance and redundancy analysis, and conduct an empirical study
of its efficiency and effectiveness comparing with representative
methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/yu04a/yu04a.pdf</url></Article><Article><id>176</id><title>Statistical Analysis of Some Multi-Category Large Margin Classification Methods
</title><author>
Tong Zhang</author><abstract>
The purpose of this paper is to investigate statistical properties of
risk minimization based  multi-category classification methods. 
These methods can be considered as natural extensions of binary large 
margin classification. We establish conditions that guarantee the 
consistency of classifiers obtained in the risk minimization framework
with respect to the classification error. 
Examples are provided for four specific forms of the general formulation, 
which extend a number of known methods.
Using these examples, we show that some risk minimization formulations 
can also be used to obtain conditional probability estimates
for the underlying problem. Such conditional probability information
can be useful for statistical inferencing tasks beyond classification.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/zhang04b/zhang04b.pdf</url></Article><Article><id>177</id><title>The Minimum Error Minimax Probability Machine
</title><author>
Kaizhu Huang, Haiqin Yang, Irwin King, Michael R. Lyu, Laiwan Chan</author><abstract>
We construct a distribution-free Bayes optimal classifier called the Minimum
Error  Minimax Probability Machine (MEMPM) in a worst-case setting, i.e., under
all possible choices of class-conditional densities with a given mean and
covariance matrix. By assuming no specific distributions for the data, our
model is thus distinguished from traditional Bayes optimal approaches, where an
assumption on the data distribution is a must. This model is extended from the
Minimax Probability Machine (MPM), a recently-proposed novel classifier, and is
demonstrated to be the general case of MPM. Moreover, it includes another
special case named the Biased Minimax Probability Machine, which is appropriate for handling biased classification. One appealing feature of MEMPM is that it
contains an explicit performance indicator, i.e., a lower bound on the
worst-case accuracy, which is shown to be tighter than that of MPM.  We provide
conditions under which the worst-case Bayes optimal classifier converges to the
Bayes optimal classifier. We demonstrate how to apply a more general
statistical framework to  estimate model input parameters robustly. We also
show how to extend our model to nonlinear classification by exploiting
kernelization techniques. A series of experiments on both synthetic data sets
and real world benchmark data sets validates our proposition and demonstrates
the effectiveness of our model.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/huang04a/huang04a.pdf</url></Article><Article><id>178</id><title>Large-Sample Learning of Bayesian Networks is NP-Hard
</title><author>
David Maxwell Chickering, David Heckerman, Christopher Meek</author><abstract>
In this paper, we provide new complexity results for algorithms that
learn discrete-variable Bayesian networks from data.  Our results
apply whenever the learning algorithm uses a scoring criterion that
favors the simplest structure for which the model is able to represent
the generative distribution exactly. Our results therefore hold
whenever the learning algorithm uses a consistent scoring criterion
and is applied to a sufficiently large dataset. We show that
identifying high-scoring structures is NP-hard, even when any
combination of one or more of the following hold: the generative
distribution is perfect with respect to some DAG containing hidden
variables; we are given an independence oracle; we are given an
inference oracle; we are given an information oracle; we restrict
potential solutions to structures in which each node has at most &lt;i&gt;k&lt;/i&gt;
parents, for all &lt;i&gt;k&lt;/i&gt;&gt;=3. 
&lt;p&gt;
Our proof relies on a new technical result that we establish in the
appendices. In particular, we provide a method for constructing the
local distributions in a Bayesian network such that the resulting
joint distribution is provably perfect with respect to the structure
of the network.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/chickering04a/chickering04a.pdf</url></Article><Article><id>179</id><title>Randomized Variable Elimination
</title><author>
David J. Stracuzzi, Paul E. Utgoff</author><abstract>
Variable selection, the process of identifying input variables that 
are relevant to a particular learning problem, has received much 
attention in the learning community. Methods that employ a learning
algorithm as a part of the selection process (wrappers) have been 
shown to outperform methods that select variables independently 
from the learning algorithm (filters), but only at great computational 
expense. We present a randomized wrapper algorithm whose computational 
requirements are within a constant factor of simply learning in the 
presence of all input variables, provided that the number of relevant 
variables is small and known in advance. We then show how to remove 
the latter assumption, and demonstrate performance on several problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/stracuzzi04a/stracuzzi04a.pdf</url></Article><Article><id>180</id><title>Some Properties of Regularized Kernel Methods
</title><author>
Ernesto De Vito, Lorenzo Rosasco, Andrea Caponnetto, Michele Piana, Alessandro Verri</author><abstract>
In regularized kernel methods, the solution of a learning problem
is found by minimizing functionals consisting of the sum of a data
and a complexity term. In this paper we investigate some
properties of a more general form of the above functionals in
which the data term corresponds to the expected risk. First, we
prove a quantitative version of the representer theorem holding
for both regression and classification, for both differentiable
and non-differentiable loss functions, and for arbitrary offset
terms. Second, we show that the case in which the offset space is
non trivial corresponds to solving a standard problem of
regularization in a Reproducing Kernel Hilbert Space in which the
penalty term is given by a seminorm. Finally, we discuss the
issues of existence and uniqueness of the solution. From the
specialization of our analysis to the discrete setting it is
immediate to establish a connection between the solution
properties of sparsity and coefficient boundedness and some
properties of the loss function. For the case of Support Vector Machines for
classification, we also obtain a complete characterization of the
whole method in terms of the Khun-Tucker conditions with no need
to introduce the dual formulation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/devito04a/devito04a.pdf</url></Article><Article><id>181</id><title>The Entire Regularization Path for the Support Vector Machine
</title><author>
Trevor Hastie, Saharon Rosset, Robert Tibshirani, Ji Zhu</author><abstract>
The support vector machine (SVM) is a widely used tool for classification.
Many efficient implementations exist for fitting a two-class SVM
model. The user has to supply values for the tuning parameters: the
regularization cost parameter, and the kernel parameters. It seems a
common practice is to use a default value for the cost parameter,
often leading to the least restrictive model. In this paper we argue
that the choice of the cost parameter can be critical. We then
derive an algorithm that can fit the entire path of SVM solutions
for every value of the cost parameter, with essentially the same
computational cost as fitting one SVM model. We illustrate our
algorithm on some examples, and use our representation to give
further insight into the range of SVM solutions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/hastie04a/hastie04a.pdf</url></Article><Article><id>182</id><title>Second Order Cone Programming Formulations for Feature Selection
</title><author>Chiranjib Bhattacharyya</author><abstract>
This paper addresses the issue of feature selection for linear 
classifiers given the moments of the class conditional
densities. The problem is posed as finding a minimal set of features 
such that the resulting classifier has a low misclassification 
error. Using a bound on the misclassification error involving the 
mean and covariance of class conditional densities and minimizing an 
&lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; norm as an approximate criterion for feature selection, a 
second order programming formulation is derived. To handle errors 
in estimation of mean and covariances, a tractable robust formulation 
is also discussed. In a slightly different setting the Fisher 
discriminant is derived. Feature selection for Fisher discriminant 
is also discussed. Experimental results on synthetic data sets and 
on real life microarray data show that the proposed formulations 
are competitive with the state of the art linear programming formulation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/bhattacharyya04a/bhattacharyya04a.pdf</url></Article><Article><id>183</id><title>Fast String Kernels using Inexact Matching for Protein Sequences
</title><author>Christina Leslie, Rui Kuang</author><abstract>
We describe several families of &lt;i&gt;k&lt;/i&gt;-mer based string kernels 
related to the recently presented mismatch kernel and designed
for use with support vector machines (SVMs) for classification
of protein sequence data.  These new kernels -- restricted gappy 
kernels, substitution kernels, and wildcard kernels -- are based 
on feature spaces indexed by &lt;i&gt;k&lt;/i&gt;-length subsequences ("&lt;i&gt;k&lt;/i&gt;-mers") 
from the string alphabet &amp;#931.  However, for all kernels we 
define here, the kernel value &lt;i&gt;K&lt;/i&gt;(&lt;i&gt;x,y&lt;/i&gt;) can be computed in 
&lt;i&gt;O&lt;/i&gt;(&lt;i&gt;c&lt;sub&gt;K&lt;/sub&gt;&lt;/i&gt;(|&lt;i&gt;x&lt;/i&gt;|+|&lt;i&gt;y&lt;/i&gt;|)) time, where the constant 
&lt;i&gt;c&lt;sub&gt;K&lt;/sub&gt;&lt;/i&gt; depends
on the parameters of the kernel but is independent of the size 
|&amp;#931| of the alphabet.  Thus the computation of these kernels 
is linear in the length of the sequences, like the mismatch kernel, 
but we improve upon the parameter-dependent constant 
&lt;i&gt;c&lt;sub&gt;K&lt;/sub&gt; = k&lt;sup&gt;m+1&lt;/sup&gt;&lt;/i&gt;|&lt;i&gt;&amp;#931&lt;/i&gt;|&lt;i&gt;&lt;sup&gt;m&lt;/sup&gt;&lt;/i&gt; 
of the (&lt;i&gt;k,m&lt;/i&gt;)-mismatch kernel.
We compute the kernels efficiently using  a trie data structure 
and relate our new kernels to the recently described transducer 
formalism.  In protein classification experiments on two benchmark 
SCOP data sets, we show that our new faster kernels achieve SVM 
classification performance comparable to the mismatch kernel and 
the Fisher kernel derived from profile hidden Markov models, and 
we investigate the dependence of the kernels on parameter choice.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/leslie04a/leslie04a.pdf</url></Article><Article><id>184</id><title>Non-negative Matrix Factorization with Sparseness Constraints
</title><author>Patrik O. Hoyer</author><abstract>
Non-negative matrix factorization (NMF) is a recently developed 
technique for finding parts-based, linear representations of 
non-negative data. Although it has successfully been applied 
in several applications, it does not always result in parts-based 
representations. In this paper, we show how explicitly incorporating 
the notion of 'sparseness' improves the found decompositions. 
Additionally, we provide complete MATLAB code both for standard 
NMF and for our extension. Our hope is that this will further 
the application of these methods to solving novel data-analysis 
problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/hoyer04a/hoyer04a.pdf</url></Article><Article><id>185</id><title>
Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning
</title><author>Evan Greensmith, Peter L. Bartlett, Jonathan Baxter</author><abstract>
Policy gradient methods for reinforcement learning avoid some of the
undesirable properties of the value function approaches, such as
policy degradation (Baxter and Bartlett, 2001).  However, the variance of the
performance gradient estimates obtained from the simulation is
sometimes excessive.  In this paper, we consider variance reduction
methods that were developed for Monte Carlo estimates of integrals.
We study two commonly used policy gradient techniques, the baseline
and actor-critic methods, from this perspective.  Both can be
interpreted as additive control variate variance reduction methods.
We consider the expected average reward performance measure, and we
focus on the GPOMDP algorithm for estimating performance gradients in
partially observable Markov decision processes controlled by
stochastic reactive policies.  We give bounds for the estimation error
of the gradient estimates for both baseline and actor-critic
algorithms, in terms of the sample size and mixing properties of the
controlled system.  For the baseline technique, we compute the optimal
baseline, and show that the popular approach of using the average
reward to define the baseline can be suboptimal.  For actor-critic
algorithms, we show that using the true value function as the critic
can be suboptimal.  We also discuss algorithms for estimating the
optimal baseline and approximate value function.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/greensmith04a/greensmith04a.pdf</url></Article><Article><id>186</id><title>
Fast Binary Feature Selection with Conditional Mutual Information
</title><author>Fran&amp;ccedil;ois Fleuret</author><abstract>
We propose in this paper a very fast feature selection technique based
on conditional mutual information. By picking features which maximize
their mutual information with the class to predict conditional to any
feature already picked, it ensures the selection of features which are
both individually informative and two-by-two weakly dependant. We show
that this feature selection method outperforms other classical
algorithms, and that a naive Bayesian classifier built with features
selected that way achieves error rates similar to those of
state-of-the-art methods such as boosting or SVMs. The implementation
we propose selects 50 features among 40,000, based on a training
set of 500 examples in a tenth of a second on a standard 1Ghz PC.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/fleuret04a/fleuret04a.pdf</url></Article><Article><id>187</id><title>
The Dynamics of AdaBoost: Cyclic Behavior and Convergence of Margins
</title><author>Cynthia Rudin, Ingrid Daubechies, Robert E. Schapire</author><abstract>

In order to study the convergence properties of the AdaBoost
algorithm, we reduce AdaBoost to a nonlinear iterated map and
study the evolution of its weight vectors. This dynamical systems
approach allows us to understand AdaBoost's convergence properties
completely in certain cases; for these cases we find stable
cycles, allowing us to explicitly solve for AdaBoost's output.
&lt;p&gt;

Using this unusual technique, we are able to show that AdaBoost
does not always converge to a maximum margin combined classifier,
answering an open question. In addition, we show that
"non-optimal" AdaBoost (where the weak learning algorithm does
not necessarily choose the best weak classifier at each iteration)
may fail to converge to a maximum margin classifier, even if
"optimal" AdaBoost produces a maximum margin. Also, we show that
if AdaBoost cycles, it cycles among "support vectors", i.e.,
examples that achieve the same smallest margin.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume5/rudin04a/rudin04a.pdf</url></Article><Article><id>188</id><title>
Asymptotic Model Selection for Naive Bayesian Networks
</title><author>Dmitry Rusakov, Dan Geiger</author><abstract>

We develop a closed form asymptotic formula to compute the marginal
likelihood of data given a naive Bayesian network model with two
hidden states and binary features. This formula deviates from the
standard BIC score. Our work provides a concrete example that
the BIC score is generally incorrect for statistical models that 
belong to stratified exponential families. This claim stands in 
contrast to linear and curved exponential families, where the BIC 
score has been proven to provide a correct asymptotic approximation 
for the marginal likelihood.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/rusakov05a/rusakov05a.pdf</url></Article><Article><id>189</id><title>
Dimension Reduction in Text Classification with Support Vector Machines
</title><author>Hyunsoo Kim, Peg Howland, Haesun Park</author><abstract>

Support vector machines (SVMs) have been recognized as one of the most
successful classification methods for many applications including text
classification.  Even though the learning ability and computational
complexity of training in support vector machines may be independent
of the dimension of the feature space, reducing computational
complexity is an essential issue to efficiently handle a large number
of terms in practical applications of text classification.  In this
paper, we adopt novel dimension reduction methods to reduce the
dimension of the document vectors dramatically. We also introduce
decision functions for the centroid-based classification algorithm and
support vector classifiers to handle the classification problem where
a document may belong to multiple classes.  Our substantial
experimental results show that with several dimension reduction
methods that are designed particularly for clustered data, higher
efficiency for both training and testing can be achieved without
sacrificing prediction accuracy of text classification even when the
dimension of the input space is significantly reduced.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/kim05a/kim05a.pdf</url></Article><Article><id>190</id><title>
Stability of Randomized Learning Algorithms
</title><author>Andre Elisseeff, Theodoros Evgeniou, Massimiliano Pontil</author><abstract>

We extend existing theory on stability, namely how much
changes in the training data influence the estimated models, and
generalization performance of deterministic learning algorithms to the
case of randomized algorithms. We give formal definitions of stability
for randomized algorithms and prove non-asymptotic bounds on the
difference between the empirical and expected error as well as the
leave-one-out and expected error of such algorithms that depend on
their random stability.  The setup we develop for this purpose can be
also used for generally studying randomized learning algorithms.  We
then use these general results to study the effects of bagging on the
stability of a learning method and to prove non-asymptotic bounds on
the predictive performance of bagging which have not been possible to
prove with the existing theory of stability for deterministic learning
algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/elisseeff05a/elisseeff05a.pdf</url></Article><Article><id>191</id><title>
Learning Hidden Variable Networks: The Information Bottleneck Approach
</title><author>Gal Elidan, Nir Friedman</author><abstract>

  A central challenge in learning probabilistic graphical models is
  dealing with domains that involve hidden variables.  The common
  approach for learning model parameters in such domains is the 
  &lt;i&gt;expectation maximization&lt;/i&gt; (EM) algorithm.  This algorithm,
  however, can easily get trapped in sub-optimal local maxima.
  Learning the model &lt;i&gt;structure&lt;/i&gt; is even more challenging.  The
  &lt;i&gt;structural EM&lt;/i&gt; algorithm can adapt the structure in the presence of
  hidden variables, but usually performs poorly without prior
  knowledge about the cardinality and location of the hidden
  variables.  In this work, we present a general approach for learning
  Bayesian networks with hidden variables that overcomes these
  problems.  The approach builds on the &lt;i&gt;information bottleneck&lt;/i&gt;
  framework of Tishby et al. (1999). We start by proving formal
  correspondence between the information bottleneck objective and the standard
  parametric EM functional.  We then use this correspondence to construct a
  learning algorithm that combines an information-theoretic smoothing
  term with a continuation procedure.  Intuitively, the algorithm
  bypasses local maxima and achieves superior solutions by following a
  continuous path from a solution of, an easy and smooth, target
  function, to a solution of the desired likelihood function.  As we
  show, our algorithmic framework allows learning of the parameters as
  well as the structure of a network. In addition, it also allows us
  to introduce new hidden variables during model selection and learn
  their cardinality.  We demonstrate the performance of our procedure
  on several challenging real-life data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/elidan05a/elidan05a.pdf</url></Article><Article><id>192</id><title>
Diffusion Kernels on Statistical Manifolds
</title><author>John Lafferty, Guy Lebanon</author><abstract>

A family of kernels for statistical learning is introduced that 
exploits the geometric structure of statistical models. The kernels 
are based on the heat equation on the Riemannian manifold defined
by the Fisher information metric associated with a statistical family, 
and generalize the Gaussian kernel of Euclidean space. As an important 
special case, kernels based on the geometry of multinomial families 
are derived, leading to kernel-based learning algorithms that apply 
naturally to discrete data. Bounds on covering numbers and Rademacher 
averages for the kernels are proved using bounds on the eigenvalues 
of the Laplacian on Riemannian manifolds. Experimental results
are presented for document classification, for which the use of 
multinomial geometry is natural and well motivated, and improvements 
are obtained over the standard use of Gaussian or linear kernels,
which have been the standard for text classification.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/lafferty05a/lafferty05a.pdf</url></Article><Article><id>193</id><title>
Information Bottleneck for Gaussian Variables
</title><author>Gal Chechik, Amir Globerson, Naftali Tishby, Yair Weiss</author><abstract>

The problem of extracting the relevant aspects of data was
previously addressed through the &lt;i&gt; information bottleneck &lt;/i&gt; (IB)
method, through (soft) clustering one variable while preserving
information about another - &lt;i&gt; relevance &lt;/i&gt; - variable. The current
work extends these ideas to obtain continuous representations that
preserve relevant information, rather than discrete clusters, for
the special case of multivariate Gaussian variables.  
While the general continuous IB problem is difficult to solve, 
we provide an analytic solution for the optimal representation and
tradeoff between compression and relevance for the this important
case. The obtained optimal representation is a noisy linear 
projection to eigenvectors of the normalized regression
matrix &amp;#931;&lt;sub&gt;x|y&lt;/sub&gt;&amp;#931;&lt;sub&gt;x&lt;/sub&gt;&lt;sup&gt;-1&lt;/sup&gt;, 
which is also the basis obtained in 
canonical correlation analysis. However, in Gaussian IB, the 
compression tradeoff parameter uniquely determines the dimension, 
as well as the scale of each eigenvector, through a cascade of
structural phase transitions. This introduces a novel interpretation 
where solutions of different ranks lie on a continuum parametrized
by the compression level. Our analysis also provides a complete 
analytic expression of the preserved information as a function of
the compression (the "information-curve"), in terms of the
eigenvalue spectrum of the data. As in the discrete case, the 
information curve is concave and smooth, though it is made
of different analytic segments for each optimal dimension. Finally,
we show how the algorithmic theory developed in the IB framework 
provides an iterative algorithm for obtaining the optimal Gaussian
projections.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/chechik05a/chechik05a.pdf</url></Article><Article><id>194</id><title>
Multiclass Boosting for Weak Classifiers
</title><author>G&amp;#252;nther Eibl, Karl-Peter Pfeiffer</author><abstract>

AdaBoost.M2 is a boosting algorithm designed for multiclass problems with weak base classifiers. The algorithm is designed to minimize a very loose bound on the training error. We propose two alternative boosting algorithms which also minimize bounds on performance measures. These performance measures are not as strongly connected to the expected error as the training error, but the derived bounds are tighter than the bound on the training error of AdaBoost.M2. In experiments the methods have roughly the same performance in minimizing the  training and test error rates. The new algorithms have the advantage that the base classifier should minimize the confidence-rated error, whereas for AdaBoost.M2 the base classifier should minimize the pseudo-loss. This makes them more easily applicable to already existing base classifiers. The new algorithms also tend to converge faster than AdaBoost.M2.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/eibl05a/eibl05a.pdf</url></Article><Article><id>195</id><title>
A Classification Framework for Anomaly Detection
</title><author>Ingo Steinwart, Don Hush, Clint Scovel</author><abstract>

One way to describe anomalies is by saying that anomalies 
are not concentrated. This leads to the problem of finding 
level sets for the data generating density. We interpret this 
learning problem as a binary classification problem and compare 
the corresponding classification risk with the standard 
performance measure for the density level problem. In particular 
it turns out that the empirical classification risk can serve as 
an empirical performance measure for the anomaly detection problem.  
This allows us to compare different anomaly detection algorithms 
&lt;i&gt;empirically&lt;/i&gt;, i.e. with the help of a test set.  Furthermore, 
by the above interpretation we can give a strong justification for 
the well-known heuristic of  artificially sampling "labeled" samples, 
provided that the sampling plan is well chosen.  In particular this 
enables us to propose a support vector machine (SVM) for anomaly 
detection for which we can easily establish universal consistency. 
Finally, we report some experiments which compare our SVM to other 
commonly used methods including the standard one-class SVM.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/steinwart05a/steinwart05a.pdf</url></Article><Article><id>196</id><title>
Denoising Source Separation
</title><author>Jaakko S&amp;#228;rel&amp;#228;, Harri Valpola</author><abstract>

A new algorithmic framework called denoising source separation (DSS)
is introduced. The main benefit of this framework is that it allows
for the easy development of new source separation algorithms which can be
optimised for specific problems. In this framework, source
separation algorithms are constructed around denoising
procedures. The resulting algorithms can range from almost blind to
highly specialised source separation algorithms. Both simple linear
and more complex nonlinear or adaptive denoising schemes are
considered. Some existing independent component analysis algorithms
are reinterpreted within the DSS framework and new, robust blind source
separation algorithms are suggested.  The framework is derived as a
one-unit equivalent to an EM algorithm for source
separation. However, in the DSS framework it is easy to utilise
various kinds of denoising procedures which need not be based on
generative models.
In the experimental section, various DSS schemes are
applied extensively to artificial data, to real
magnetoencephalograms and to simulated CDMA mobile network signals.
Finally, various extensions to the proposed DSS algorithms are
considered. These include nonlinear observation mappings,
hierarchical models and over-complete, nonorthogonal feature spaces.
With these extensions, DSS appears to have relevance to many
existing models of neural information processing.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/sarela05a/sarela05a.pdf</url></Article><Article><id>197</id><title>
Tutorial on Practical Prediction Theory for Classification
</title><author>John Langford</author><abstract>

We discuss basic prediction theory and its impact on classification
success evaluation, implications for learning algorithm design, and
uses in learning algorithm execution. This tutorial is meant to be
a comprehensive compilation of results which are both theoretically
rigorous and quantitatively useful. &lt;p&gt;

There are two important implications of the results presented
here. The first is that common practices for reporting results in
classification should change to use the test set bound. The second is
that train set bounds can sometimes be used to directly motivate
learning algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/langford05a/langford05a.pdf</url></Article><Article><id>198</id><title>
Generalization Bounds and Complexities Based on Sparsity and Clustering for Convex Combinations of Functions from Random Classes
</title><author>Savina Andonova Jaeger</author><abstract>

A unified  approach is taken for deriving new generalization
 data dependent bounds for several classes of algorithms
explored in the existing literature by different approaches. This
unified approach is based on an extension of Vapnik's inequality for
VC classes of sets to random classes of sets - that is, classes
depending on the random data, invariant under permutation of the
 data and possessing the increasing property.
Generalization bounds are derived for convex combinations of
functions from random classes with certain properties. Algorithms,
such as SVMs (support vector machines), boosting with
 decision stumps, radial basis function networks, some hierarchies
of kernel machines or convex combinations of indicator functions
over sets with finite VC dimension, generate classifier functions
that fall into the above category. We also explore the individual
complexities of the classifiers, such as sparsity of weights and
weighted variance over clusters from the convex combination
introduced by Koltchinskii and Panchenko (2004), and show
sparsity-type and cluster-variance-type generalization bounds for
random classes.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/jaeger05a/jaeger05a.pdf</url></Article><Article><id>199</id><title>
A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs
</title><author>S. Sathiya Keerthi, Dennis DeCoste</author><abstract>

This paper develops a fast method for solving linear SVMs with 
&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;
loss function that is suited for large scale data mining tasks such as
text classification.  This is done by modifying the finite Newton
method of Mangasarian in several ways.  Experiments indicate that the
method is much faster than decomposition methods such as SVM&lt;sup&gt;light&lt;/sup&gt;,
SMO and BSVM (e.g., 4-100 fold), especially when the number of
examples is large. The paper also suggests ways of extending the
method to other loss functions such as the modified Huber's loss
function and the &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; loss function, and also for 
solving ordinal regression.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/keerthi05a/keerthi05a.pdf</url></Article><Article><id>200</id><title>
Core Vector Machines: Fast SVM Training on Very Large Data Sets
</title><author>Ivor W. Tsang, James T. Kwok, Pak-Ming Cheung</author><abstract>

Standard SVM training has &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;m&lt;sup&gt;3&lt;/sup&gt;&lt;/i&gt;) time and 
&lt;i&gt;O&lt;/i&gt;(&lt;i&gt;m&lt;sup&gt;2&lt;/sup&gt;&lt;/i&gt;) space complexities, where &lt;i&gt;m&lt;/i&gt; 
is the training set size. It is thus computationally infeasible
on very large data sets. By observing that practical SVM 
implementations only &lt;i&gt;approximate&lt;/i&gt; the optimal solution 
by an iterative strategy, we scale up kernel methods by exploiting 
such "approximateness" in this paper.  We first show that many kernel 
methods can be equivalently formulated as minimum enclosing ball (MEB)
problems in computational geometry. Then, by adopting an efficient 
approximate MEB algorithm, we obtain provably approximately optimal 
solutions with the idea of core sets. Our proposed Core Vector Machine
(CVM) algorithm can be used with nonlinear kernels and has a time 
complexity that is &lt;i&gt;linear&lt;/i&gt; in &lt;i&gt;m&lt;/i&gt; and a space
complexity that is &lt;i&gt;independent&lt;/i&gt; of &lt;i&gt;m&lt;/i&gt;.
Experiments on large toy and real-world data sets demonstrate that 
the CVM is as accurate as existing SVM implementations, but is
much faster and can handle much larger data sets than existing 
scale-up methods.  For example, CVM with the Gaussian kernel produces 
superior results on the KDDCUP-99 intrusion detection data, which has 
about five million training patterns, in only 1.4 seconds on a 3.2GHz 
Pentium--4 PC.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/tsang05a/tsang05a.pdf</url></Article><Article><id>201</id><title>
Generalization Bounds for the Area Under the ROC Curve
</title><author>Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, Dan Roth</author><abstract>

We study generalization properties of the area under the ROC curve (AUC), a 
quantity that has been advocated as an evaluation criterion for the bipartite 
ranking problem.
The AUC is a different term than the error rate used for 
evaluation in classification problems; consequently, existing generalization 
bounds for the classification error rate cannot be used to draw conclusions 
about the AUC. 
In this paper, we define the expected accuracy of a 
ranking function (analogous to the expected error rate of a classification
function), and derive distribution-free probabilistic bounds on the deviation 
of the empirical AUC of a ranking function (observed on a finite data 
sequence) from its expected accuracy.  
We derive both a large deviation bound, which serves to bound the expected 
accuracy of a ranking function in terms of its empirical AUC on a test
sequence, and a uniform convergence bound, which serves to bound the expected 
accuracy of a learned ranking function in terms of its empirical AUC on a 
training sequence.
Our uniform convergence bound is expressed in terms of a new set of 
combinatorial parameters that we term the bipartite rank-shatter coefficients;
these play the same role in our result as do the standard VC-dimension related 
shatter coefficients (also known as the growth function) in uniform 
convergence results for the classification error rate.
A comparison of our result with a recent uniform convergence result derived by
Freund et al. (2003) for a quantity closely related to the AUC shows that 
the bound provided by our result can be considerably tighter.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/agarwal05a/agarwal05a.pdf</url></Article><Article><id>202</id><title>
Learning with Decision Lists of Data-Dependent Features
</title><author>Mario Marchand, Marina Sokolova</author><abstract>

We present a learning algorithm for decision lists which allows
features that are constructed from the data and allows a trade-off
between accuracy and complexity. We provide bounds on the
generalization error of this learning algorithm in terms of the
number of errors and the size of the classifier it finds on the
training data. We also compare its performance on some natural
data sets with the set covering machine and the support vector
machine. Furthermore, we show that the proposed bounds on the
generalization error provide effective guides for model selection.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/marchand05a/marchand05a.pdf</url></Article><Article><id>203</id><title>
Estimating Functions for Blind Separation When Sources Have Variance Dependencies
</title><author>Motoaki Kawanabe, Klaus-Robert M&amp;#252;ller</author><abstract>

A blind separation problem where the sources are not independent,
but have variance dependencies is discussed. For this scenario
Hyv&amp;#228;rinen and Hurri (2004) proposed an algorithm which requires 
no assumption on distributions of sources and no parametric model 
of dependencies between components.  In this paper, we extend 
the semiparametric approach of Amari and Cardoso (1997) to variance 
dependencies and study estimating functions for blind separation of 
such dependent sources.  In particular, we show that many ICA 
algorithms are applicable to the variance-dependent model as well
under mild conditions, although they should in principle not. 
Our results indicate that separation can be done based only on 
normalized sources which are adjusted to have stationary variances
and is not affected by the dependent activity levels. We also study 
the asymptotic distribution of the quasi maximum likelihood method and
the stability of the natural gradient learning in detail. Simulation 
results of artificial and realistic examples match well with our 
theoretical findings.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/kawanabe05a/kawanabe05a.pdf</url></Article><Article><id>204</id><title>
Characterization of a Family of Algorithms for Generalized 
Discriminant Analysis on Undersampled Problems
</title><author>Jieping Ye</author><abstract>

A generalized discriminant analysis based on a new optimization 
criterion  is presented. The criterion extends the optimization 
criteria of the classical Linear Discriminant Analysis (LDA) when 
the scatter matrices are singular. An efficient algorithm for  
the new optimization problem is presented.  
&lt;p&gt;
The solutions to the 
proposed criterion form a family of algorithms for generalized LDA, 
which can be characterized in a closed form. We study two specific 
algorithms, namely Uncorrelated LDA (ULDA) and Orthogonal LDA (OLDA). 
ULDA was previously proposed for feature extraction and dimension 
reduction, whereas OLDA is a novel algorithm proposed in this paper. 
The features in the reduced space of ULDA are uncorrelated, while 
the discriminant vectors of OLDA are orthogonal to each other. We 
have conducted a comparative study on a variety of real-world data 
sets to evaluate ULDA and OLDA in terms of classification accuracy.  

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ye05a/ye05a.pdf</url></Article><Article><id>205</id><title>
Tree-Based Batch Mode Reinforcement Learning
</title><author>Damien  Ernst, Pierre  Geurts, Louis  Wehenkel</author><abstract>

Reinforcement  learning  aims to  determine  an  optimal  control policy  from
interaction with  a system  or from observations  gathered from a  system.  In
batch mode,  it can  be achieved by  approximating the  so-called 
&lt;i&gt;Q&lt;/i&gt;-function based on a set of four-tuples  (&lt;i&gt;x&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt;, 
&lt;i&gt;u&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt; , &lt;i&gt;r&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt;, &lt;i&gt;x&lt;sub&gt;t+1&lt;/sub&gt;&lt;/i&gt;) where 
&lt;i&gt;x&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt; denotes the  system state  at time  &lt;i&gt;t&lt;/i&gt;,  
&lt;i&gt;u&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt; the  control action  taken, &lt;i&gt;r&lt;sub&gt;t&lt;/sub&gt;&lt;/i&gt;  
the instantaneous reward obtained and &lt;i&gt;x&lt;sub&gt;t+1&lt;/sub&gt;&lt;/i&gt; the 
successor state of the system, and  by   determining  the  control   
policy  from  this &lt;i&gt;Q&lt;/i&gt;-function.   
The &lt;i&gt;Q&lt;/i&gt;-function approximation  may be  obtained from the  limit of a  
sequence of (batch mode) supervised learning  problems.  Within this framework 
we describe the  use of several  classical tree-based  supervised learning  
methods (CART, Kd-tree, tree bagging) and two newly proposed ensemble 
algorithms, namely &lt;i&gt;extremely&lt;/i&gt; and &lt;i&gt;totally&lt;/i&gt; randomized trees.  
We study their performances on several examples and find that  the ensemble 
methods based on regression trees perform  well in  extracting relevant  
information about  the  optimal control policy from sets of four-tuples.   
In particular, the totally randomized trees give good results  while 
ensuring the convergence of  the sequence, whereas by relaxing the 
convergence constraint  even better accuracy results are provided
by the extremely  randomized trees.  

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ernst05a/ernst05a.pdf</url></Article><Article><id>206</id><title>
Learning Module Networks
</title><author>Eran Segal, Dana Pe'er, Aviv Regev, Daphne Koller, Nir Friedman</author><abstract>

Methods for learning Bayesian networks can discover dependency
structure between observed variables. Although these methods are
useful in many applications, they run into computational and
statistical problems in domains that involve a large number of
variables.  In this paper, we consider a solution that is applicable
when many variables have similar behavior. We introduce a new class of
models, &lt;i&gt;module networks&lt;/i&gt;, that explicitly partition the
variables into modules, so that the variables in each module share the
same parents in the network and the same conditional probability
distribution.  We define the semantics of module networks, and
describe an algorithm that learns the modules' composition and their
dependency structure from data. Evaluation on real data in the domains
of gene expression and the stock market shows that module networks
generalize better than Bayesian networks, and that the learned module
network structure reveals regularities that are obscured in learned
Bayesian networks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/segal05a/segal05a.pdf</url></Article><Article><id>207</id><title>
Active Learning to Recognize Multiple Types of Plankton
</title><author>Tong Luo, Kurt Kramer, Dmitry B. Goldgof, Lawrence O. Hall, Scott Samson, Andrew Remsen, Thomas Hopkins</author><abstract>

This paper presents an active learning method which reduces the 
labeling effort of domain experts in multi-class classification 
problems.  Active learning is applied in conjunction with
support vector machines to recognize underwater zooplankton 
from higher-resolution, new generation SIPPER II images.
Most previous work on active learning with support vector machines 
only deals with two class problems.  In this paper, we propose an 
active learning approach "breaking ties" for multi-class support
vector machines using the one-vs-one approach with a probability 
approximation. Experimental results indicate that our approach often 
requires significantly less labeled images to reach a given accuracy 
than the approach of labeling the least certain test example and 
random sampling.  It can also be applied in batch mode resulting 
in an accuracy comparable to labeling one image at a time and 
retraining. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/luo05a/luo05a.pdf</url></Article><Article><id>208</id><title>
Learning Multiple Tasks with Kernel Methods
</title><author>Theodoros Evgeniou, Charles A. Micchelli, Massimiliano Pontil</author><abstract>

We study the problem of learning many related tasks simultaneously
using kernel methods and regularization. The standard single-task
kernel methods, such as support vector machines and regularization
networks, are extended to the case of multi-task learning.  Our
analysis shows that the problem of estimating many task functions with
regularization can be cast as a single task learning problem if a
family of multi-task kernel functions we define is used.  These
kernels model relations among the tasks and are derived from a novel
form of regularizers. Specific kernels that can be used for multi-task
learning are provided and experimentally tested on two real
data sets. In agreement with past empirical work on multi-task
learning, the experiments show that learning multiple related tasks
simultaneously using the proposed approach can significantly
outperform standard single-task learning particularly when there are
many related tasks but few data per task.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/evgeniou05a/evgeniou05a.pdf</url></Article><Article><id>209</id><title>
Adaptive Online Prediction by Following the Perturbed Leader
</title><author>Marcus Hutter, Jan Poland</author><abstract>

When applying aggregating strategies to Prediction with Expert
Advice (PEA), the learning rate must be adaptively tuned. The
natural choice of sqrt(complexity/current loss)
renders the analysis of Weighted Majority (WM) derivatives quite
complicated. In particular, for arbitrary weights there have
been no results proven so far. The analysis of the alternative
Follow the Perturbed Leader (FPL) algorithm from Kalai and
Vempala (2003) based on Hannan's algorithm is easier. We
derive loss bounds for adaptive learning rate and both finite
expert classes with uniform weights and countable expert
classes with arbitrary weights. For the former setup, our loss
bounds match the best known results so far, while for the
latter our results are new.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/hutter05a/hutter05a.pdf</url></Article><Article><id>210</id><title>
Variational Message Passing
</title><author>John Winn, Christopher M. Bishop</author><abstract>

Bayesian inference is now widely established as one of the
principal foundations for machine learning. In practice, exact
inference is rarely possible, and so a variety of approximation
techniques have been developed, one of the most widely used being
a deterministic framework called variational inference. In this
paper we introduce Variational Message Passing (VMP), a general
purpose algorithm for applying variational inference to Bayesian
Networks. Like belief propagation, VMP proceeds by sending
messages between nodes in the network and updating posterior
beliefs using local operations at each node. Each such update
increases a lower bound on the log evidence (unless already at a
local maximum). In contrast to belief propagation, VMP can be
applied to a very general class of conjugate-exponential models
because it uses a factorised variational approximation.
Furthermore, by introducing additional variational parameters, VMP
can be applied to models containing non-conjugate distributions.
The VMP framework also allows the lower bound to be evaluated, and
this can be used both for model comparison and for detection of
convergence. Variational message passing has been implemented in
the form of a general purpose inference engine called VIBES
('Variational Inference for BayEsian networkS') which allows
models to be specified graphically and then solved variationally
without recourse to coding.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/winn05a/winn05a.pdf</url></Article><Article><id>211</id><title>
Estimation of Non-Normalized Statistical Models by Score Matching
</title><author>Aapo Hyv&amp;#228;rinen</author><abstract>

One often wants to estimate statistical models where the probability
density function is known only up to a multiplicative normalization
constant. Typically, one then has to resort to Markov Chain Monte
Carlo methods, or approximations of the normalization constant. Here,
we propose that such models can be estimated by minimizing the
expected squared distance between the gradient of the log-density
given by the model and the gradient of the log-density of the observed
data.  While the estimation of the gradient of log-density function
is, in principle, a very difficult non-parametric problem, we prove a
surprising result that gives a simple formula for this objective
function. The density function of the observed data does not appear in
this formula, which simplifies to a sample average of a sum of some
derivatives of the log-density given by the model.  The validity of
the method is demonstrated on multivariate Gaussian and independent
component analysis models, and by estimating an overcomplete filter
set for natural image data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf</url></Article><Article><id>212</id><title>
Smooth &amp;#949;-Insensitive Regression by Loss Symmetrization
</title><author>Ofer Dekel, Shai Shalev-Shwartz, Yoram Singer</author><abstract>

We describe new loss functions for regression problems along with an
accompanying algorithmic framework which utilizes these functions.  These loss
functions are derived by symmetrization of margin-based losses commonly used in
boosting algorithms, namely, the logistic loss and the exponential loss.  The
resulting symmetric logistic loss can be viewed as a smooth approximation to
the  &amp;#949;-insensitive hinge loss used in support vector regression. We
describe and analyze two parametric families of batch learning algorithms for
minimizing these symmetric losses. The first family employs an iterative
&lt;i&gt;log-additive&lt;/i&gt; update which can be viewed as a regression counterpart to
recent boosting algorithms. The second family utilizes an iterative
&lt;i&gt;additive&lt;/i&gt; update step. We also describe and analyze online gradient
descent (GD) and exponentiated gradient (EG) algorithms for the symmetric
logistic loss. A byproduct of our work is a new simple form of regularization
for boosting-based classification and regression algorithms. Our regression
framework also has implications on classification algorithms, namely, a new
additive update boosting algorithm for classification. We demonstrate the
merits of our algorithms in a series of experiments.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/dekel05a/dekel05a.pdf</url></Article><Article><id>213</id><title>
Quasi-Geodesic Neural Learning Algorithms Over the Orthogonal Group: A Tutorial
</title><author>Simone Fiori</author><abstract>

The aim of this contribution is to present a tutorial on learning
algorithms for a single neural layer whose connection matrix belongs
to the orthogonal group. The algorithms exploit geodesics
appropriately connected as piece-wise approximate integrals of the
exact differential learning equation. The considered learning
equations essentially arise from the Riemannian-gradient-based
optimization theory with deterministic and diffusion-type
gradient. The paper aims specifically at reviewing the relevant
mathematics (and at presenting it in as much transparent way as
possible in order to make it accessible to readers that do not possess
a background in differential geometry), at bringing together modern
optimization methods on manifolds and at comparing the different
algorithms on a common machine learning problem. As a numerical
case-study, we consider an application to non-negative independent
component analysis, although it should be recognized that Riemannian
gradient methods give rise to general-purpose algorithms, by no means
limited to ICA-related applications.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/fiori05a/fiori05a.pdf</url></Article><Article><id>214</id><title>
Machine Learning Methods for Predicting Failures in Hard Drives:  A Multiple-Instance Application
</title><author>Joseph F. Murray, Gordon F. Hughes, Kenneth Kreutz-Delgado</author><abstract>

We compare machine learning methods applied to a difficult real-world
problem: predicting computer hard-drive failure using attributes monitored
internally by individual drives.  The problem is one of detecting rare
events in a time series of noisy and nonparametrically-distributed data. We
develop a new algorithm based on the multiple-instance learning framework
and the naive Bayesian classifier (mi-NB) which is specifically designed
for the low false-alarm case, and is shown to have promising performance.
Other methods compared are support vector machines (SVMs), unsupervised
clustering, and non-parametric statistical tests (rank-sum and reverse
arrangements).  The failure-prediction performance of the SVM, rank-sum and
mi-NB algorithm is considerably better than the threshold method currently
implemented in drives, while maintaining low false alarm rates.  Our
results suggest that nonparametric statistical tests should be considered
for learning problems involving detecting rare events in time series data.
An appendix details the calculation of rank-sum significance probabilities
in the case of discrete, tied observations, and we give new recommendations
about when the exact calculation should be used instead of the
commonly-used normal approximation.  These normal approximations may be
particularly inaccurate for rare event problems like hard drive failures.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/murray05a/murray05a.pdf</url></Article><Article><id>215</id><title>
Multiclass Classification with Multi-Prototype Support Vector Machines
</title><author>Fabio Aiolli, Alessandro Sperduti</author><abstract>
&lt;p&gt;
Winner-take-all multiclass classifiers are built on the top of a
set of prototypes each representing one of the available classes.
A pattern is then classified with the label associated to the most
'similar' prototype. Recent proposal of SVM extensions to
multiclass can be considered instances of the same strategy with
one prototype per class.
&lt;/p&gt;
&lt;p&gt;
The multi-prototype SVM proposed in this paper extends multiclass
SVM to multiple prototypes per class. It allows to combine several
vectors in a principled way to obtain large margin decision
functions. For this problem, we give a compact constrained
quadratic formulation and we propose a greedy optimization
algorithm able to find locally optimal solutions for the non
convex objective function.
&lt;/p&gt;
&lt;p&gt;
This algorithm proceeds by reducing the overall problem into a
series of simpler convex problems. For the solution of these
reduced problems an efficient optimization algorithm is proposed.
A number of pattern selection strategies are then discussed to
speed-up the optimization process. In addition, given the
combinatorial nature of the overall problem, stochastic search
strategies are suggested to escape from local minima which are not
globally optimal.
&lt;/p&gt;
&lt;p&gt;
Finally, we report experiments on a number of datasets. The
performance obtained using few simple linear prototypes is
comparable to that obtained by state-of-the-art kernel-based
methods but with a significant reduction
(of one or two orders) in response time.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/aiolli05a/aiolli05a.pdf</url></Article><Article><id>216</id><title>
Prioritization Methods for Accelerating MDP Solvers
</title><author>David Wingate, Kevin D. Seppi</author><abstract>

The performance of value and policy iteration can be dramatically
improved by eliminating redundant or useless backups, and by backing
up states in the right order.  We study several methods designed to
accelerate these iterative solvers, including prioritization,
partitioning, and variable reordering.  We generate a family of
algorithms by combining several of the methods discussed, and present
extensive empirical evidence demonstrating that performance can
improve by several orders of magnitude for many problems, while
preserving accuracy and convergence guarantees.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/wingate05a/wingate05a.pdf</url></Article><Article><id>217</id><title>
Learning from Examples as an Inverse Problem
</title><author>Ernesto De Vito, Lorenzo Rosasco, Andrea Caponnetto, Umberto De Giovannini, Francesca Odone</author><abstract>

Many works related learning from examples to regularization techniques
for inverse problems, emphasizing the strong algorithmic and
conceptual analogy of certain learning algorithms with regularization
algorithms.  In particular it is well known that regularization
schemes such as Tikhonov regularization can be effectively used in the
context of learning and are closely related to algorithms such as
support vector machines.  Nevertheless the connection with inverse
problem was considered only for the discrete (finite sample) problem
and the probabilistic aspects of learning from examples were not taken
into account.  In this paper we provide a natural extension of such
analysis to the continuous (population) case and study the interplay
between the discrete and continuous problems.  From a theoretical
point of view, this allows to draw a clear connection between the
consistency approach in learning theory and the stability convergence
property in ill-posed inverse problems.  The main mathematical result
of the paper is a new probabilistic bound for the regularized
least-squares algorithm.  By means of standard results on the
approximation term, the consistency of the algorithm easily follows.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/devito05a/devito05a.pdf</url></Article><Article><id>218</id><title>
Loopy Belief Propagation: Convergence and Effects of Message Errors
</title><author>Alexander T. Ihler, John W. Fisher III, Alan S. Willsky</author><abstract>

Belief propagation (BP) is an increasingly popular method of performing
approximate inference on arbitrary graphical models.  At times, even
further approximations are required, whether due to quantization of the
messages or model parameters, from other simplified message or model
representations, or from stochastic approximation methods.  The
introduction of such errors into the BP message computations has the
potential to affect the solution obtained adversely.  We analyze the
effect resulting from message approximation under two particular measures
of error, and show bounds on the accumulation of errors in the system.
This analysis leads to convergence conditions for traditional BP message
passing, and both strict bounds and estimates of the resulting error in
systems of approximate BP message passing.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ihler05a/ihler05a.pdf</url></Article><Article><id>219</id><title>
Learning a Mahalanobis Metric from Equivalence Constraints
</title><author>Aharon Bar-Hillel, Tomer Hertz, Noam Shental, Daphna Weinshall</author><abstract>

&lt;p&gt;
Many learning algorithms use a metric defined over the input space as
a principal tool, and their performance critically depends on the
quality of this metric.  We address the problem of learning metrics
using side-information in the form of equivalence constraints.  Unlike
labels, we demonstrate that this type of side-information can
sometimes be automatically obtained without the need of human
intervention.  We show how such side-information can be used to modify
the representation of the data, leading to improved clustering and
classification.
&lt;/p&gt;
&lt;p&gt;
Specifically, we present the Relevant Component Analysis (RCA)
algorithm, which is a simple and efficient algorithm for learning a
Mahalanobis metric.  We show that RCA is the solution of an
interesting optimization problem, founded on an information theoretic
basis.  If dimensionality reduction is allowed within RCA, we show
that it is optimally accomplished by a version of
Fisher's linear discriminant that uses constraints. Moreover, under certain Gaussian
assumptions, RCA can be viewed as a Maximum Likelihood estimation of
the within class covariance matrix. We conclude with extensive
empirical evaluations of RCA, showing its advantage over alternative
methods.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/bar-hillel05a/bar-hillel05a.pdf</url></Article><Article><id>220</id><title>
Algorithmic Stability and Meta-Learning
</title><author>Andreas Maurer</author><abstract>

A mechnism of transfer learning is analysed, where samples drawn from
different learning tasks of an environment are used to improve the learners
performance on a new task. We give a general method to prove generalisation
error bounds for such meta-algorithms. The method can be applied to the bias
learning model of J. Baxter and to derive novel generalisation bounds for
meta-algorithms searching spaces of uniformly stable algorithms. We also
present an application to regularized least squares regression.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/maurer05a/maurer05a.pdf</url></Article><Article><id>221</id><title>
Matrix Exponentiated Gradient Updates for On-line Learning and Bregman Projection
</title><author>Koji Tsuda, Gunnar R&amp;#228;tsch, Manfred K. Warmuth</author><abstract>

We address the problem of learning a symmetric positive definite
matrix.  The central issue is to design parameter updates that
preserve positive definiteness.  Our updates are motivated with the
&lt;i&gt;von Neumann&lt;/i&gt; divergence. Rather than treating the most general
case, we focus on two key applications that exemplify our methods:
on-line learning with a simple square loss, and finding a symmetric
positive definite matrix subject to linear constraints.  The updates
generalize the exponentiated gradient (EG) update and AdaBoost,
respectively: the parameter is now a symmetric positive definite
matrix of trace one instead of a probability vector (which in this
context is a diagonal positive definite matrix with trace one).  The
generalized updates use matrix logarithms and exponentials to preserve
positive definiteness.  Most importantly, we show how the derivation
and the analyses of the original EG update and AdaBoost generalize to
the non-diagonal case. We apply the resulting &lt;i&gt;matrix exponentiated
gradient&lt;/i&gt; (MEG) update and &lt;i&gt;DefiniteBoost&lt;/i&gt; to the problem of
learning a kernel matrix from distance measurements.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/tsuda05a/tsuda05a.pdf</url></Article><Article><id>222</id><title>
Gaussian Processes for Ordinal Regression
</title><author>Wei Chu, Zoubin Ghahramani</author><abstract>

We present a probabilistic kernel approach to ordinal regression
based on Gaussian processes. A threshold model that generalizes
the &lt;i&gt;probit&lt;/i&gt; function is used as the likelihood function for
ordinal variables. Two inference techniques, based on the Laplace
approximation and the expectation propagation algorithm
respectively, are derived for hyperparameter learning and model
selection. We compare these two Gaussian process approaches with a
previous ordinal regression method based on support vector
machines on some benchmark and real-world data sets, including
applications of ordinal regression to collaborative filtering and
gene expression analysis. Experimental results on these data sets
verify the usefulness of our approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/chu05a/chu05a.pdf</url></Article><Article><id>223</id><title>
Learning the Kernel with Hyperkernels
</title><author>Cheng Soon Ong, Alexander J. Smola, Robert C. Williamson</author><abstract>
&lt;p&gt;
This paper addresses the problem of choosing a kernel suitable for
estimation with a support vector machine, hence further automating
machine learning.  This goal is achieved by defining a reproducing
kernel Hilbert space on the space of kernels itself. Such a
formulation leads to a statistical estimation problem similar to
the problem of minimizing a regularized risk functional.
&lt;/p&gt; 
&lt;p&gt;
We state the equivalent representer theorem for the choice of kernels
and present a semidefinite programming formulation of the resulting
optimization problem. Several recipes for constructing hyperkernels
are provided, as well as the details of common machine learning
problems. Experimental results for classification, regression and
novelty detection on UCI data show the feasibility of our approach.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ong05a/ong05a.pdf</url></Article><Article><id>224</id><title>
A Generalization Error for Q-Learning
</title><author>Susan A. Murphy</author><abstract>

 Planning problems that involve learning a policy from a single
training set of finite horizon trajectories arise in both social
science and medical fields.  We consider Q-learning with function
approximation for this setting and derive an upper bound on the
generalization error.  This upper bound is in terms of quantities
minimized by a Q-learning algorithm, the complexity of the
approximation space and an approximation term due to the mismatch
between Q-learning and the goal of learning a policy that maximizes
the value function.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/murphy05a/murphy05a.pdf</url></Article><Article><id>225</id><title>
Learning the Kernel Function via Regularization
</title><author>Charles A. Micchelli, Massimiliano Pontil</author><abstract>

We study the problem of finding an optimal kernel from a prescribed
convex set of kernels &lt;i&gt;K&lt;/i&gt; for learning a real-valued function by
regularization. We establish for a wide variety of regularization
functionals that this leads to a convex optimization problem and, for
square loss regularization, we characterize the solution of this
problem.  We show that, although &lt;i&gt;K&lt;/i&gt; may be an uncountable set,
the optimal kernel is always obtained as a convex combination of at
most &lt;i&gt;m+2&lt;/i&gt; basic kernels, where &lt;i&gt;m&lt;/i&gt; is the number of data examples. In
particular, our results apply to learning the optimal radial kernel or
the optimal dot product kernel.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/micchelli05a/micchelli05a.pdf</url></Article><Article><id>226</id><title>
Analysis of Variance of Cross-Validation Estimators of the Generalization Error
</title><author>Marianthi Markatou, Hong Tian, Shameek Biswas, George Hripcsak</author><abstract>

This paper brings together methods from two different disciplines:
statistics and machine learning. We address the problem of estimating
the variance of cross-validation (CV) estimators of the generalization
error. In particular, we approach the problem of variance estimation
of the CV estimators of generalization error as a problem in
approximating the moments of a statistic. The approximation
illustrates the role of training and test sets in the performance of
the algorithm. It provides a unifying approach to evaluation of
various methods used in obtaining training and test sets and it takes
into account the variability due to different training and test
sets. For the simple problem of predicting the sample mean and in the
case of smooth loss functions, we show that the variance of the CV
estimator of the generalization error is a function of the moments of
the random variables Y=&lt;i&gt;Card&lt;/i&gt;(S&lt;sub&gt;j&lt;/sub&gt; &amp;#8745; S&lt;sub&gt;j'&lt;/sub&gt;)
and Y*=&lt;i&gt;Card&lt;/i&gt;(S&lt;sub&gt;j&lt;/sub&gt;&lt;sup&gt;c&lt;/sup&gt; &amp;#8745;
S&lt;sub&gt;j'&lt;/sub&gt;&lt;sup&gt;c&lt;/sup&gt;), where S&lt;sub&gt;j&lt;/sub&gt;, S&lt;sub&gt;j'&lt;/sub&gt; are
two training sets, and S&lt;sub&gt;j&lt;/sub&gt;&lt;sup&gt;c&lt;/sup&gt;,
S&lt;sub&gt;j'&lt;/sub&gt;&lt;sup&gt;c&lt;/sup&gt; are the corresponding test sets. We prove
that the distribution of Y and Y* is hypergeometric and we compare our
estimator with the one proposed by Nadeau and Bengio (2003). We extend
these results in the regression case and the case of absolute error
loss, and indicate how the methods can be extended to the
classification case. We illustrate the results through simulation.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/markatou05a/markatou05a.pdf</url></Article><Article><id>227</id><title>
Semigroup Kernels on Measures
</title><author>Marco Cuturi, Kenji Fukumizu, Jean-Philippe Vert</author><abstract>

We present a family of positive definite kernels on measures,
characterized by the fact that the value of the kernel between two
measures is a function of their sum. These kernels can be used to
derive kernels on structured objects, such as images and texts, by
representing these objects as sets of components, such as pixels
or words, or more generally as measures on the space of
components. Several kernels studied in this work make use of
common quantities defined on measures such as entropy or
generalized variance to detect similarities. Given an a priori
kernel on the space of components itself, the approach is further
extended by restating the previous results in a more efficient and
flexible framework using the "kernel trick". Finally, a
constructive approach to such positive definite kernels through an
integral representation theorem is proved, before presenting
experimental results on a benchmark experiment of handwritten
digits classification to illustrate the validity of the approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/cuturi05a/cuturi05a.pdf</url></Article><Article><id>228</id><title>
Separating a Real-Life Nonlinear Image Mixture
</title><author>Lu&amp;#237;s B. Almeida</author><abstract>
&lt;p&gt;
When acquiring an image of a paper document, the image printed on the
back page sometimes shows through. The mixture of the front- and
back-page images thus obtained is markedly nonlinear, and thus 
constitutes a good real-life test case for nonlinear blind source
separation.
&lt;/p&gt;&lt;p&gt;
This paper addresses a difficult version of this problem,
corresponding to the use of "onion skin" paper, which results in a
relatively strong nonlinearity of the mixture, which becomes close to
singular in the lighter regions of the images. The separation is
achieved through the MISEP technique, which is an extension of the
well known INFOMAX method. The separation results are assessed with
objective quality measures. They show an improvement over the
results obtained with linear separation, but have room for further
improvement.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/almeida05a/almeida05a.pdf</url></Article><Article><id>229</id><title>
Concentration Bounds for Unigram Language Models
</title><author>Evgeny Drukh, Yishay Mansour</author><abstract>

&lt;p&gt;
We show several high-probability concentration bounds for learning
unigram language models. One interesting quantity is the
probability of all words appearing exactly &lt;i&gt;k&lt;/i&gt; times in a sample
of size &lt;i&gt;m&lt;/i&gt;. A standard estimator for this quantity is the
Good-Turing estimator. The existing analysis on its error shows a
high-probability bound of approximately &lt;i&gt;O(k / m&lt;sup&gt;1/2&lt;/sup&gt;)&lt;/i&gt;. 
We improve its dependency on &lt;i&gt;k&lt;/i&gt; to &lt;i&gt;O(k&lt;sup&gt;1/4&lt;/sup&gt; / 
m&lt;sup&gt;1/2&lt;/sup&gt; + k / m)&lt;/i&gt;.  We also analyze the
empirical frequencies estimator, showing that with high
probability its error is bounded by approximately &lt;i&gt;O( 1 /
k + k&lt;sup&gt;1/2&lt;/sup&gt; / m)&lt;/i&gt;. We derive a combined estimator,
which has an error of approximately &lt;i&gt;O(m&lt;sup&gt;-2/5&lt;/sup&gt;)&lt;/i&gt;, for
 any &lt;i&gt;k&lt;/i&gt;.
&lt;/p&gt;&lt;p&gt;
A standard measure for the quality of a learning algorithm is its
expected per-word log-loss. The leave-one-out method can be used
for estimating the log-loss of the unigram model. We show that its
error has a high-probability bound of approximately &lt;i&gt;O(1 / m&lt;sup&gt;1/2&lt;/sup&gt;)&lt;/i&gt;, 
for any underlying distribution.
&lt;/p&gt;&lt;p&gt;
We also bound the log-loss a priori, as a function of various
parameters of the distribution.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/drukh05a/drukh05a.pdf</url></Article><Article><id>230</id><title>
An MDP-Based Recommender System
</title><author>Guy Shani, David Heckerman, Ronen I. Brafman</author><abstract>

Typical recommender systems adopt a static view of the recommendation
process and treat it as a prediction problem.  We argue that it is
more appropriate to view the problem of generating recommendations as
a sequential optimization problem and, consequently, that Markov
decision processes (MDPs) provide a more appropriate model for
recommender systems.  MDPs introduce two benefits: they take into
account the long-term effects of each recommendation and
the expected value of each recommendation.  To succeed in
practice, an MDP-based recommender system must employ a strong initial
model, must be solvable quickly, and should not consume too much
memory. In this paper, we describe our particular MDP model, its
initialization using a predictive model, the solution and update
algorithm, and its actual performance on a commercial site.  We also
describe the particular predictive model we used which outperforms
previous models. Our system is one of a small number of commercially
deployed recommender systems. As far as we know, it is the first to
report experimental analysis conducted on a
real commercial site. These results validate the commercial value
of recommender systems, and in particular, of our MDP-based approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/shani05a/shani05a.pdf</url></Article><Article><id>231</id><title>
Universal Algorithms for Learning Theory Part I : Piecewise Constant Functions
</title><author>Peter Binev, Albert Cohen, Wolfgang Dahmen, Ronald DeVore, Vladimir Temlyakov</author><abstract>

This paper is concerned with the construction and analysis of a
universal estimator for the regression problem in supervised learning.
Universal means that the estimator does not depend on any a priori
assumptions about the regression function to be estimated.  The
universal estimator studied in this paper consists of a least-square
fitting procedure using piecewise constant functions on a partition
which depends adaptively on the data.  The partition is generated by a
splitting procedure which differs from those used in CART algorithms.
It is proven that this estimator performs at the optimal convergence
rate for a wide class of priors on the regression function.  Namely,
as will be made precise in the text, if the regression function is in
any one of a certain class of approximation spaces (or smoothness
spaces of order not exceeding one -- a limitation resulting because
the estimator uses piecewise constants) measured relative to the
marginal measure, then the estimator converges to the regression
function (in the least squares sense) with an optimal rate of
convergence in terms of the number of samples.  The estimator is also
numerically feasible and can be implemented on-line.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/binev05a/binev05a.pdf</url></Article><Article><id>232</id><title>
Efficient Computation of Gapped Substring Kernels on Large Alphabets
</title><author>Juho Rousu, John Shawe-Taylor</author><abstract>

&lt;p&gt;
We present a sparse dynamic programming algorithm that, given two
strings &lt;i&gt;s&lt;/i&gt; and &lt;i&gt;t&lt;/i&gt; , a gap penalty &amp;#955;, and an integer
&lt;i&gt;p&lt;/i&gt;, computes the value of the gap-weighted length-&lt;i&gt;p&lt;/i&gt;
subsequences kernel. The algorithm works in time &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;p&lt;/i&gt;
|&lt;i&gt;M&lt;/i&gt;| log |&lt;i&gt;t&lt;/i&gt;|), where &lt;i&gt;M&lt;/i&gt; = {(&lt;i&gt;i,j&lt;/i&gt;) | 
&lt;i&gt;s&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt; = &lt;i&gt;t&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt;} is the set of matches of
characters in the two sequences. The algorithm is easily adapted to
handle bounded length subsequences and different gap-penalty schemes,
including penalizing by the total length of gaps and the number of
gaps as well as incorporating character-specific match/gap penalties.
&lt;/p&gt;

&lt;p&gt; The new algorithm is empirically evaluated against a full dynamic
programming approach and a trie-based algorithm both on synthetic and
newswire article data. Based on the experiments, the full dynamic
programming approach is the fastest on short strings, and on long
strings if the alphabet is small. On large alphabets, the new sparse
dynamic programming algorithm is the most efficient. On medium-sized
alphabets the trie-based approach is best if the maximum number of
allowed gaps is strongly restricted.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/rousu05a/rousu05a.pdf</url></Article><Article><id>233</id><title>
Clustering on the Unit Hypersphere using von Mises-Fisher  Distributions
</title><author>Arindam Banerjee, Inderjit S. Dhillon, Joydeep Ghosh, Suvrit Sra</author><abstract>

Several large scale data mining applications, such as text
categorization and gene expression analysis, involve high-dimensional
data that is also inherently directional in nature.  Often such data
is &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt; normalized so that it lies on the surface of a
unit hypersphere.  Popular models such as (mixtures of) multi-variate
Gaussians are inadequate for characterizing such data. This paper
proposes a generative mixture-model approach to clustering directional
data based on the von Mises-Fisher (vMF) distribution, which arises
naturally for data distributed on the unit hypersphere.  In
particular, we derive and analyze two variants of the Expectation
Maximization (EM) framework for estimating the mean and concentration
parameters of this mixture.  Numerical estimation of the concentration
parameters is non-trivial in high dimensions since it involves
functional inversion of ratios of Bessel functions.  We also formulate
two clustering algorithms corresponding to the variants of EM that we
derive.  Our approach provides a theoretical basis for the use of
cosine similarity that has been widely employed by the information
retrieval community, and obtains the spherical kmeans algorithm
(kmeans with cosine similarity) as a special case of both variants.
Empirical results on clustering of high-dimensional text and
gene-expression data based on a mixture of vMF distributions show that
the ability to estimate the concentration parameter for each vMF
component, which is not present in existing approaches, yields
superior results, especially for difficult clustering tasks in
high-dimensional spaces.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/banerjee05a/banerjee05a.pdf</url></Article><Article><id>234</id><title>
Inner Product Spaces for Bayesian Networks
</title><author>Atsuyoshi Nakamura, Michael Schmitt, Niels Schmitt, Hans Ulrich Simon</author><abstract>

Bayesian networks have become one of the major models used for
statistical inference.  We study the question whether the decisions
computed by a Bayesian network can be represented within a
low-dimensional inner product space. We focus on two-label
classification tasks over the Boolean domain.  As main results we
establish upper and lower bounds on the dimension of the inner product
space for Bayesian networks with an explicitly given (full or reduced)
parameter collection. In particular, these bounds are tight up to a
factor of &lt;i&gt;2&lt;/i&gt;. For some nontrivial cases of Bayesian networks we
even determine the exact values of this dimension.  We further
consider logistic autoregressive Bayesian networks and show that every
sufficiently expressive inner product space must have dimension at
least &amp;#937;(&lt;i&gt;n&lt;sup&gt;2&lt;/sup&gt;&lt;/i&gt;), where &lt;i&gt;n&lt;/i&gt; is the number of
network nodes. We also derive the bound
&lt;i&gt;2&lt;/i&gt;&lt;sup&gt;&amp;#937;(&lt;i&gt;n&lt;/i&gt;)&lt;/sup&gt; for an artificial variant of
this network, thereby demonstrating the limits of our approach and
raising an interesting open question.  As a major technical
contribution, this work reveals combinatorial and algebraic structures
within Bayesian networks such that known methods for the derivation of
lower bounds on the dimension of inner product spaces can be brought
into play.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/nakamura05a/nakamura05a.pdf</url></Article><Article><id>235</id><title>
Maximum Margin Algorithms with Boolean Kernels
</title><author>Roni Khardon, Rocco A. Servedio</author><abstract>
&lt;p&gt;
Recent work has introduced Boolean kernels with which one can learn
linear threshold functions over a feature space containing all
conjunctions of length up to &lt;i&gt;k&lt;/i&gt; (for any 1 &amp;#8804;
&lt;i&gt;k&lt;/i&gt; &amp;#8804; &lt;i&gt;n&lt;/i&gt;) over the original &lt;i&gt;n&lt;/i&gt; Boolean
features in the input space.  This motivates the question of whether
maximum margin algorithms such as Support Vector Machines can learn
Disjunctive Normal Form expressions in the Probably Approximately
Correct (PAC) learning model by using this kernel.  We study this
question, as well as a variant in which structural risk minimization
(SRM) is performed where the class hierarchy is taken over the length
of conjunctions.
&lt;/p&gt;
&lt;p&gt;
We show that maximum margin algorithms using the Boolean kernels do
not PAC learn &lt;i&gt;t&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;)-term DNF for any &lt;i&gt;t&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;)
= &amp;#969;(1), even when used with such a SRM scheme.  We also
consider PAC learning under the uniform distribution and show that if
the kernel uses conjunctions of length
&amp;#732;&amp;#969;(&amp;#8730;&lt;i&gt;n&lt;/i&gt;) then the maximum margin hypothesis
will fail on the uniform distribution as well.  Our results concretely
illustrate that margin based algorithms may overfit when learning
simple target functions with natural kernels.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/khardon05a/khardon05a.pdf</url></Article><Article><id>236</id><title>
A Bayes Optimal Approach for Partitioning the Values of Categorical Attributes 
</title><author>Marc Boull&amp;#233;</author><abstract>

In supervised machine learning, the partitioning of the values (also
called grouping) of a categorical attribute aims at constructing a new
synthetic attribute which keeps the information of the initial
attribute and reduces the number of its values. In this paper, we
propose a new grouping method MODL founded on a Bayesian
approach. The method relies on a model space of grouping models and on
a prior distribution defined on this model space. This results in an
evaluation criterion of grouping, which is minimal for the most
probable grouping given the data, &lt;i&gt;i.e.&lt;/i&gt; the Bayes optimal grouping. We
propose new super-linear optimization heuristics that yields
near-optimal groupings. Extensive comparative experiments demonstrate
that the MODL grouping method builds high quality groupings in terms
of predictive quality, robustness and small number of groups.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/boulle05a/boulle05a.pdf</url></Article><Article><id>237</id><title>
Large Margin Methods for Structured and Interdependent Output Variables 
</title><author>Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, Yasemin Altun</author><abstract>

Learning general functional dependencies between arbitrary input and
output spaces is one of the key challenges in computational
intelligence. While recent progress in machine learning has mainly
focused on designing flexible and powerful input representations, this
paper addresses the complementary issue of designing classification
algorithms that can deal with more complex outputs, such as trees,
sequences, or sets. More generally, we consider problems involving
multiple dependent output variables, structured output spaces, and
classification problems with class attributes.  In order to accomplish
this, we propose to appropriately generalize the well-known notion of
a separation margin and derive a corresponding maximum-margin
formulation. While this leads to a quadratic program with a
potentially prohibitive, i.e. exponential, number of constraints, we
present a cutting plane algorithm that solves the optimization problem
in polynomial time for a large class of problems.  The proposed method
has important applications in areas such as computational biology,
natural language processing, information retrieval/extraction, and
optical character recognition. Experiments from various domains
involving different types of output spaces emphasize the breadth and
generality of our approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/tsochantaridis05a/tsochantaridis05a.pdf</url></Article><Article><id>238</id><title>
Frames, Reproducing Kernels, Regularization and Learning
</title><author>Alain Rakotomamonjy,  St&amp;#233;phane Canu</author><abstract>

This work deals with a method for building a reproducing kernel
Hilbert space (RKHS) from a Hilbert space with frame elements
having special properties. Conditions on existence and a method of
construction are given. Then, these RKHS are used within the
framework of regularization theory for function approximation.
Implications on semiparametric estimation are discussed and a
multiscale scheme of regularization is also proposed.
 Results on toy and real-world approximation problems illustrate the
effectiveness of such methods.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/rakotomamonjy05a/rakotomamonjy05a.pdf</url></Article><Article><id>239</id><title>
Local Propagation in Conditional Gaussian Bayesian Networks
</title><author>Robert G. Cowell</author><abstract>

This paper describes a scheme for local computation in conditional
Gaussian Bayesian networks that combines the approach of
Lauritzen and Jensen (2001) with some elements of
Shachter and Kenley (1989).  Message passing takes place on an
elimination tree structure rather than the more compact (and usual)
junction tree of cliques.  This yields a local computation scheme in
which all calculations involving the continuous variables are
performed by manipulating univariate regressions, and hence matrix
operations are avoided.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/cowell05a/cowell05a.pdf</url></Article><Article><id>240</id><title>
A Bayesian Model for Supervised Clustering with the Dirichlet Process Prior
</title><author>Hal Daum&amp;#233; III, Daniel Marcu</author><abstract>

We develop a Bayesian framework for tackling the supervised clustering
problem, the generic problem encountered in tasks such as reference
matching, coreference resolution, identity uncertainty and record
linkage.  Our clustering model is based on the Dirichlet process
prior, which enables us to define distributions over the countably
infinite sets that naturally arise in this problem.  We add
&lt;i&gt;supervision&lt;/i&gt; to our model by positing the existence of a set of
unobserved random variables (we call these "reference types") that
are generic across all clusters.  Inference in our framework, which
requires integrating over infinitely many parameters, is solved using
Markov chain Monte Carlo techniques.  We present algorithms for both
conjugate and non-conjugate priors.  We present a simple---but
general---parameterization of our model based on a Gaussian
assumption.  We evaluate this model on one artificial task and three
real-world tasks, comparing it against both unsupervised and
state-of-the-art supervised algorithms.  Our results show that our
model is able to outperform other models across a variety of tasks and
performance metrics.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/daume05a/daume05a.pdf</url></Article><Article><id>241</id><title>
Fast Kernel Classifiers with Online and Active Learning
</title><author>Antoine Bordes, Seyda Ertekin, Jason Weston, L&amp;#233;on Bottou</author><abstract>
&lt;p&gt;
Very high dimensional learning systems become theoretically possible when
training examples are abundant. The computing cost then becomes the limiting
factor. Any efficient learning algorithm should at least take a brief look at
each example. But should all examples be given equal attention?
&lt;/p&gt;&lt;p&gt;
This contribution proposes an empirical answer.  
We first present an online SVM algorithm based on this premise.  
LASVM yields competitive misclassification rates after a single 
pass over the training examples, outspeeding state-of-the-art SVM solvers.  
Then we show how active example selection can yield faster training, 
higher accuracies, and simpler models, using only a fraction 
of the training example labels.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/bordes05a/bordes05a.pdf</url></Article><Article><id>242</id><title>
Managing Diversity in Regression Ensembles
</title><author>Gavin Brown, Jeremy L. Wyatt, Peter Ti&amp;#328;o</author><abstract>

Ensembles are a widely used and effective technique in machine learning---their
success is commonly attributed to the degree of disagreement, or 'diversity',
within the ensemble.  For ensembles where the individual estimators output
crisp class labels, this 'diversity' is not well understood and remains an open
research issue.  For ensembles of regression estimators, the diversity can be
exactly formulated in terms of the covariance between individual estimator
outputs, and the optimum level is expressed in terms of a
&lt;i&gt;bias-variance-covariance&lt;/i&gt; trade-off.  Despite this, most approaches to
learning ensembles use heuristics to encourage the right degree of diversity.
In this work we show how to explicitly control diversity through the error
function. The first contribution of this paper is to show that &lt;i&gt;by taking
the combination mechanism for the ensemble into account we can derive an error
function for each individual that balances ensemble diversity with individual
accuracy&lt;/i&gt;.  We show the relationship between this error function and an
existing algorithm called &lt;i&gt;negative correlation learning&lt;/i&gt;, which uses a
heuristic penalty term added to the mean squared error function.  It is
demonstrated that these methods control the bias-variance-covariance trade-off
systematically, and can be utilised with any estimator capable of minimising a
quadratic error function, for example MLPs, or RBF networks.
As a second contribution, we derive a strict upper bound on the coefficient of
the penalty term, which holds for any estimator that can be cast in a
generalised linear regression framework, with mild assumptions on the basis
functions. Finally we present the results of an empirical study, showing
significant improvements over simple ensemble learning, and finding that this
technique is competitive with a variety of methods, including boosting,
bagging, mixtures of experts, and Gaussian processes, on a number of tasks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/brown05a/brown05a.pdf</url></Article><Article><id>243</id><title>
Active Coevolutionary Learning of Deterministic Finite Automata
</title><author>Josh Bongard, Hod Lipson</author><abstract>

This paper describes an active learning approach to the problem of
grammatical inference, specifically the inference of deterministic
finite automata (DFAs). We refer to the algorithm as the
estimation-exploration algorithm (EEA). This approach differs from
previous passive and active learning approaches to grammatical
inference in that training data is actively proposed by the
algorithm, rather than passively receiving training data from some
external teacher. Here we show that this algorithm outperforms one
version of the most powerful set of algorithms for grammatical
inference, evidence driven state merging (EDSM), on
randomly-generated DFAs. The performance increase is due to the
fact that the EDSM algorithm only works well for DFAs with
specific balances (percentage of positive labelings), while the
EEA is more consistent over a wider range of balances. Based on
this finding we propose a more general method for generating DFAs
to be used in the development of future grammatical inference
algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/bongard05a/bongard05a.pdf</url></Article><Article><id>244</id><title>
Assessing Approximate Inference for Binary Gaussian Process Classification
</title><author>Malte Kuss, Carl Edward Rasmussen</author><abstract>

Gaussian process priors can be used to define flexible, probabilistic
classification models. Unfortunately exact Bayesian inference is
analytically intractable and various approximation techniques have
been proposed. In this work we review and compare Laplace's method and
Expectation Propagation for approximate Bayesian inference in the
binary Gaussian process classification model. We present a
comprehensive comparison of the approximations, their predictive
performance and marginal likelihood estimates to results obtained by
MCMC sampling. We explain theoretically and corroborate empirically
the advantages of Expectation Propagation compared to Laplace's
method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/kuss05a/kuss05a.pdf</url></Article><Article><id>245</id><title>
Clustering with Bregman Divergences
</title><author>Arindam Banerjee, Srujana Merugu, Inderjit S. Dhillon, Joydeep Ghosh</author><abstract>

A wide variety of distortion functions, such as squared Euclidean  
distance, Mahalanobis distance, Itakura-Saito distance and relative  
entropy, have been used for clustering. In this paper, we propose and  
analyze parametric hard and soft clustering algorithms based on a  
large class of distortion functions known as Bregman divergences. The  
proposed algorithms unify centroid-based parametric clustering  
approaches, such as classical &lt;tt&gt;kmeans&lt;/tt&gt;, the Linde-Buzo-Gray (LBG)  
algorithm and information-theoretic clustering, which arise by special  
choices of the Bregman divergence. The algorithms maintain the  
simplicity and scalability of the classical &lt;tt&gt;kmeans&lt;/tt&gt; algorithm,  
while generalizing the method to a large class of clustering loss  
functions.  This is achieved by first posing the hard clustering  
problem in terms of minimizing the loss in Bregman information, a  
quantity motivated by rate distortion theory, and then deriving an  
iterative algorithm that monotonically decreases this loss. In  
addition,  
we show that there is a bijection between regular exponential families  
and a large class of Bregman divergences, that we call regular Bregman  
divergences. This result enables the development of an alternative  
interpretation of an efficient EM scheme for learning mixtures of  
exponential family distributions, and leads to a simple soft  
clustering algorithm for regular Bregman divergences. Finally, we  
discuss the connection between rate distortion theory and Bregman  
clustering and present an information theoretic analysis of Bregman  
clustering algorithms in terms of a trade-off between compression and  
loss in Bregman information.  

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/banerjee05b/banerjee05b.pdf</url></Article><Article><id>246</id><title>
Combining Information Extraction Systems Using Voting and Stacked Generalization
</title><author>Georgios Sigletos, Georgios Paliouras, Constantine D. Spyropoulos, Michalis Hatzopoulos</author><abstract>

This article investigates the effectiveness of voting and stacked
generalization -also known as stacking- in the context of information
extraction (IE). A new stacking framework is proposed that
accommodates well-known approaches for IE. The key idea is to perform
cross-validation on the base-level data set, which consists of text
documents annotated with relevant information, in order to create a
meta-level data set that consists of feature vectors. A classifier is
then trained using the new vectors. Therefore, base-level IE systems
are combined with a common classifier at the meta-level. Various
voting schemes are presented for comparing against stacking in various
IE domains. Well known IE systems are employed at the base-level,
together with a variety of classifiers at the meta-level. Results show
that both voting and stacking work better when relying on
probabilistic estimates by the base-level systems. Voting proved to be
effective in most domains in the experiments. Stacking, on the other
hand, proved to be consistently effective over all domains, doing
comparably or better than voting and always better than the best
base-level systems. Particular emphasis is also given to explaining
the results obtained by voting and stacking at the meta-level, with
respect to the varying degree of similarity in the output of the
base-level systems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/sigletos05a/sigletos05a.pdf</url></Article><Article><id>247</id><title>
Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models
</title><author>Neil Lawrence</author><abstract>

Summarising a high dimensional data set with a low dimensional embedding
is a standard approach for exploring its structure. In this paper
we provide an overview of some existing techniques for discovering
such embeddings. We then introduce a novel probabilistic interpretation
of principal component analysis (PCA) that we term dual probabilistic
PCA (DPPCA). The DPPCA model has the additional advantage that the
linear mappings from the embedded space can easily be non-linearised
through Gaussian processes. We refer to this model as a Gaussian process
latent variable model (GP-LVM). Through analysis of the GP-LVM objective
function, we relate the model to popular spectral techniques such
as kernel PCA and multidimensional scaling. We then review a practical
algorithm for GP-LVMs in the context of large data sets and develop
it to also handle discrete valued data and missing attributes. We
demonstrate the model on a range of real-world and artificially generated
data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/lawrence05a/lawrence05a.pdf</url></Article><Article><id>248</id><title>
A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data
</title><author>Rie Kubota Ando, Tong Zhang</author><abstract>

One of the most important issues in machine learning is whether one
can improve the performance of a supervised learning algorithm by
including unlabeled data.  Methods that use both labeled and unlabeled
data are generally referred to as semi-supervised learning.  Although
a number of such methods are proposed, at the current stage, we still
don't have a complete understanding of their effectiveness.  This
paper investigates a closely related problem, which leads to a novel
approach to semi-supervised learning.  Specifically we consider
learning predictive structures on hypothesis spaces (that is, what
kind of classifiers have good predictive power) from multiple learning
tasks.  We present a general framework in which the structural
learning problem can be formulated and analyzed theoretically, and
relate it to learning with unlabeled data.  Under this framework,
algorithms for structural learning will be proposed, and computational
issues will be investigated.  Experiments will be given to demonstrate
the effectiveness of the proposed algorithms in the semi-supervised
learning setting.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf</url></Article><Article><id>249</id><title>
Feature Selection for Unsupervised and Supervised Inference: The Emergence of Sparsity in a Weight-Based Approach
</title><author>Lior Wolf, Amnon Shashua</author><abstract>

&lt;p&gt;
The problem of selecting a subset of relevant features in a
potentially overwhelming quantity of data is classic and found in many
branches of science. Examples in computer vision, text processing and
more recently bio-informatics are abundant. In text classification
tasks, for example, it is not uncommon to have 10&lt;sup&gt;4&lt;/sup&gt; to
10&lt;sup&gt;7&lt;/sup&gt; features of the size of the vocabulary containing word
frequency counts, with the expectation that only a small fraction of
them are relevant. Typical examples include the automatic sorting of
URLs into a web directory and the detection of spam email.
&lt;/p&gt;
&lt;p&gt;
In this work we present a definition of "relevancy" based on
spectral properties of the Laplacian of the features' measurement
matrix. The feature selection process is then based on a continuous
ranking of the features defined by a least-squares optimization
process. A remarkable property of the feature relevance function is
that sparse solutions for the ranking values naturally emerge as a
result of a "biased non-negativity" of a key matrix in the
process. As a result, a simple least-squares optimization process
converges onto a sparse solution, i.e., a selection of a subset of
features which form a local maximum over the relevance function. The
feature selection algorithm can be embedded in both unsupervised and
supervised inference problems and empirical evidence show that the
feature selections typically achieve high accuracy even when only a
small fraction of the features are relevant.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/wolf05a/wolf05a.pdf</url></Article><Article><id>250</id><title>
Working Set Selection Using Second Order Information for Training Support Vector Machines
</title><author>Rong-En Fan, Pai-Hsuen Chen, Chih-Jen Lin</author><abstract>

Working set selection is an important step in
decomposition methods for training support vector machines (SVMs).
This paper develops a new technique for working set selection  in
SMO-type decomposition methods.
It uses second order information to achieve fast convergence.
Theoretical properties such as linear convergence are established.
Experiments demonstrate that
the proposed method is faster than existing selection methods
using first order information.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/fan05a/fan05a.pdf</url></Article><Article><id>251</id><title>
New Horn Revision Algorithms
</title><author>Judy Goldsmith, Robert H. Sloan</author><abstract>

A revision algorithm is a learning algorithm that identifies
the target concept, starting from an initial concept.
Such an algorithm is considered efficient if its complexity
(in terms of the measured resource) is
polynomial in the syntactic distance between the initial
and the target concept, but only  polylogarithmic in  the number of
variables in the universe. 
We give efficient revision algorithms in the model
of learning with equivalence and membership queries.
The algorithms work in a general revision model where
both deletion and addition revision operators
are allowed. In this model one of the main open problems
is the efficient revision of Horn formulas.
Two revision algorithms are
presented for special cases of this problem: for depth-1 acyclic Horn
formulas, and for definite Horn formulas with unique heads.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/goldsmith05a/goldsmith05a.pdf</url></Article><Article><id>252</id><title>
A Unifying View of Sparse Approximate Gaussian Process Regression
</title><author>Joaquin Qui&amp;#241;onero-Candela, Carl Edward Rasmussen</author><abstract>

  We provide a new unifying view, including all existing proper probabilistic
  sparse approximations for Gaussian process regression. Our approach relies on
  expressing the &lt;i&gt;effective prior&lt;/i&gt; which the methods are using. This
  allows new insights to be gained, and highlights the relationship between
  existing methods. It also allows for a clear theoretically justified ranking
  of the closeness of the known approximations to the corresponding full GPs.
  Finally we point directly to designs of new better sparse approximations,
  combining the best of the existing strategies, within attractive
  computational constraints.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/quinonero-candela05a/quinonero-candela05a.pdf</url></Article><Article><id>253</id><title>
What's Strange About Recent Events (WSARE): An Algorithm for the Early Detection of Disease Outbreaks
</title><author>Weng-Keen Wong, Andrew Moore, Gregory Cooper, Michael Wagner</author><abstract>

Traditional biosurveillance algorithms detect disease outbreaks by looking for
peaks in a univariate time series of health-care data.  Current health-care 
surveillance data, however, are no longer simply univariate data streams.
Instead, a wealth of spatial, temporal, demographic and symptomatic
information is available.  We present an early disease outbreak detection 
algorithm called What's Strange About Recent Events (WSARE), which uses a 
multivariate approach to improve its timeliness of detection.   WSARE employs 
a rule-based technique that compares recent health-care data against data from
a baseline distribution and finds subgroups of the recent data whose 
proportions have changed the most from the baseline data.  In addition, 
health-care data also pose difficulties for surveillance algorithms because of
inherent temporal trends such as seasonal effects and day of week variations.  
WSARE approaches this problem using a Bayesian network to produce a baseline 
distribution that accounts for these temporal trends.  The algorithm itself 
incorporates a wide range of ideas, including association rules, Bayesian 
networks, hypothesis testing and permutation tests to produce a detection 
algorithm that is careful to evaluate the significance of the alarms that it 
raises.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/wong05a/wong05a.pdf</url></Article><Article><id>254</id><title>
Change Point Problems in Linear Dynamical Systems
</title><author>Onno Zoeter, Tom Heskes</author><abstract>

&lt;p&gt;
We study the problem of learning two regimes (we have a normal and a
prefault regime in mind) based on a train set of non-Markovian
observation sequences. Key to the  
model is that we assume that once the system switches from the normal
to the prefault regime it cannot restore and will eventually result in 
a fault. We refer to the particular setting as
&lt;i&gt;semi-supervised&lt;/i&gt; since we assume the only information given
to the learner is whether a particular sequence ended with a stop
(implying that the sequence was generated by the normal regime) or
with a fault (implying that there was a switch from the normal to the
fault regime). In the latter case the particular time point at which a
switch occurred is not known. 
&lt;/p&gt;
&lt;p&gt;
The underlying model used is a &lt;i&gt;switching linear 
dynamical system (SLDS)&lt;/i&gt;. The constraints in the regime transition
probabilities result in an exact inference procedure that scales
quadratically with the length of a sequence. 
Maximum aposteriori (MAP) parameter estimates can be
found using an expectation maximization (EM) 
algorithm with this inference algorithm in the E-step.
For long sequences this will not be practically feasible and an
approximate inference and an approximate EM procedure is called
for. We describe a flexible class of approximations corresponding to
different choices of clusters in a Kikuchi free energy with weak
consistency constraints.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/zoeter05a/zoeter05a.pdf</url></Article><Article><id>255</id><title>
Asymptotics in Empirical Risk Minimization
</title><author>Leila Mohammadi, Sara van de Geer</author><abstract>

In this paper, we study a two-category classification problem.
We indicate the categories by labels &lt;i&gt;Y=1&lt;/i&gt; and &lt;i&gt;Y=-1&lt;/i&gt;. 
We observe a covariate, or feature, 
&lt;i&gt;X &amp;#8712; &lt;/i&gt;X&lt;i&gt; &amp;#8834; &amp;#8476;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;.
Consider a collection &lt;i&gt;{h&lt;sub&gt;a&lt;/sub&gt;}&lt;/i&gt; of classifiers indexed 
by a finite-dimensional
parameter &lt;i&gt;a&lt;/i&gt;, and the classifier &lt;i&gt;h&lt;sub&gt;a*&lt;/sub&gt;&lt;/i&gt; that minimizes 
the prediction error
over this class. The parameter &lt;i&gt;a*&lt;/i&gt; is estimated by the empirical risk minimizer
&lt;i&gt;&amp;#226;&lt;sub&gt;n&lt;/sub&gt;&lt;/i&gt; over the class, where the empirical risk is calculated on a
training sample of size &lt;i&gt;n&lt;/i&gt;. We apply the Kim Pollard Theorem to show 
that under certain differentiability assumptions, &lt;i&gt;&amp;#226;&lt;sub&gt;n&lt;/sub&gt;&lt;/i&gt; converges 
to &lt;i&gt;a*&lt;/i&gt; with rate
&lt;i&gt;n&lt;sup&gt;-1/3&lt;/sup&gt;&lt;/i&gt;, and also present the asymptotic distribution of the
renormalized estimator.

&lt;p&gt;
For example, let &lt;i&gt;V&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; denote the set
of &lt;i&gt;x&lt;/i&gt; on which, given &lt;i&gt;X=x&lt;/i&gt;, the label &lt;i&gt;Y=1&lt;/i&gt; is more likely
(than the label &lt;i&gt;Y=-1&lt;/i&gt;). If &lt;i&gt;X&lt;/i&gt; is one-dimensional, the set 
&lt;i&gt;V&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; is the
union of  disjoint intervals. The problem is then to estimate the thresholds
of the intervals. We  obtain the asymptotic distribution of the empirical
risk minimizer when the classifiers have &lt;i&gt;K&lt;/i&gt; thresholds, where &lt;i&gt;K&lt;/i&gt; 
is fixed.
We furthermore consider an extension to higher-dimensional &lt;i&gt;X&lt;/i&gt;,  assuming
basically that &lt;i&gt;V&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; has a smooth boundary in some given parametric
class.
&lt;/p&gt;

&lt;p&gt;
We also discuss various rates of convergence when the differentiability
conditions are possibly violated. Here, we again restrict ourselves to
one-dimensional &lt;i&gt;X&lt;/i&gt;. We show that the rate
is &lt;i&gt;n&lt;sup&gt;-1&lt;/sup&gt;&lt;/i&gt; in certain cases, and then also obtain the asymptotic distribution for the empirical prediction error.
&lt;/p&gt;


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/mohammadi05a/mohammadi05a.pdf</url></Article><Article><id>256</id><title>
Convergence Theorems for Generalized Alternating Minimization Procedures
</title><author>Asela Gunawardana, William Byrne</author><abstract>

The EM algorithm is widely used to develop iterative parameter
estimation procedures for statistical models.  In cases where these
procedures strictly follow the EM formulation, the convergence
properties of the estimation procedures are well understood.  In
some instances there are practical reasons to develop procedures
that do not strictly fall within the EM framework.  We study EM
variants in which the E-step is not performed exactly, either to
obtain improved rates of convergence, or due to approximations
needed to compute statistics under a model family over which E-steps
cannot be realized.  Since these variants are not EM procedures, the
standard (G)EM convergence results do not apply to them.  We present
an information geometric framework for describing such algorithms
and analyzing their convergence properties.  We apply this framework
to analyze the convergence properties of incremental EM and
variational EM.  For incremental EM, we discuss conditions under
these algorithms converge in likelihood.  For variational EM, we
show how the E-step approximation prevents convergence to local
maxima in likelihood.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/gunawardana05a/gunawardana05a.pdf</url></Article><Article><id>257</id><title>
Kernel Methods for Measuring Independence
</title><author>Arthur Gretton, Ralf Herbrich, Alexander Smola, Olivier Bousquet, Bernhard Sch&amp;#246;lkopf</author><abstract>

We introduce two new functionals, the constrained covariance
and the kernel mutual information, to measure the degree of independence
of random variables. These quantities are both based on the covariance
between functions of the random variables in reproducing kernel Hilbert
spaces (RKHSs). We prove that when the RKHSs are universal, both functionals
are zero if and only if the random variables are pairwise independent.
We also show that the kernel mutual information is an upper bound
near independence on the Parzen window estimate of the mutual information.
Analogous results apply for two correlation-based dependence functionals
introduced earlier: we show the kernel canonical correlation and the
kernel generalised variance to be independence measures for universal
kernels, and prove the latter to be an upper bound on the mutual information
near independence. The performance of the kernel dependence functionals
in measuring independence is verified in the context of independent
component analysis.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/gretton05a/gretton05a.pdf</url></Article><Article><id>258</id><title>
Efficient Margin Maximizing with Boosting
</title><author>Gunnar R&amp;#228;tsch, Manfred K. Warmuth</author><abstract>
&lt;p&gt;
  AdaBoost produces a linear combination of base hypotheses and predicts
  with the sign of this linear combination.  The linear combination may
  be viewed as a hyperplane in feature space where the base hypotheses
  form the features.  It has been observed that the generalization error
  of the algorithm continues to improve even after all examples are on
  the correct side of the current hyperplane.  The improvement is
  attributed to the experimental observation that the distances
  (margins) of the examples to the separating hyperplane are increasing
  even after all examples are on the correct side.
&lt;/p&gt;
&lt;p&gt;
  We introduce a new version of AdaBoost, called
  AdaBoost*&lt;sub&gt;&amp;#957;&lt;/sub&gt;, that
  explicitly maximizes the minimum margin of the examples up to a given
  precision. The algorithm incorporates a current estimate of the
  achievable margin into its calculation of the linear coefficients of
  the base hypotheses.  The bound on the number of iterations needed by
  the new algorithms is the same as the number needed by a known version
  of AdaBoost that must have an explicit estimate of the achievable
  margin as a parameter. We also illustrate experimentally 
  that our algorithm requires considerably fewer iterations 
  than other algorithms that aim to maximize the margin.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/ratsch05a/ratsch05a.pdf</url></Article><Article><id>259</id><title>
On the Nystr&amp;#246;m Method for Approximating a Gram Matrix for Improved Kernel-Based Learning
</title><author>Petros Drineas, Michael W. Mahoney</author><abstract>
&lt;p&gt;
A problem for many kernel-based methods is that the amount of computation 
required to find the solution scales as &lt;i&gt;O(n&lt;sup&gt;3&lt;/sup&gt;)&lt;/i&gt;, 
where &lt;i&gt;n&lt;/i&gt; is the number of training examples.
We develop and analyze an algorithm to compute an easily-interpretable low-rank 
approximation to an &lt;i&gt;n &amp;#215; n&lt;/i&gt; Gram matrix &lt;i&gt;G&lt;/i&gt; such that computations of 
interest may be performed more rapidly.
The approximation is of the form &lt;i&gt;&lt;sup&gt;~&lt;/sup&gt;G&lt;sub&gt;k&lt;/sub&gt; = 
CW&lt;sub&gt;k&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;C&lt;sup&gt;T&lt;/sup&gt;&lt;/i&gt;, where &lt;i&gt;C&lt;/i&gt; is a 
matrix consisting of a small number &lt;i&gt;c&lt;/i&gt; of columns of &lt;i&gt;G&lt;/i&gt; and 
&lt;i&gt;W&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; is the best 
rank-&lt;i&gt;k&lt;/i&gt; approximation to &lt;i&gt;W&lt;/i&gt;, the matrix formed by 
the intersection between those &lt;i&gt;c&lt;/i&gt; columns of &lt;i&gt;G&lt;/i&gt; and 
the corresponding &lt;i&gt;c&lt;/i&gt; rows of &lt;i&gt;G&lt;/i&gt;.
An important aspect of the algorithm is the probability distribution used to 
randomly sample the columns;
we will use a judiciously-chosen and data-dependent nonuniform probability 
distribution.
Let ||&amp;#183;||&lt;sub&gt;2&lt;/sub&gt; and ||&amp;#183;||&lt;sub&gt;&lt;i&gt;F&lt;/i&gt;&lt;/sub&gt;  denote the 
spectral norm and the 
Frobenius norm, respectively, of a matrix, and let &lt;i&gt;G&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; 
be the best rank-&lt;i&gt;k&lt;/i&gt; approximation to &lt;i&gt;G&lt;/i&gt;. 
We prove that by choosing &lt;i&gt;O(k/&amp;#x3B5;&lt;sup&gt;4&lt;/sup&gt;)&lt;/i&gt; columns
&lt;/p&gt;
&lt;center&gt;

||&lt;i&gt;G-CW&lt;sub&gt;k&lt;/sub&gt;&lt;sup&gt;+&lt;/sup&gt;C&lt;sup&gt;T&lt;/sup&gt;&lt;/i&gt;||&lt;sub&gt;&amp;#958;&lt;/sub&gt; 
&amp;#8804; ||&lt;i&gt;G-G&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;||&lt;sub&gt;&amp;#958;&lt;/sub&gt; + 
&amp;#x3B5; &amp;#931;&lt;i&gt;&lt;sub&gt;i=1&lt;/sub&gt;&lt;sup&gt;n&lt;/sup&gt; G&lt;sub&gt;ii&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; &lt;/i&gt;  ,
&lt;/center&gt;
&lt;p&gt;
both in expectation and with high probability, for both &lt;i&gt;&amp;#958; = 2&lt;/i&gt;, &lt;i&gt;F&lt;/i&gt;, 
and for all &lt;i&gt;k: 0 &amp;#8804; k &amp;#8804;&lt;/i&gt; rank&lt;i&gt;(W)&lt;/i&gt;.
This approximation can be computed using &lt;i&gt;O(n)&lt;/i&gt; additional space and time, 
after making two passes over the data from external storage.
The relationships between this algorithm, other related matrix decompositions, 
and the Nystr&amp;#246;m method from integral equation theory are discussed.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/drineas05a/drineas05a.pdf</url></Article><Article><id>260</id><title>
Expectation Consistent Approximate Inference
</title><author>Manfred Opper, Ole Winther</author><abstract>

We propose a novel framework for approximations to
intractable probabilistic models which is based on a
free energy formulation. The
approximation can be understood as replacing an average
over the original intractable distribution with a tractable one.
It requires two tractable probability
distributions which are made consistent on a set of
moments and encode different features of the original intractable
distribution. In this way we are able to use
Gaussian approximations for models with discrete or bounded
variables which allow us to include non-trivial
correlations. These are neglected in many other methods.
We test the framework on toy benchmark problems for
binary variables on fully connected graphs and 2D grids
and compare with other methods, such as loopy belief propagation.
Good performance is already achieved by using single nodes as tractable
substructures. Significant improvements are obtained when a spanning
tree is used instead.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume6/opper05a/opper05a.pdf</url></Article><Article><id>261</id><title>
Statistical Comparisons of Classifiers over Multiple Data Sets
</title><author>Janez Dem&amp;#353;ar</author><abstract>

While methods for comparing two learning algorithms on a single
data set have been scrutinized for quite some time already, the
issue of statistical tests for comparisons of more algorithms on
multiple data sets, which is even more essential to typical machine
learning studies, has been all but ignored. This article reviews
the current practice and then theoretically and empirically
examines several suitable tests. Based on that, we recommend a set
of simple, yet safe and robust non-parametric tests for
statistical comparisons of classifiers: the Wilcoxon signed ranks
test for comparison of two classifiers and the Friedman test with
the corresponding post-hoc tests for comparison of more classifiers
over multiple data sets. Results of the latter can also be neatly
presented with the newly introduced CD (critical difference)
diagrams.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/demsar06a/demsar06a.pdf</url></Article><Article><id>262</id><title>
Incremental Algorithms for Hierarchical Classification
</title><author>Nicol&amp;#242; Cesa-Bianchi, Claudio Gentile, Luca Zaniboni</author><abstract>

&lt;p&gt;
We study the problem of classifying data in a given taxonomy
when classifications associated with multiple and/or partial paths
are allowed.
We introduce a new algorithm that incrementally learns a
linear-threshold classifier for each node of the taxonomy.
A hierarchical classification is obtained by evaluating
the trained node classifiers in a top-down fashion.
To evaluate classifiers in our multipath framework,
we define a new hierarchical loss function, the H-loss,
capturing the intuition that whenever a classification
mistake is made on a node of the taxonomy, then no loss should
be charged for any additional mistake occurring in the subtree
of that node.
&lt;/p&gt;
&lt;p&gt;
Making no assumptions on the mechanism generating the data instances,
and assuming a linear noise model for the labels,
we bound the H-loss of our on-line algorithm in terms of the H-loss
of a reference classifier knowing the true parameters of the label-generating 
process.
We show that, in expectation, the excess cumulative H-loss grows at most
logarithmically in the length of the data sequence.
Furthermore, our analysis reveals the precise dependence of the rate
of convergence on the eigenstructure of the data each node observes.
&lt;/p&gt;
&lt;p&gt;
Our theoretical results are complemented by a number of experiments on texual
corpora. In these experiments we show that, after only one epoch of training,
our algorithm performs much better than Perceptron-based hierarchical 
classifiers, and reasonably close to a hierarchical support vector machine.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/cesa-bianchi06a/cesa-bianchi06a.pdf</url></Article><Article><id>263</id><title>
On the Complexity of Learning Lexicographic Strategies
</title><author>Michael Schmitt, Laura Martignon</author><abstract>
&lt;p&gt;
  Fast and frugal heuristics are well studied models of bounded rationality.
  Psychological research has proposed the take-the-best heuristic as a
  successful strategy in decision making with limited resources.
  Take-the-best searches for a sufficiently good ordering of cues (or
  features) in a task where objects are to be compared lexicographically.  We
  investigate the computational complexity of finding optimal cue permutations
  for lexicographic strategies and prove that the problem is NP-complete.  It
  follows that no efficient (that is, polynomial-time) algorithm computes
  optimal solutions, unless P=NP. We further analyze the complexity of
  approximating optimal cue permutations for lexicographic strategies.  We
  show that there is no efficient algorithm that approximates the optimum to
  within any constant factor, unless P=NP.
&lt;/p&gt;
&lt;p&gt;
  The results have implications for the complexity of learning lexicographic
  strategies from examples. They show that learning them in polynomial time
  within the model of agnostic probably approximately correct (PAC) learning
  is impossible, unless RP=NP.  We further consider greedy approaches for
  building lexicographic strategies and determine upper and lower bounds for
  the performance ratio of simple algorithms.  Moreover, we present a greedy
  algorithm that performs provably better than take-the-best.  Tight bounds on
  the sample complexity for learning lexicographic strategies are also given
  in this article.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/schmitt06a/schmitt06a.pdf</url></Article><Article><id>264</id><title>
Generalized Bradley-Terry Models and Multi-Class Probability Estimates
</title><author>Tzu-Kuo Huang, Ruby C. Weng, Chih-Jen Lin</author><abstract>

The Bradley-Terry model for obtaining individual skill from paired
comparisons has been popular in many areas.  In machine learning, this
model is related to multi-class probability estimates by coupling all
pairwise classification results. Error correcting output codes (ECOC)
are a general framework to decompose a multi-class problem to several
binary problems. To obtain probability estimates under this framework,
this paper introduces a generalized Bradley-Terry model in which
paired individual comparisons are extended to paired team comparisons.
We propose a simple algorithm with convergence proofs to solve the
model and obtain individual skill. Experiments on synthetic and re al
data demonstrate that the algorithm is useful for obtaining
multi-class probability estimates. Moreover, we discuss four
extensions of the proposed model: 1) weighted individual skill, 2)
home-field advantage, 3) ties, and 4) comparisons with more than two
teams.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/huang06a/huang06a.pdf</url></Article><Article><id>265</id><title>
Bounds for Linear Multi-Task Learning
</title><author>Andreas Maurer</author><abstract>

We give dimension-free and data-dependent bounds for linear multi-task
learning where a common linear operator is chosen to preprocess data for a
vector of task specific linear-thresholding classifiers. The complexity
penalty of multi-task learning is bounded by a simple expression involving
the margins of the task-specific classifiers, the Hilbert-Schmidt norm of
the selected preprocessor and the Hilbert-Schmidt norm of the covariance
operator for the total mixture of all task distributions, or, alternatively,
the Frobenius norm of the total Gramian matrix for the data-dependent
version. The results can be compared to state-of-the-art results on linear
single-task learning.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/maurer06a/maurer06a.pdf</url></Article><Article><id>266</id><title>
Active Learning in Approximately Linear Regression
Based on Conditional Expectation of Generalization Error
</title><author>Masashi Sugiyama</author><abstract>

The goal of active learning is to determine the locations of training
input points so that the generalization error is minimized.  We
discuss the problem of active learning in linear regression scenarios.
Traditional active learning methods using least-squares learning often
assume that the model used for learning is correctly specified.  In
many practical situations, however, this assumption may not be
fulfilled.  Recently, active learning methods using
"importance"-weighted least-squares learning have been proposed, which
are shown to be robust against misspecification of models.  In this
paper, we propose a new active learning method also using the weighted
least-squares learning, which we call &lt;i&gt;ALICE&lt;/i&gt; (Active Learning
using the Importance-weighted least-squares learning based on
Conditional Expectation of the generalization error).  An important
difference from existing methods is that we predict the
&lt;i&gt;conditional&lt;/i&gt; expectation of the generalization error given
training input points, while existing methods predict the &lt;i&gt;full&lt;/i&gt;
expectation of the generalization error.  Due to this difference, the
training input design can be fine-tuned depending on the realization
of training input points.  Theoretically, we prove that the proposed
active learning criterion is a more accurate predictor of the
&lt;i&gt;single-trial&lt;/i&gt; generalization error than the existing criterion.
Numerical studies with toy and benchmark data sets show that the
proposed method compares favorably to existing methods.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/sugiyama06a/sugiyama06a.pdf</url></Article><Article><id>267</id><title>
MinReg: A Scalable Algorithm for Learning Parsimonious
Regulatory Networks in Yeast and Mammals
</title><author>Dana Pe'er, Amos Tanay, Aviv Regev</author><abstract>

In recent years, there has been a growing interest in applying Bayesian
networks and their extensions to reconstruct &lt;i&gt;regulatory networks&lt;/i&gt; from
gene expression data.  Since the gene expression domain involves a large
number of variables and a limited number of samples, it poses both
computational and statistical challenges to Bayesian network learning
algorithms.  Here we define a constrained family of Bayesian network
structures suitable for this domain and devise an efficient search algorithm
that utilizes these structural constraints to find high scoring networks
from data.  Interestingly, under reasonable assumptions on the underlying
probability distribution, we can provide performance guarantees on our
algorithm. Evaluation on real data from yeast and mouse, demonstrates that
our method cannot only reconstruct a high quality model of the yeast
regulatory network, but is also the first method to scale to the complexity
of mammalian networks and successfully reconstructs a reasonable model over
thousands of variables.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/peer06a/peer06a.pdf</url></Article><Article><id>268</id><title>
Learning the Structure of Linear Latent Variable Models
</title><author>Ricardo Silva, Richard Scheine, Clark Glymour, Peter Spirtes</author><abstract>

We describe anytime search procedures that (1) find disjoint subsets
of recorded variables for which the members of each subset are
d-separated by a single common unrecorded cause, if such exists; (2)
return information about the causal relations among the latent factors
so identified. We prove the procedure is point-wise consistent
assuming (a) the causal relations can be represented by a directed
acyclic graph (DAG) satisfying the Markov Assumption and the
Faithfulness Assumption; (b) unrecorded variables are not caused by
recorded variables; and (c) dependencies are linear. We compare the procedure with
standard approaches over a variety of simulated structures and sample sizes, and
illustrate its practical value with brief studies of social science
data sets. Finally, we consider generalizations for non-linear
systems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/silva06a/silva06a.pdf</url></Article><Article><id>269</id><title>
In Search of Non-Gaussian Components of a High-Dimensional Distribution
</title><author>Gilles Blanchard, Motoaki Kawanabe, Masashi Sugiyama, Vladimir Spokoiny, Klaus-Robert M&amp;#252;ller</author><abstract>

Finding non-Gaussian components of high-dimensional data is an
important preprocessing step for efficient information processing.
This article proposes a new &lt;i&gt;linear&lt;/i&gt; method to identify the
"non-Gaussian subspace" within a very general semi-parametric
framework.  Our proposed method, called NGCA (non-Gaussian component
analysis), is based on a linear operator which, to any arbitrary
nonlinear (smooth) function, associates a vector belonging to the
low dimensional non-Gaussian target subspace, up to an estimation
error.  By applying this operator to a family of different nonlinear
functions, one obtains a family of different vectors lying in a
vicinity of the target space. As a final step, the target space
itself is estimated by applying PCA to this family of vectors.  We
show that this procedure is consistent in the sense that the
estimaton error tends to zero at a parametric rate, uniformly over
the family, Numerical examples demonstrate the usefulness of our
method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/blanchard06a/blanchard06a.pdf</url></Article><Article><id>270</id><title>
Some Discriminant-Based PAC Algorithms
</title><author>Paul W. Goldberg</author><abstract>
&lt;p&gt;
A classical approach in multi-class pattern classification is the
following. Estimate the probability distributions that generated the
observations for each label class, and then label new instances by
applying the Bayes classifier to the estimated distributions.  That
approach provides more useful information than just a class label; it
also provides estimates of the conditional distribution of class
labels, in situations where there is class overlap.
&lt;/p&gt;&lt;p&gt;
We would like to know whether it is harder to build accurate
classifiers via this approach, than by techniques that may process
all data with distinct labels together. In this paper we make
that question precise by considering it in the context of PAC
learnability. We propose two restrictions on the PAC learning
framework that are intended to correspond with the above approach,
and consider their relationship with standard PAC learning.
Our main restriction of interest leads to some interesting algorithms
that show that the restriction is not stronger (more restrictive)
than various other well-known restrictions on PAC learning.
An alternative slightly milder restriction turns out to be almost
equivalent to unrestricted PAC learning.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/goldberg06a/goldberg06a.pdf</url></Article><Article><id>271</id><title>
Kernels on Prolog Proof Trees: Statistical Learning in the ILP Setting
</title><author>Andrea Passerini, Paolo Frasconi, Luc De Raedt</author><abstract>

We develop kernels for measuring the similarity between relational
instances using background knowledge expressed in first-order logic.
The method allows us to bridge the gap between traditional inductive
logic programming (ILP) representations and statistical approaches
to supervised learning. Logic programs are first used to generate
proofs of given visitor programs that use predicates declared in the
available background knowledge. A kernel is then defined over pairs
of proof trees. The method can be used for supervised learning tasks
and is suitable for classification as well as regression. We report
positive empirical results on Bongard-like and &lt;i&gt;M&lt;/i&gt;-of-&lt;i&gt;N&lt;/i&gt; problems
that are difficult or impossible to solve with traditional ILP
techniques, as well as on real bioinformatics and chemoinformatics
data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/passerini06a/passerini06a.pdf</url></Article><Article><id>272</id><title>
Using Machine Learning to Guide Architecture Simulation
</title><author>Greg Hamerly, Erez Perelman, Jeremy Lau, Brad Calder, Timothy Sherwood</author><abstract>
&lt;p&gt;
An essential step in designing a new computer architecture is the
careful examination of different design options.  It is critical that
computer architects have efficient means by which they may estimate
the impact of various design options on the overall machine.  This
task is complicated by the fact that different programs, and even
different parts of the &lt;i&gt;same&lt;/i&gt; program, may have distinct behaviors
that interact with the hardware in different ways.  Researchers use
very detailed simulators to estimate processor performance, which
models every cycle of an executing program.  Unfortunately, simulating
every cycle of a real program can take weeks or months.
&lt;/p&gt;&lt;p&gt;
To address this problem we have created a tool called SimPoint that
uses data clustering algorithms from machine learning to automatically
find repetitive patterns in a program's execution.  By simulating one
representative of each repetitive behavior pattern, simulation time
can be reduced to minutes instead of weeks for standard benchmark
programs, with very little cost in terms of accuracy. We describe this
important problem, the data representation and preprocessing methods
used by SimPoint, the clustering algorithm at the core of SimPoint,
and we evaluate different options for tuning SimPoint.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/hamerly06a/hamerly06a.pdf</url></Article><Article><id>273</id><title>
Superior Guarantees for Sequential Prediction and Lossless Compression via Alphabet Decomposition
</title><author>Ron Begleiter, Ran El-Yaniv</author><abstract>

We present worst case bounds for the learning
rate of a known prediction method that is based on hierarchical
applications of binary context tree weighting (CTW) predictors. A
heuristic application of this approach that relies on Huffman's alphabet
decomposition is known to achieve state-of-the-art performance
in prediction and lossless compression benchmarks. We show that our
new bound for this heuristic is tighter than the best known
performance guarantees for prediction and lossless compression
algorithms in various settings. This result
substantiates the efficiency of this hierarchical method and provides a compelling
explanation for its practical success.
In addition, we present the results of a few experiments that
examine other possibilities for improving the multi-alphabet
prediction performance of CTW-based algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/begleiter06a/begleiter06a.pdf</url></Article><Article><id>274</id><title>
Geometric Variance Reduction in Markov Chains: Application to Value Function and Gradient Estimation
</title><author>R&amp;#233;mi Munos</author><abstract>
&lt;p&gt;
We study a variance reduction technique for Monte Carlo estimation
of functionals in Markov chains. The method is based on designing
&lt;i&gt;sequential control variates&lt;/i&gt; using successive approximations
of the function of interest &lt;i&gt;V&lt;/i&gt;. Regular Monte Carlo estimates have
a variance of &lt;i&gt;O(1/N)&lt;/i&gt;, where &lt;i&gt;N&lt;/i&gt; is the number of sample trajectories
of the Markov chain. Here, we obtain a geometric variance reduction
&lt;i&gt;O(&amp;#961;&lt;sup&gt;N&lt;/sup&gt;)&lt;/i&gt; (with &amp;#961;&lt;1) up to a threshold that depends on
the approximation error &lt;i&gt;V-AV&lt;/i&gt;, where &lt;i&gt;A&lt;/i&gt; is an &lt;i&gt;approximation
operator&lt;/i&gt; linear in the values. Thus, if &lt;i&gt;V&lt;/i&gt; belongs to the right
approximation space (i.e. &lt;i&gt;AV=V&lt;/i&gt;), the variance decreases geometrically
to zero.
&lt;/p&gt;&lt;p&gt;
An immediate application is value function estimation in Markov chains,
which may be used for policy evaluation in a policy iteration algorithm
for solving Markov Decision Processes. 
&lt;/p&gt;&lt;p&gt;
Another important domain, for which variance reduction is highly needed,
is gradient estimation, that is computing the sensitivity &lt;i&gt;&amp;#8706;&lt;sub&gt;&amp;#945;&lt;/sub&gt;V&lt;/i&gt;
of the performance measure &lt;i&gt;V&lt;/i&gt; with respect to some parameter &amp;#945;
of the transition probabilities. For example, in policy parametric
optimization, computing an estimate of the policy gradient is required
to perform a gradient optimization method.
&lt;/p&gt;&lt;p&gt;
We show that, using two approximations for the &lt;i&gt;value function&lt;/i&gt;
and the &lt;i&gt;gradient&lt;/i&gt;, a geometric variance reduction is also achieved,
up to a threshold that depends on the approximation errors of both
of those representations.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/munos06a/munos06a.pdf</url></Article><Article><id>275</id><title>
Inductive Synthesis of Functional Programs: An Explanation Based Generalization Approach
</title><author>Emanuel Kitzelmann, Ute Schmid</author><abstract>

We describe an approach to the inductive synthesis of recursive
equations from input/output-examples which is based on the classical
two-step approach to induction of functional Lisp programs of
Summers (1977).  In a first step, I/O-examples are rewritten to
traces which explain the outputs given the respective inputs based on
a datatype theory. These traces can be integrated into one conditional
expression which represents a non-recursive program.  In a second
step, this initial program term is generalized into recursive
equations by searching for syntactical regularities in the term. Our
approach extends the classical work in several aspects. The most
important extensions are that we are able to induce a &lt;i&gt;set&lt;/i&gt; of
recursive equations in one synthesizing step, the equations may
contain more than one recursive call, and additionally needed
parameters are automatically introduced.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/kitzelmann06a/kitzelmann06a.pdf</url></Article><Article><id>276</id><title>
Optimising Kernel Parameters and Regularisation Coefficients for Non-linear Discriminant Analysis
</title><author>Tonatiuh Pe&amp;#241;a Centeno, Neil D. Lawrence</author><abstract>

In this paper we consider a novel Bayesian interpretation of Fisher's
discriminant analysis. We relate Rayleigh's coefficient to a noise
model that minimises a cost based on the most probable class centres
and that abandons the 'regression to the labels' assumption used by
other algorithms. Optimisation of the noise model yields a direction 
of discrimination equivalent to Fisher's discriminant, and with the
incorporation of a prior we can apply Bayes' rule to infer the
posterior distribution of the direction of
discrimination. Nonetheless, we argue that an additional constraining
distribution has to be included if sensible results are to be
obtained. Going further, with the use of a Gaussian process prior we
show the equivalence of our model to a regularised kernel Fisher's
discriminant. A key advantage of our approach is the facility to
determine kernel parameters and the regularisation coefficient through
the optimisation of the marginal log-likelihood of the data. An
added bonus of the new formulation is that it enables us to link the
regularisation coefficient with the generalisation error.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/centeno06a/centeno06a.pdf</url></Article><Article><id>277</id><title>
Learning Recursive Control Programs from Problem Solving
</title><author>Pat Langley, Dongkyu Choi</author><abstract>

In this paper, we propose a new representation for physical control
-- teleoreactive logic programs -- along with an interpreter that
uses them to achieve goals. In addition, we present a new learning
method that acquires recursive forms of these structures from traces
of successful problem solving. We report experiments in three different
domains that demonstrate the generality of this approach. In closing,
we review related work on learning complex skills and discuss directions
for future research on this topic.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/langley06a/langley06a.pdf</url></Article><Article><id>278</id><title>
Learning Coordinate Covariances via Gradients
</title><author>Sayan Mukherjee, Ding-Xuan Zhou</author><abstract>

We introduce an algorithm that learns gradients from samples in
the supervised learning framework. An error analysis is given for
the convergence of the gradient estimated by the algorithm to the
true gradient. The utility of the algorithm for the problem of
variable selection as well as determining variable covariance is
illustrated on  simulated data as well as two gene expression
data sets. For square loss we provide a very efficient
implementation with respect to both memory and time.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/mukherjee06a/mukherjee06a.pdf</url></Article><Article><id>279</id><title>
Online Passive-Aggressive Algorithms
</title><author>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, Yoram Singer</author><abstract>

We present a family of margin based online learning algorithms for various
prediction tasks. In particular we derive and analyze algorithms for binary and
multiclass categorization, regression, uniclass prediction and sequence
prediction. 
The update steps of our different algorithms are all based on analytical
solutions to simple constrained optimization problems.  This unified view
allows us to prove worst-case loss bounds for the different algorithms and for
the various decision problems based on a single lemma. Our bounds on the
cumulative loss of the algorithms are relative to the smallest loss that can be
attained by any fixed hypothesis, and as such are applicable to both realizable
and unrealizable settings. We demonstrate some of the merits of the proposed
algorithms in a series of experiments with synthetic and real data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/crammer06a/crammer06a.pdf</url></Article><Article><id>280</id><title>
Toward Attribute Efficient Learning of Decision Lists and Parities
</title><author>Adam R. Klivans, Rocco A. Servedio</author><abstract>
&lt;p&gt;
We consider two well-studied problems regarding attribute
efficient learning:  learning
decision lists and learning parity functions.
First, we give an algorithm for learning decision
lists of length &lt;i&gt;k&lt;/i&gt; over &lt;i&gt;n&lt;/i&gt; variables using 
&lt;i&gt;2&lt;sup&gt;&amp;#213;(k&lt;sup&gt;1/3&lt;/sup&gt;)&lt;/sup&gt; log n&lt;/i&gt; examples and time 
&lt;i&gt;n&lt;sup&gt;&amp;#213;(k&lt;sup&gt;1/3&lt;/sup&gt;)&lt;/sup&gt;&lt;/i&gt;. This is the first
algorithm for learning decision lists that has both subexponential
sample complexity and subexponential running time in the relevant
parameters.  Our approach is based on
a new construction of low degree, low weight polynomial threshold
functions for decision lists. For a wide range of parameters our
construction matches a lower bound due to Beigel for 
decision lists and gives an essentially optimal tradeoff between
polynomial threshold function degree and weight.  
&lt;/p&gt;&lt;p&gt;
Second, we give an
algorithm for learning an unknown parity function on &lt;i&gt;k&lt;/i&gt; out of &lt;i&gt;n&lt;/i&gt;
variables using &lt;i&gt;O(n&lt;sup&gt;1-1/k&lt;/sup&gt;)&lt;/i&gt; examples in poly&lt;i&gt;(n)&lt;/i&gt; time. For
&lt;i&gt;k=o(&lt;/i&gt;log &lt;i&gt;n)&lt;/i&gt; this yields the first polynomial time algorithm
for learning parity on a superconstant number of variables with
sublinear sample complexity. We also give a simple algorithm
for learning an unknown length-&lt;i&gt;k&lt;/i&gt; parity using &lt;i&gt;O(k&lt;/i&gt; log &lt;i&gt;n)&lt;/i&gt;
examples in &lt;i&gt;n&lt;sup&gt;k/2&lt;/sup&gt;&lt;/i&gt; time, which 
improves on the naive &lt;i&gt;n&lt;sup&gt;k&lt;/sup&gt;&lt;/i&gt; time
bound of exhaustive search.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/klivans06a/klivans06a.pdf</url></Article><Article><id>281</id><title>
A Direct Method for Building Sparse Kernel Learning Algorithms
</title><author>Mingrui Wu, Bernhard Sch&amp;#246;lkopf, G&amp;#246;khan Bak&amp;#305;r</author><abstract>

Many kernel learning algorithms, including support vector machines,
result in a kernel machine, such as a kernel classifier, whose key
component is a weight vector in a feature space implicitly introduced
by a positive definite kernel function. This weight vector is usually
obtained by solving a convex optimization problem. Based on this fact
we present a direct method to build sparse kernel learning algorithms
by adding one more constraint to the original convex optimization
problem, such that the sparseness of the resulting kernel machine is
explicitly controlled while at the same time performance is kept as
high as possible. A gradient based approach is provided to solve this
modified optimization problem. Applying this method to the support
vectom machine results in a concrete algorithm for building sparse 
large margin classifiers. These classifiers essentially find a discriminating
subspace that can be spanned by a small number of vectors, and in this
subspace, the different classes of data are linearly well
separated. Experimental results over several classification benchmarks
demonstrate the effectiveness of our approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/wu06a/wu06a.pdf</url></Article><Article><id>282</id><title>
Stochastic Complexities of Gaussian Mixtures in Variational Bayesian Approximation
</title><author>Kazuho Watanabe, Sumio Watanabe</author><abstract>
&lt;p&gt;
Bayesian learning has been widely used and proved to be effective in many
 data modeling problems. However, computations involved in it require
 huge costs and generally cannot be performed exactly. The variational 
Bayesian approach, proposed as an approximation of Bayesian learning, 
has provided computational tractability and good generalization 
performance in many applications. 
&lt;/p&gt;&lt;p&gt;
 The properties and capabilities of variational Bayesian learning itself have not
 been clarified yet. It is still unknown how good approximation the
 variational Bayesian approach can achieve. In this paper, we discuss 
variational Bayesian learning of Gaussian
 mixture models and derive upper and lower bounds of variational 
stochastic complexities. The variational stochastic complexity, 
which corresponds to the minimum variational free energy and a lower 
bound of the Bayesian evidence, not only becomes important in
 addressing the model selection problem, but also enables us to discuss the
 accuracy of the variational Bayesian approach as an approximation of 
true Bayesian learning.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/watanabe06a/watanabe06a.pdf</url></Article><Article><id>283</id><title>
Pattern Recognition for  Conditionally Independent Data
</title><author>Daniil Ryabko</author><abstract>
&lt;p&gt;
In this work we consider the task of relaxing the i.i.d. assumption
in  pattern recognition (or classification), aiming to make
existing learning algorithms applicable to a wider range of tasks.
Pattern recognition is guessing a discrete label of
some  object based on a set of given examples (pairs of
objects and labels). We consider the case 
of deterministically defined labels. 
Traditionally, this
task is studied under the assumption that examples
are independent and identically distributed. However,
it turns out that many results of pattern recognition
 theory carry over 
a  weaker assumption. Namely, under the assumption
of conditional independence and identical distribution of objects,
while the only assumption on the distribution of labels is that the
rate of occurrence of each label should be above some positive threshold.
&lt;/p&gt;&lt;p&gt;
We find a broad class of learning algorithms for which estimations of
the probability of the classification error  achieved under the 
classical i.i.d. assumption can
be generalized to the similar estimates for  case of 
conditionally i.i.d. examples.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/ryabko06a/ryabko06a.pdf</url></Article><Article><id>284</id><title>
Learning Minimum Volume Sets
</title><author>Clayton D. Scott, Robert D. Nowak</author><abstract>

Given a probability measure &lt;i&gt;P&lt;/i&gt; and a reference measure
&lt;i&gt;&amp;#956;&lt;/i&gt;, one is often interested in the minimum &lt;i&gt;&amp;#956;&lt;/i&gt;-measure set
with &lt;i&gt;P&lt;/i&gt;-measure at least &lt;i&gt;&amp;#945;&lt;/i&gt;.  Minimum volume sets of this
type summarize the regions of greatest probability mass of &lt;i&gt;P&lt;/i&gt;,
and are useful for detecting anomalies and constructing confidence
regions.  This paper addresses the problem of estimating minimum
volume sets based on independent samples distributed according to
&lt;i&gt;P&lt;/i&gt;.  Other than these samples, no other information is available
regarding &lt;i&gt;P&lt;/i&gt;, but the reference measure &lt;i&gt;&amp;#956;&lt;/i&gt; is assumed to be
known. We introduce rules for estimating minimum volume sets that
parallel the empirical risk minimization and structural risk
minimization principles in classification. As in classification, we
show that the performances of our estimators are controlled by the
rate of uniform convergence of empirical to true probabilities over
the class from which the estimator is drawn. Thus we obtain finite
sample size performance bounds in terms of VC dimension and related
quantities. We also demonstrate strong universal consistency, an
oracle inequality, and rates of convergence. The proposed estimators
are illustrated with histogram and decision tree set estimation
rules.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/scott06a/scott06a.pdf</url></Article><Article><id>285</id><title>
Some Theory for Generalized Boosting Algorithms
</title><author>Peter J. Bickel, Ya'acov Ritov, Alon Zakai</author><abstract>

We give a review of various aspects of boosting, clarifying the
issues through a few simple results, and relate our work and that of
others to the minimax paradigm of statistics. We consider the
population version of the  boosting algorithm and prove its
convergence to the Bayes classifier as a corollary of a general
result about Gauss-Southwell optimization in Hilbert space. We then
investigate the algorithmic  convergence of the sample version, and
give bounds to the time until perfect separation of the sample. We
conclude by some results on the statistical optimality of the &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;
boosting.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bickel06a/bickel06a.pdf</url></Article><Article><id>286</id><title>
QP Algorithms with Guaranteed Accuracy and Run Time for Support Vector Machines
</title><author>Don Hush, Patrick Kelly, Clint Scovel, Ingo Steinwart</author><abstract>

We describe polynomial--time algorithms
that produce approximate solutions with guaranteed
accuracy for a class of QP problems that are used in the
design of support vector machine classifiers.
These algorithms employ a two--stage process where the
first stage produces an approximate
solution to a dual QP problem and the second stage maps
this approximate dual solution to an approximate primal solution.
For the second stage we describe an &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt; log &lt;i&gt;n&lt;/i&gt;)
algorithm that maps an approximate dual solution with accuracy
&lt;i&gt;(2(2K&lt;sub&gt;m&lt;/sub&gt;)&lt;sup&gt;1/2&lt;/sup&gt;+8(&amp;#955;)&lt;sup&gt;1/2&lt;/sup&gt;)&lt;sup&gt;-2&lt;/sup&gt; 
&amp;#955; &amp;#949;&lt;sub&gt;p&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/i&gt;
to an approximate primal solution with
accuracy &lt;i&gt;&amp;#949;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;
where &lt;i&gt;n&lt;/i&gt; is the number of data samples,
&lt;i&gt;K&lt;sub&gt;n&lt;/sub&gt;&lt;/i&gt; is the maximum kernel value over the data and
&lt;i&gt;&amp;#955; &gt; 0&lt;/i&gt; is the SVM regularization parameter.
For the first stage we present new results
for &lt;i&gt;decomposition&lt;/i&gt; algorithms and
describe new decomposition algorithms with guaranteed
accuracy and run time.
In particular, for &lt;i&gt;&amp;#964;-rate certifying&lt;/i&gt; decomposition algorithms
we establish the optimality of &lt;i&gt;&amp;#964; = 1/(n-1)&lt;/i&gt;.
In addition
we extend the recent &lt;i&gt;&amp;#964; = 1/(n-1)&lt;/i&gt; algorithm of Simon
(2004) to form two new &lt;i&gt;composite&lt;/i&gt; algorithms
that also achieve the &lt;i&gt;&amp;#964; = 1/(n-1)&lt;/i&gt; iteration bound
of List and Simon (2005), but yield faster run times in practice.
We also exploit the &amp;#964;-rate certifying property of these
algorithms to produce new stopping rules that are computationally
efficient and that guarantee a specified accuracy for the
approximate dual solution.
Furthermore,
for the dual QP problem corresponding to the standard classification
problem we describe operational conditions for which the Simon and composite
algorithms possess an upper bound of &lt;i&gt;O(n)&lt;/i&gt; on the number of iterations.
For this same problem we also describe general conditions for which
a matching lower bound exists
for &lt;i&gt;any&lt;/i&gt; decomposition algorithm that uses working sets of size 2.
For the Simon and composite algorithms we also establish an &lt;i&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt;
bound on the overall run time for the first stage.
Combining the first and second stages gives
an overall run time of &lt;i&gt;O(n&lt;sup&gt;2&lt;/sup&gt;(c&lt;sub&gt;k&lt;/sub&gt; + 1))&lt;/i&gt;
where &lt;i&gt;c&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; is an upper bound on the computation to perform
a kernel evaluation.  Pseudocode is presented
for a complete algorithm that inputs an accuracy &lt;i&gt;&amp;#949;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;
and produces an approximate solution that satisfies
this accuracy in low order polynomial time.
Experiments are included to illustrate the new stopping rules and
to compare the Simon and composite decomposition algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/hush06a/hush06a.pdf</url></Article><Article><id>287</id><title>
Policy Gradient in Continuous Time
</title><author>R&amp;#233;mi Munos</author><abstract>
&lt;p&gt;
Policy search is a method for approximately solving an optimal
control problem by performing a parametric optimization search in
a given class of parameterized policies. In order to process a local
optimization technique, such as a gradient method, we wish to evaluate
the sensitivity of the performance measure with respect to the policy
parameters, the so-called &lt;i&gt;policy gradient&lt;/i&gt;. This paper is concerned
with the estimation of the policy gradient for continuous-time, deterministic
state dynamics, in a &lt;i&gt;reinforcement learning&lt;/i&gt; framework, that
is, when the decision maker does not have a model of the state
dynamics.
&lt;/p&gt;
&lt;p&gt;
We show that usual likelihood ratio methods used in discrete-time,
fail to proceed the gradient because they are subject to variance
explosion when the discretization time-step decreases to 0. We
describe an alternative approach based on the approximation of the
pathwise derivative, which leads to a policy gradient estimate that
converges almost surely to the true gradient when the time-step tends
to 0. The underlying idea starts with the derivation of an explicit
representation of the policy gradient using pathwise derivation. This
derivation makes use of the knowledge of the state dynamics. Then,
in order to estimate the gradient from the observable data only, we
use a stochastic policy to discretize the continuous deterministic
system into a stochastic discrete process, which enables to replace
the unknown coefficients by quantities that solely depend on known
data. We prove the almost sure convergence of this estimate to the
true policy gradient when the discretization time-step goes to zero. 
&lt;/p&gt;
&lt;p&gt;
The method is illustrated on two target problems, in discrete
and continuous control spaces.
&lt;/p&gt;


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/munos06b/munos06b.pdf</url></Article><Article><id>288</id><title>
Learning Image Components for Object Recognition
</title><author>Michael W. Spratling</author><abstract>

In order to perform object recognition it is necessary to learn representations
of the underlying components of images.  Such components correspond to objects,
object-parts, or features.  Non-negative matrix factorisation is a generative
model that has been specifically proposed for finding such meaningful
representations of image data, through the use of non-negativity constraints on
the factors.  This article reports on an empirical investigation of the
performance of non-negative matrix factorisation algorithms. It is found that
such algorithms need to impose additional constraints on the sparseness of the
factors in order to successfully deal with occlusion. However, these constraints
can themselves result in these algorithms failing to identify image components
under certain conditions.  In contrast, a recognition model (a competitive
learning neural network algorithm) reliably and accurately learns
representations of elementary image features without such constraints.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/spratling06a/spratling06a.pdf</url></Article><Article><id>289</id><title>
Consistency and Convergence Rates of One-Class SVMs and Related Algorithms
</title><author>R&amp;#233;gis Vert, Jean-Philippe Vert</author><abstract>

We determine the asymptotic behaviour of the function computed by
support vector machines (SVM) and related algorithms that minimize a
regularized empirical convex loss function in the reproducing kernel
Hilbert space of the Gaussian RBF kernel, in the situation where the
number of examples tends to infinity, the bandwidth of the Gaussian
kernel tends to 0, and the regularization parameter is held
fixed. Non-asymptotic convergence bounds to this limit in the &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;
sense are provided, together with upper bounds on the classification
error that is shown to converge to the Bayes risk, therefore proving
the Bayes-consistency of a variety of methods although the
regularization term does not vanish. These results are particularly
relevant to the one-class SVM, for which the regularization can not
vanish by construction, and which is shown for the first time to be a
consistent density level set estimator.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/vert06a/vert06a.pdf</url></Article><Article><id>290</id><title>
Infinite-&amp;#963; Limits For Tikhonov Regularization
</title><author>Ross A. Lippert, Ryan M. Rifkin</author><abstract>



We consider the problem of Tikhonov regularization with a general
convex loss function: this formalism includes
support vector machines and regularized least squares.  For a family of
kernels that includes the Gaussian, parameterized by a "bandwidth"
parameter &amp;#963;, we characterize the limiting solution as &amp;#963;
&amp;#8594; &amp;#8734;.  In particular, we show that if we
set the regularization parameter &amp;#955; = &lt;sup&gt;~&lt;/sup&gt;&amp;#955; &amp;#963;&lt;sup&gt;-2&lt;i&gt;p&lt;/i&gt;&lt;/sup&gt;, the regularization term of the Tikhonov
problem tends to an indicator function on polynomials of degree
&amp;#8970;&lt;i&gt;p&lt;/i&gt;&amp;#8971; (with residual regularization in the case where &lt;i&gt;p&lt;/i&gt;
&amp;#8712; &lt;i&gt;Z&lt;/i&gt;).  The proof rests on two key ideas: &lt;i&gt;epi-convergence&lt;/i&gt;, a
notion of functional convergence under which limits of minimizers
converge to minimizers of limits, and a &lt;i&gt;value-based formulation
of learning&lt;/i&gt;, where we work with regularization on the function output
values (&lt;i&gt;y&lt;/i&gt;) as opposed to the function expansion coefficients in the
RKHS.  Our result generalizes and unifies previous results in this
area.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/lippert06a/lippert06a.pdf</url></Article><Article><id>291</id><title>
Evolutionary Function Approximation for Reinforcement Learning
</title><author>Shimon Whiteson, Peter Stone</author><abstract>

Temporal difference methods are theoretically grounded and empirically
effective methods for addressing reinforcement learning problems.
In most real-world reinforcement learning tasks, TD methods require
a function approximator to represent the value function.  However,
using function approximators requires manually making crucial
representational decisions.  This paper investigates
&lt;i&gt;evolutionary function approximation&lt;/i&gt;, a novel approach to
automatically selecting function approximator representations that
enable efficient individual learning.  This method &lt;i&gt;evolves&lt;/i&gt;
individuals that are better able to &lt;i&gt;learn&lt;/i&gt;.  We present a
fully implemented instantiation of evolutionary function
approximation which combines NEAT, a neuroevolutionary optimization
technique, with Q-learning, a popular TD method.  The resulting
NEAT+Q algorithm automatically discovers effective representations
for neural network function approximators.  This paper also presents
&lt;i&gt;on-line evolutionary computation&lt;/i&gt;, which improves the on-line
performance of evolutionary computation by borrowing selection
mechanisms used in TD methods to choose individual actions and using
them in evolutionary computation to select policies for evaluation.
We evaluate these contributions with extended empirical studies in
two domains: 1) the mountain car task, a standard reinforcement
learning benchmark on which neural network function approximators
have previously performed poorly and 2) server job scheduling, a
large probabilistic domain drawn from the field of autonomic
computing.  The results demonstrate that evolutionary function
approximation can significantly improve the performance of TD
methods and on-line evolutionary computation can significantly
improve evolutionary methods.  This paper also presents additional
tests that offer insight into what factors can make neural network
function approximation difficult in practice.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/whiteson06a/whiteson06a.pdf</url></Article><Article><id>292</id><title>
Rearrangement Clustering: Pitfalls, Remedies, and Applications
</title><author>Sharlee Climer, Weixiong Zhang</author><abstract>

Given a matrix of values in which the rows correspond to objects and
the columns correspond to features of the objects, rearrangement
clustering is the problem of rearranging the rows of the matrix such
that the sum of the similarities between adjacent rows is maximized.
Referred to by various names and reinvented several 
times, this clustering technique has been
extensively used in many fields over the last three decades.  In this paper, we
point out two critical pitfalls that have been previously overlooked.
The first pitfall is deleterious when rearrangement clustering is applied to
objects that form natural clusters.  The second concerns a
similarity metric that is commonly used.  We present an algorithm that
overcomes these pitfalls.  This algorithm is based on a variation of
the Traveling
Salesman Problem.  It offers an extra benefit as it
automatically determines cluster boundaries.  Using this algorithm, we
&lt;i&gt;optimally&lt;/i&gt; solve four
benchmark problems and a 2,467-gene expression data clustering
problem.  As expected, our new algorithm identifies better clusters 
than those found by previous
approaches in all five cases.  Overall,  
our results demonstrate the benefits
of rectifying the pitfalls and exemplify the usefulness of this
clustering technique.  Our code is available at our
websites. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/climer06a/climer06a.pdf</url></Article><Article><id>293</id><title>
Segmental Hidden Markov Models with Random Effects for Waveform Modeling
</title><author>Seyoung Kim, Padhraic Smyth</author><abstract>

This paper proposes a general probabilistic framework for
shape-based modeling and classification of waveform data. A
segmental hidden Markov model (HMM) is used to characterize
waveform shape and shape variation is captured by adding random
effects to the segmental model.  The resulting probabilistic
framework provides a basis for learning of waveform models from
data  as well as   parsing and recognition of new waveforms.
Expectation-maximization (EM) algorithms are derived and
investigated for fitting such models to data. In particular, the
"expectation conditional maximization either" (ECME) algorithm is
shown to provide significantly faster convergence than a standard
EM procedure. Experimental results on two real-world data sets
demonstrate that the proposed approach leads to improved accuracy
in classification and segmentation  when compared to alternatives
such as Euclidean distance matching, dynamic time warping, and
segmental HMMs without random effects.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/kim06a/kim06a.pdf</url></Article><Article><id>294</id><title>
Lower Bounds and Aggregation in Density Estimation
</title><author>Guillaume Lecu&amp;#233;</author><abstract>

In this paper we prove the optimality of an aggregation
procedure. We prove lower bounds for aggregation of model
selection type of &lt;i&gt;M&lt;/i&gt; density estimators for the Kullback-Leibler
divergence (KL), the Hellinger's distance and the &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-distance.
The lower bound, with respect to the KL distance, can be achieved
by the on-line type estimate suggested, among others, by
Yang (2000a). Combining these results, we state that log
&lt;i&gt;M/n&lt;/i&gt; is an optimal rate of aggregation in the sense of
Tsybakov (2003), where &lt;i&gt;n&lt;/i&gt; is the sample size.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/lecue06a/lecue06a.pdf</url></Article><Article><id>295</id><title>
Quantile Regression Forests
</title><author>Nicolai Meinshausen</author><abstract>

Random forests were introduced as a machine learning tool 
in Breiman (2001) and have
since proven to be very popular and powerful for high-dimensional 
regression and classification. 
For regression, random forests give an accurate approximation of the
conditional mean of a response variable. 
It is shown here that random forests provide information about
the full conditional distribution of the response variable, not only
about the conditional mean. Conditional quantiles can be inferred with
quantile regression forests, a generalisation of random forests.
Quantile regression forests give a non-parametric and accurate
way of estimating conditional quantiles for high-dimensional predictor
variables. 
The algorithm is shown to be consistent. Numerical examples suggest that
the algorithm is competitive in terms of predictive power.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/meinshausen06a/meinshausen06a.pdf</url></Article><Article><id>296</id><title>
Sparse Boosting
</title><author>Peter B&amp;#252;hlmann, Bin Yu</author><abstract>

&lt;p&gt;
We propose Sparse Boosting (the Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost algorithm), 
a variant on  
boosting with the squared error loss. Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost yields sparser
solutions than the previously proposed &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boosting by 
minimizing some penalized &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;-loss functions, the 
&lt;i&gt;FPE&lt;/i&gt; model selection criteria, through small-step gradient descent. 
Although boosting 
may give already relatively sparse solutions, for example corresponding to the
soft-thresholding estimator in orthogonal linear models, there is sometimes
a desire for more sparseness to increase prediction accuracy and ability
for better variable selection: such goals can be achieved with
Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost.   
&lt;/p&gt;
&lt;p&gt;
We prove an equivalence of Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost to 
Breiman's nonnegative garrote
estimator for orthogonal linear models and demonstrate the generic
nature of Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost for nonparametric interaction modeling. 
For an automatic selection of the tuning parameter
in Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost we propose to employ the 
gMDL model selection criterion 
which can also be used for early stopping of &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boosting. 
Consequently, we can select between Sparse&lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boost 
and &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;Boosting by comparing their gMDL scores.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/buehlmann06a/buehlmann06a.pdf</url></Article><Article><id>297</id><title>
One-Class Novelty Detection for Seizure Analysis from Intracranial EEG
</title><author>Andrew B. Gardner, Abba M. Krieger, George Vachtsevanos, Brian Litt</author><abstract>


This paper describes an application of one-class support vector
machine (SVM) novelty detection for detecting seizures in humans. Our
technique maps intracranial electroencephalogram (EEG) time series
into corresponding novelty sequences by classifying short-time,
energy-based statistics computed from one-second windows of data. We
train a classifier on epochs of interictal (normal) EEG. During ictal
(seizure) epochs of EEG, seizure activity induces distributional
changes in feature space that increase the empirical outlier
fraction. A hypothesis test determines when the parameter change
differs significantly from its nominal value, signaling a seizure
detection event.  Outputs are gated in a .one-shot. manner using
persistence to reduce the false alarm rate of the system. The detector
was validated using leave-one-out cross-validation (LOO-CV) on a
sample of 41 interictal and 29 ictal epochs, and achieved 97.1%
sensitivity, a mean detection latency of -7.58 seconds, and an
asymptotic false positive rate (FPR) of 1.56 false positives per hour
(Fp/hr).  These results are better than those obtained from a novelty
detection technique based on Mahalanobis distance outlier detection,
and comparable to the performance of a supervised learning technique
used in experimental implantable devices (Echauz et al., 2001). The
novelty detection paradigm overcomes three significant limitations of
competing methods: the need to collect seizure data, precisely mark
seizure onset and offset times, and perform patient-specific parameter
tuning for detector training.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/gardner06a/gardner06a.pdf</url></Article><Article><id>298</id><title>
A Graphical Representation of Equivalence Classes of AMP Chain Graphs
</title><author>Alberto Roverato, Milan Studen&amp;#253;</author><abstract>


This paper deals with chain graph models under alternative AMP
interpretation. A new representative of an AMP Markov equivalence
class, called the &lt;i&gt;largest deflagged graph&lt;/i&gt;, is proposed.
The representative is based on revealed internal structure of the
AMP Markov equivalence class. More specifically, the AMP Markov
equivalence class decomposes into finer &lt;i&gt;strong equivalence&lt;/i&gt;
classes and there exists a distinguished strong equivalence class
among those forming the AMP Markov equivalence class. The largest
deflagged graph is the largest chain graph in that distinguished
strong equivalence class. A composed graphical procedure to get
the largest deflagged graph on the basis of any AMP Markov equivalent
chain graph is presented. In general, the largest deflagged graph
differs from the AMP essential graph, which is another
representative of the AMP Markov equivalence class.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/roverato06a/roverato06a.pdf</url></Article><Article><id>299</id><title>
Action Elimination and Stopping Conditions for
the Multi-Armed Bandit and Reinforcement Learning Problems
</title><author>Eyal Even-Dar, Shie Mannor, Yishay Mansour</author><abstract>


We incorporate statistical confidence intervals in both the
multi-armed bandit and the reinforcement learning problems. In the
bandit problem we show that given &lt;i&gt;n&lt;/i&gt; arms, it suffices to pull the
arms a total of &lt;i&gt;O&lt;/i&gt;((&lt;i&gt;n&lt;/i&gt;/&amp;#949;&lt;sup&gt;2&lt;/sup&gt;)log(1/&amp;#948;)) times to
find an &amp;#949;-optimal arm with probability of at least 1-&amp;#948;.
This bound matches the lower bound of Mannor and Tsitsiklis (2004)
up to constants. We also devise action elimination
procedures in reinforcement learning algorithms. We describe a
framework that is based on learning the confidence interval around
the value function or the Q-function and eliminating actions that
are not optimal (with high probability). We provide a model-based
and a model-free variants of the elimination method. We further
derive stopping conditions guaranteeing that the learned policy is
approximately optimal with high probability. Simulations demonstrate
a considerable speedup and added robustness over &amp;#949;-greedy
Q-learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/evendar06a/evendar06a.pdf</url></Article><Article><id>300</id><title>
Step Size Adaptation in Reproducing Kernel Hilbert Space
</title><author>S. V. N. Vishwanathan, Nicol N. Schraudolph, Alex J. Smola</author><abstract>

This paper presents an online support vector machine (SVM) that uses
the stochastic meta-descent (SMD) algorithm to adapt its step size
automatically.  We formulate the online learning problem as a
stochastic gradient descent in reproducing kernel Hilbert space
(RKHS) and translate SMD to the nonparametric setting, where its
gradient trace parameter is no longer a coefficient vector but an
element of the RKHS.  We derive efficient updates that allow us to
perform the step size adaptation in linear time.  We apply the
online SVM framework to a variety of loss functions, and in
particular show how to handle structured output spaces and achieve
efficient online multiclass classification. Experiments show that
our algorithm outperforms more primitive methods for setting the
gradient step size.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/schraudolph06a/schraudolph06a.pdf</url></Article><Article><id>301</id><title>
New Algorithms for Efficient High-Dimensional Nonparametric Classification
</title><author>Ting Liu, Andrew W. Moore, Alexander Gray</author><abstract>

This paper is about non-approximate acceleration of high-dimensional
nonparametric operations such as &lt;i&gt;k&lt;/i&gt; nearest neighbor classifiers. We
attempt to exploit the fact that even if we want exact answers to
nonparametric queries, we usually do not need to explicitly find the
data points close to the query, but merely need to answer questions
about the properties of that set of data points. This offers a small
amount of computational leeway, and we investigate how much that
leeway can be exploited. This is applicable to many algorithms in
nonparametric statistics, memory-based learning and kernel-based
learning. But for clarity, this paper concentrates on pure &lt;i&gt;k&lt;/i&gt;-NN
classification. We introduce new ball-tree algorithms that on
real-world data sets give accelerations from 2-fold to 100-fold
compared against highly optimized traditional ball-tree-based
&lt;i&gt;k&lt;/i&gt;-NN. These results include data sets with up to 10&lt;sup&gt;6&lt;/sup&gt; 
dimensions and 10&lt;sup&gt;5&lt;/sup&gt; records, and demonstrate non-trivial 
speed-ups while giving exact answers.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/liu06a/liu06a.pdf</url></Article><Article><id>302</id><title>
A Very Fast Learning Method for Neural Networks Based on Sensitivity Analysis
</title><author>Enrique Castillo, Bertha Guijarro-Berdi&amp;#241;as, Oscar Fontenla-Romero, Amparo Alonso-Betanzos</author><abstract>

This paper introduces a learning method for two-layer feedforward
neural networks based on sensitivity analysis, which uses a linear
training algorithm for each of the two layers. First, random values
are assigned to the outputs of the first layer; later, these initial
values are updated based on sensitivity formulas, which use the
weights in each of the layers; the process is repeated until
convergence. Since these weights are learnt solving a linear system
of equations, there is an important saving in computational time.
The method also gives the local sensitivities of the least square
errors with respect to input and output data, with no extra
computational cost, because the necessary information becomes
available without extra calculations. This method, called the
Sensitivity-Based Linear Learning Method, can also be used to
provide an initial set of weights, which significantly improves the
behavior of other learning algorithms. The theoretical basis for the
method is given and its performance is illustrated by its
application to several examples in which it is compared with several
learning algorithms and well known data sets. The results have shown
a learning speed generally faster than other existing methods. In
addition, it can be used as an initialization tool for other well
known methods with significant improvements.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/castillo06a/castillo06a.pdf</url></Article><Article><id>303</id><title>
Computational and Theoretical Analysis of  Null Space  and Orthogonal Linear Discriminant Analysis
</title><author>Jieping Ye, Tao Xiong</author><abstract>
&lt;p&gt;
Dimensionality reduction is an important pre-processing step in many
applications.  Linear discriminant analysis (LDA) is a classical
statistical approach for supervised dimensionality reduction. It aims
to maximize the ratio of the between-class distance to the
within-class distance, thus maximizing the class discrimination. It
has been used widely in many applications. However, the classical LDA
formulation requires the nonsingularity of the scatter matrices
involved. For undersampled problems, where the data dimensionality is
much larger than the sample size, all scatter matrices are singular
and classical LDA fails. Many extensions, including null space LDA
(NLDA) and orthogonal LDA (OLDA), have been proposed in the past to
overcome this problem.  NLDA aims to maximize the between-class
distance in the null space of the within-class scatter matrix, while
OLDA computes a set of orthogonal discriminant vectors via the
simultaneous diagonalization of the scatter matrices. They have been
applied successfully in various applications.
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a computational and theoretical analysis of
NLDA and OLDA.  Our main result shows that under a mild condition
which holds in many applications involving high-dimensional data, NLDA
is equivalent to OLDA. We have performed extensive experiments on
various types of data and results are consistent with our theoretical
analysis. We further apply the regularization to OLDA. The algorithm
is called regularized OLDA (or ROLDA for short). An efficient
algorithm is presented to estimate the regularization value in ROLDA.
A comparative study on classification shows that ROLDA is very
competitive with OLDA. This confirms the effectiveness of the
regularization in ROLDA.
&lt;/p&gt;


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/ye06a/ye06a.pdf</url></Article><Article><id>304</id><title>
Worst-Case Analysis of Selective Sampling for Linear Classification
</title><author>Nicol&amp;#242; Cesa-Bianchi, Claudio Gentile, Luca Zaniboni</author><abstract>

A selective sampling algorithm is a learning algorithm for
classification that, based on the past observed data, decides whether
to ask the label of each new instance to be classified.  In this
paper, we introduce a general technique for turning linear-threshold
classification algorithms from the general additive family into
randomized selective sampling algorithms. For the most popular
algorithms in this family we derive mistake bounds that hold for
individual sequences of examples. These bounds show that our
semi-supervised algorithms can achieve, on average, the same accuracy
as that of their fully supervised counterparts, but using fewer
labels.  Our theoretical results are corroborated by a number of
experiments on real-world textual data.  The outcome of these
experiments is essentially predicted by our theoretical results: Our
selective sampling algorithms tend to perform as well as the
algorithms receiving the true label after each classification, while
observing in practice substantially fewer labels.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/cesa-bianchi06b/cesa-bianchi06b.pdf</url></Article><Article><id>305</id><title>
Nonparametric Quantile Estimation
</title><author>Ichiro Takeuchi, Quoc V. Le, Timothy D. Sears, Alexander J. Smola</author><abstract>

 In regression, the desired estimate of &lt;i&gt;y&lt;/i&gt;|&lt;i&gt;x&lt;/i&gt; is not always given by a
 conditional mean, although this is most common. Sometimes one wants to
 obtain a good estimate that satisfies the property that a proportion,
 &amp;#964;, of &lt;i&gt;y&lt;/i&gt;|&lt;i&gt;x&lt;/i&gt;, will be below the estimate. For &amp;#964; = 0.5 this is
 an estimate of the &lt;i&gt;median&lt;/i&gt;. What might be called median
 regression, is subsumed under the term &lt;i&gt;quantile regression&lt;/i&gt;.  We
 present a nonparametric version of a quantile estimator, which can be
 obtained by solving a simple quadratic programming problem and provide
 uniform convergence statements and bounds on the quantile property of
 our estimator. Experimental results show the feasibility of the
 approach and competitiveness of our method with existing ones.  We
 discuss several types of extensions including an approach to solve the
 &lt;i&gt;quantile crossing&lt;/i&gt; problems, as well as a method to incorporate
 prior qualitative knowledge such as monotonicity constraints.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/takeuchi06a/takeuchi06a.pdf</url></Article><Article><id>306</id><title>
The Interplay of Optimization and Machine Learning Research
</title><author>Kristin P. Bennett, Emilio Parrado-Hern&amp;#225;ndez</author><abstract>

The fields of machine learning and mathematical
programming are increasingly intertwined.  Optimization problems
lie at the heart of most machine learning approaches. The Special
Topic on Machine Learning and Large Scale Optimization examines
this interplay. Machine learning researchers have embraced the
advances in mathematical programming allowing new types of models
to be pursued.  The special topic includes models using quadratic,
linear, second-order cone, semi-definite, and semi-infinite
programs. We observe that the qualities of good optimization
algorithms from the machine learning and optimization perspectives
can be quite different. Mathematical programming puts a premium on
accuracy, speed, and robustness.   Since generalization is the
bottom line in machine learning and training is normally done
off-line, accuracy and small speed improvements are of little
concern in machine learning.  Machine learning prefers simpler
algorithms that work in reasonable computational time for
specific classes of problems. Reducing machine learning problems
to well-explored mathematical programming classes with robust
general purpose optimization codes allows machine learning
researchers to rapidly develop new techniques. In turn, machine
learning presents new challenges to mathematical programming. The
special issue include papers from two primary themes:  novel
machine learning models and novel optimization approaches for
existing models. Many papers blend both themes, making small
changes in the underlying core mathematical program that enable
the develop of effective new algorithms. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/MLOPT-intro06a/MLOPT-intro06a.pdf</url></Article><Article><id>307</id><title>
Second Order Cone Programming Approaches for Handling Missing and Uncertain Data
</title><author>Pannagadatta K. Shivaswamy, Chiranjib Bhattacharyya, Alexander J. Smola</author><abstract>

We propose a novel second order cone programming formulation for
designing robust classifiers which can handle uncertainty in
observations.  Similar formulations are also derived for designing
regression functions which are robust to uncertainties in the
regression setting. The proposed formulations are independent of the
underlying distribution, requiring only the existence of second
order moments. These formulations are then specialized to the case
of missing values in observations for both classification and
regression problems.  Experiments show that the proposed
formulations outperform imputation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/shivaswamy06a/shivaswamy06a.pdf</url></Article><Article><id>308</id><title>
Ensemble Pruning Via Semi-definite Programming
</title><author>Yi Zhang, Samuel Burer, W. Nick Street</author><abstract>

An ensemble is a group of learning models that jointly solve a
problem. However, the ensembles generated by existing techniques are
sometimes unnecessarily large, which can lead to extra memory usage,
computational costs, and occasional decreases in effectiveness. The
purpose of ensemble pruning is to search for a good subset of ensemble
members that performs as well as, or better than, the original
ensemble. This subset selection problem is a combinatorial
optimization problem and thus finding the exact optimal solution is
computationally prohibitive. Various heuristic methods have been
developed to obtain an approximate solution. However, most of the
existing heuristics use simple greedy search as the optimization
method, which lacks either theoretical or empirical quality
guarantees. In this paper, the ensemble subset selection problem is
formulated as a quadratic integer programming problem. By applying
semi-definite programming (SDP) as a solution technique, we are able
to get better approximate solutions. Computational experiments show
that this SDP-based pruning algorithm outperforms other heuristics in
the literature. Its application in a classifier-sharing study also
demonstrates the effectiveness of the method.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/zhang06a/zhang06a.pdf</url></Article><Article><id>309</id><title>
Linear Programs for Hypotheses Selection in Probabilistic Inference Models
</title><author>Anders Bergkvist, Peter Damaschke,  Marcel L&amp;#252;thi</author><abstract>

We consider an optimization problem in probabilistic inference: Given
&lt;i&gt;n&lt;/i&gt; hypotheses &lt;i&gt;H&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt;, &lt;i&gt;m&lt;/i&gt; possible 
observations &lt;i&gt;O&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, their
conditional probabilities &lt;i&gt;p&lt;sub&gt;kj&lt;/sub&gt;&lt;/i&gt;, and a particular 
&lt;i&gt;O&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, select a
possibly small subset of hypotheses excluding the true target only
with some error probability &amp;#949;. After specifying the
optimization goal we show that this problem can be solved through a
linear program in &lt;i&gt;mn&lt;/i&gt; variables that indicate the probabilities to
discard a hypothesis given an observation. Moreover, we can compute
optimal strategies where only &lt;i&gt;O(m+n)&lt;/i&gt; of these variables get
fractional values. The manageable size of the linear programs and the
mostly deterministic shape of optimal strategies makes the method
practicable. We interpret the dual variables as worst-case
distributions of hypotheses, and we point out some counterintuitive
nonmonotonic behaviour of the variables as a function of the error
bound &amp;#949;. One of the open problems is the existence of a
purely combinatorial algorithm that is faster than generic linear
programming.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bergkvist06a/bergkvist06a.pdf</url></Article><Article><id>310</id><title>
Bayesian Network Learning with Parameter Constraints
</title><author>Radu Stefan Niculescu, Tom M. Mitchell, R. Bharat Rao</author><abstract>

&lt;p&gt;
The task of learning models for many real-world problems requires
incorporating domain knowledge into learning algorithms, to enable
accurate learning from a realistic volume of training data. This paper
considers a variety of types of domain knowledge for constraining
parameter estimates when learning Bayesian networks. In particular, we
consider domain knowledge that constrains the values or relationships
among subsets of parameters in a Bayesian network with known
structure.
&lt;/p&gt;&lt;p&gt;
We incorporate a wide variety of parameter constraints into learning
procedures for Bayesian networks, by formulating this task as a
constrained optimization problem. The assumptions made in module
networks, dynamic Bayes nets and context specific independence models
can be viewed as particular cases of such parameter constraints. We
present closed form solutions or fast iterative algorithms for
estimating parameters subject to several specific classes of parameter
constraints, including equalities and inequalities among parameters,
constraints on individual parameters, and constraints on sums and
ratios of parameters, for discrete and continuous variables. Our
methods cover learning from both frequentist and Bayesian points of
view, from both complete and incomplete data.
&lt;/p&gt;&lt;p&gt;
We present formal guarantees for our estimators, as well as methods
for automatically learning useful parameter constraints from data.  To
validate our approach, we apply it to the domain of fMRI brain image
analysis. Here we demonstrate the ability of our system to first learn
useful relationships among parameters, and then to use them to
constrain the training of the Bayesian network, resulting in improved
cross-validated accuracy of the learned model.  Experiments on
synthetic data are also presented.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/niculescu06a/niculescu06a.pdf</url></Article><Article><id>311</id><title>
Learning Sparse Representations by Non-Negative Matrix Factorization and Sequential Cone Programming
</title><author>Matthias Heiler, Christoph Schn&amp;#246;rr</author><abstract>

We exploit the biconvex nature of the Euclidean non-negative matrix
factorization (NMF) optimization problem to derive optimization
schemes based on sequential quadratic and second order cone
programming.  We show that for ordinary NMF, our approach performs
as well as existing state-of-the-art algorithms, while for
sparsity-constrained NMF, as recently proposed by P. O. Hoyer in
&lt;i&gt;JMLR 5 (2004)&lt;/i&gt;, it outperforms previous methods.  In addition,
we show how to extend NMF learning within the same optimization
framework in order to make use of class membership information in
supervised learning problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/heiler06a/heiler06a.pdf</url></Article><Article><id>312</id><title>
Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problems
</title><author>Tijl De Bie, Nello Cristianini</author><abstract>
&lt;p&gt;
The rise of convex programming has changed the face of many research
fields in recent years, machine learning being one of the ones that
benefitted the most. A very recent developement, the relaxation of
combinatorial problems to semi-definite programs (SDP), has gained
considerable attention over the last decade (Helmberg, 2000; De Bie 
and Cristianini, 2004a).
Although SDP problems can be solved in polynomial time, for many
relaxations the exponent in the polynomial complexity bounds is too
high for scaling to large problem sizes. This has hampered their
uptake as a powerful new tool in machine learning.
&lt;/p&gt;&lt;p&gt;
In this paper, we present a new and fast SDP relaxation of the
normalized graph cut problem, and investigate its usefulness in
unsupervised and semi-supervised learning. In particular, this
provides a convex algorithm for transduction, as well as approaches
to clustering. We further propose a whole cascade of fast
relaxations that all hold the middle between older spectral
relaxations and the new SDP relaxation, allowing one to trade off
computational cost versus relaxation accuracy. Finally, we discuss
how the methodology developed in this paper can be applied to other
combinatorial problems in machine learning, and we treat the max-cut
problem as an example.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/debie06a/debie06a.pdf</url></Article><Article><id>313</id><title>
Maximum-Gain Working Set Selection for SVMs
</title><author>Tobias Glasmachers, Christian Igel</author><abstract>

Support vector machines are trained by solving constrained
quadratic
optimization problems.
This is usually done with an iterative decomposition algorithm
operating on a small working set of variables in every iteration.
The training time strongly depends on the selection of these
variables.  We propose the maximum-gain working set selection
algorithm for large scale quadratic programming. It is based on the
idea to greedily maximize the progress in each single iteration. The
algorithm takes second order information from cached kernel matrix
entries into account. We prove the convergence to an optimal
solution of a variant termed hybrid maximum-gain working set
selection.  This method is empirically compared to the prominent
most violating pair selection and the latest algorithm using second
order information. For large training sets our new selection scheme
is significantly faster.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/glasmachers06a/glasmachers06a.pdf</url></Article><Article><id>314</id><title>
Parallel Software for Training Large Scale Support Vector Machines on Multiprocessor Systems
</title><author>Luca Zanni, Thomas Serafini, Gaetano Zanghirati</author><abstract>

Parallel software for solving the quadratic program arising in training
&lt;i&gt;support vector machines&lt;/i&gt; for classification problems is introduced.
The software implements an iterative decomposition technique and exploits
both the storage and the computing resources
available on  multiprocessor systems, by distributing
the heaviest computational tasks of each decomposition iteration.
Based on a wide range of recent theoretical advances,
relevant decomposition issues, such as the quadratic
subproblem solution, the gradient updating, the working set selection,
are systematically described and
their careful combination to get an
effective parallel tool is discussed.
A comparison with state-of-the-art packages on benchmark problems
demonstrates the good accuracy and the remarkable time saving achieved
by the proposed software. Furthermore, challenging experiments on 
real-world data sets with millions training samples highlight 
how the software makes
large scale standard nonlinear support vector machines
effectively tractable on common multiprocessor systems.
This feature is not shown by any of the available codes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/zanni06a/zanni06a.pdf</url></Article><Article><id>315</id><title>
Building Support Vector Machines with Reduced Classifier Complexity
</title><author>S. Sathiya Keerthi, Olivier Chapelle, Dennis DeCoste</author><abstract>

Support vector machines (SVMs), though accurate, are not preferred in
applications requiring great classification speed, due to the number
of support vectors being large. To overcome this problem we devise a
primal method with the following properties: (1) it decouples the idea
of basis functions from the concept of support vectors; (2) it
greedily finds a set of kernel basis functions of a specified maximum
size (&lt;i&gt;d&lt;sub&gt;max&lt;/sub&gt;&lt;/i&gt;) to approximate the SVM primal cost 
function well; (3)
it is efficient and roughly scales as &lt;i&gt;O(nd&lt;sub&gt;max&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; where 
&lt;i&gt;n&lt;/i&gt; is the
number of training examples; and, (4) the number of basis functions it
requires to achieve an accuracy close to the SVM accuracy is usually
far less than the number of SVM support vectors.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/keerthi06a/keerthi06a.pdf</url></Article><Article><id>316</id><title>
Exact 1-Norm Support Vector Machines Via Unconstrained Convex Differentiable Minimization
</title><author>Olvi L. Mangasarian</author><abstract>

Support vector machines utilizing the 1-norm, typically
set up as linear programs (Mangasarian, 2000; Bradley and 
Mangasarian, 1998), are formulated here
as a completely unconstrained minimization  of a convex differentiable 
piecewise-quadratic objective function in the dual space. The objective function,
which has a Lipschitz continuous gradient and contains only one
additional finite parameter, can be minimized by a generalized
Newton method and leads to an exact solution of the support vector
machine problem. The approach here is based on a formulation
of a very general linear program as an unconstrained minimization
problem and its application to support vector machine classification
problems. The present approach which generalizes both
(Mangasarian, 2004) and (Fung and Mangasarian, 2004) is also applied to nonlinear
approximation where a minimal number of nonlinear kernel functions
are utilized to approximate a function from a given number
of function values.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/mangasarian06a/mangasarian06a.pdf</url></Article><Article><id>317</id><title>
Large Scale Multiple Kernel Learning
</title><author>S&amp;#246;ren Sonnenburg, Gunnar R&amp;#228;tsch, Christin Sch&amp;#228;fer, Bernhard Sch&amp;#246;lkopf</author><abstract>

While classical kernel-based learning algorithms are based on a single
kernel, in practice it is often desirable to use multiple kernels.
Lanckriet et al. (2004) considered conic combinations of kernel
matrices for classification, leading to a convex quadratically
constrained quadratic program. We show that it can be rewritten as a
semi-infinite linear program that can be efficiently solved by
recycling the standard SVM implementations. Moreover, we generalize
the formulation and our method to a larger class of problems,
including regression and one-class classification. Experimental
results show that the proposed algorithm works for hundred thousands of examples or
hundreds of kernels to be combined, and helps for automatic model
selection, improving the interpretability of the learning result. In a 
second part we discuss general speed up mechanism for
SVMs, especially when used with &lt;i&gt;sparse&lt;/i&gt; feature maps as appear
for string kernels, allowing us to train a string kernel SVM on a 10
million real-world splice data set from computational biology.  We
integrated multiple kernel learning in our machine learning toolbox
&lt;tt&gt;SHOGUN&lt;/tt&gt; for which the source code is publicly available 
at &lt;tt&gt;http://www.fml.tuebingen.mpg.de/raetsch/projects/shogun&lt;/tt&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/sonnenburg06a/sonnenburg06a.pdf</url></Article><Article><id>318</id><title>
Efficient Learning of Label Ranking by Soft Projections onto Polyhedra
</title><author>Shai Shalev-Shwartz, Yoram Singer</author><abstract>

We discuss the problem of learning to rank labels from a real valued
feedback associated with each label. We cast the feedback as a
preferences graph where the nodes of the graph are the labels and
edges express preferences over labels. We tackle the learning problem
by defining a loss function for comparing a predicted graph with a
feedback graph. This loss is materialized by decomposing the feedback
graph into bipartite sub-graphs. We then adopt the maximum-margin
framework which leads to a quadratic optimization problem with linear
constraints. While the size of the problem grows quadratically with
the number of the nodes in the feedback graph, we derive a problem of
a significantly smaller size and prove that it attains the same
minimum. We then describe an efficient algorithm, called SOPOPO, for
solving the reduced problem by employing a soft projection onto the
polyhedron defined by a reduced set of constraints. We also describe
and analyze a wrapper procedure for batch learning when multiple
graphs are provided for training. We conclude with a set of
experiments which show significant improvements in run time over a
state of the art interior-point algorithm.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/shalev-shwartz06a/shalev-shwartz06a.pdf</url></Article><Article><id>319</id><title>
Kernel-Based Learning of Hierarchical Multilabel Classification Models
</title><author>Juho Rousu, Craig Saunders, Sandor Szedmak, John Shawe-Taylor</author><abstract>
&lt;p&gt;
We present a kernel-based algorithm for hierarchical text
classification where the documents are allowed to belong to more
than one category at a time. The classification model is a variant
of the Maximum Margin Markov Network framework, where the
classification hierarchy is represented as a  Markov tree equipped
with an exponential family defined on the edges.
We present an efficient optimization
algorithm based on incremental conditional gradient ascent in
single-example subspaces spanned by the marginal dual variables.
The optimization is facilitated with a dynamic programming based
algorithm that computes best update directions in the feasible set.
&lt;/p&gt;&lt;p&gt;
Experiments show that the algorithm can feasibly optimize training
sets of thousands of examples and classification hierarchies
consisting of hundreds of nodes. Training of the full hierarchical
model is as efficient as training independent SVM-light classifiers
for each node.  The algorithm's predictive accuracy was found to be
competitive with other recently introduced hierarchical multi-category
or multilabel classification learning algorithms.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/rousu06a/rousu06a.pdf</url></Article><Article><id>320</id><title>
Structured Prediction, Dual Extragradient and Bregman Projections
</title><author>Ben Taskar, Simon Lacoste-Julien, Michael I. Jordan</author><abstract>

We present a simple and scalable algorithm for maximum-margin
estimation of structured output models, including an important
class of Markov networks and combinatorial models.  We formulate
the estimation problem as a convex-concave saddle-point problem
that allows us to use simple projection methods based on the
dual extragradient algorithm (Nesterov, 2003).
The projection step can be solved using
dynamic programming or combinatorial algorithms for min-cost
convex flow, depending on the structure of the problem. We show
that this approach provides a memory-efficient alternative to
formulations based on reductions to a quadratic program (QP). We
analyze the convergence of the method and present experiments on
two very different structured prediction tasks: 3D image
segmentation and word alignment, illustrating the favorable
scaling properties of our algorithm.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/taskar06a/taskar06a.pdf</url></Article><Article><id>321</id><title>
Active Learning with Feedback on Features and Instances
</title><author>Hema Raghavan, Omid Madani, Rosie Jones</author><abstract>

We extend the traditional active learning framework to include
feedback on features in addition to labeling instances, and we execute
a careful study of the effects of feature selection and human feedback
on features in the setting of text categorization.  Our experiments on
a variety of categorization tasks indicate that there is significant
potential in improving classifier performance by feature re-weighting,
beyond that achieved via membership queries alone (traditional active
learning) if we have access to an &lt;i&gt;oracle&lt;/i&gt; that can point to the
important (most predictive) features.  Our experiments on human
subjects indicate that human feedback on feature relevance can
identify a sufficient proportion of the most relevant features (over
50% in our experiments).  We find that on average, labeling a feature
takes much less time than labeling a document.  We devise an algorithm
that interleaves labeling features and documents which significantly
accelerates standard active learning in our simulation experiments.
Feature feedback can complement traditional active learning in
applications such as news filtering, e-mail classification, and
personalization, where the human teacher can have significant
knowledge on the relevance of features.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/raghavan06a/raghavan06a.pdf</url></Article><Article><id>322</id><title>
Large Scale Transductive SVMs
</title><author>Ronan Collobert, Fabian Sinz, Jason Weston, L&amp;#233;on Bottou</author><abstract>

We show how the concave-convex procedure can be applied
to transductive SVMs, which traditionally require solving
a combinatorial search problem. This
provides for the first time a highly scalable algorithm in the nonlinear
case.
Detailed experiments verify the utility of our approach. Software
is available at &lt;tt&gt;http://www.kyb.tuebingen.mpg.de/bs/people/fabee/transduction.html&lt;/tt&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/collobert06a/collobert06a.pdf</url></Article><Article><id>323</id><title>
Considering Cost Asymmetry in Learning Classifiers
</title><author>Francis R. Bach, David Heckerman, Eric Horvitz</author><abstract>

Receiver Operating Characteristic (ROC) curves are a standard way to
display the performance of a set of binary classifiers for all
feasible ratios of the costs associated with false positives and
false negatives. For linear classifiers, the set of classifiers is
typically obtained by training once, holding constant the estimated
slope and then varying the intercept to obtain a parameterized set
of classifiers whose performances can be plotted in the ROC plane.
We consider the alternative of varying the asymmetry of the cost
function used for training. We show that the ROC curve obtained by
varying both the intercept and the asymmetry, and hence the slope,
always outperforms the ROC curve obtained by varying only the
intercept. In addition, we present a path-following algorithm for
the support vector machine (SVM) that can compute efficiently the
entire ROC curve, and that has the same computational complexity as
training a single classifier. Finally, we provide a theoretical
analysis of the relationship between the asymmetric cost model
assumed when training a classifier and the cost model assumed in
applying the classifier. In particular, we show that the mismatch
between the step function used for testing and its convex upper
bounds, usually used for training, leads to a provable and
quantifiable difference around extreme asymmetries.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bach06a/bach06a.pdf</url></Article><Article><id>324</id><title>
Learning Factor Graphs in Polynomial Time and Sample Complexity
</title><author>Pieter Abbeel, Daphne Koller, Andrew Y. Ng</author><abstract>

We study the computational and sample complexity of parameter and
structure learning in graphical models.  Our main result shows that
the class of factor graphs with bounded degree can be learned in
polynomial time and from a polynomial number of training examples,
assuming that the data is generated by a network in this class.  This
result covers both parameter estimation for a known network structure
and structure learning.  It implies as a corollary that we can learn
factor graphs for both Bayesian networks and Markov networks of
bounded degree, in polynomial time and sample complexity. Importantly,
unlike standard maximum likelihood estimation algorithms, our method
does not require inference in the underlying network, and so applies
to networks where inference is intractable.  We also show that the
error of our learned model degrades gracefully when the generating
distribution is not a member of the target class of networks. In
addition to our main result, we show that the sample complexity of
parameter learning in graphical models has an &lt;i&gt;O&lt;/i&gt;(1) dependence
on the number of variables in the model when using the KL-divergence
normalized by the number of variables as the performance criterion.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/abbeel06a/abbeel06a.pdf</url></Article><Article><id>325</id><title>
Collaborative Multiagent Reinforcement Learning by Payoff Propagation
</title><author>Jelle R. Kok, Nikos Vlassis</author><abstract>

In this article we describe a set of scalable techniques for
learning the behavior of a group of agents in a collaborative
multiagent setting.  As a basis we use the framework of coordination
graphs of Guestrin, Koller, and Parr (2002a) which exploits the dependencies between
agents to decompose the global payoff function into a sum of local
terms. First, we deal with the single-state case and describe a
payoff propagation algorithm that computes the individual actions
that approximately maximize the global payoff function.  The method
can be viewed as the decision-making analogue of belief propagation
in Bayesian networks. Second, we focus on learning the behavior of
the agents in sequential decision-making tasks.  We introduce
different model-free reinforcement-learning techniques, unitedly
called Sparse Cooperative &lt;i&gt;Q&lt;/i&gt;-learning, which approximate the global
action-value function based on the topology of a coordination graph,
and perform updates using the contribution of the individual agents
to the maximal global action value.  The combined use of an
edge-based decomposition of the action-value function and the payoff
propagation algorithm for efficient action selection, result in an
approach that scales only linearly in the problem size. We provide
experimental evidence that our method outperforms related multiagent
reinforcement-learning methods based on temporal differences.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/kok06a/kok06a.pdf</url></Article><Article><id>326</id><title>
Estimating the "Wrong" Graphical Model: Benefits in the Computation-Limited Setting
</title><author>Martin J. Wainwright</author><abstract>

Consider the problem of joint parameter estimation and prediction in a
Markov random field: that is, the model parameters are estimated on the
basis of an initial set of data, and then the fitted model is used to
perform prediction (e.g., smoothing, denoising, interpolation) on a
new noisy observation.  Working under the restriction of limited
computation, we analyze a joint method in which the &lt;i&gt;same convex
variational relaxation&lt;/i&gt; is used to construct an M-estimator for
fitting parameters, and to perform approximate marginalization for the
prediction step.  The key result of this paper is that in the
computation-limited setting, using an inconsistent parameter estimator
(i.e., an estimator that returns the "wrong" model even in the
infinite data limit) is provably beneficial, since the resulting
errors can partially compensate for errors made by using an
approximate prediction technique.  En route to this result, we analyze
the asymptotic properties of M-estimators based on convex variational
relaxations, and establish a Lipschitz stability property that holds
for a broad class of convex variational methods.  This stability
result provides additional incentive, apart from the obvious benefit
of unique global optima, for using message-passing methods based on
convex variational relaxations.  We show that joint
estimation/prediction based on the reweighted sum-product algorithm
substantially outperforms a commonly used heuristic based on ordinary
sum-product.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/wainwright06a/wainwright06a.pdf</url></Article><Article><id>327</id><title>
Streamwise Feature Selection
</title><author>Jing Zhou, Dean P. Foster, Robert A. Stine, Lyle H. Ungar</author><abstract>

In &lt;i&gt;streamwise feature selection&lt;/i&gt;, new features are sequentially
considered for addition to a predictive model.  When the space of
potential features is large, streamwise feature selection offers
many advantages over traditional feature selection methods, which
assume that all features are known in advance.  Features can be
generated dynamically, focusing the search for new features on
promising subspaces, and overfitting can be controlled by
dynamically adjusting the threshold for adding features to the
model.  In contrast to traditional forward feature selection
algorithms such as stepwise regression in which at each step all
possible features are evaluated and the best one is selected,
streamwise feature selection only evaluates each feature once when
it is generated. We describe information-investing and
&amp;#945;-investing, two adaptive complexity penalty methods for
streamwise feature selection which dynamically adjust the threshold
on the error reduction required for adding a new feature.  These two
methods give false discovery rate style guarantees against
overfitting.  They differ from standard penalty methods such as AIC,
BIC and RIC, which always drastically over- or under-fit in the
limit of infinite numbers of non-predictive features. Empirical
results show that streamwise regression is competitive with (on
small data sets) and superior to (on large data sets) much more
compute-intensive feature selection methods such as stepwise
regression, and allows feature selection on problems with millions
of potential features.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/zhou06a/zhou06a.pdf</url></Article><Article><id>328</id><title>
Linear Programming Relaxations and Belief Propagation -- An Empirical Study
</title><author>Chen Yanover, Talya Meltzer, Yair Weiss</author><abstract>
&lt;p&gt;
The problem of finding the most probable (MAP) configuration in
graphical models comes up in a wide range of applications. In a
general graphical model this problem is NP hard, but various
approximate algorithms have been developed.  Linear programming (LP)
relaxations are a standard method in computer science for
approximating combinatorial problems and have been used for finding
the most probable assignment in small graphical models. However,
applying this powerful method to real-world problems is extremely
challenging due to the large numbers of variables and constraints in
the linear program. Tree-Reweighted Belief Propagation is a promising
recent algorithm for solving LP relaxations, but little is known about
its running time on large problems.
&lt;/p&gt;
&lt;p&gt;
In this paper we compare tree-reweighted belief propagation (TRBP) and powerful
general-purpose LP solvers (CPLEX) on relaxations of real-world graphical
models from the fields of computer vision and computational biology. We find
that TRBP almost always finds the solution significantly faster than all the
solvers in CPLEX and more importantly, TRBP can be applied to large scale
problems for which the solvers in CPLEX cannot be applied. Using TRBP we can
find the MAP configurations in a matter of minutes for a large range of real
world problems.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/yanover06a/yanover06a.pdf</url></Article><Article><id>329</id><title>
Incremental Support Vector Learning: Analysis, Implementation and Applications
</title><author>Pavel Laskov, Christian Gehl, Stefan Kr&amp;#252;ger, Klaus-Robert M&amp;#252;ller</author><abstract>

Incremental Support Vector Machines (SVM) are instrumental in
practical applications of online learning. This work focuses on the
design and analysis of efficient incremental SVM learning, with the
aim of providing a fast, numerically stable and robust
implementation. A detailed analysis of convergence and of
algorithmic complexity of incremental SVM learning is carried out.
Based on this analysis, a new design of storage and numerical
operations is proposed, which speeds up the training of an
incremental SVM by a factor of 5 to 20. The performance of the new
algorithm is demonstrated in two scenarios: learning with limited
resources and active learning. Various applications of the
algorithm, such as in drug discovery, online monitoring of
industrial devices and and surveillance of network traffic, can be
foreseen. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/laskov06a/laskov06a.pdf</url></Article><Article><id>330</id><title>
A Simulation-Based Algorithm for Ergodic Control of Markov Chains Conditioned on Rare Events
</title><author>Shalabh Bhatnagar, Vivek S. Borkar, Madhukar Akarapu</author><abstract>

We study the problem of long-run average cost control of Markov chains
conditioned on a rare event. In a related recent work, a simulation
based algorithm for estimating performance measures associated with a
Markov chain conditioned on a rare event has been developed. We extend
ideas from this work and develop an adaptive algorithm for obtaining,
online, optimal control policies conditioned on a rare event.  Our
algorithm uses three timescales or step-size schedules. On the slowest
timescale, a gradient search algorithm for policy updates that is
based on one-simulation simultaneous perturbation stochastic
approximation (SPSA) type estimates is used. Deterministic
perturbation sequences obtained from appropriate normalized Hadamard
matrices are used here. The fast timescale recursions compute the
conditional transition probabilities of an associated chain by
obtaining solutions to the multiplicative Poisson equation (for a
given policy estimate).  Further, the risk parameter associated with
the value function for a given policy estimate is updated on a
timescale that lies in between the two scales above. We briefly sketch
the convergence analysis of our algorithm and present a numerical
application in the setting of routing multiple flows in communication
networks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bhatnagar06a/bhatnagar06a.pdf</url></Article><Article><id>331</id><title>
Learning Spectral Clustering, With Application To Speech Separation
</title><author>Francis R. Bach, Michael I. Jordan</author><abstract>

Spectral clustering refers to a class of techniques which rely on
the eigenstructure of a similarity matrix to partition points into
disjoint clusters, with points in the same cluster having high
similarity and points in different clusters having low similarity.
In this paper, we derive new cost functions for spectral
clustering based on measures of error between a given partition
and a solution of the spectral relaxation of a minimum normalized
cut problem.  Minimizing these cost functions with respect to the
partition leads to new spectral clustering algorithms.  Minimizing
with respect to the similarity matrix leads to algorithms for
learning the similarity matrix from fully labelled data sets. We
apply our learning algorithm to the blind one-microphone speech
separation problem, casting the problem as one of segmentation
of the spectrogram.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bach06b/bach06b.pdf</url></Article><Article><id>332</id><title>
A Linear Non-Gaussian Acyclic Model for Causal Discovery
</title><author>Shohei Shimizu, Patrik O. Hoyer, Aapo Hyv&amp;#228;rinen, Antti Kerminen</author><abstract>

In recent years, several methods have been proposed for the discovery
of causal structure from non-experimental data. Such methods make
various assumptions on the data generating process to facilitate its
identification from purely observational data. Continuing this line of
research, we show how to discover the complete causal structure of
continuous-valued data, under the assumptions that (a) the data
generating process is linear, (b) there are no unobserved confounders,
and (c) disturbance variables have non-Gaussian distributions of
non-zero variances. The solution relies on the use of the statistical
method known as independent component analysis, and does not require
any pre-specified time-ordering of the variables. We provide a
complete Matlab package for performing this LiNGAM analysis (short for
Linear Non-Gaussian Acyclic Model), and demonstrate the effectiveness
of the method using artificially generated data and real-world data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/shimizu06a/shimizu06a.pdf</url></Article><Article><id>333</id><title>
Walk-Sums and Belief Propagation in Gaussian Graphical Models
</title><author>Dmitry M. Malioutov, Jason K. Johnson, Alan S. Willsky</author><abstract>

We present a new framework based on walks in a graph for analysis and
inference in Gaussian graphical models. The key idea is to decompose
the correlation between each pair of variables as a sum over all walks
between those variables in the graph. The weight of each walk is given
by a product of edgewise partial correlation coefficients. This
representation holds for a large class of Gaussian graphical models
which we call walk-summable. We give a precise characterization of
this class of models, and relate it to other classes including
diagonally dominant, attractive, non-frustrated, and
pairwise-normalizable. We provide a walk-sum interpretation of
Gaussian belief propagation in trees and of the approximate method of
loopy belief propagation in graphs with cycles.  The walk-sum
perspective leads to a better understanding of Gaussian belief
propagation and to stronger results for its convergence in loopy
graphs.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/malioutov06a/malioutov06a.pdf</url></Article><Article><id>334</id><title>
Distance Patterns in Structural Similarity
</title><author>Thomas K&amp;#228;mpke</author><abstract>

Similarity of edge labeled graphs is considered in the sense of minimum 
squared distance between corresponding values. Vertex correspondences are 
established by isomorphisms if both graphs are of equal size and by 
subisomorphisms if one graph has fewer vertices than the other. Best fit 
isomorphisms and subisomorphisms amount to solutions of quadratic 
assignment problems and are computed exactly as well as approximately
by minimum cost flow, linear assignment relaxations and related graph 
algorithms.  

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/kaempke06a/kaempke06a.pdf</url></Article><Article><id>335</id><title>
A Hierarchy of Support Vector Machines for Pattern Detection
</title><author>Hichem Sahbi, Donald Geman</author><abstract>
&lt;p&gt;
We introduce a computational design for pattern detection
based on a tree-structured network of support vector machines (SVMs).
An SVM is associated with each cell in a recursive partitioning of the
space of patterns (hypotheses) into increasingly finer subsets.  The
hierarchy is traversed coarse-to-fine and each chain of positive
responses from the root to a leaf constitutes a detection.  Our
objective is to design and build a network which balances overall
error and computation.
&lt;/p&gt;&lt;p&gt;
Initially, SVMs are constructed for each cell with no
constraints.  This "free network" is then perturbed, cell by cell,
into another network, which is "graded" in two ways: first, the
number of support vectors of each SVM is reduced (by clustering) in
order to adjust to a pre-determined, increasing function of cell
depth; second, the decision boundaries are shifted to preserve all
positive responses from the original set of training data.  The limits
on the numbers of clusters (virtual support vectors) result from
minimizing the mean computational cost of collecting all detections
subject to a bound on the expected number of false positives.
&lt;/p&gt;&lt;p&gt;
When applied to detecting faces in cluttered scenes, the
patterns correspond to poses and the free network is already faster
and more accurate than applying a single pose-specific SVM many times.
The graded network promotes very rapid processing of background
regions while maintaining the discriminatory power of the free
network.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/sahbi06a/sahbi06a.pdf</url></Article><Article><id>336</id><title>
Adaptive Prototype Learning Algorithms: Theoretical and Experimental Studies
</title><author>Fu Chang, Chin-Chin Lin, Chi-Jen Lu</author><abstract>

In this paper, we propose a number of adaptive prototype learning
(APL) algorithms. They employ the same algorithmic scheme to determine
the number and location of prototypes, but differ in the use of
samples or the weighted averages of samples as prototypes, and also in
the assumption of distance measures. To understand these algorithms
from a theoretical viewpoint, we address their convergence properties,
as well as their consistency under certain conditions. We also present
a soft version of APL, in which a non-zero training error is allowed
in order to enhance the generalization power of the resultant
classifier. Applying the proposed algorithms to twelve UCI benchmark
data sets, we demonstrate that they outperform many instance-based
learning algorithms, the &lt;i&gt;k&lt;/i&gt;-nearest neighbor rule, and support vector
machines in terms of average test accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/chang06a/chang06a.pdf</url></Article><Article><id>337</id><title>
A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests
</title><author>Luis M. de Campos</author><abstract>

We propose a new scoring function for learning Bayesian networks from
data using score+search algorithms. This is based on the concept of
mutual information and exploits some well-known properties of this
measure in a novel way. Essentially, a statistical independence test
based on the chi-square distribution, associated with the mutual
information measure, together with a property of additive
decomposition of this measure, are combined in order to measure the
degree of interaction between each variable and its parent variables
in the network.  The result is a non-Bayesian scoring function called
MIT (mutual information tests) which belongs to the family of scores
based on information theory. The MIT score also represents a
penalization of the Kullback-Leibler divergence between the joint
probability distributions associated with a candidate network and with
the available data set.  Detailed results of a complete experimental
evaluation of the proposed scoring function and its comparison with
the well-known K2, BDeu and BIC/MDL scores are also presented.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/decampos06a/decampos06a.pdf</url></Article><Article><id>338</id><title>
Noisy-OR Component Analysis and its Application to Link Analysis
</title><author>Tom&amp;#225;&amp;#353; &amp;#352;ingliar, Milo&amp;#353; Hauskrecht</author><abstract>

We develop a new component analysis framework, the &lt;i&gt;Noisy-Or
Component Analyzer&lt;/i&gt; (NOCA), that targets high-dimensional binary
data. NOCA is a probabilistic latent variable model that assumes the
expression of observed high-dimensional binary data is driven by a
small number of hidden binary sources combined via noisy-or units.
The component analysis procedure is equivalent to learning of NOCA
parameters.  Since the classical EM formulation of the NOCA learning
problem is intractable, we develop its variational approximation.  We
test the NOCA framework on two problems: (1) a synthetic
image-decomposition problem and (2) a co-citation data analysis
problem for thousands of CiteSeer documents. We demonstrate good
performance of the new model on both problems.  In addition, we
contrast the model to two mixture-based latent-factor models: the
probabilistic latent semantic analysis (PLSA) and latent Dirichlet
allocation (LDA).  Differing assumptions underlying these models cause
them to discover different types of structure in co-citation data,
thus illustrating the benefit of NOCA in building our understanding of
high-dimensional data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/singliar06a/singliar06a.pdf</url></Article><Article><id>339</id><title>
Learning a Hidden Hypergraph
</title><author>Dana Angluin, Jiang Chen</author><abstract>

We consider the problem of learning a hypergraph using edge-detecting queries.
In this model, the learner may query whether a set of vertices induces an 
edge of the hidden hypergraph or not.
We show that an &lt;i&gt;r&lt;/i&gt;-uniform hypergraph with &lt;i&gt;m&lt;/i&gt; edges and &lt;i&gt;n&lt;/i&gt; 
vertices is learnable with &lt;i&gt;O&lt;/i&gt;(2&lt;sup&gt;4&lt;i&gt;r&lt;/i&gt;&lt;/sup&gt;&lt;i&gt;m&lt;/i&gt; &amp;#183; 
&lt;i&gt;poly&lt;/i&gt;(&lt;i&gt;r&lt;/i&gt;,log&lt;i&gt;n&lt;/i&gt;)) queries with high probability.
The queries can be made in &lt;i&gt;O&lt;/i&gt;(min(2&lt;sup&gt;&lt;i&gt;r&lt;/i&gt;&lt;/sup&gt; 
(log &lt;i&gt;m+r&lt;/i&gt;)&lt;sup&gt;2&lt;/sup&gt;, (log &lt;i&gt;m+r&lt;/i&gt;)&lt;sup&gt;3&lt;/sup&gt;)) rounds.
We also give an algorithm that learns an almost uniform hypergraph of 
dimension &lt;i&gt;r&lt;/i&gt; using &lt;i&gt;O&lt;/i&gt;(2&lt;sup&gt;&lt;i&gt;O&lt;/i&gt;((1+&amp;#916;/2)r)&lt;/sup&gt; &amp;#183; 
&lt;i&gt;m&lt;/i&gt;&lt;sup&gt;1+&amp;#916;/2&lt;/sup&gt; &amp;#183; &lt;i&gt;poly&lt;/i&gt;(log &lt;i&gt;n&lt;/i&gt;)) 
queries with high probability,
where &amp;#916; is the difference between the maximum and the minimum edge 
sizes.  This upper bound matches our lower bound of 
&amp;#937;((&lt;i&gt;m&lt;/i&gt;/(1+&amp;#916;/2))&lt;sup&gt;1+&amp;#916;/2&lt;/sup&gt;) for this 
class of hypergraphs in terms of dependence on &lt;i&gt;m&lt;/i&gt;.
The queries can also be made in 
&lt;i&gt;O&lt;/i&gt;((1+&amp;#916;) &amp;#183; min(2&lt;sup&gt;&lt;i&gt;r&lt;/i&gt;&lt;/sup&gt; (log &lt;i&gt;m+r&lt;/i&gt;)&lt;sup&gt;2&lt;/sup&gt;, 
(log &lt;i&gt;m+r&lt;/i&gt;)&lt;sup&gt;3&lt;/sup&gt;)) rounds.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/angluin06a/angluin06a.pdf</url></Article><Article><id>340</id><title>
An Efficient Implementation of an Active Set Method for SVMs
</title><author>Katya Scheinberg</author><abstract>

We propose an active set algorithm to solve the convex 
quadratic programming (QP) problem which is the core of 
the support vector machine (SVM) training. 
The underlying method is not new and is based on the 
extensive practice of the Simplex method and its variants
for convex quadratic problems. However, its application
to large-scale SVM problems is new. Until recently the 
traditional active set methods were considered impractical for
large SVM problems. By adapting the methods to the special 
structure of SVM problems we were able to produce an efficient 
implementation.  We conduct an extensive study of the behavior 
of our method and its variations on SVM problems.
 We present computational results comparing our method with
Joachims' SVM&lt;sup&gt;&lt;i&gt;light&lt;/i&gt;&lt;/sup&gt; (see Joachims, 1999). 
The results show that our method has overall
better performance on many SVM problems. It seems to have 
a particularly strong advantage on more difficult problems. 
In addition this algorithm has better theoretical properties 
and it  naturally extends to the incremental mode. Since 
the proposed method solves the standard SVM formulation, as 
does SVM&lt;sup&gt;&lt;i&gt;light&lt;/i&gt;&lt;/sup&gt;, the generalization properties of these 
two approaches are identical and we do not discuss them in 
the paper.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/scheinberg06a/scheinberg06a.pdf</url></Article><Article><id>341</id><title>
Causal Graph Based Decomposition of Factored MDPs
</title><author>Anders Jonsson, Andrew Barto</author><abstract>

We present Variable Influence Structure Analysis, or VISA, an
algorithm that performs hierarchical decomposition of factored
Markov decision processes.
VISA uses a dynamic Bayesian network model of actions, and
constructs a causal graph that captures relationships between
state variables.
In tasks with sparse causal graphs VISA exploits structure by
introducing activities that cause the values of state variables
to change.
The result is a hierarchy of activities that together represent a
solution to the original task.
VISA performs state abstraction for each activity by
ignoring irrelevant state variables and lower-level activities.
In addition, we describe an algorithm for constructing compact
models of the activities introduced.
State abstraction and compact activity models enable VISA
to apply efficient algorithms to solve the stand-alone subtask
associated with each activity.
Experimental results show that the decomposition introduced by
VISA can significantly accelerate construction of an optimal, or
near-optimal, policy.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/jonsson06a/jonsson06a.pdf</url></Article><Article><id>342</id><title>
Accurate Error Bounds for the Eigenvalues of the Kernel Matrix
</title><author>Mikio L. Braun</author><abstract>

The eigenvalues of the kernel matrix play an important role in a
number of kernel methods, in particular, in kernel principal component
analysis. It is well known that the eigenvalues of the kernel matrix
converge as the number of samples tends to infinity.  We derive
probabilistic finite sample size bounds on the approximation error of
individual eigenvalues which have the important property that the
bounds scale with the eigenvalue under consideration, reflecting the
actual behavior of the approximation errors as predicted by asymptotic
results and observed in numerical simulations. Such scaling bounds
have so far only been known for tail sums of eigenvalues.
Asymptotically, the bounds presented here have a slower than
stochastic rate, but the number of sample points necessary to make
this disadvantage noticeable is often unrealistically large.
Therefore, under practical conditions, and for all but the largest few
eigenvalues, the bounds presented here form a significant improvement
over existing non-scaling bounds.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/braun06a/braun06a.pdf</url></Article><Article><id>343</id><title>
Point-Based Value Iteration for Continuous POMDPs
</title><author>Josep M. Porta, Nikos Vlassis, Matthijs T.J. Spaan, Pascal Poupart</author><abstract>

We propose a novel approach to optimize Partially Observable Markov
Decisions Processes (POMDPs) defined on continuous spaces.  To date,
most algorithms for model-based POMDPs are restricted to discrete
states, actions, and observations, but many real-world problems such
as, for instance, robot navigation, are naturally defined on
continuous spaces. In this work, we demonstrate that the value
function for continuous POMDPs is convex in the beliefs over
continuous state spaces, and piecewise-linear convex for the
particular case of discrete observations and actions but still
continuous states. We also demonstrate that continuous Bellman backups
are contracting and isotonic ensuring the monotonic convergence of
value-iteration algorithms. Relying on those properties, we extend the
algorithm, originally developed for discrete POMDPs, to work in
continuous state spaces by representing the observation, transition,
and reward models using Gaussian mixtures, and the beliefs using
Gaussian mixtures or particle sets.  With these representations, the
integrals that appear in the Bellman backup can be computed in closed
form and, therefore, the algorithm is computationally
feasible. Finally, we further extend to deal with continuous action
and observation sets by designing effective sampling approaches.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/porta06a/porta06a.pdf</url></Article><Article><id>344</id><title>
Learning Parts-Based Representations of Data
</title><author>David A. Ross, Richard S. Zemel</author><abstract>

Many perceptual models and theories hinge on treating objects as a
collection of constituent parts.  When applying these approaches to
data, a fundamental problem arises: how can we determine what are the
parts?
We attack this problem using learning, proposing a form of generative 
latent factor model, in which each
data dimension is allowed to select a different factor or part as its
explanation.  This approach permits a range of variations that
posit different models for the appearance of a part.  
Here we provide the details for two such models: a
discrete and a continuous one.
  Further, we show that this latent factor model can be extended
hierarchically to account for correlations between the appearances of
different parts.  This permits modelling of data consisting of
multiple categories, and learning these categories simultaneously
with the parts when they are unobserved.  Experiments demonstrate the
ability to learn parts-based representations, and categories, of
facial images and user-preference data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/ross06a/ross06a.pdf</url></Article><Article><id>345</id><title>
Manifold  Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples
</title><author>Mikhail Belkin, Partha Niyogi, Vikas Sindhwani</author><abstract>

We propose a family of learning algorithms based on a new form of
regularization that allows us to exploit the geometry of the marginal
distribution.  We focus on a semi-supervised framework that
incorporates labeled and unlabeled data in a general-purpose learner.
Some transductive graph learning algorithms and standard methods
including support vector machines and regularized least squares can be
obtained as special cases.  We use properties of reproducing kernel
Hilbert spaces to prove new Representer theorems that provide
theoretical basis for the algorithms.  As a result (in contrast to
purely graph-based approaches) we obtain a natural out-of-sample
extension to novel examples and so are able to handle both
transductive and truly semi-supervised settings.  We present
experimental evidence suggesting that our semi-supervised algorithms
are able to use unlabeled data effectively. Finally we have a brief
discussion of unsupervised and fully supervised learning within our
general framework.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/belkin06a/belkin06a.pdf</url></Article><Article><id>346</id><title>
Consistency of Multiclass Empirical Risk Minimization Methods Based on Convex Loss
</title><author>Di-Rong Chen, Tao Sun</author><abstract>

The consistency of classification algorithm plays a central role
in statistical learning theory. A consistent algorithm guarantees
us that taking more samples essentially suffices to roughly
reconstruct the unknown distribution. We consider the consistency
of ERM scheme over classes of combinations of very simple rules
(base classifiers) in multiclass classification. Our approach is,
under some mild conditions, to establish a quantitative
relationship between classification errors and convex risks. In
comparison with the related previous work, the feature of our
result is that the conditions are mainly expressed in terms of the
differences between some values of the convex function.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/chen06a/chen06a.pdf</url></Article><Article><id>347</id><title>
Bounds for the Loss in Probability of Correct Classification Under Model Based Approximation
</title><author>Magnus Ekdahl, Timo Koski</author><abstract>

In many pattern recognition/classification problem the true class
conditional model and class probabilities are approximated for reasons
of reducing complexity and/or of statistical estimation.  The
approximated classifier is expected to have worse performance, here
measured by the probability of correct classification. We present an
analysis valid in general, and easily computable formulas for
estimating the degradation in probability of correct classification
when compared to the optimal classifier. An example of an
approximation is the Na&amp;#239;ve Bayes classifier. We show that the
performance of the Na&amp;#239;ve Bayes depends on the degree of functional
dependence between the features and labels.  We provide a sufficient
condition for zero loss of performance, too.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/ekdahl06a/ekdahl06a.pdf</url></Article><Article><id>348</id><title>
Estimation of Gradients and Coordinate Covariation in Classification
</title><author>Sayan Mukherjee, Qiang Wu</author><abstract>

We introduce an algorithm that simultaneously estimates a
classification function as well as its gradient in
the supervised learning framework. The motivation for the
algorithm is to find salient variables and estimate
how they covary. An efficient implementation with respect
to both memory and time is given. The utility of the
algorithm is illustrated on  simulated data as well as a gene
expression data set. An error analysis is given for
the convergence of the estimate of the classification function
and its gradient to the true classification function and
true gradient.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/mukherjee06b/mukherjee06b.pdf</url></Article><Article><id>349</id><title>
Expectation Correction for Smoothed Inference in Switching Linear Dynamical Systems
</title><author>David Barber</author><abstract>

We introduce a method for approximate smoothed inference in a class
of switching linear dynamical systems, based on a novel form of
Gaussian Sum smoother. This class includes the switching Kalman
'Filter' and the more general case of switch transitions dependent
on the continuous latent state. The method improves on the standard
Kim smoothing approach by dispensing with one of the key
approximations, thus making fuller use of the available future
information.
Whilst the central assumption required is projection to a mixture of
Gaussians, we show that an additional conditional independence
assumption results in a simpler but accurate alternative. Our method
consists of a single Forward and Backward Pass and is reminiscent of
the standard smoothing 'correction' recursions in the simpler linear
dynamical system. The method is numerically stable and compares
favourably against alternative approximations, both in cases where a
single mixture component provides a good posterior approximation,
and where a multimodal approximation is required.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/barber06a/barber06a.pdf</url></Article><Article><id>350</id><title>
On Model Selection Consistency of Lasso
</title><author>Peng Zhao, Bin Yu</author><abstract>
&lt;p&gt;
Sparsity or parsimony of statistical models is crucial for their
proper interpretations, as in sciences and social sciences. Model
selection is a commonly used method to find such models, but usually
involves a computationally heavy combinatorial search.
Lasso (Tibshirani, 1996) is now being used as a computationally
feasible alternative to model selection. Therefore it is important
to study Lasso for model selection purposes.
&lt;/p&gt;&lt;p&gt;
In this paper, we prove that a single condition, which we call the
Irrepresentable Condition, is almost necessary and sufficient for
Lasso to select the true model both in the classical fixed &lt;i&gt;p&lt;/i&gt; 
setting and in the large &lt;i&gt;p&lt;/i&gt; setting as the sample size &lt;i&gt;n&lt;/i&gt; 
gets large.  Based on these results, sufficient
conditions that are verifiable in practice are given to relate to
previous works and help applications of Lasso for feature selection
and sparse representation.
&lt;/p&gt;&lt;p&gt;
This Irrepresentable Condition, which depends mainly on the
covariance of the predictor variables, states that Lasso selects the
true model consistently if and (almost) only if the predictors that
are not in the true model are "irrepresentable" (in a sense to be
clarified) by predictors that are in the true model. Furthermore,
simulations are carried out to provide insights and understanding of
this result.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/zhao06a/zhao06a.pdf</url></Article><Article><id>351</id><title>
Stability Properties of Empirical Risk Minimization over Donsker Classes
</title><author>Andrea Caponnetto, Alexander Rakhlin</author><abstract>

We study some stability properties of algorithms which minimize
(or almost-minimize) empirical error over Donsker classes of
functions. We show that, as the number &lt;i&gt;n&lt;/i&gt; of samples grows, the
&lt;i&gt;L&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;-diameter of the set of almost-minimizers of empirical error
with tolerance &lt;i&gt;&amp;#958;&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;)=&lt;i&gt;o&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;-1/2&lt;/sup&gt;) 
converges to zero in
probability. Hence, even in the case of multiple minimizers of
expected error, as &lt;i&gt;n&lt;/i&gt; increases it becomes less and less likely that
adding a sample (or a number of samples) to the training set will
result in a large jump to a new hypothesis. Moreover, under some
assumptions on the entropy of the class, along with an assumption
of Komlos-Major-Tusnady type, we derive a power rate of decay for
the diameter of almost-minimizers. This rate, through an
application of a uniform ratio limit inequality, is shown to
govern the closeness of the expected errors of the
almost-minimizers. In fact, under the above assumptions, the
expected errors of almost-minimizers become closer with a rate strictly
faster than &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;-1/2&lt;/sup&gt;.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/caponnetto06a/caponnetto06a.pdf</url></Article><Article><id>352</id><title>
Linear State-Space Models for Blind Source Separation
</title><author>Rasmus Kongsgaard Olsson, Lars Kai Hansen</author><abstract>

We apply a type of generative modelling to the problem of blind source
separation in which prior knowledge about the latent source signals,
such as time-varying auto-correlation and quasi-periodicity, are
incorporated into a linear state-space model. In simulations, we show
that in terms of signal-to-error ratio, the sources are inferred more
accurately as a result of the inclusion of strong prior knowledge.  We
explore different schemes of maximum-likelihood optimization for the
purpose of learning the model parameters. The Expectation Maximization
algorithm, which is often considered the standard optimization method
in this context, results in slow convergence when the noise variance
is small. In such scenarios, quasi-Newton optimization yields
substantial improvements in a range of signal to noise ratios. We
analyze the performance of the methods on convolutive mixtures of
speech signals.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/olsson06a/olsson06a.pdf</url></Article><Article><id>353</id><title>
On Representing and Generating Kernels by Fuzzy Equivalence Relations
</title><author>Bernhard Moser</author><abstract>

Kernels are two-placed functions that can be interpreted as inner
products in some Hilbert space.  It is this property which makes
kernels predestinated to carry linear models of learning,
optimization or classification strategies over to non-linear variants.
Following this idea, various kernel-based methods like support vector
machines or kernel principal component analysis have been conceived
which prove to be successful for machine learning, data mining and
computer vision applications.  When applying a kernel-based method a
central question is the choice and the design of the kernel function.
This paper provides a novel view on kernels based on fuzzy-logical
concepts which allows to incorporate prior knowledge in the design
process.  It is demonstrated that kernels mapping to the unit interval
with constant one in its diagonal can be represented by a commonly
used fuzzy-logical formula for representing fuzzy rule bases.  This
means that a great class of kernels can be represented by
fuzzy-logical concepts.  Apart from this result, which only guarantees
the existence of such a representation, constructive examples are
presented and the relation to unlabeled learning is pointed out.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/moser06a/moser06a.pdf</url></Article><Article><id>354</id><title>
A Robust Procedure For Gaussian Graphical Model Search From Microarray Data With &lt;i&gt;p&lt;/i&gt; Larger Than &lt;i&gt;n&lt;/i&gt;
</title><author>Robert Castelo, Alberto Roverato</author><abstract>

Learning of large-scale networks of interactions from microarray
data is an important and challenging problem in bioinformatics. A
widely used approach is to assume that the available data constitute
a random sample from a multivariate distribution belonging to a
Gaussian graphical model. As a consequence, the prime objects of
inference are &lt;i&gt;full-order partial correlations&lt;/i&gt; which are
partial correlations between two variables given the remaining ones.
In the context of microarray data the number of variables exceed the
sample size and this precludes the application of traditional
structure learning procedures because a sampling version of
full-order partial correlations does not exist. In this paper we
consider &lt;i&gt;limited-order partial correlations&lt;/i&gt;, these are
partial correlations computed on marginal distributions of
manageable size, and provide a set of rules that allow one to assess
the usefulness of these quantities to derive the independence
structure of the underlying Gaussian graphical model. Furthermore,
we introduce a novel structure learning procedure based on a
quantity, obtained from limited-order partial correlations, that we
call the &lt;i&gt;non-rejection rate&lt;/i&gt;. The applicability and usefulness of
the procedure are demonstrated by both simulated and real data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/castelo06a/castelo06a.pdf</url></Article><Article><id>355</id><title>
Universal Kernels
</title><author>Charles A. Micchelli, Yuesheng Xu, Haizhang Zhang</author><abstract>

In this paper we investigate conditions on the features of a
continuous kernel so that it may approximate an arbitrary continuous
target function uniformly on any compact subset of the input space.
A number of concrete examples are given of kernels with this
universal approximating property.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/micchelli06a/micchelli06a.pdf</url></Article><Article><id>356</id><title>
Machine Learning for Computer Security
</title><author>Philip K. Chan, Richard P. Lippmann</author><abstract>

The prevalent use of computers and internet has enhanced the quality
of life for many people, but it has also attracted undesired attempts
to undermine these systems.  This special topic contains several
research studies on how machine learning algorithms can help improve
the security of computer systems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/MLSEC-intro06a/MLSEC-intro06a.pdf</url></Article><Article><id>357</id><title>
Spam Filtering Using Statistical Data Compression Models
</title><author>Andrej Bratko, Gordon V. Cormack, Bogdan Filipi&amp;#269;, Thomas R. Lynam, Bla&amp;#382; Zupan</author><abstract>

Spam filtering poses a special problem in text categorization, of
which the defining characteristic is that filters face an active
adversary, which constantly attempts to evade filtering. Since spam
evolves continuously and most practical applications are based on
online user feedback, the task calls for fast, incremental and robust
learning algorithms. In this paper, we investigate a novel approach to
spam filtering based on adaptive statistical data compression
models. The nature of these models allows them to be employed as
probabilistic text classifiers based on character-level or binary
sequences. By modeling messages as sequences, tokenization and other
error-prone preprocessing steps are omitted altogether, resulting in a
method that is very robust. The models are also fast to construct and
incrementally updateable. We evaluate the filtering performance of two
different compression algorithms; dynamic Markov compression and
prediction by partial matching. The results of our empirical
evaluation indicate that compression models outperform currently
established spam filters, as well as a number of methods proposed in
previous studies.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/bratko06a/bratko06a.pdf</url></Article><Article><id>358</id><title>
Spam Filtering Based On The Analysis Of Text Information Embedded Into Images
</title><author>Giorgio Fumera, Ignazio Pillai, Fabio Roli</author><abstract>

In recent years anti-spam filters have become necessary tools for
Internet service providers to face up to the continuously growing spam
phenomenon.  Current server-side anti-spam filters are made up of
several modules aimed at detecting different features of spam e-mails.
In particular, text categorisation techniques have been investigated
by researchers for the design of modules for the analysis of the
semantic content of e-mails, due to their potentially higher
generalisation capability with respect to manually derived
classification rules used in current server-side filters.  However,
very recently spammers introduced a new trick consisting of embedding
the spam message into attached images, which can make all current
techniques based on the analysis of digital text in the subject and
body fields of e-mails ineffective.
In this paper we propose an
approach to anti-spam filtering which exploits the text information
embedded into images sent as attachments.  Our approach is based on
the application of state-of-the-art text categorisation techniques to
the analysis of text extracted by OCR tools from images attached to
e-mails.  The effectiveness of the proposed approach is experimentally
evaluated on two large corpora of spam e-mails.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/fumera06a/fumera06a.pdf</url></Article><Article><id>359</id><title>
Learning to Detect and Classify Malicious Executables in the Wild
</title><author>J. Zico Kolter, Marcus A. Maloof</author><abstract>

We describe the use of machine learning and data mining to
detect and classify malicious executables as they appear in the wild.
We gathered 1,971 benign and 1,651 malicious executables and encoded
each as a training example using &lt;i&gt;n&lt;/i&gt;-grams of byte codes as features.
Such processing resulted in more than 255 million distinct &lt;i&gt;n&lt;/i&gt;-grams.
After selecting the most relevant &lt;i&gt;n&lt;/i&gt;-grams for prediction,
we evaluated a variety of inductive methods, including naive Bayes,
decision trees, support vector machines, and boosting.
Ultimately, boosted decision trees outperformed other methods
with an area under the &lt;small&gt;ROC&lt;/small&gt; curve of 0.996.
Results suggest that our methodology will scale to larger collections
of executables.
We also evaluated how well the methods classified executables based
on the function of their payload, such as opening a backdoor
and mass-mailing.
Areas under the &lt;small&gt;ROC&lt;/small&gt; curve for detecting payload function
were in the neighborhood of 0.9, which were smaller than those for
the detection task.
However, we attribute this drop in performance to fewer training
examples and to the challenge of obtaining properly labeled examples,
rather than to a failing of the methodology or to some inherent difficulty
of the classification task.
Finally, we applied detectors to 291 malicious executables
discovered after we gathered our original collection,
and boosted decision trees achieved a true-positive rate of 0.98 for
a desired false-positive rate of 0.05.
This result is particularly important, for it suggests that our
methodology could be used as the basis for an operational system
for detecting previously undiscovered malicious executables.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/kolter06a/kolter06a.pdf</url></Article><Article><id>360</id><title>
On Inferring Application Protocol Behaviors in Encrypted Network Traffic
</title><author>Charles V. Wright, Fabian Monrose, Gerald M. Masson</author><abstract>

Several fundamental security mechanisms for restricting access to
network resources rely on the ability of a reference monitor to
inspect the contents of traffic as it traverses the network.  However,
with the increasing popularity of cryptographic protocols, the
traditional means of inspecting packet contents to enforce security
policies is no longer a viable approach as message contents are
concealed by encryption. In this paper, we investigate the extent to
which common application protocols can be identified using only the
features that remain intact after encryption---namely packet size,
timing, and direction.  We first present what we believe to be the
first exploratory look at protocol identification in encrypted tunnels
which carry traffic from many TCP connections simultaneously, using
only post-encryption observable features.  We then explore the problem
of protocol identification in individual encrypted TCP connections,
using much less data than in other recent approaches.  The results of
our evaluation show that our classifiers achieve accuracy greater than
90% for several protocols in aggregate traffic, and, for most
protocols, greater than 80% when making fine-grained classifications
on single connections.  Moreover, perhaps most surprisingly, we show
that one can even estimate the number of live connections in certain
classes of encrypted tunnels to within, on average, better than 20%.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume7/wright06a/wright06a.pdf</url></Article><Article><id>361</id><title>
Nonlinear Boosting Projections for Ensemble Construction
</title><author>Nicol&amp;#225;s Garc&amp;#237;a-Pedrajas, C&amp;#233;sar Garc&amp;#237;a-Osorio, Colin Fyfe</author><abstract>

In this paper we propose a novel approach for ensemble construction
based on the use of nonlinear projections to achieve both accuracy and
diversity of individual classifiers. The proposed approach combines
the philosophy of boosting, putting more effort on difficult
instances, with the basis of the random subspace method. Our main
contribution is that instead of using a random subspace, we construct
a projection taking into account the instances which have posed most
difficulties to previous classifiers.  In this way, consecutive
nonlinear projections are created by a neural network trained using
only incorrectly classified instances. The feature subspace induced by
the hidden layer of this network is used as the input space to a new
classifier. The method is compared with bagging and boosting
techniques, showing an improved performance on a large set of 44
problems from the UCI Machine Learning Repository. An additional study
showed that the proposed approach is less sensitive to noise in the
data than boosting methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/garcia-pedrajas07a/garcia-pedrajas07a.pdf</url></Article><Article><id>362</id><title>
Multi-Task Learning for Classification with Dirichlet Process Priors
</title><author>Ya Xue, Xuejun Liao, Lawrence Carin, Balaji Krishnapuram</author><abstract>

Consider the problem of learning logistic-regression models for
multiple classification tasks, where the training data set for each
task is not drawn from the same statistical distribution. In such a
multi-task learning (MTL) scenario, it is necessary to identify
groups of similar tasks that should be learned jointly. Relying on a
Dirichlet process (DP) based statistical model to learn the extent
of similarity between classification tasks, we develop
computationally efficient algorithms for two different forms of the
MTL problem. First, we consider a &lt;i&gt;symmetric&lt;/i&gt; multi-task
learning (SMTL) situation in which classifiers for multiple tasks
are learned jointly using a variational Bayesian (VB) algorithm.
Second, we consider an &lt;i&gt;asymmetric&lt;/i&gt; multi-task learning (AMTL)
formulation in which the posterior density function from the SMTL
model parameters (from previous tasks) is used as a prior for a new
task: this approach has the significant advantage of not requiring
storage and use of all previous data from prior tasks. The AMTL
formulation is solved with a simple Markov Chain Monte Carlo (MCMC)
construction. Experimental results on two real life MTL problems
indicate that the proposed algorithms: (a) automatically identify
subgroups of related tasks whose training data appear to be drawn
from similar distributions; and (b) are more accurate than simpler
approaches such as single-task learning, pooling of data across all
tasks, and simplified approximations to DP.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/xue07a/xue07a.pdf</url></Article><Article><id>363</id><title>
A Unified Continuous Optimization Framework for Center-Based Clustering Methods
</title><author>Marc Teboulle</author><abstract>

Center-based partitioning clustering algorithms rely on minimizing
an appropriately formulated objective function, and different
formulations suggest different possible algorithms. In this paper,
we start with the standard nonconvex and nonsmooth formulation of
the partitioning clustering problem. We demonstrate that within
this elementary formulation, convex analysis tools and
optimization theory provide a unifying language and framework to
design, analyze and extend hard and soft center-based clustering
algorithms, through a generic algorithm which retains the
computational simplicity of the popular k-means scheme. We show
that several well known and more recent center-based clustering
algorithms, which have been derived either heuristically, or/and
have emerged from intuitive analogies in physics, statistical
techniques and information theoretic perspectives can be recovered
as special cases of the proposed analysis and we streamline their
relationships.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/teboulle07a/teboulle07a.pdf</url></Article><Article><id>364</id><title>
Minimax Regret Classifier for Imprecise Class Distributions
</title><author>Roc&amp;#237;o Alaiz-Rodr&amp;#237;guez, Alicia Guerrero-Curieses, Jes&amp;#250;s Cid-Sueiro</author><abstract>

The design of a minimum risk classifier based on data usually
stems from the stationarity assumption that the conditions during
training and test are the same: the misclassification costs
assumed during training must be in agreement with real costs, and
the same statistical process must have generated both training and
test data. Unfortunately, in real world applications, these
assumptions may not hold. This paper deals with the problem of
training a classifier when prior probabilities cannot be reliably
induced from training data. Some strategies based on optimizing
the worst possible case (conventional minimax) have been proposed
previously in the literature, but they may achieve a robust
classification at the expense of a severe performance degradation.
In this paper we propose a &lt;i&gt;minimax regret&lt;/i&gt;
(&lt;i&gt;minimax deviation&lt;/i&gt;) approach, that seeks to minimize the
maximum deviation from the performance of the optimal risk
classifier. A neural-based &lt;i&gt;minimax regret&lt;/i&gt; classifier for
general multi-class decision problems is presented.
Experimental results show its robustness and the advantages in
relation to other approaches.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/alaiz-rodriguez07a/alaiz-rodriguez07a.pdf</url></Article><Article><id>365</id><title>
Distances between Data Sets Based on Summary Statistics
</title><author>Nikolaj Tatti</author><abstract>

The concepts of similarity and distance are crucial in data mining. We
consider the problem of defining the distance between two data sets by
comparing summary statistics computed from the data sets. The initial
definition of our distance is based on geometrical notions of certain
sets of distributions. We show that this distance can be computed in
cubic time and that it has several intuitive properties. We also show
that this distance is the unique Mahalanobis distance satisfying
certain assumptions. We also demonstrate that if we are dealing with
binary data sets, then the distance can be represented naturally by
certain parity functions, and that it can be evaluated in linear
time. Our empirical tests with real world data show that the distance
works well.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/tatti07a/tatti07a.pdf</url></Article><Article><id>366</id><title>
Building Blocks for Variational Bayesian Learning of Latent Variable Models
</title><author>Tapani Raiko, Harri Valpola, Markus Harva, Juha Karhunen</author><abstract>

We introduce standardised building blocks designed to be used with
variational Bayesian learning. The blocks include Gaussian variables,
summation, multiplication, nonlinearity, and delay.  A large variety
of latent variable models can be constructed from these blocks,
including nonlinear and variance models, which are lacking from most
existing variational systems.  The introduced blocks are designed to
fit together and to yield efficient update rules.  Practical
implementation of various models is easy thanks to an associated
software package which derives the learning formulas automatically
once a specific model structure has been fixed.  Variational Bayesian
learning provides a cost function which is used both for updating the
variables of the model and for optimising the model structure.  All
the computations can be carried out locally, resulting in linear
computational complexity.  We present experimental results on several
structures, including a new hierarchical nonlinear model for variances
and means. The test results demonstrate the good performance and
usefulness of the introduced method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/raiko07a/raiko07a.pdf</url></Article><Article><id>367</id><title>
A Probabilistic Analysis of EM for Mixtures of Separated, Spherical Gaussians
</title><author>Sanjoy Dasgupta, Leonard Schulman</author><abstract>

We show that, given data from a mixture of &lt;i&gt;k&lt;/i&gt; well-separated
spherical Gaussians in &lt;i&gt;&amp;#8476;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;, a simple two-round variant of
EM will, with high probability, learn the parameters of the Gaussians
to near-optimal precision, if the dimension is high (&lt;i&gt;d &gt;&gt;&lt;/i&gt; ln
&lt;i&gt;k&lt;/i&gt;). We relate this to previous theoretical and empirical work on the
EM algorithm.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/dasgupta07a/dasgupta07a.pdf</url></Article><Article><id>368</id><title>
Noise Tolerant Variants of the Perceptron Algorithm
</title><author>Roni Khardon, Gabriel Wachman</author><abstract>

A large number of variants of the Perceptron algorithm have been
proposed and partially evaluated in recent work.  One type of
algorithm aims for noise tolerance by replacing the last hypothesis of
the perceptron with another hypothesis or a vote among hypotheses.
Another type simply adds a margin term to the perceptron in order to
increase robustness and accuracy, as done in support vector machines.
A third type borrows further from support vector machines and
constrains the update function of the perceptron in ways that mimic
soft-margin techniques. The performance of these algorithms, and the
potential for combining different techniques, has not been studied in
depth.  This paper provides such an experimental study and reveals
some interesting facts about the algorithms.  In particular the
perceptron with margin is an effective method for tolerating noise and
stabilizing the algorithm.  This is surprising since the margin in
itself is not designed or used for noise tolerance, and there are no
known guarantees for such performance.  In most cases, similar
performance is obtained by the voted-perceptron which has the
advantage that it does not require parameter selection.  Techniques
using soft margin ideas are run-time intensive and do not give
additional performance benefits.  The results also highlight the
difficulty with automatic parameter selection which is required with
some of these variants.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/khardon07a/khardon07a.pdf</url></Article><Article><id>369</id><title>
Learnability of Gaussians with Flexible Variances
</title><author>Yiming Ying, Ding-Xuan Zhou</author><abstract>

Gaussian kernels with flexible variances provide a
rich family of Mercer kernels for learning algorithms. We show that
the union of the unit balls of reproducing kernel Hilbert spaces
generated by Gaussian kernels with flexible variances is a uniform
Glivenko-Cantelli (uGC) class. This result confirms a conjecture
concerning learnability of Gaussian kernels and verifies the uniform
convergence of many learning algorithms involving Gaussians with
changing variances. Rademacher averages and empirical covering
numbers are used to estimate sample errors of multi-kernel
regularization schemes associated with general loss functions. It is
then shown that the regularization error associated with the least
square loss and the Gaussian kernels can be greatly improved when
flexible variances are allowed. Finally, for regularization schemes
generated by Gaussian kernels with flexible variances we present
explicit learning rates for regression with least square loss and
classification with hinge loss.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/ying07a/ying07a.pdf</url></Article><Article><id>370</id><title>
Separating Models of Learning from Correlated and Uncorrelated Data
</title><author>Ariel Elbaz, Homin K. Lee, Rocco A. Servedio, Andrew Wan</author><abstract>

We consider a natural framework of learning from correlated data, in
which successive examples used for learning are generated according to
a random walk over the space of possible examples.  A recent paper by
Bshouty et al. (2003) shows that the class of polynomial-size DNF
formulas is efficiently learnable in this random walk model; this
result suggests that the Random Walk model is more powerful than
comparable standard models of learning from independent examples, in
which similarly efficient DNF learning algorithms are not known.  We
give strong evidence that the Random Walk model is indeed more
powerful than the standard model, by showing that if any cryptographic
one-way function exists (a universally held belief in cryptography),
then there is a class of functions that can be learned efficiently in
the Random Walk setting but not in the standard setting where all
examples are independent.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/elbaz07a/elbaz07a.pdf</url></Article><Article><id>371</id><title>
Comments on the "Core Vector Machines: Fast SVM Training on Very Large Data Sets"
</title><author>Ga&amp;#235;lle Loosli, St&amp;#233;phane Canu</author><abstract>

In a recently published paper in JMLR, Tsang et al. (2005) present an
algorithm for SVM called Core Vector Machines (CVM) and illustrate its
performances through comparisons with other SVM solvers. After reading
the CVM paper we were surprised by some of the reported results. In
order to clarify the matter, we decided to reproduce some of the
experiments.  It turns out that to some extent, our results contradict
those reported.  Reasons of these different behaviors are given
through the analysis of the stopping criterion.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/loosli07a/loosli07a.pdf</url></Article><Article><id>372</id><title>
General Polynomial Time Decomposition Algorithms
</title><author>Nikolas List, Hans Ulrich Simon</author><abstract>
&lt;p&gt;
We present a general decomposition algorithm that is uniformly
applicable to every (suitably normalized) instance of Convex 
Quadratic Optimization and efficiently approaches an optimal 
solution. The number of iterations required to be within &lt;i&gt;&amp;#949;&lt;/i&gt;
of optimality grows linearly with 1/&lt;i&gt;&amp;#949;&lt;/i&gt; and quadratically 
with the number &lt;i&gt;m&lt;/i&gt; of variables. The working set selection can be
performed in polynomial time. If we restrict our considerations
to instances of Convex Quadratic Optimization with at most &lt;i&gt;k&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; 
equality constraints for some fixed constant &lt;i&gt;k&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; plus some 
so-called box-constraints (conditions that hold for most
variants of SVM-optimization), the working set is found in linear 
time. Our analysis builds on a generalization of the concept 
of rate certifying pairs that was introduced by Hush and Scovel. 
In order to extend their results to arbitrary instances of Convex 
Quadratic Optimization, we introduce the general notion of a rate 
certifying &lt;i&gt;q&lt;/i&gt;-set. We improve on the results by Hush and Scovel (2003) 
in several ways. First our result holds for  Convex Quadratic
Optimization whereas the results by Hush and Scovel are specialized to
SVM-optimization. Second, we achieve a higher rate  of convergence
even for the special case of SVM-optimization (despite the generality
of our approach). Third, our analysis is technically
simpler.
&lt;/p&gt;&lt;p&gt;
We prove furthermore that the strategy for working set selection which 
is based on rate certifying sets coincides with a strategy which is 
based on a so-called "sparse witness of sub-optimality". Viewed from this 
perspective, our main result improves on convergence results 
by List and Simon (2004) and Simon (2004) by providing convergence rates 
(and by holding under more general conditions). 
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/list07a/list07a.pdf</url></Article><Article><id>373</id><title>
Dynamics and Generalization Ability of LVQ Algorithms
</title><author>Michael Biehl, Anarta Ghosh, Barbara Hammer</author><abstract>

Learning vector quantization (LVQ) schemes constitute intuitive,
powerful classification heuristics with numerous successful
applications but, so far, limited theoretical background.  We study
LVQ rigorously within a simplifying model situation: two competing
prototypes are trained from a sequence of examples drawn from a
mixture of Gaussians.  Concepts from statistical physics and the
theory of on-line learning allow for an exact description of the
training dynamics in high-dimensional feature space.  The analysis
yields typical learning curves, convergence properties, and achievable
generalization abilities.  This is also possible for heuristic
training schemes which do not relate to a cost function.  We compare
the performance of several algorithms, including Kohonen's LVQ1 and
LVQ+/-, a limiting case of LVQ2.1.  The former shows close to optimal
performance, while LVQ+/- displays divergent behavior. We investigate
how early stopping can overcome this difficulty.  Furthermore, we
study a crisp version of robust soft LVQ, which was recently derived
from a statistical formulation.  Surprisingly, it exhibits relatively
poor generalization.  Performance improves if a window for the
selection of data is introduced; the resulting algorithm corresponds
to cost function based LVQ2.  The dependence of these results on the
model parameters, for example, prior class probabilities, is
investigated systematically, simulations confirm our analytical
findings.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/biehl07a/biehl07a.pdf</url></Article><Article><id>374</id><title>
Statistical Consistency of Kernel Canonical Correlation Analysis
</title><author>Kenji Fukumizu, Francis R. Bach, Arthur Gretton</author><abstract>

While kernel canonical correlation analysis (CCA) has been applied
in many contexts, the convergence of finite sample estimates of the
associated functions to their population counterparts has not yet
been established. This paper gives a mathematical proof of the
statistical convergence of kernel CCA, providing a theoretical
justification for the method. The proof uses covariance operators
defined on reproducing kernel Hilbert spaces, and analyzes the
convergence of their empirical estimates of finite rank to their
population counterparts, which can have infinite rank. The result
also gives a sufficient condition for convergence on the
regularization coefficient involved in kernel CCA: this should
decrease as &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;-1/3&lt;/sup&gt;, where &lt;i&gt;n&lt;/i&gt; is the number 
of data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/fukumizu07a/fukumizu07a.pdf</url></Article><Article><id>375</id><title>
Learning Equivariant Functions with Matrix Valued Kernels
</title><author>Marco Reisert, Hans Burkhardt</author><abstract>

This paper presents a new class of matrix valued kernels that are
ideally suited to learn vector valued equivariant functions. Matrix
valued kernels are a natural generalization of the common notion of a
kernel.  We set the theoretical foundations of so called equivariant
matrix valued kernels.  We work out several properties of equivariant
kernels, we give an interpretation of their behavior and show
relations to scalar kernels. The notion of (ir)reducibility of group
representations is transferred into the framework of matrix valued
kernels. At the end to two exemplary applications are demonstrated.
We design a non-linear rotation and translation equivariant filter for
2D-images and propose an invariant object detector based on the
generalized Hough transform.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/reisert07a/reisert07a.pdf</url></Article><Article><id>376</id><title>
Boosted Classification Trees and Class Probability/Quantile Estimation
</title><author>David Mease, Abraham J. Wyner, Andreas Buja</author><abstract>
&lt;p&gt;
The standard by which binary classifiers are usually judged,
misclassification error, assumes equal costs of misclassifying the
two classes or, equivalently, classifying at the 1/2 quantile of the
conditional class probability function P[y=1|x].  Boosted
classification trees are known to perform quite well for such
problems. In this article we consider the use of standard,
off-the-shelf boosting for two more general
problems: 1) classification with unequal costs or, equivalently,
classification at quantiles other than 1/2, and 2) estimation of the
conditional class probability function &lt;i&gt;P&lt;/i&gt;[&lt;i&gt;y&lt;/i&gt;=1|&lt;i&gt;x&lt;/i&gt;].  
We first examine
whether the latter problem, estimation of &lt;i&gt;P&lt;/i&gt;[&lt;i&gt;y&lt;/i&gt;=1|&lt;i&gt;x&lt;/i&gt;], can be solved
with LogitBoost, and with AdaBoost when combined with a natural link
function.  The answer is negative: both approaches are often
ineffective because they overfit &lt;i&gt;P&lt;/i&gt;[&lt;i&gt;y&lt;/i&gt;=1|&lt;i&gt;x&lt;/i&gt;] even though they perform
well as classifiers. A major negative point of the present article
is the disconnect between class probability estimation and
classification.
&lt;/p&gt;&lt;p&gt;
Next we consider the practice of over/under-sampling of the two
classes.  We present an algorithm that uses AdaBoost in
conjunction with &lt;b&gt;O&lt;/b&gt;ver/&lt;b&gt;U&lt;/b&gt;nder-&lt;b&gt;S&lt;/b&gt;ampling and 
&lt;b&gt;J&lt;/b&gt;ittering of the data "JOUS-Boost".  This algorithm is
simple, yet successful, and it preserves the advantage of relative
protection against overfitting, but for arbitrary
misclassification costs and, equivalently, arbitrary quantile
boundaries.  We then use collections of classifiers obtained from
a grid of quantiles to form estimators of class probabilities. The
estimates of the class probabilities compare favorably to those
obtained by a variety of methods across both simulated and real
data sets.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/mease07a/mease07a.pdf</url></Article><Article><id>377</id><title>
Value Regularization and Fenchel Duality
</title><author>Ryan M. Rifkin, Ross A. Lippert</author><abstract>

Regularization is an approach to function learning that balances fit
and smoothness.  In practice, we search for a function &lt;i&gt;f&lt;/i&gt; with a
finite representation &lt;i&gt;f&lt;/i&gt; = &amp;#931;&lt;i&gt;&lt;sub&gt;i&lt;/sub&gt; c&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt;
&amp;#966;&lt;i&gt;&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt;(&amp;#183;).   In most treatments, the &lt;i&gt;c&lt;sub&gt;i&lt;/sub&gt;&lt;/i&gt;
are the primary objects of study.  We consider &lt;i&gt; value
regularization&lt;/i&gt;, constructing optimization problems in which the
predicted values at the training points are the primary variables, and
therefore the central objects of study.  Although this is a simple
change, it has profound consequences.  From convex conjugacy and the
theory of Fenchel duality, we derive separate optimality conditions
for the regularization and loss portions of the learning problem; this
technique yields clean and short derivations of standard algorithms.
This framework is ideally suited to studying many other phenomena at
the intersection of learning theory and optimization.  We obtain a
value-based variant of the representer theorem, which underscores the
transductive nature of regularization in reproducing kernel Hilbert
spaces.  We unify and extend previous results on learning kernel
functions, with very simple proofs.  We analyze the use of
unregularized bias terms in optimization problems, and low-rank
approximations to kernel matrices, obtaining new results in these
areas.  In summary, the combination of value regularization and
Fenchel duality are valuable tools for studying the optimization
problems in machine learning.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/rifkin07a/rifkin07a.pdf</url></Article><Article><id>378</id><title>
Integrating Na&amp;#239;ve Bayes and FOIL
</title><author>Niels Landwehr, Kristian Kersting, Luc De Raedt</author><abstract>

A novel relational learning approach that tightly integrates the
na&amp;#239;ve Bayes learning scheme with the inductive logic programming
rule-learner FOIL is presented.  In contrast to previous
combinations that have employed na&amp;#239;ve Bayes only for
post-processing the rule sets, the presented approach employs the
na&amp;#239;ve Bayes criterion to guide its search directly.  The proposed
technique is implemented in the &lt;small&gt;N&lt;/small&gt;FOIL and &lt;small&gt;T&lt;/small&gt;FOIL
systems, which employ standard na&amp;#239;ve Bayes and tree augmented
na&amp;#239;ve Bayes models respectively.  We show that these integrated
approaches to probabilistic model and rule learning outp erform
post-processing approaches. They also yield significantly more
accurate models than si mple rule learning and are competitive with
more sophisticated ILP systems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/landwehr07a/landwehr07a.pdf</url></Article><Article><id>379</id><title>
A Stochastic Algorithm for Feature Selection in Pattern Recognition
</title><author>S&amp;#233;bastien Gadat, Laurent Younes</author><abstract>

We introduce a new model addressing feature selection from a large dictionary
of variables that can be computed from a signal or an image. Features are
extracted according to an efficiency criterion, on the basis of specified
classification or recognition tasks. This is done by estimating a probability
distribution &lt;i&gt;P&lt;/i&gt; on the complete dictionary, which distributes its mass
over the more efficient, or informative, components. We implement a stochastic
gradient descent algorithm, using the probability as a state variable and
optimizing a multi-task goodness of fit criterion for classifiers based on
variable randomly chosen according to &lt;i&gt;P&lt;/i&gt;. We then generate classifiers
from the optimal distribution of weights learned on the training set.
 The method is first tested on
several pattern recognition problems including face detection, handwritten
digit recognition, spam classification and micro-array analysis. We then compare
our approach with other step-wise algorithms like random forests or recursive feature
elimination.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/gadat07a/gadat07a.pdf</url></Article><Article><id>380</id><title>
Learning Horn Expressions with L&lt;small&gt;OG&lt;/small&gt;A&lt;small&gt;N&lt;/small&gt;-H
</title><author>Marta Arias, Roni Khardon, J&amp;#233;r&amp;#244;me Maloberti</author><abstract>

The paper introduces L&lt;small&gt;OG&lt;/small&gt;A&lt;small&gt;N&lt;/small&gt;-H &amp;#151;
a system for learning first-order
function-free Horn expressions from interpretations. The system is
based on an algorithm that learns by asking questions and that was
proved correct in previous work. The current paper shows how the
algorithm can be implemented in a practical system, and introduces a
new algorithm based on it that avoids interaction and learns from
examples only. The L&lt;small&gt;OG&lt;/small&gt;A&lt;small&gt;N&lt;/small&gt;-H 
 system implements these algorithms and
adds several facilities and optimizations that allow efficient
applications in a wide range of problems. As one of the important
ingredients, the system includes several fast procedures for
solving the subsumption problem, an NP-complete problem that needs
to be solved many times during the learning process. We describe
qualitative and quantitative experiments in several domains. The
experiments demonstrate that the system can deal with varied
problems, large amounts of data, and that it achieves good
classification accuracy.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/arias07a/arias07a.pdf</url></Article><Article><id>381</id><title>
Consistent Feature Selection for Pattern Recognition in Polynomial Time
</title><author>Roland Nilsson, Jos&amp;#233; M. Pe&amp;#241;a, Johan Bj&amp;#246;rkegren, Jesper Tegn&amp;#233;r</author><abstract>

We analyze two different feature selection problems: finding a minimal
feature set optimal for classification (&lt;small&gt;MINIMAL-OPTIMAL&lt;/small&gt;)
&lt;i&gt;vs.&lt;/i&gt;  finding all features relevant to the target variable
(&lt;small&gt;ALL-RELEVANT&lt;/small&gt;).  The latter problem is motivated by recent
applications within bioinformatics, particularly gene expression
analysis.  For both problems, we identify classes of data
distributions for which there exist consistent, polynomial-time
algorithms.  We also prove that &lt;small&gt;ALL-RELEVANT&lt;/small&gt; is much harder
than &lt;small&gt;MINIMAL-OPTIMAL&lt;/small&gt; and propose two consistent,
polynomial-time algorithms.  We argue that the distribution classes
considered are reasonable in many practical cases, so that our results
simplify feature selection in a wide range of machine learning tasks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/nilsson07a/nilsson07a.pdf</url></Article><Article><id>382</id><title>
Estimating High-Dimensional Directed Acyclic Graphs with the PC-Algorithm
</title><author>Markus Kalisch, Peter B&amp;#252;hlmann</author><abstract>

We consider the PC-algorithm (Spirtes et al., 2000) for estimating the
skeleton and equivalence class of a very high-dimensional directed
acyclic graph (DAG) with corresponding Gaussian distribution. The
PC-algorithm is computationally feasible and often very fast for
sparse problems with many nodes (variables), and it has the attractive
property to automatically achieve high computational efficiency as a
function of sparseness of the true underlying DAG.  We prove uniform
consistency of the algorithm for very high-dimensional, sparse DAGs
where the number of nodes is allowed to quickly grow with sample size
&lt;i&gt;n&lt;/i&gt;, as fast as &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;sup&gt;a&lt;/sup&gt;&lt;/i&gt;) for any
0 &lt; &lt;i&gt;a&lt;/i&gt; &lt; &amp;#8734;. The sparseness assumption is rather minimal
requiring only that the neighborhoods in the DAG are of lower order
than sample size &lt;i&gt;n&lt;/i&gt;.  We also demonstrate the PC-algorithm for
simulated data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/kalisch07a/kalisch07a.pdf</url></Article><Article><id>383</id><title>
Margin Trees for High-dimensional Classification
</title><author>Robert Tibshirani, Trevor Hastie</author><abstract>

We propose a method for the classification of more than two classes,
from high-dimensional features.  Our approach is to build a binary
decision tree in a top-down manner, using the optimal margin
classifier at each split. We implement an exact greedy algorithm for
this task, and compare its performance to less greedy procedures based
on clustering of the matrix of pairwise margins. We compare the
performance of the "margin tree" to the closely related "all-pairs"
(one versus one) support vector machine, and nearest centroids on a
number of cancer microarray data sets.  We also develop a simple
method for feature selection. We find that the margin tree has
accuracy that is competitive with other methods and offers additional
interpretability in its putative grouping of the classes.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/tibshirani07a/tibshirani07a.pdf</url></Article><Article><id>384</id><title>
Relational Dependency Networks
</title><author>Jennifer Neville, David Jensen</author><abstract>

Recent work on graphical models for relational data has demonstrated
significant improvements in classification and inference when models
represent the dependencies among instances. Despite its use in
conventional statistical models, the assumption of instance
independence is contradicted by most relational data sets. For
example, in citation data there are dependencies among the topics of a
paper's references, and in genomic data there are dependencies among
the functions of interacting proteins. In this paper, we present
relational dependency networks (RDNs), graphical models that are
capable of expressing and reasoning with such dependencies in a
relational setting. We discuss RDNs in the context of relational Bayes
networks and relational Markov networks and outline the relative
strengths of RDNs---namely, the ability to represent cyclic
dependencies, simple methods for parameter estimation, and efficient
structure learning techniques. The strengths of RDNs are due to the
use of &lt;i&gt;pseudolikelihood&lt;/i&gt; learning techniques, which estimate an
efficient approximation of the full joint distribution. We present
learned RDNs for a number of real-world data sets and evaluate the
models in a prediction context, showing that RDNs identify and exploit
cyclic relational dependencies to achieve significant performance
gains over conventional conditional models. In addition, we use
synthetic data to explore model performance under various relational
data characteristics, showing that RDN learning and inference
techniques are accurate over a wide range of conditions.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/neville07a/neville07a.pdf</url></Article><Article><id>385</id><title>
Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence Data
</title><author>Charles Sutton, Andrew McCallum, Khashayar Rohanimanesh</author><abstract>

In sequence modeling, we often wish to represent complex interaction
between labels, such as when performing multiple, cascaded labeling
tasks on the same sequence, or when long-range dependencies exist.  We
present &lt;i&gt;dynamic conditional random fields (DCRFs)&lt;/i&gt;, a
generalization of linear-chain conditional random fields (CRFs) in
which each time slice contains a set of state variables and edges---a
distributed state representation as in dynamic Bayesian networks
(DBNs)---and parameters are tied across slices.  Since exact inference
can be intractable in such models, we perform approximate inference
using several schedules for belief propagation, including tree-based
reparameterization (TRP). On a natural-language chunking task, we show
that a DCRF performs better than a series of linear-chain CRFs,
achieving comparable performance using only half the training data.
In addition to maximum conditional likelihood, we present two
alternative approaches for training DCRFs: &lt;i&gt;marginal likelihood
training&lt;/i&gt;, for when we are primarily interested in predicting only a
subset of the variables, and &lt;i&gt;cascaded training&lt;/i&gt;, for when we
have a distinct data set for each state variable, as in transfer
learning.  We evaluate marginal training and cascaded training on both
synthetic data and real-world text data, finding that marginal
training can improve accuracy when uncertainty exists over the latent
variables, and that for transfer learning, a DCRF trained in a
cascaded fashion performs better than a linear-chain CRF that predicts
the final task directly.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/sutton07a/sutton07a.pdf</url></Article><Article><id>386</id><title>
The Pyramid Match Kernel: Efficient Learning with Sets of Features
</title><author>Kristen Grauman, Trevor Darrell</author><abstract>

In numerous domains it is useful to represent a single example by
the set of the local features or parts that comprise it. However,
this representation poses a challenge to many conventional machine
learning techniques, since sets may vary in cardinality and elements
lack a meaningful ordering. Kernel methods can learn complex
functions, but a kernel over unordered set inputs must somehow solve
for correspondences---generally a computationally expensive task
that becomes impractical for large set sizes. We present a new fast
kernel function called the &lt;i&gt;pyramid match&lt;/i&gt; that measures
partial match similarity in time linear in the number of features.
The pyramid match maps unordered feature sets to multi-resolution
histograms and computes a weighted histogram intersection in order
to find implicit correspondences based on the finest resolution
histogram cell where a matched pair first appears. We show the
pyramid match yields a Mercer kernel, and we prove bounds on its
error relative to the optimal partial matching cost. We demonstrate
our algorithm on both classification and regression tasks, including
object recognition, 3-D human pose inference, and time of
publication estimation for documents, and we show that the proposed
method is accurate and significantly more efficient than current
approaches.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/grauman07a/grauman07a.pdf</url></Article><Article><id>387</id><title>
Infinitely Imbalanced Logistic Regression
</title><author>Art B. Owen</author><abstract>

In binary classification problems it is common for
the two classes to be imbalanced: one case is very
rare compared to the other. In this paper we consider
the infinitely imbalanced case where one class has a finite
sample size and the other class's sample size grows without bound.
For logistic regression, the infinitely imbalanced case often
has a useful solution.  Under mild conditions,
the intercept diverges as expected, but
the rest of the coefficient vector approaches a non trivial
and useful limit.
That limit can be expressed in terms of exponential tilting
and is the minimum of a convex objective function.
The limiting form of logistic regression suggests a computational
shortcut for fraud detection problems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/owen07a/owen07a.pdf</url></Article><Article><id>388</id><title>
Sparseness vs Estimating Conditional Probabilities: Some Asymptotic Results
</title><author>Peter L. Bartlett, Ambuj Tewari</author><abstract>

One of the nice properties of kernel classifiers such as SVMs is that
they often produce sparse solutions. However, the decision functions
of these classifiers cannot always be used to estimate the conditional
probability of the class label. We investigate the relationship
between these two properties and show that these are intimately
related: sparseness does not occur when the conditional probabilities
can be unambiguously estimated.  We consider a family of convex loss
functions and derive sharp asymptotic results for the fraction of data
that becomes support vectors.  This enables us to characterize the
exact trade-off between sparseness and the ability to estimate
conditional probabilities for these loss functions.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/bartlett07a/bartlett07a.pdf</url></Article><Article><id>389</id><title>
Concave Learners for Rankboost
</title><author>Ofer Melnik, Yehuda Vardi, Cun-Hui Zhang</author><abstract>

Rankboost has been shown to be an effective algorithm for combining
ranks. However, its ability to generalize well and not overfit is
directly related to the choice of weak learner, in the sense that
regularization of the rank function is due to the regularization properties
of its weak learners. We present a regularization property called
&lt;i&gt;consistency in preference and confidence&lt;/i&gt; that mathematically
translates into monotonic concavity, and describe a new weak ranking
learner (MWGR) that generates ranking functions with this property.
In experiments combining ranks from multiple face recognition algorithms
and an experiment combining text information retrieval systems, rank
functions using MWGR proved superior to binary weak learners. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/melnik07a/melnik07a.pdf</url></Article><Article><id>390</id><title>
&lt;i&gt;Gini&lt;/i&gt; Support Vector Machine: Quadratic Entropy Based Robust Multi-Class Probability Regression
</title><author>Shantanu Chakrabartty, Gert Cauwenberghs</author><abstract>

Many classification tasks require estimation of output class
probabilities for use as confidence scores or for inference integrated
with other models.
Probability estimates derived from large margin classifiers such as
support vector machines (SVMs) are often unreliable.  We extend SVM
large margin classification to &lt;i&gt;Gini&lt;/i&gt;SVM maximum entropy multi-class
probability regression.  &lt;i&gt;Gini&lt;/i&gt;SVM combines a quadratic (Gini-Simpson)
entropy based agnostic model with a kernel based similarity model.  A
form of Huber loss in the &lt;i&gt;Gini&lt;/i&gt;SVM primal formulation elucidates a
connection to robust estimation, further corroborated by the impulsive
noise filtering property of the reverse water-filling procedure to
arrive at normalized classification margins.  The &lt;i&gt;Gini&lt;/i&gt;SVM normalized
classification margins directly provide estimates of class conditional
probabilities, approximating kernel logistic regression (KLR) but at
reduced computational cost.  As with other SVMs, &lt;i&gt;Gini&lt;/i&gt;SVM produces a
sparse kernel expansion and is trained by solving a quadratic program
under linear constraints.  &lt;i&gt;Gini&lt;/i&gt;SVM training is efficiently
implemented by sequential minimum optimization or by growth
transformation on probability functions.
Results on synthetic and benchmark data, including speaker
verification and face detection data, show improved classification
performance and increased tolerance to imprecision over soft-margin
SVM and KLR.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/chakrabartty07a/chakrabartty07a.pdf</url></Article><Article><id>391</id><title>
Preventing Over-Fitting during Model Selection via Bayesian Regularisation of the Hyper-Parameters
</title><author>Gavin C. Cawley, Nicola L. C. Talbot</author><abstract>

While the model parameters of a kernel machine are typically given by the
solution of a convex optimisation problem, with a single global optimum, the
selection of good values for the regularisation and kernel parameters is much
less straightforward.  Fortunately the leave-one-out cross-validation
procedure can be performed or a least approximated very efficiently in
closed form for a wide variety of kernel learning methods, providing a
convenient means for model selection.  Leave-one-out cross-validation based
estimates of performance, however, generally exhibit a relatively high
variance and are therefore prone to over-fitting.  In this paper, we
investigate the novel use of Bayesian regularisation at the second level of
inference, adding a regularisation term to the model selection criterion
corresponding to a prior over the hyper-parameter values, where the additional
regularisation parameters are integrated out analytically.  Results obtained
on a suite of thirteen real-world and synthetic benchmark data sets clearly
demonstrate the benefit of this approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/cawley07a/cawley07a.pdf</url></Article><Article><id>392</id><title>
Combining PAC-Bayesian and Generic Chaining Bounds
</title><author>Jean-Yves Audibert, Olivier Bousquet</author><abstract>

There exist many different generalization error bounds in statistical
learning theory. Each of these bounds contains an improvement over the
others for certain situations or algorithms.  Our goal is, first, to
underline the links between these bounds, and second, to combine the
different improvements into a single bound. In particular we combine
the PAC-Bayes approach introduced by McAllester (1998), which is
interesting for randomized predictions, with the optimal union bound
provided by the generic chaining technique developed by Fernique and
Talagrand (see Talagrand, 1996), in a way that also takes into account
the variance of the combined functions. We also show how this connects
to Rademacher based bounds.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/audibert07a/audibert07a.pdf</url></Article><Article><id>393</id><title>
Anytime Learning of Decision Trees
</title><author>Saher Esmeir, Shaul Markovitch</author><abstract>

The majority of existing algorithms for learning decision trees are
greedy---a tree is induced top-down, making locally optimal decisions
at each node.  In most cases, however, the constructed tree is not
globally optimal.  Even the few non-greedy learners cannot learn good
trees when the concept is difficult.  Furthermore, they require a
fixed amount of time and are not able to generate a better tree if
additional time is available.  We introduce a framework for anytime
induction of decision trees that overcomes these problems by trading
computation speed for better tree quality.  Our proposed family of
algorithms employs a novel strategy for evaluating candidate splits.
A biased sampling of the space of consistent trees rooted at an
attribute is used to estimate the size of the minimal tree under that
attribute, and an attribute with the smallest expected tree is
selected.  We present two types of anytime induction algorithms: a
&lt;i&gt;contract&lt;/i&gt; algorithm that determines the sample size on the basis
of a pre-given allocation of time, and an &lt;i&gt;interruptible&lt;/i&gt;
algorithm that starts with a greedy tree and continuously improves
subtrees by additional sampling.  Experimental results indicate that,
for several hard concepts, our proposed approach exhibits good anytime
behavior and yields significantly better decision trees when more time
is available.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/esmeir07a/esmeir07a.pdf</url></Article><Article><id>394</id><title>
Classification in Networked Data: A Toolkit and a Univariate Case Study
</title><author>Sofus A. Macskassy, Foster Provost</author><abstract>

This paper is about classifying entities that are interlinked with
entities for which the class is known.  After surveying prior work, we
present NetKit, a modular toolkit for classification in networked
data, and a case-study of its application to networked data used in
prior machine learning research.  NetKit is based on a node-centric
framework in which classifiers comprise a local classifier, a
relational classifier, and a collective inference procedure.  Various
existing node-centric relational learning algorithms can be
instantiated with appropriate choices for these components, and new
combinations of components realize new algorithms.  The case study
focuses on univariate network classification, for which the only
information used is the structure of class linkage in the network
(i.e., only links and some class labels).  To our knowledge, no work
previously has evaluated systematically the power of class-linkage
alone for classification in machine learning benchmark data sets.  The
results demonstrate that very simple network-classification models
perform quite well---well enough that they should be used regularly as
baseline classifiers for studies of learning with networked data.  The
simplest method (which performs remarkably well) highlights the close
correspondence between several existing methods introduced for
different purposes---that is, Gaussian-field classifiers, Hopfield
networks, and relational-neighbor classifiers.  The case study also
shows that there are two sets of techniques that are preferable in
different situations, namely when few versus many labels are known
initially.  We also demonstrate that link selection plays an important
role similar to traditional feature selection.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/macskassy07a/macskassy07a.pdf</url></Article><Article><id>395</id><title>
Covariate Shift Adaptation by Importance Weighted Cross Validation
</title><author>Masashi Sugiyama, Matthias Krauledat, Klaus-Robert M&amp;#252;ller</author><abstract>

A common assumption in supervised learning is that the input points in
the training set follow the &lt;i&gt;same&lt;/i&gt; probability distribution as
the input points that will be given in the future test phase.
However, this assumption is not satisfied, for example, when the
outside of the training region is extrapolated.  The situation where
the training input points and test input points follow
&lt;i&gt;different&lt;/i&gt; distributions while the conditional distribution of
output values given input points is unchanged is called the
&lt;i&gt;covariate shift&lt;/i&gt;.  Under the covariate shift, standard model
selection techniques such as cross validation do not work as desired
since its unbiasedness is no longer maintained.  In this paper, we
propose a new method called &lt;i&gt;importance weighted cross
validation&lt;/i&gt; (IWCV), for which we prove its unbiasedness even under the
covariate shift.  The IWCV procedure is the only one that can be
applied for unbiased classification under covariate shift, whereas
alternatives to IWCV exist for regression.  The usefulness of our
proposed method is illustrated by simulations, and furthermore
demonstrated in the brain-computer interface, where strong
non-stationarity effects can be seen between training and test
sessions.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/sugiyama07a/sugiyama07a.pdf</url></Article><Article><id>396</id><title>
On the Consistency of Multiclass Classification Methods
</title><author>Ambuj Tewari, Peter L. Bartlett</author><abstract>

Binary classification is a well studied special case of the classification
problem. Statistical properties of binary classifiers, such as consistency,
have been investigated in a variety of settings.  Binary classification methods
can be generalized in many ways to handle multiple classes. It turns out that
one can lose consistency in generalizing a binary classification method to deal
with multiple classes. We study a rich family of multiclass methods and provide
a necessary and sufficient condition for their consistency.  We illustrate our
approach by applying it to some multiclass methods proposed in the literature.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/tewari07a/tewari07a.pdf</url></Article><Article><id>397</id><title>
Dimensionality Reduction of Multimodal Labeled Data by Local Fisher Discriminant Analysis
</title><author>Masashi Sugiyama</author><abstract>

Reducing the dimensionality of data without losing intrinsic
information is an important preprocessing step in high-dimensional
data analysis.  Fisher discriminant analysis (FDA) is a traditional
technique for supervised dimensionality reduction, but it tends to
give undesired results if samples in a class are &lt;i&gt;multimodal&lt;/i&gt;.
An unsupervised dimensionality reduction method called
locality-preserving projection (LPP) can work well with multimodal
data due to its locality preserving property.  However, since LPP does
not take the label information into account, it is not necessarily
useful in supervised learning scenarios.  In this paper, we propose a
new linear supervised dimensionality reduction method called
&lt;i&gt;local Fisher discriminant analysis&lt;/i&gt; (LFDA), which effectively
combines the ideas of FDA and LPP.  LFDA has an analytic form of the
embedding transformation and the solution can be easily computed just
by solving a generalized eigenvalue problem.  We demonstrate the
practical usefulness and high scalability of the LFDA method in data
visualization and classification tasks through extensive simulation
studies.  We also show that LFDA can be extended to non-linear
dimensionality reduction scenarios by applying the kernel trick.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/sugiyama07b/sugiyama07b.pdf</url></Article><Article><id>398</id><title>
Undercomplete Blind Subspace Deconvolution
</title><author>Zolt&amp;#225;n Szab&amp;#243;, Barnab&amp;#225;s P&amp;#243;czos, Andr&amp;#225;s L&amp;#337;rincz</author><abstract>

We introduce the blind subspace deconvolution (BSSD) problem,
which is the extension of both the blind source deconvolution
(BSD) and the independent subspace analysis (ISA) tasks. We
examine the case of the undercomplete BSSD (uBSSD). Applying
temporal concatenation we reduce this problem to ISA. The
associated 'high dimensional' ISA problem can be handled by a
recent technique called joint f-decorrelation (JFD).
Similar decorrelation methods have been used previously for kernel
independent component analysis (kernel-ICA). More precisely, the
kernel canonical correlation (KCCA) technique is a member of this
family, and, as is shown in this paper, the kernel generalized
variance (KGV) method can also be seen as a decorrelation method
in the feature space. These kernel based algorithms will be
adapted to the ISA task. In the numerical examples, we (i) examine
how efficiently the emerging higher dimensional ISA tasks can be
tackled, and (ii) explore the working and advantages of the
derived kernel-ISA methods.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/szabo07a/szabo07a.pdf</url></Article><Article><id>399</id><title>
Bilinear Discriminant Component Analysis
</title><author>Mads Dyrholm, Christoforos Christoforou, Lucas C. Parra</author><abstract>

Factor analysis and discriminant analysis are often used as
complementary approaches to identify linear components in two
dimensional data arrays. For three dimensional arrays, which may
organize data in dimensions such as space, time, and trials, the
opportunity arises to combine these two approaches.  A new method,
Bilinear Discriminant Component Analysis (BDCA), is derived and
demonstrated in the context of functional brain imaging data for which
it seems ideally suited. The work suggests to identify a subspace
projection which optimally separates classes while ensuring that each
dimension in this space captures an independent contribution to the
discrimination.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/dyrholm07a/dyrholm07a.pdf</url></Article><Article><id>400</id><title>
Loop Corrections for Approximate Inference on Factor Graphs
</title><author>Joris M. Mooij, Hilbert J. Kappen</author><abstract>

We propose a method to improve approximate inference methods by
correcting for the influence of loops in the graphical model. The
method is a generalization and alternative implementation of a recent
idea from Montanari and Rizzo (2005). It is applicable to arbitrary
factor graphs, provided that the size of the Markov blankets is not
too large. It consists of two steps: (i) an approximate inference
method, for example, belief propagation, is used to approximate
&lt;i&gt;cavity distributions&lt;/i&gt; for each variable (i.e., probability
distributions on the Markov blanket of a variable for a modified
graphical model in which the factors involving that variable have been
removed); (ii) all cavity distributions are improved by a
message-passing algorithm that cancels out approximation errors by
imposing certain consistency constraints.  This loop correction (LC)
method usually gives significantly better results than the original,
uncorrected, approximate inference algorithm that is used to estimate
the effect of loops.  Indeed, we often observe that the loop-corrected
error is approximately the square of the error of the uncorrected
approximate inference method. In this article, we compare different
variants of the loop correction method with other approximate
inference methods on a variety of graphical models, including "real
world" networks, and conclude that the LC method generally obtains
the most accurate results.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/mooij07a/mooij07a.pdf</url></Article><Article><id>401</id><title>
Penalized Model-Based Clustering with Application to Variable Selection
</title><author>Wei Pan, Xiaotong Shen</author><abstract>

Variable selection in clustering analysis is both challenging
and important. 
In the context of model-based clustering analysis with
a common diagonal covariance matrix, which is
especially suitable for "high dimension, low sample size" settings,
we propose a penalized likelihood approach
with an &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; penalty function, automatically realizing variable
selection via thresholding and delivering a sparse solution. 
We derive an EM algorithm to fit our proposed model, and
propose a modified BIC as a model selection 
criterion to choose the number of components and the
penalization parameter.
A simulation study and an application to gene function
prediction with gene expression profiles demonstrate the
utility of our method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/pan07a/pan07a.pdf</url></Article><Article><id>402</id><title>
Local Discriminant Wavelet Packet Coordinates for Face Recognition
</title><author>Chao-Chun Liu, Dao-Qing Dai, Hong Yan</author><abstract>

Face recognition is a challenging problem due to variations in pose,
illumination, and expression. Techniques that can provide effective
feature representation with enhanced discriminability are crucial.
Wavelets have played an important role in image processing for its
ability to capture localized spatial-frequency information of
images. In this paper, we propose a novel &lt;i&gt;local discriminant
coordinates&lt;/i&gt; method based on wavelet packet for face recognition to
compensate for these variations. Traditional wavelet-based methods
for face recognition select or operate on the most discriminant
subband, and neglect the scattered characteristic of discriminant
features. The proposed method selects  the most discriminant
coordinates uniformly from all spatial frequency subbands to
overcome the deficiency of traditional wavelet-based methods. To
measure the discriminability of coordinates, a new dilation
invariant entropy and a maximum &lt;i&gt;a posterior&lt;/i&gt; logistic model
are put forward. Moreover, a new &lt;i&gt;triangle square ratio&lt;/i&gt;
criterion is used to improve classification using the Euclidean
distance and the cosine criterion. Experimental results show that
the proposed method is robust for face recognition under variations
in illumination, pose and expression.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/liu07a/liu07a.pdf</url></Article><Article><id>403</id><title>
Synergistic Face Detection and Pose Estimation with Energy-Based Models
</title><author>Margarita Osadchy, Yann Le Cun, Matthew L. Miller</author><abstract>
&lt;p&gt;
We describe a novel method for simultaneously detecting faces and
estimating their pose in real time. The method employs a convolutional
network to map images of faces to points on a low-dimensional manifold
parametrized by pose, and images of non-faces to points far away from
that manifold. Given an image, detecting a face and estimating its
pose is viewed as minimizing an energy function with respect to the
face/non-face binary variable and the continuous pose parameters.  The
system is trained to minimize a loss function that drives correct
combinations of labels and pose to be associated with lower energy
values than incorrect ones.
&lt;/p&gt;&lt;p&gt;
The system is designed to handle very large range of poses without
retraining. The performance of the system was tested on three
standard data sets---for frontal views, rotated faces, and 
profiles---is comparable to previous systems that are designed to handle a
single one of these data sets.
&lt;/p&gt;&lt;p&gt;
We show that a system trained simuiltaneously for detection and
pose estimation is more accurate on &lt;i&gt;both tasks&lt;/i&gt; than similar
systems trained for each task separately.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/osadchy07a/osadchy07a.pdf</url></Article><Article><id>404</id><title>
Maximum Entropy Density Estimation with Generalized Regularization and an Application to Species Distribution Modeling
</title><author>Miroslav Dud&amp;#237;k, Steven J. Phillips, Robert E. Schapire</author><abstract>

We present a unified and complete account of maximum entropy
density estimation subject to constraints represented by convex
potential functions or, alternatively, by convex regularization. We
provide fully general performance guarantees and an algorithm with a
complete convergence proof. As special cases, we easily derive
performance guarantees for many known regularization types,
including &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;, &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;, &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;, and &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt; + &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; style
regularization. We propose an algorithm solving a large and general
subclass of generalized maximum entropy problems, including all
discussed in the paper, and prove its convergence. Our approach
generalizes and unifies techniques based on information geometry and
Bregman divergences as well as those based more directly on
compactness. Our work is motivated by a novel application of maximum
entropy to species distribution modeling, an important problem in
conservation biology and ecology. In a set of experiments on
real-world data, we demonstrate the utility of maximum entropy in
this setting. We explore effects of different feature types, sample
sizes, and regularization levels on the performance of maxent, and
discuss interpretability of the resulting models.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/dudik07a/dudik07a.pdf</url></Article><Article><id>405</id><title>
Measuring Differentiability:  Unmasking Pseudonymous Authors
</title><author>Moshe Koppel, Jonathan Schler, Elisheva Bonchek-Dokow</author><abstract>

In the authorship verification problem, we are given examples of the
writing of a single author and are asked to determine if given long
texts were or were not written by this author. We present a new
learning-based method for adducing the "depth of difference" between
two example sets and offer evidence that this method solves the
authorship verification problem with very high accuracy. The
underlying idea is to test the rate of degradation of the accuracy of
learned models as the best features are iteratively dropped from the
learning process.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/koppel07a/koppel07a.pdf</url></Article><Article><id>406</id><title>
Bayesian Quadratic Discriminant Analysis
</title><author>Santosh Srivastava, Maya R. Gupta, B&amp;#233;la A. Frigyik</author><abstract>

Quadratic discriminant analysis is a common tool for classification,
but estimation of the Gaussian parameters can be ill-posed. This
paper contains theoretical and algorithmic contributions to Bayesian
estimation for quadratic discriminant analysis. A distribution-based
Bayesian classifier is derived using information geometry. Using a
calculus of variations approach to define a functional Bregman
divergence for distributions, it is shown that the Bayesian
distribution-based classifier that minimizes the expected Bregman
divergence of each class conditional distribution also minimizes the
expected misclassification cost. A series approximation is used to
relate regularized discriminant analysis to Bayesian discriminant
analysis. A new Bayesian quadratic discriminant analysis classifier
is proposed where the prior is defined using a coarse estimate of
the covariance based on the training data; this classifier is termed
BDA7. Results on benchmark data sets and simulations show that BDA7
performance is competitive with, and in some cases significantly
better than, regularized quadratic discriminant analysis and the
cross-validated Bayesian quadratic discriminant analysis classifier
Quadratic Bayes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/srivastava07a/srivastava07a.pdf</url></Article><Article><id>407</id><title>
From External to Internal Regret
</title><author>Avrim Blum, Yishay Mansour</author><abstract>
&lt;p&gt;
External regret compares the performance of an online algorithm,
selecting among &lt;i&gt;N&lt;/i&gt; actions, to the performance of the best of those
actions in hindsight.  Internal regret compares the loss of an online
algorithm to the loss of a modified online algorithm, which
consistently replaces one action by another.
&lt;/p&gt;&lt;p&gt;
In this paper we give a simple generic reduction that, given an
algorithm for the external regret problem, converts it to an efficient
online algorithm for the internal regret problem.  We provide methods
that work both in the &lt;i&gt; full information&lt;/i&gt; model, in which the loss
of every action is observed at each time step, and the &lt;i&gt; partial
information&lt;/i&gt; (bandit) model, where at each time step only the loss of
the selected action is observed.
The importance of internal regret in game theory is due to the
fact that in a general game, if each player has sublinear internal
regret, then the empirical frequencies converge to a correlated
equilibrium.
&lt;/p&gt;

&lt;p&gt;
For external regret we also derive a quantitative regret bound for a
very general setting of regret, which includes an arbitrary set of
modification rules (that possibly modify the online algorithm) and an
arbitrary set of time selection functions (each giving different
weight to each time step).  The regret for a given time selection and
modification rule is the difference between the cost of the online
algorithm and the cost of the modified online algorithm, where the
costs are weighted by the time selection function.  This can be viewed
as a generalization of the previously-studied &lt;i&gt;sleeping experts&lt;/i&gt;
setting.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/blum07a/blum07a.pdf</url></Article><Article><id>408</id><title>
Graph Laplacians and their Convergence on Random Neighborhood Graphs
</title><author>Matthias Hein, Jean-Yves Audibert, Ulrike von Luxburg</author><abstract>

Given a sample from a probability measure with support on a
submanifold in Euclidean space one can construct a neighborhood graph
which can be seen as an approximation of the submanifold.  The graph
Laplacian of such a graph is used in several machine learning methods
like semi-supervised learning, dimensionality reduction and
clustering.  In this paper we determine the pointwise limit of three
different graph Laplacians used in the literature as the sample size
increases and the neighborhood size approaches zero. We show that for
a uniform measure on the submanifold all graph Laplacians have the
same limit up to constants. However in the case of a non-uniform
measure on the submanifold only the so called random walk graph
Laplacian converges to the weighted Laplace-Beltrami operator.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/hein07a/hein07a.pdf</url></Article><Article><id>409</id><title>
Generalization Error Bounds in Semi-supervised Classification Under the Cluster Assumption
</title><author>Philippe Rigollet</author><abstract>

We consider semi-supervised classification when part of the available data
is unlabeled. These unlabeled data can be useful for the classification
problem when we make an assumption relating the behavior of the regression
function to that of the marginal distribution.  Seeger (2000) proposed the
well-known &lt;i&gt;cluster assumption&lt;/i&gt; as a reasonable one.  We propose a
mathematical formulation of this assumption and a method based on
density level sets estimation that takes advantage of it to achieve fast rates
of convergence both in the number of unlabeled examples and the number of
labeled examples.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/rigollet07a/rigollet07a.pdf</url></Article><Article><id>410</id><title>
Learning to Classify Ordinal Data: The Data Replication Method
</title><author>Jaime S. Cardoso, Joaquim F. Pinto da Costa</author><abstract>

Classification of ordinal data is one of the most important tasks of
relation learning. This paper introduces a new machine learning
paradigm specifically intended for classification problems where the
classes have a natural order. The technique reduces the problem of
classifying ordered classes to the standard two-class problem. The
introduced method is then mapped into support vector machines and
neural networks. Generalization bounds of the proposed ordinal
classifier are also provided. An experimental study with artificial and
real data sets, including an application to gene expression analysis,
verifies the usefulness of the proposed approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/cardoso07a/cardoso07a.pdf</url></Article><Article><id>411</id><title>
Attribute-Efficient and Non-adaptive Learning of Parities and DNF Expressions
</title><author>Vitaly Feldman</author><abstract>
&lt;p&gt;
We consider the problems of attribute-efficient PAC learning of two
well-studied concept classes: parity functions and DNF expressions
over {0,1}&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt;. We show that attribute-efficient learning of parities
with respect to the uniform distribution is equivalent to decoding
high-rate random linear codes from low number of errors, a
long-standing open problem in coding theory. This is the first
evidence that attribute-efficient learning of a natural PAC learnable
concept class can be computationally hard.  &lt;/p&gt;

&lt;p&gt; An algorithm is said to use membership queries (MQs) 
&lt;i&gt;non-adaptively&lt;/i&gt; if the points at which the algorithm asks MQs do not
depend on the target concept. Using a simple non-adaptive parity
learning algorithm and a modification of Levin's algorithm for
locating a weakly-correlated parity due to Bshouty et al. (1999), we give the
first non-adaptive and attribute-efficient algorithm for learning DNF
with respect to the uniform distribution. Our algorithm runs in time
&lt;i&gt;&amp;#213;&lt;/i&gt;(&lt;i&gt;ns&lt;/i&gt;&lt;sup&gt;4&lt;/sup&gt;/&amp;#949;) and uses &lt;i&gt;&amp;#213;&lt;/i&gt;(&lt;i&gt;s&lt;/i&gt;&lt;sup&gt;4&lt;/sup&gt;
&amp;#183; log&lt;sup&gt;2&lt;/sup&gt;&lt;i&gt;n&lt;/i&gt;/&amp;#949;) non-adaptive MQs, where &lt;i&gt;s&lt;/i&gt; is the number of
terms in the shortest DNF representation of the target concept. The
algorithm improves on the best previous algorithm for learning DNF
(of Bshouty et al., 1999) and can also be easily modified to tolerate
random persistent classification noise in MQs.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/feldman07a/feldman07a.pdf</url></Article><Article><id>412</id><title>
PAC-Bayes Risk Bounds for Stochastic Averages and Majority Votes of Sample-Compressed Classifiers
</title><author>Fran&amp;#231;ois Laviolette, Mario Marchand</author><abstract>

We propose a PAC-Bayes theorem for the sample-compression setting
where each classifier is described by a compression subset of the
training data and a message string of additional information. This
setting, which is the appropriate one to describe many learning
algorithms, strictly generalizes the usual data-independent
setting where classifiers are represented only by data-independent
message strings (or parameters taken from a continuous set). The
proposed PAC-Bayes theorem for the sample-compression setting
reduces to the PAC-Bayes theorem of Seeger (2002) and  Langford (2005)
when the compression subset of each classifier vanishes. For
posteriors having all their weights on a single sample-compressed
classifier, the general risk bound reduces to a bound similar to
the tight sample-compression bound proposed in Laviolette et al. (2005).
Finally, we extend our results to the case where each
sample-compressed classifier of a data-dependent ensemble may
abstain of predicting a class label.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/laviolette07a/laviolette07a.pdf</url></Article><Article><id>413</id><title>
On the Effectiveness of Laplacian Normalization for Graph Semi-supervised Learning
</title><author>Rie Johnson, Tong Zhang</author><abstract>

This paper investigates the effect of Laplacian normalization in
graph-based semi-supervised learning.  To this end, we consider
multi-class transductive learning on graphs with Laplacian
regularization.  Generalization bounds are derived using geometric
properties of the graph.  Specifically, by introducing a definition of
graph cut from learning theory, we obtain generalization bounds that
depend on the Laplacian regularizer.  We then use this analysis to
better understand the role of graph Laplacian matrix normalization.
Under assumptions that the cut is small, we derive near-optimal
normalization factors by approximately minimizing the generalization
bounds.  The analysis reveals the limitations of the standard
degree-based normalization method in that the resulting normalization
factors can vary significantly within each connected component with
the same class label, which may cause inferior generalization
performance. Our theory also suggests a remedy that does not suffer
from this problem.  Experiments confirm the superiority of the
normalization scheme motivated by learning theory on artificial and
real-world data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/johnson07a/johnson07a.pdf</url></Article><Article><id>414</id><title>
An Interior-Point Method for Large-Scale &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-Regularized Logistic Regression
</title><author>Kwangmoo Koh, Seung-Jean Kim, Stephen Boyd</author><abstract>

Logistic regression with &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; regularization has been proposed as
a promising method for feature selection in classification problems.
In this paper we describe an efficient interior-point method for
solving large-scale &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-regularized logistic regression
problems. Small problems with up to a thousand or so features and
examples can be solved in seconds on a PC; medium sized problems,
with tens of thousands of features and examples, can be solved in
tens of seconds (assuming some sparsity in the data). A variation on
the basic method, that uses a preconditioned conjugate gradient
method to compute the search step, can solve very large problems,
with a million features and examples (e.g., the 20 Newsgroups data
set), in a few minutes, on a PC. Using warm-start
techniques, a good approximation of the entire regularization path
can be computed much more efficiently than by solving a family of
problems independently.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/koh07a/koh07a.pdf</url></Article><Article><id>415</id><title>
Multi-class Protein Classification Using Adaptive Codes
</title><author>Iain Melvin, Eugene Ie, Jason Weston, William Stafford Noble, Christina Leslie</author><abstract>

Predicting a protein's structural class from its amino acid sequence
is a fundamental problem in computational biology.  Recent machine
learning work in this domain has focused on developing new input space
representations for protein sequences, that is, string kernels, some
of which give state-of-the-art performance for the binary prediction
task of discriminating between one class and all the others.  However,
the underlying protein classification problem is in fact a huge
multi-class problem, with over 1000 protein folds and even more
structural subcategories organized into a hierarchy.  To handle this
challenging many-class problem while taking advantage of progress on
the binary problem, we introduce an adaptive code approach in the
output space of one-vs-the-rest prediction scores.  Specifically, we
use a ranking perceptron algorithm to learn a weighting of binary
classifiers that improves multi-class prediction with respect to a
fixed set of output codes. We use a cross-validation set-up to
generate output vectors for training, and we define codes that capture
information about the protein structural hierarchy.  Our code
weighting approach significantly improves on the standard one-vs-all
method for two difficult multi-class protein classification problems:
remote homology detection and fold recognition.  Our algorithm also
outperforms a previous code learning approach due to Crammer and
Singer, trained here using a perceptron, when the dimension of the
code vectors is high and the number of classes is large.  Finally, we
compare against PSI-BLAST, one of the most widely used methods in
protein sequence analysis, and find that our method strongly
outperforms it on every structure classification problem that we
consider.  Supplementary data and source code are available at
&lt;tt&gt;&lt;a href="http://www.cs.columbia.edu/compbio/adaptive"&gt;http://www.cs.columbia.edu/compbio/adaptive&lt;/a&gt;&lt;/tt&gt;.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/melvin07a/melvin07a.pdf</url></Article><Article><id>416</id><title>
Spherical-Homoscedastic Distributions: The Equivalency of Spherical and Normal Distributions in Classification
</title><author>Onur C. Hamsici, Aleix M. Martinez</author><abstract>

Many feature representations, as in genomics, describe directional
data where all feature vectors share a common norm. In other
cases, as in computer vision, a norm or variance normalization
step, where all feature vectors are normalized to a common length,
is generally used. These representations and pre-processing step
map the original data from &amp;#8476;&lt;sup&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sup&gt; to the surface of a
hypersphere &lt;i&gt;S&lt;/i&gt;&lt;sup&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sup&gt;. Such representations should then be
modeled using spherical distributions. However, the difficulty
associated with such spherical representations has prompted
researchers to model their spherical data using Gaussian
distributions instead---as if the data were represented in
&amp;#8476;&lt;sup&gt;&lt;i&gt;p&lt;/i&gt;&lt;/sup&gt; rather than &lt;i&gt;S&lt;/i&gt;&lt;sup&gt;&lt;i&gt;p&lt;/i&gt;-1&lt;/sup&gt;. 
This opens the question to
whether the classification results calculated with the Gaussian
approximation are the same as those obtained when using the
original spherical distributions. In this paper, we show that in
some particular cases (which we named spherical-homoscedastic) the
answer to this question is positive. In the more general case
however, the answer is negative. For this reason, we further
investigate the additional error added by the Gaussian modeling.
We conclude that the more the data deviates from
spherical-homoscedastic, the less advisable it is to employ the
Gaussian approximation. We then show how our derivations can be
used to define optimal classifiers for spherical-homoscedastic
distributions. By using a kernel which maps the original space
into one where the data adapts to the spherical-homoscedastic
model, we can derive non-linear classifiers with potential
applications in a large number of problems. We conclude this paper
by demonstrating the uses of spherical-homoscedasticity in the
classification of images of objects, gene expression sequences,
and text data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/hamsici07a/hamsici07a.pdf</url></Article><Article><id>417</id><title>
Handling Missing Values when Applying Classification Models
</title><author>Maytal Saar-Tsechansky, Foster Provost</author><abstract>

Much work has studied the effect of different treatments of missing values on
model induction, but little work has analyzed treatments for the common case
of missing values at prediction time. This paper first compares several
different methods---predictive value imputation, the distribution-based
imputation used by C4.5, and using reduced models---for applying
classification trees to instances with missing values (and also shows evidence
that the results generalize to bagged trees and to logistic regression). The
results show that for the two most popular treatments, each is preferable
under different conditions. Strikingly the reduced-models approach, seldom
mentioned or used, consistently outperforms the other two methods, sometimes
by a large margin. The lack of attention to reduced modeling may be due in
part to its (perceived) expense in terms of computation or storage. Therefore,
we then introduce and evaluate alternative, hybrid approaches that allow users
to balance between more accurate but computationally expensive reduced
modeling and the other, less accurate but less computationally expensive
treatments. The results show that the hybrid methods can scale gracefully to
the amount of investment in computation/storage, and that they outperform
imputation even for small investments.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/saar-tsechansky07a/saar-tsechansky07a.pdf</url></Article><Article><id>418</id><title>
Compression-Based Averaging of Selective Naive Bayes Classifiers
</title><author>Marc Boull&amp;#233;</author><abstract>

The naive Bayes classifier has proved to be very effective on many
real data applications. Its performance usually benefits from an
accurate estimation of univariate conditional probabilities and from
variable selection. However, although variable selection is a
desirable feature, it is prone to overfitting. In this paper, we
introduce a Bayesian regularization technique to select the most
probable subset of variables compliant with the naive Bayes
assumption.  We also study the limits of Bayesian model averaging in
the case of the naive Bayes assumption and introduce a new weighting
scheme based on the ability of the models to conditionally compress
the class labels. The weighting scheme on the models reduces to a
weighting scheme on the variables, and finally results in a naive
Bayes classifier with "soft variable selection". Extensive
experiments show that the compression-based averaged classifier
outperforms the Bayesian model averaging scheme.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/boulle07a/boulle07a.pdf</url></Article><Article><id>419</id><title>
A Nonparametric Statistical Approach to Clustering via Mode Identification
</title><author>Jia Li, Surajit Ray, Bruce G. Lindsay</author><abstract>

A new clustering approach based on mode identification is developed by
applying new optimization techniques to a nonparametric density estimator.  A
cluster is formed by those sample points that ascend to the same local
maximum (mode) of the density function.  The path from a point to its
associated mode is efficiently solved by an EM-style algorithm, namely, the
Modal EM (MEM).  This method is then extended for hierarchical clustering by
recursively locating modes of kernel density estimators with increasing
bandwidths.  Without model fitting, the mode-based clustering yields a
density description for every cluster, a major advantage of
mixture-model-based clustering.  Moreover, it ensures that every cluster
corresponds to a bump of the density.  The issue of diagnosing clustering
results is also investigated.  Specifically, a pairwise separability measure
for clusters is defined using the ridgeline between the density bumps of two
clusters.  The ridgeline is solved for by the Ridgeline EM (REM) algorithm,
an extension of MEM.  Based upon this new measure, a cluster merging
procedure is created to enforce strong separation.  Experiments on simulated
and real data demonstrate that the mode-based clustering approach tends to
combine the strengths of linkage and mixture-model-based clustering.  In
addition, the approach is robust in high dimensions and when clusters deviate
substantially from Gaussian distributions.  Both of these cases pose
difficulty for parametric mixture modeling.  A C package on the new
algorithms is developed for public access at
http://www.stat.psu.edu/&amp;#8764;jiali/hmac.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/li07a/li07a.pdf</url></Article><Article><id>420</id><title>
Polynomial Identification in the Limit of Substitutable Context-free Languages
</title><author>Alexander Clark, R&amp;#233;mi Eyraud</author><abstract>

This paper formalises the idea of substitutability introduced by
Zellig Harris in the 1950s and makes it the basis for a learning
algorithm from positive data only for a subclass of context-free
languages. We show that there is a polynomial characteristic set,
and thus prove polynomial identification in the limit of this
class. We discuss the relationship of this class of languages to
other common classes discussed in grammatical inference. 
It transpires that it is not necessary to identify constituents in
order to learn a context-free language&amp;#8212;it is sufficient to identify
the
syntactic congruence, and the operations of the syntactic monoid can
be converted into a context-free grammar. We also
discuss modifications to the algorithm that produces a reduction
system rather than a context-free grammar, that will be much more
compact. We discuss the relationship to Angluin's notion of
reversibility for regular languages. We also demonstrate that an
implementation of this algorithm is capable of learning a classic
example of structure dependent syntax in English: this constitutes a
refutation of an argument that has
been used in support of nativist theories of language. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/clark07a/clark07a.pdf</url></Article><Article><id>421</id><title>
Structure and Majority Classes in Decision Tree Learning
</title><author>Ray J. Hickey</author><abstract>

To provide good classification accuracy on unseen examples, a decision
tree, learned by an algorithm such as ID3, must have sufficient
structure and also identify the correct majority class in each of its
leaves. If there are inadequacies in respect of either of these, the
tree will have a percentage classification rate below that of the
maximum possible for the domain, namely (100 - Bayes error rate). An
error decomposition is introduced which enables the relative
contributions of deficiencies in structure and in incorrect
determination of majority class to be isolated and quantified. A
sub-decomposition of majority class error permits separation of the
sampling error at the leaves from the possible bias introduced by the
attribute selection method of the induction algorithm. It is shown
that sampling error can extend to 25% when there are more than two
classes. Decompositions are obtained from experiments on several data
sets. For ID3, the effect of selection bias is shown to vary from
being statistically non-significant to being quite substantial, with
the latter appearing to be associated with a simple underlying model.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/hickey07a/hickey07a.pdf</url></Article><Article><id>422</id><title>
Characterizing the Function Space for Bayesian Kernel Models
</title><author>Natesh S. Pillai, Qiang Wu, Feng Liang, Sayan Mukherjee, Robert L. Wolpert</author><abstract>

Kernel methods have been very popular in the machine learning
literature in the last ten years, mainly in the context of Tikhonov
regularization algorithms.  In this paper we study a coherent Bayesian
kernel model based on an integral operator defined as the convolution
of a kernel with a signed measure.  Priors on the random signed
measures correspond to prior distributions on the functions mapped by
the integral operator. We study several classes of signed measures and
their image mapped by the integral operator. In particular, we
identify a general class of measures whose image is dense in the
reproducing kernel Hilbert space (RKHS) induced by the kernel.  A
consequence of this result is a function theoretic foundation for
using non-parametric prior specifications in Bayesian modeling, such
as Gaussian process and Dirichlet process prior distributions. We
discuss the construction of priors on spaces of signed measures using
Gaussian and L&amp;#233;vy processes, with the Dirichlet processes being a
special case the latter. Computational issues involved with sampling
from the posterior distribution are outlined for a univariate
regression and a high dimensional classification problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/pillai07a/pillai07a.pdf</url></Article><Article><id>423</id><title>
"Ideal Parent" Structure Learning for Continuous Variable Bayesian Networks
</title><author>Gal Elidan, Iftach Nachman, Nir Friedman</author><abstract>

Bayesian networks in general, and continuous variable networks in
particular, have become increasingly popular in recent years, largely
due to advances in methods that facilitate automatic learning from
data. Yet, despite these advances, the key task of learning the
structure of such models remains a computationally intensive
procedure, which limits most applications to parameter learning. This
problem is even more acute when learning networks in the presence of
missing values or hidden variables, a scenario that is part of many
real-life problems. In this work we present a general method for
speeding structure search for continuous variable networks with common
parametric distributions. We efficiently evaluate the approximate
merit of candidate structure modifications and apply time consuming
(exact) computations only to the most promising ones, thereby
achieving significant improvement in the running time of the search
algorithm. Our method also naturally and efficiently facilitates the
addition of useful new hidden variables into the network structure, a
task that is typically considered both conceptually difficult and
computationally prohibitive. We demonstrate our method on synthetic
and real-life data sets, both for learning structure on fully and
partially observable data, and for introducing new hidden variables
during structure search.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/elidan07a/elidan07a.pdf</url></Article><Article><id>424</id><title>
Behavioral Shaping for Geometric Concepts
</title><author>Manu Chhabra, Robert A. Jacobs, Daniel &amp;#352;tefankovi&amp;#269;</author><abstract>

In a search problem, an agent uses the membership oracle of a target
concept to find a positive example of the concept. In a &lt;i&gt;shaped
search problem&lt;/i&gt; the agent is aided by a sequence of increasingly
restrictive concepts leading to the target concept (analogous to
behavioral shaping). The concepts are given by membership oracles, and
the agent has to find a positive example of the target concept while
minimizing the total number of oracle queries. We show that for the
concept class of intervals on the real line an agent using a bounded
number of queries &lt;i&gt;per oracle&lt;/i&gt; exists. In contrast, for the
concept class of unions of two intervals on the real line no agent
with a bounded number of queries per oracle exists. We then
investigate the (amortized) number of queries per oracle needed for
the shaped search problem over other concept classes. We explore the
following methods to obtain efficient agents. For axis-parallel
rectangles we use a bootstrapping technique to obtain gradually better
approximations of the target concept. We show that given rectangles
&lt;i&gt;R&lt;/i&gt; &amp;#8838; &lt;i&gt;A&lt;/i&gt; &amp;#8838; &amp;#8477;&lt;sup&gt;&lt;i&gt;d&lt;/i&gt;&lt;/sup&gt; one can 
obtain a rectangle &lt;i&gt;A'&lt;/i&gt; &amp;#8839; &lt;i&gt;R&lt;/i&gt;
with vol(&lt;i&gt;A'&lt;/i&gt;) / vol(&lt;i&gt;R&lt;/i&gt;) &amp;#8804; 2, using only &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;d&lt;/i&gt;
&amp;#8901; vol(&lt;i&gt;A&lt;/i&gt;) / vol(&lt;i&gt;R&lt;/i&gt;)) random samples from &lt;i&gt;A&lt;/i&gt;.  For ellipsoids of
bounded eccentricity in &amp;#8477;&lt;sup&gt;&lt;i&gt;d&lt;/i&gt;&lt;/sup&gt;  we analyze a deterministic ray-shooting
process which uses a sequence of rays to get close to the
centroid. Finally, we use algorithms for generating random points in
convex bodies (Dyer et al., 1991; Kannan et al., 1997) to give a randomized agent for the
concept class of convex bodies. In the final section, we explore
connections between our bootstrapping method and active
learning. Specifically, we use the bootstrapping technique for
axis-parallel rectangles to active learn axis-parallel rectangles
under the uniform distribution in &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;d&lt;/i&gt; ln(1/&amp;#949;)) labeled
samples.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/chhabra07a/chhabra07a.pdf</url></Article><Article><id>425</id><title>
Large Margin Semi-supervised Learning
</title><author>Junhui Wang, Xiaotong Shen</author><abstract>

In classification, semi-supervised learning occurs when a
large amount of unlabeled data is available with only a small
number of labeled data. In such a situation, how to enhance
predictability of classification through unlabeled data is the
focus. In this article, we introduce a novel large margin
semi-supervised learning methodology, using grouping
information from unlabeled data, together with the concept of
margins, in a form of regularization controlling the interplay
between labeled and unlabeled data. Based on this methodology,
we develop two specific machines involving support vector machines
and &amp;#968;-learning, denoted as SSVM and SPSI, through difference
convex programming. In addition, we estimate the generalization error
using both labeled and unlabeled data, for tuning regularizers.
Finally, our theoretical and numerical analyses indicate that
the proposed methodology achieves the desired objective of
delivering high performance in generalization, particularly against
some strong performers.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/wang07a/wang07a.pdf</url></Article><Article><id>426</id><title>
Fast Iterative Kernel Principal Component Analysis
</title><author>Simon G&amp;#252;nter, Nicol N. Schraudolph, S. V. N. Vishwanathan</author><abstract>

We develop gain adaptation methods that improve convergence of the
kernel Hebbian algorithm (KHA) for iterative kernel PCA
(Kim et al., 2005).  KHA has a scalar gain parameter which is either
held constant or decreased according to a predetermined annealing
schedule, leading to slow convergence. We accelerate it by
incorporating the reciprocal of the current estimated eigenvalues as
part of a gain vector. An additional normalization term then allows us
to eliminate a tuning parameter in the annealing schedule.  Finally we
derive and apply stochastic meta-descent (SMD) gain vector adaptation
(Schraudolph, 1999, 2002) in reproducing kernel Hilbert
space to further speed up convergence. Experimental results on kernel
PCA and spectral clustering of USPS digits, motion capture and image
denoising, and image super-resolution tasks confirm that our methods
converge substantially faster than conventional KHA. To demonstrate
scalability, we perform kernel PCA on the entire MNIST data set.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/guenter07a/guenter07a.pdf</url></Article><Article><id>427</id><title>
A Generalized Maximum Entropy Approach to Bregman Co-clustering and Matrix Approximation
</title><author>Arindam Banerjee, Inderjit Dhillon, Joydeep Ghosh, Srujana Merugu, Dharmendra S. Modha</author><abstract>

Co-clustering, or simultaneous clustering of rows and columns of a
two-dimensional data matrix, is rapidly becoming a powerful data
analysis technique. Co-clustering has enjoyed wide success in varied
application domains such as text clustering, gene-microarray
analysis, natural language processing and image, speech and video
analysis. In this paper, we introduce a partitional co-clustering
formulation that is driven by the search for a good matrix
approximation---every co-clustering is associated with an
approximation of the original data matrix and the quality of
co-clustering is determined by the approximation error.  We allow
the approximation error to be measured using a large class of loss
functions called Bregman divergences that include squared Euclidean
distance and KL-divergence as special cases. In addition, we permit
multiple structurally different co-clustering schemes that preserve
various linear statistics of the original data matrix.  To
accomplish the above tasks, we introduce a new &lt;i&gt;minimum Bregman
information&lt;/i&gt; (MBI) principle that simultaneously generalizes the
&lt;i&gt;maximum entropy&lt;/i&gt; and &lt;i&gt;standard least squares&lt;/i&gt; principles,
and leads to a matrix approximation that is optimal among all
generalized additive models in a certain natural parameter space.
Analysis based on this principle yields an elegant meta algorithm,
special cases of which include most previously known alternate
minimization based clustering algorithms such as kmeans and
co-clustering algorithms such as information
theoretic (Dhillon et al., 2003b) and minimum sum-squared residue
co-clustering (Cho et al., 2004). To demonstrate the generality and
flexibility of our co-clustering framework, we provide examples and
empirical evidence on a variety of problem domains and also describe
novel co-clustering applications such as missing value prediction
and compression of categorical data matrices.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/banerjee07a/banerjee07a.pdf</url></Article><Article><id>428</id><title>
Truncating the Loop Series Expansion for Belief Propagation
</title><author>Vicen&amp;#231; G&amp;#243;mez, Joris M. Mooij, Hilbert J. Kappen</author><abstract>

Recently, Chertkov and Chernyak (2006b) derived an exact expression for the partition sum
(normalization constant) corresponding to a graphical model, which is an
expansion around the belief propagation (BP) solution. By adding correction terms to
the BP free energy, one for each "generalized loop" in the factor graph, the
exact partition sum is obtained.
However, the usually enormous number of
generalized loops generally prohibits summation over &lt;i&gt;all&lt;/i&gt; correction
terms.
In this article we introduce truncated loop series BP (TLSBP), a particular way
of truncating the loop series of Chertkov &amp; Chernyak by considering generalized loops
as compositions of simple loops.
We analyze the performance of TLSBP in different scenarios, including the Ising model
on square grids and regular random graphs, and on PROMEDAS, a large probabilistic
medical diagnostic system.
We show that TLSBP often improves upon the accuracy of the BP solution, at the
expense of increased computation time.
We also show that the performance of TLSBP strongly depends on
the degree of interaction between the variables.
For weak interactions, truncating the series leads to significant improvements,
whereas for strong interactions it can be ineffective,
even if a high number of terms is considered.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/gomez07a/gomez07a.pdf</url></Article><Article><id>429</id><title>
Very Fast Online Learning of Highly Non Linear Problems
</title><author>Aggelos Chariatis</author><abstract>

The experimental investigation on the efficient learning of highly
non-linear problems by online training, using ordinary feed forward
neural networks and stochastic gradient descent on the errors computed
by back-propagation, gives evidence that the most crucial factors for
efficient training are the hidden units' differentiation, the
attenuation of the hidden units' interference and the selective
attention on the parts of the problems where the approximation error
remains high. In this report, we present global and local selective
attention techniques and a new hybrid activation function that enables
the hidden units to acquire individual receptive fields which may be
global or local depending on the problem's local complexities. The
presented techniques enable very efficient training on complex
classification problems with embedded subproblems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/chariatis07a/chariatis07a.pdf</url></Article><Article><id>430</id><title>
Unlabeled Compression Schemes for Maximum Classes
</title><author>Dima Kuzmin, Manfred K. Warmuth</author><abstract>

Maximum concept classes of VC dimension &lt;i&gt;d&lt;/i&gt;
over &lt;i&gt;n&lt;/i&gt; domain points have size &lt;i&gt;n&lt;/i&gt; C &amp;#8804;&lt;i&gt;d&lt;/i&gt;, and this is an upper bound on the size of any concept class
of VC dimension &lt;i&gt;d&lt;/i&gt; over &lt;i&gt;n&lt;/i&gt; points.
We give a compression scheme for any maximum class that 
represents each concept by a subset of up
to &lt;i&gt;d&lt;/i&gt; unlabeled domain points
and has the property that for
any sample of a concept in the class,
the representative of exactly
one of the concepts consistent with the sample
is a subset of the domain of the sample.
This allows us to compress any sample of a concept
in the class to a subset of up to &lt;i&gt;d&lt;/i&gt; unlabeled sample points such that
this subset represents a concept consistent with the
entire original sample. 
Unlike the previously known compression scheme 
for maximum classes  (Floyd and Warmuth, 1995) which compresses
to labeled subsets of the sample of size equal &lt;i&gt;d&lt;/i&gt;, 
our new scheme is tight in the sense that the number of possible 
unlabeled compression sets of size at most &lt;i&gt;d&lt;/i&gt; equals the 
number of concepts in the class.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/kuzmin07a/kuzmin07a.pdf</url></Article><Article><id>431</id><title>
Refinable Kernels
</title><author>Yuesheng Xu, Haizhang Zhang</author><abstract>

Motivated by  mathematical learning from training data, we introduce
the notion of &lt;i&gt;refinable kernels&lt;/i&gt;. Various characterizations of
refinable kernels are presented. The concept of refinable kernels
leads to the introduction of &lt;i&gt;wavelet-like reproducing kernels&lt;/i&gt;.
We also investigate a refinable kernel that forms a Riesz basis. In
particular, we characterize refinable translation invariant kernels,
and refinable kernels defined by refinable functions. This study
leads to multiresolution analysis of reproducing kernel Hilbert
spaces.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/xu07a/xu07a.pdf</url></Article><Article><id>432</id><title>
A Complete Characterization of a Family of Solutions to a Generalized Fisher Criterion
</title><author>Marco Loog</author><abstract>

Recently, Ye (2005) suggested yet another optimization criterion
for discriminant analysis and proposed a characterization of the
family of solutions to this objective.  The characterization, however,
merely describes a part of the full solution set, that is, it is not
&lt;i&gt;complete&lt;/i&gt; and therefore not at all a characterization. This
correspondence first gives the correct characterization and afterwards
compares it to Ye's.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/loog07a/loog07a.pdf</url></Article><Article><id>433</id><title>
Transfer Learning via Inter-Task Mappings for Temporal Difference Learning
</title><author>Matthew E. Taylor, Peter Stone, Yaxin Liu</author><abstract>
&lt;p&gt;
&lt;i&gt;Temporal difference&lt;/i&gt; (TD) learning (Sutton and Barto, 1998) has become a
popular reinforcement learning technique in recent years. TD methods,
relying on function approximators to generalize learning to novel
situations, have had some experimental successes and have been shown
to exhibit some desirable properties in theory, but the most basic
algorithms have often been found slow in practice. This empirical
result has motivated the development of many methods that speed up
reinforcement learning by modifying a task for the learner or helping
the learner better generalize to novel situations. This article
focuses on generalizing &lt;i&gt;across tasks&lt;/i&gt;, thereby speeding up
learning, via a novel form of transfer using handcoded task
relationships. We compare learning on a complex task with three
function approximators, a cerebellar model arithmetic computer (CMAC),
an artificial neural network (ANN), and a radial basis function (RBF),
and empirically demonstrate that directly transferring the
&lt;i&gt;action-value function&lt;/i&gt; can lead to a dramatic speedup in
learning with all three. Using &lt;i&gt;transfer via inter-task mapping&lt;/i&gt;
(&lt;small&gt;TVITM&lt;/small&gt;), agents are able to learn one task and then markedly reduce
the time it takes to learn a more complex task. Our algorithms are
fully implemented and tested in the RoboCup soccer Keepaway domain.
&lt;/p&gt;&lt;p&gt;
This article contains and extends material published in two conference
papers (Taylor and Stone, 2005; Taylor et al., 2005).
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/taylor07a/taylor07a.pdf</url></Article><Article><id>434</id><title>
Proto-value Functions: A Laplacian Framework for Learning Representation and Control in Markov Decision Processes
</title><author>Sridhar Mahadevan, Mauro Maggioni</author><abstract>

This paper introduces a novel &lt;i&gt;spectral&lt;/i&gt; framework for solving
Markov decision processes (MDPs) by jointly learning representations
and optimal policies.  The major components of the framework described
in this paper include: (i) A general scheme for constructing
representations or &lt;i&gt;basis functions&lt;/i&gt; by diagonalizing symmetric
&lt;i&gt;diffusion&lt;/i&gt; operators (ii) A specific instantiation of this
approach where global basis functions called &lt;i&gt;proto-value
functions&lt;/i&gt; (PVFs) are formed using the eigenvectors of the &lt;i&gt;graph
Laplacian&lt;/i&gt; on an undirected graph formed from state transitions
induced by the MDP (iii) A three-phased procedure called 
&lt;i&gt;representation policy iteration&lt;/i&gt; comprising of a sample collection
phase, a representation learning phase that constructs basis functions
from samples, and a final parameter estimation phase that determines
an (approximately) optimal policy within the (linear) subspace spanned
by the (current) basis functions. (iv) A specific instantiation of the
RPI framework using least-squares policy iteration (LSPI) as the
parameter estimation method (v) Several strategies for scaling the
proposed approach to large discrete and continuous state spaces,
including the &lt;i&gt;Nystr&amp;#246;m&lt;/i&gt; extension for out-of-sample
interpolation of eigenfunctions, and the use of &lt;i&gt;Kronecker sum
factorization&lt;/i&gt; to construct compact eigenfunctions in product spaces
such as factored MDPs (vi) Finally, a series of illustrative discrete
and continuous control tasks, which both illustrate the concepts and
provide a benchmark for evaluating the proposed approach.  Many
challenges remain to be addressed in scaling the proposed framework to
large MDPs, and several elaboration of the proposed framework are
briefly summarized at the end.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/mahadevan07a/mahadevan07a.pdf</url></Article><Article><id>435</id><title>
Online Learning of Multiple Tasks with a Shared Loss
</title><author>Ofer Dekel, Philip M. Long, Yoram Singer</author><abstract>

We study the problem of learning multiple tasks in parallel within the
online learning framework.  On each online round, the algorithm
receives an instance for each of the parallel tasks and responds by
predicting the label of each instance. We consider the case where the
predictions made on each round all contribute toward a common
goal. The relationship between the various tasks is defined by a
global loss function, which evaluates the overall quality of the
multiple predictions made on each round. Specifically, each individual
prediction is associated with its own loss value, and then these
multiple loss values are combined into a single number using the
global loss function. We focus on the case where the global loss
function belongs to the family of absolute norms, and present several
online learning algorithms for the induced problem. We prove
worst-case relative loss bounds for all of our algorithms, and
demonstrate the effectiveness of our approach on a large-scale
multiclass-multilabel text categorization problem.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/dekel07a/dekel07a.pdf</url></Article><Article><id>436</id><title>
Euclidean Embedding of Co-occurrence Data
</title><author>Amir Globerson, Gal Chechik, Fernando Pereira, Naftali Tishby</author><abstract>

Embedding algorithms search for a low dimensional continuous
representation of data, but most algorithms only handle objects of a
single type for which pairwise distances are specified.  This paper
describes a method for embedding objects of different types, such as
images and text, into a single common Euclidean space, based on their
co-occurrence statistics. The joint distributions are modeled as
exponentials of Euclidean distances in the low-dimensional embedding
space, which links the problem to convex optimization over positive
semidefinite matrices.  The local structure of the embedding
corresponds to the statistical correlations via random walks in the
Euclidean space. We quantify the performance of our method on two text
data sets, and show that it consistently and significantly outperforms
standard methods of statistical correspondence modeling, such as
multidimensional scaling, IsoMap and correspondence analysis.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/globerson07a/globerson07a.pdf</url></Article><Article><id>437</id><title>
Harnessing the Expertise of 70,000 Human Editors: Knowledge-Based Feature Generation for Text Categorization
</title><author>Evgeniy Gabrilovich, Shaul Markovitch</author><abstract> Most existing methods for text categorization employ
induction algorithms that use the words appearing in the training
documents as features.  While they perform well in many categorization
tasks, these methods are inherently limited when faced with more
complicated tasks where external knowledge is essential. Recently,
there have been efforts to augment these basic features with external
knowledge, including semi-supervised learning and transfer
learning. In this work, we present a new framework for automatic
acquisition of world knowledge and methods for incorporating it into
the text categorization process. Our approach enhances machine
learning algorithms with features generated from domain-specific and
common-sense knowledge.  This knowledge is represented by ontologies
that contain hundreds of thousands of concepts, further enriched
through controlled Web crawling. Prior to text categorization, a
feature generator analyzes the documents and maps them onto
appropriate ontology concepts that augment the bag of words used in
simple supervised learning.  Feature generation is accomplished
through contextual analysis of document text, thus implicitly
performing word sense disambiguation.  Coupled with the ability to
generalize concepts using the ontology, this approach addresses two
significant problems in natural language processing---synonymy and
polysemy. Categorizing documents with the aid of knowledge-based
features leverages information that cannot be deduced from the
training documents alone. We applied our methodology using the Open
Directory Project, the largest existing Web directory built by over
70,000 human editors. Experimental results over a range of data sets
confirm improved performance compared to the bag of words document
representation.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/gabrilovich07a/gabrilovich07a.pdf</url></Article><Article><id>438</id><title>
AdaBoost is Consistent
</title><author>Peter L. Bartlett, Mikhail Traskin</author><abstract> 

The risk, or probability of error, of the classifier produced by the
AdaBoost algorithm is investigated. In particular, we consider the
stopping strategy to be used in AdaBoost to achieve universal
consistency. We show that provided AdaBoost is stopped after
&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1-&lt;i&gt;&amp;#949;&lt;/i&gt;&lt;/sup&gt; iterations---for sample size &lt;i&gt;n&lt;/i&gt; and 
&lt;i&gt;&amp;#949;&lt;/i&gt; &amp;#8712; (0,1)---the
sequence of risks of the classifiers it produces approaches the
Bayes risk.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/bartlett07b/bartlett07b.pdf</url></Article><Article><id>439</id><title>
The On-Line Shortest Path Problem Under Partial Monitoring
</title><author>Andr&amp;#225;s Gy&amp;#246;rgy, Tam&amp;#225;s Linder, G&amp;#225;bor Lugosi, Gy&amp;#246;rgy Ottucs&amp;#225;k</author><abstract> 

The on-line shortest path problem is considered under various models
of partial monitoring.  Given a weighted directed acyclic graph whose
edge weights can change in an arbitrary (adversarial) way, a decision
maker has to choose in each round of a game a path between two
distinguished vertices such that the loss of the chosen path (defined
as the sum of the weights of its composing edges) be as small as
possible.  In a setting generalizing the multi-armed bandit problem,
after choosing a path, the decision maker learns only the weights of
those edges that belong to the chosen path. For this problem, an
algorithm is given whose average cumulative loss in &lt;i&gt;n&lt;/i&gt; rounds exceeds
that of the best path, matched off-line to the entire sequence of the
edge weights, by a quantity that is proportional to 1/&amp;#8730;&lt;i&gt;n&lt;/i&gt; and
depends only polynomially on the number of edges of the graph. The
algorithm can be implemented with
complexity that is linear in the number of
rounds &lt;i&gt;n&lt;/i&gt; (i.e., the average complexity per round is constant)
and in the number of edges.  An extension to the so-called
label efficient setting is also given, in which the decision maker is
informed about the weights of the edges corresponding to the chosen
path at a total of &lt;i&gt;m&lt;/i&gt; &amp;#8810;  &lt;i&gt;n&lt;/i&gt; time instances.  Another extension is
shown where the decision maker competes against a time-varying path, a
generalization of the problem of tracking the best expert. A version
of the multi-armed bandit setting for shortest path is also discussed
where the decision maker learns only the total weight of the chosen path
but not the weights of the individual edges on the path. Applications to
routing in packet switched networks along with simulation results are
also presented.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/gyoergy07a/gyoergy07a.pdf</url></Article><Article><id>440</id><title>
The Locally Weighted Bag of Words Framework for Document Representation
</title><author>Guy Lebanon, Yi Mao, Joshua Dillon</author><abstract> 

The popular bag of words assumption represents a document as a
histogram of word occurrences. While computationally efficient, such a
representation is unable to maintain any sequential information. We
present an effective sequential document representation that goes
beyond the bag of words representation and its &lt;i&gt;n&lt;/i&gt;-gram
extensions. This representation uses local smoothing to embed
documents as smooth curves in the multinomial simplex thereby
preserving valuable sequential information. In contrast to bag of
words or &lt;i&gt;n&lt;/i&gt;-grams, the new representation is able to robustly
capture medium and long range sequential trends in the document. We
discuss the representation and its geometric properties and
demonstrate its applicability for various text processing tasks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/lebanon07a/lebanon07a.pdf</url></Article><Article><id>441</id><title>
The Need for Open Source Software in Machine Learning
</title><author>S&amp;#246;ren Sonnenburg, Mikio L. Braun, Cheng Soon Ong, Samy Bengio, Leon Bottou, Geoffrey Holmes, Yann LeCun, Klaus-Robert M&amp;#252;ller, Fernando Pereira, Carl Edward Rasmussen, Gunnar R&amp;#228;tsch, Bernhard Sch&amp;#246;lkopf, Alexander Smola, Pascal Vincent, Jason Weston, Robert Williamson</author><abstract> 

Open source tools have recently reached a level of maturity which
makes them suitable for building large-scale real-world systems. At
the same time, the field of machine learning has developed a large
body of powerful learning algorithms for diverse applications.
However, the true potential of these methods is not used, since
existing implementations are not openly shared, resulting in software
with low usability, and weak interoperability. We argue that this
situation can be significantly improved by increasing incentives for
researchers to publish their software under an open source
model. Additionally, we outline the problems authors are faced with
when trying to publish algorithmic implementations of machine learning
methods.  We believe that a resource of peer reviewed software
accompanied by short articles would be highly valuable to both the
machine learning and the general scientific community.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/sonnenburg07a/sonnenburg07a.pdf</url></Article><Article><id>442</id><title>
On the Representer Theorem and Equivalent Degrees of Freedom of SVR
</title><author>Francesco Dinuzzo, Marta Neve, Giuseppe De Nicolao, Ugo Pietro Gianazza</author><abstract> 

Support Vector Regression (SVR) for discrete data is considered.
An alternative formulation of the representer theorem is derived.
This result is based on the newly introduced notion of
pseudoresidual and the use of subdifferential calculus. The
representer theorem is exploited to analyze the sensitivity
properties of &amp;#949;-insensitive SVR and introduce the notion
of approximate degrees of freedom. The degrees of freedom are
shown to play a key role in the evaluation of the optimism, that
is the difference between the expected in-sample error and the
expected empirical risk. In this way, it is possible to define a
&lt;i&gt;C&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-like statistic that can be used for tuning the parameters
of SVR. The proposed tuning procedure is tested on a simulated
benchmark problem and on a real world problem (Boston Housing
data set).

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/dinuzzo07a/dinuzzo07a.pdf</url></Article><Article><id>443</id><title>
Nonlinear Estimators and Tail Bounds for Dimension Reduction in &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; Using Cauchy Random Projections
</title><author>Ping Li, Trevor J. Hastie, Kenneth W. Church</author><abstract> 
&lt;p&gt;
For dimension reduction in the &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; norm, the method of
&lt;i&gt;Cauchy random projections&lt;/i&gt; multiplies
the original data matrix &lt;b&gt;A&lt;/b&gt; &amp;#8712; &amp;#8477;&lt;sup&gt;&lt;i&gt;n&amp;#215;D&lt;/i&gt;&lt;/sup&gt;
with a random matrix &lt;b&gt;R&lt;/b&gt; &amp;#8712; &amp;#8477;&lt;sup&gt;&lt;i&gt;D&amp;#215;k&lt;/i&gt;&lt;/sup&gt; 
(&lt;i&gt;k&lt;/i&gt;&amp;#8810;&lt;i&gt;D&lt;/i&gt;) whose entries are i.i.d. samples
of the standard Cauchy &lt;i&gt;C&lt;/i&gt;(0,1). Because of the impossibility result,  one can not
hope to recover the pairwise &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; distances in &lt;b&gt;A&lt;/b&gt;
from &lt;b&gt;B&lt;/b&gt;=&lt;b&gt;A&lt;/b&gt;&amp;#215;&lt;b&gt;R&lt;/b&gt;&amp;#8712; &amp;#8477;&lt;sup&gt;&lt;i&gt;n&amp;#215;k&lt;/i&gt;&lt;/sup&gt;,
using linear estimators without incurring large
errors. However, nonlinear estimators are still useful for certain
applications in data stream computations, information
retrieval, learning, and data mining.
&lt;/p&gt;&lt;p&gt;
We study three types of nonlinear estimators: the 
&lt;i&gt;sample median&lt;/i&gt; estimators, the &lt;i&gt;geometric mean&lt;/i&gt;
estimators, and the &lt;i&gt;maximum likelihood&lt;/i&gt; estimators (MLE). We derive tail bounds
for the &lt;i&gt;geometric mean&lt;/i&gt; estimators and establish that 
&lt;i&gt;k&lt;/i&gt; = &lt;i&gt;O&lt;/i&gt;(log &lt;i&gt;n&lt;/i&gt; / &amp;#949;&lt;sup&gt;2&lt;/sup&gt;) suffices with the constants
explicitly given. Asymptotically (as &lt;i&gt;k&lt;/i&gt;&amp;#8594;&amp;#8734;), both the 
&lt;i&gt;sample median&lt;/i&gt;  and the &lt;i&gt;geometric mean&lt;/i&gt; estimators are about 
80% efficient compared to the MLE. We analyze the moments of the MLE
and propose approximating its distribution of by an
inverse Gaussian.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/li07b/li07b.pdf</url></Article><Article><id>444</id><title>
Revised Loss Bounds for the Set Covering Machine and Sample-Compression Loss Bounds for Imbalanced Data
</title><author>Zakria Hussain, Fran&amp;#231;ois Laviolette, Mario Marchand, John Shawe-Taylor, Spencer Charles Brubaker, Matthew D. Mullin</author><abstract> 

Marchand and Shawe-Taylor (2002) have proposed a loss bound for the set covering
machine that has the property to depend on the observed fraction
of positive examples and on what the classifier achieves on the
positive training examples. We show that this loss bound is
incorrect. We then propose a loss bound, valid for any
sample-compression learning algorithm (including the set covering
machine), that depends on the observed fraction of positive
examples and on what the classifier achieves on them. We also
compare numerically the loss bound proposed in this paper with the
incorrect bound, the original SCM bound and a
recently proposed loss bound of  Marchand and Sokolova (2005) (which does not
depend on the observed fraction of positive examples) and show
that the latter loss bounds can be substantially larger than the
new bound in the presence of imbalanced misclassifications.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/hussain07a/hussain07a.pdf</url></Article><Article><id>445</id><title>
VC Theory of Large Margin Multi-Category Classifiers
</title><author>Yann Guermeur</author><abstract> 

&lt;p&gt;
In the context of discriminant analysis, Vapnik's statistical
learning theory has mainly been developed in three directions:
the computation of dichotomies with binary-valued functions,
the computation of dichotomies with real-valued functions,
and the computation of polytomies with functions taking their values
in finite sets, typically the set of categories itself. 
The case of classes of vector-valued functions
used to compute polytomies has seldom been considered independently,
which is unsatisfactory, for three main reasons. First,
this case encompasses the other ones.
Second, it cannot be treated appropriately
through a na&amp;#239;ve extension of the results devoted to the computation
of dichotomies. Third, most of the classification problems met in practice
involve multiple categories.
&lt;/p&gt;
&lt;p&gt;
In this paper, a VC theory of large margin multi-category classifiers
is introduced. Central in this theory are generalized VC dimensions called
the &amp;#947;-&amp;#936;-dimensions. First, a uniform convergence bound
on the risk of the classifiers of interest is derived.
The capacity measure involved in this bound is a covering number.
This covering number can be upper bounded in terms of the
&amp;#947;-&amp;#936;-dimensions thanks to generalizations of Sauer's lemma, 
as is illustrated
in the specific case of the scale-sensitive Natarajan dimension.
A bound on this latter dimension is then computed for the class of functions
on which multi-class SVMs are based. This makes it possible to apply
the structural risk minimization inductive principle to those machines.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/guermeur07a/guermeur07a.pdf</url></Article><Article><id>446</id><title>
Learning in Environments with Unknown Dynamics: Towards more Robust Concept Learners
</title><author>Marlon N&amp;#250;&amp;#241;ez, Ra&amp;#250;l Fidalgo, Rafael Morales</author><abstract> 

In the process of concept learning, target concepts may have portions
with short-term changes, other portions may support long-term changes,
and yet others may not change at all. For this reason several local
windows need to be handled. We suggest facing this problem, which
naturally exists in the field of concept learning, by allocating
windows which can adapt their size to portions of the target
concept. We propose an incremental decision tree that is updated with
incoming examples. Each leaf of the decision tree holds a time window
and a local performance measure as the main parameter to be
controlled. When the performance of a leaf decreases, the size of its
local window is reduced. This learning algorithm, called OnlineTree2,
automatically adjusts its internal parameters in order to face the
current dynamics of the data stream. Results show that it is
comparable to other batch algorithms when facing problems with no
concept change, and it is better than evaluated methods in its ability
to deal with concept drift when dealing with problems in which:
concept change occurs at different speeds, noise may be present and,
examples may arrive from different areas of the problem domain
(virtual drift).

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/nunez07a/nunez07a.pdf</url></Article><Article><id>447</id><title>
Hierarchical Average Reward Reinforcement Learning
</title><author>Mohammad Ghavamzadeh, Sridhar Mahadevan</author><abstract> 

&lt;p&gt;
Hierarchical reinforcement learning (HRL) is a general framework for
scaling reinforcement learning (RL) to problems with large state and
action spaces by using the task (or action) structure to restrict the 
space of policies. Prior work in HRL including HAMs, options, MAXQ, 
and PHAMs has been limited to the &lt;i&gt;discrete-time discounted 
reward semi-Markov decision process&lt;/i&gt; (SMDP) model. The average 
reward optimality criterion has been recognized to be more appropriate 
for a wide class of continuing tasks than the discounted framework. 
Although average reward RL has been studied for decades, prior work 
has been largely limited to flat policy representations. 
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a framework for HRL based on the 
&lt;i&gt;average reward&lt;/i&gt; optimality criterion. We investigate two formulations
of HRL based on the average reward SMDP model, both for discrete-time
and continuous-time. These formulations correspond to two notions of
optimality that have been previously explored in HRL: &lt;i&gt;hierarchical 
optimality&lt;/i&gt; and &lt;i&gt;recursive optimality&lt;/i&gt;. We present algorithms that 
learn to find hierarchically and recursively optimal average reward 
policies under discrete-time and continuous-time average reward 
SMDP models.
&lt;/p&gt;
&lt;p&gt;
We use two automated guided vehicle (AGV) scheduling tasks as
experimental testbeds to study the empirical performance of the
proposed algorithms. The first problem is a relatively simple AGV
scheduling task, in which the hierarchically and recursively optimal 
policies are different. We compare the proposed algorithms with three 
other HRL methods, including a hierarchically optimal discounted 
reward algorithm and a recursively optimal discounted reward algorithm 
on this problem. The second problem is a larger AGV scheduling task. 
We model this problem using both discrete-time and continuous-time 
models. We use a hierarchical task decomposition in which the 
hierarchically and recursively optimal policies are the same for this 
problem. We compare the performance of the proposed algorithms 
with a hierarchically optimal discounted reward algorithm and a 
recursively optimal discounted reward algorithm, as well as a 
non-hierarchical average reward algorithm. The results show that 
the proposed hierarchical average reward algorithms converge to 
the same performance as their discounted reward counterparts. 
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/ghavamzadeh07a/ghavamzadeh07a.pdf</url></Article><Article><id>448</id><title>
Ranking the Best Instances
</title><author>St&amp;#233;phan Cl&amp;#233;men&amp;#231;on, Nicolas Vayatis</author><abstract> 

We formulate a local form of the bipartite ranking problem where the goal is to
focus on the best instances. We propose a methodology based on the
construction of real-valued scoring functions. We study empirical
risk minimization of dedicated statistics which involve empirical
quantiles of the scores. We first state the problem of 
&lt;i&gt;finding&lt;/i&gt; the best instances which can be cast as a classification
problem with mass constraint. Next, we develop special performance
measures for the local ranking problem which extend the Area Under
an ROC Curve (AUC) criterion and describe the optimal
elements of these new criteria. We also highlight the fact that
the goal of ranking the best instances cannot be achieved in a
stage-wise manner where first, the best instances would be
tentatively identified and then a standard AUC criterion could be
applied. Eventually, we state preliminary statistical results for
the local ranking problem.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/clemencon07a/clemencon07a.pdf</url></Article><Article><id>449</id><title>
Stagewise Lasso
</title><author>Peng Zhao, Bin Yu</author><abstract> 
&lt;p&gt;
Many statistical machine learning algorithms
minimize either an empirical loss function as
in AdaBoost, or a penalized empirical loss as in Lasso or SVM.
A single regularization tuning parameter controls the trade-off
between fidelity to the data and generalizability, or
equivalently between bias and variance.
When this tuning parameter changes, a regularization "path" of solutions
to the minimization problem is generated, and the whole path is needed to select
a tuning parameter to optimize the prediction or interpretation performance.
Algorithms such as homotopy-Lasso or LARS-Lasso and Forward Stagewise Fitting (FSF) 
(aka e-Boosting) are of great interest because
of their resulted sparse models for interpretation in addition to prediction.
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose the BLasso algorithm that
ties the FSF (e-Boosting) algorithm with the Lasso method
that minimizes the &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; penalized &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt; loss. 
BLasso is derived
as a coordinate descent method with a fixed stepsize applied to the
general Lasso loss function (&lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; penalized convex loss). It
consists of both a forward step and a backward step. The forward
step is similar to e-Boosting or FSF, but the
backward step is new and revises the FSF (or e-Boosting) path to approximate the
Lasso path. In the cases of a finite number of base learners and a
bounded Hessian of the loss function,
the BLasso path is shown to converge to the Lasso path when
the stepsize goes to zero. For
cases with a larger number of base learners than the sample size
and when the true model is sparse, our simulations indicate
that the BLasso model estimates
are sparser than those from FSF with comparable
or slightly better prediction performance, and that
the the discrete stepsize of BLasso and FSF has
an additional regularization effect in terms
of prediction and sparsity.
Moreover, we introduce the Generalized BLasso
algorithm
to minimize a general convex loss penalized by a general convex
function. Since the (Generalized) BLasso relies only on differences not derivatives,
we conclude that it provides a class of
simple and easy-to-implement algorithms
for tracing the regularization or solution paths of penalized minimization problems.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/zhao07a/zhao07a.pdf</url></Article><Article><id>450</id><title>
A New Probabilistic Approach in Rank Regression with Optimal Bayesian Partitioning
</title><author>Carine Hue, Marc Boull&amp;#233;</author><abstract> 
&lt;p&gt;
In this paper, we consider the supervised learning task which consists
in predicting the normalized rank of a numerical variable. We
introduce a novel probabilistic approach to estimate the posterior
distribution of the target rank conditionally to the predictors. We
turn this learning task into a model selection problem. For that, we
define a 2D partitioning family obtained by discretizing numerical
variables and grouping categorical ones and we derive an analytical
criterion to select the partition with the highest posterior
probability. We show how these partitions can be used to build
univariate predictors and multivariate ones under a naive Bayes
assumption.
&lt;/p&gt;
&lt;p&gt;
We also propose a new evaluation criterion for probabilistic rank
estimators. Based on the logarithmic score, we show that such
criterion presents the advantage to be minored, which is not the case
of the logarithmic score computed for probabilistic value estimator.
&lt;/p&gt;
&lt;p&gt;
A first set of experimentations on synthetic data shows the good
properties of the proposed criterion and of our partitioning approach.
A second set of experimentations on real data shows competitive
performance of the univariate and selective naive Bayes rank
estimators projected on the value range compared to methods submitted
to a recent challenge on probabilistic metric regression tasks.
&lt;/p&gt;
&lt;p&gt;
Our approach is applicable for all regression problems with
 categorical or numerical predictors. It is particularly interesting
 for those with a high number of predictors as it automatically
 detects the variables which contain predictive information. It builds
 pertinent predictors of the normalized rank of the numerical target
 from one or several predictors.  As the criteria selection is
 regularized by the presence of a prior and a posterior term, it does
 not suffer from overfitting.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/hue07a/hue07a.pdf</url></Article><Article><id>451</id><title>
Dynamic Weighted Majority: An Ensemble Method for Drifting Concepts
</title><author>J. Zico Kolter, Marcus A. Maloof</author><abstract> 

We present an ensemble method for concept drift that dynamically creates
and removes weighted experts in response to changes in performance.
The method, dynamic weighted majority (&lt;small&gt;DWM&lt;/small&gt;), uses four mechanisms
to cope with concept drift:
It trains online learners of the ensemble, it weights those learners
based on their performance, it removes them, also based on their
performance, and it adds new experts based on the global performance
of the ensemble.
After an extensive evaluation---consisting of five experiments,
eight learners,
and thirty data sets that varied in type of target
concept, size, presence of noise, and the like---we concluded that
&lt;small&gt;DWM&lt;/small&gt; outperformed other learners
that only incrementally learn concept descriptions,
that maintain and use previously encountered examples, and
that employ an unweighted, fixed-size ensemble of experts.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume8/kolter07a/kolter07a.pdf</url></Article><Article><id>452</id><title>
Max-margin Classification of Data with Absent Features
</title><author>Gal Chechik, Geremy Heitz, Gal Elidan, Pieter Abbeel, Daphne Koller</author><abstract>

We consider the problem of learning classifiers in structured domains,
where some objects have a subset of features that are inherently
absent due to complex relationships between the features.  Unlike the
case where a feature exists but its value is not observed, here we
focus on the case where a feature may not even exist (structurally
absent) for some of the samples. The common approach for handling
missing features in discriminative models is to first complete their
unknown values, and then use a standard classification procedure over
the completed data. This paper focuses on features that are known to
be non-existing, rather than have an unknown value. We show how
incomplete data can be classified &lt;i&gt;directly&lt;/i&gt; without any
completion of the missing features using a max-margin learning
framework. We formulate an objective function, based on the geometric
interpretation of the margin, that aims to maximize the margin of each
sample in its own relevant subspace. In this formulation, the linearly
separable case can be transformed into a binary search over a series
of second order cone programs (SOCP), a convex problem that can be
solved efficiently. We also describe two approaches for optimizing the
general case: an approximation that can be solved as a standard
quadratic program (QP) and an iterative approach for solving the exact
problem.  By avoiding the pre-processing phase in which the data is
completed, both of these approaches could offer considerable
computational savings. More importantly, we show that the elegant
handling of missing values by our approach allows it to both
outperform other methods when the missing values have non-trivial
structure, and be competitive with other methods when the values are
missing at random. We demonstrate our results on several standard
benchmarks and two real-world problems: edge prediction in metabolic
pathways, and automobile detection in natural images.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chechik08a/chechik08a.pdf</url></Article><Article><id>453</id><title>
Linear-Time Computation of Similarity Measures for Sequential Data
</title><author>Konrad Rieck, Pavel Laskov</author><abstract>
&lt;p&gt;
Efficient and expressive comparison of sequences is an essential
procedure for learning with sequential data. In this article we
propose a generic framework for computation of similarity measures for
sequences, covering various kernel, distance and non-metric similarity
functions. The basis for comparison is embedding of sequences using a
formal language, such as a set of natural words, &lt;i&gt;k&lt;/i&gt;-grams or all
contiguous subsequences. As realizations of the framework we provide
linear-time algorithms of different complexity and capabilities using
sorted arrays, tries and suffix trees as underlying data structures.
&lt;/p&gt;

&lt;p&gt;
Experiments on data sets from bioinformatics, text processing and
computer security illustrate the efficiency of the proposed
algorithms---enabling peak performances of up to 10&lt;sup&gt;6&lt;/sup&gt;
pairwise comparisons per second. The utility of distances and
non-metric similarity measures for sequences as alternatives to string
kernels is demonstrated in applications of text categorization,
network intrusion detection and transcription site recognition in DNA.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/rieck08a/rieck08a.pdf</url></Article><Article><id>454</id><title>
On the Suitable Domain for SVM Training in Image Coding
</title><author>Gustavo Camps-Valls, Juan Guti&amp;#233;rrez, Gabriel G&amp;#243;mez-P&amp;#233;rez, Jes&amp;#250;s Malo</author><abstract>

&lt;p&gt;
Conventional SVM-based image coding methods are founded on
independently restricting the distortion in every image
coefficient at some particular image representation.
Geometrically, this implies allowing arbitrary signal distortions
in an &lt;i&gt;n&lt;/i&gt;-dimensional rectangle defined by the
&amp;#949;-insensitivity zone in each dimension of the selected
image representation domain. Unfortunately, not every image
representation domain is well-suited for such a simple,
scalar-wise, approach because statistical and/or perceptual
interactions between the coefficients may exist. These
interactions imply that scalar approaches may induce distortions
that do not follow the image statistics and/or are perceptually
annoying. Taking into account these relations would imply using
non-rectangular &amp;#949;-insensitivity regions (allowing
coupled distortions in different coefficients), which is beyond
the conventional SVM formulation.
&lt;/p&gt;

&lt;p&gt;
In this paper, we report a condition on the suitable domain for
developing efficient SVM image coding schemes.
We analytically demonstrate that no linear domain fulfills this
condition because of the statistical and perceptual
inter-coefficient relations that exist in these domains.
This theoretical result is experimentally
confirmed by comparing SVM learning in previously reported linear
domains and in a recently proposed non-linear perceptual domain
that simultaneously reduces the statistical and perceptual
relations (so it is closer to fulfilling the proposed condition).
These results highlight the relevance of an appropriate choice of
the image representation before SVM learning.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/camps-valls08a/camps-valls08a.pdf</url></Article><Article><id>455</id><title>
Discriminative Learning of Max-Sum Classifiers
</title><author>Vojt&amp;#283;ch Franc, Bogdan Savchynskyy</author><abstract>

The max-sum classifier predicts &lt;i&gt;n&lt;/i&gt;-tuple of labels from &lt;i&gt;n&lt;/i&gt;-tuple of
observable variables by maximizing a sum of quality functions defined over
neighbouring pairs of labels and observable variables.
Predicting labels as MAP assignments of a Random Markov Field is a
particular example of the max-sum classifier.
Learning parameters of the max-sum classifier is a challenging problem
because even computing the response of such classifier is NP-complete
in general. Estimating parameters using the Maximum Likelihood
approach is feasible only for a subclass of max-sum classifiers with
an acyclic structure of neighbouring pairs. Recently, the discriminative methods
represented by the perceptron and the Support Vector Machines, originally
designed for binary linear classifiers, have been extended for learning some
subclasses of the max-sum classifier. Besides the max-sum classifiers with the
acyclic neighbouring structure, it has been shown that the discriminative
learning is possible even with arbitrary neighbouring structure provided the
quality functions fulfill some additional constraints. In this article, we extend the
discriminative approach to other three classes of max-sum classifiers with
an arbitrary neighbourhood structure. We derive learning algorithms for two
subclasses of max-sum classifiers whose response can be computed in polynomial
time: (i) the max-sum classifiers with supermodular quality functions and
(ii) the max-sum classifiers whose response can be computed exactly by a
linear programming relaxation. Moreover, we show that the learning problem
can be approximately solved even for a general max-sum classifier.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/franc08a/franc08a.pdf</url></Article><Article><id>456</id><title>
Active Learning by Spherical Subdivision
</title><author>Falk-Florian Henrich, Klaus Obermayer</author><abstract>

We introduce a computationally feasible, "constructive" active
learning method for binary classification. The learning algorithm is
initially formulated for separable classification problems, for a
hyperspherical data space with constant data density, and for great
spheres as classifiers. In order to reduce computational complexity
the version space is restricted to spherical simplices and learning
procedes by subdividing the edges of maximal length. We show that this
procedure optimally reduces a tight upper bound on the generalization
error. The method is then extended to other separable classification
problems using products of spheres as data spaces and isometries
induced by charts of the sphere. An upper bound is provided for the
probability of disagreement between classifiers (hence the
generalization error) for non-constant data densities on the sphere.
The emphasis of this work lies on providing mathematically exact
performance estimates for active learning strategies.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/henrich08a/henrich08a.pdf</url></Article><Article><id>457</id><title>
Evidence Contrary to the Statistical View of Boosting
</title><author>David Mease, Abraham Wyner</author><abstract>

The statistical perspective on boosting algorithms focuses on
optimization, drawing parallels with maximum likelihood estimation
for logistic regression. In this paper we present empirical evidence
that raises questions about this view. Although the statistical
perspective provides a theoretical framework within which it  is
possible to derive theorems and create new algorithms in general
contexts, we show that there remain many unanswered important
questions. Furthermore, we provide examples that reveal crucial
flaws in  the many practical suggestions and new methods that are
derived from the statistical view.   We perform carefully designed
experiments using simple simulation models to illustrate some of
these flaws and their practical consequences.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/mease08a/mease08a.pdf</url></Article><Article><id>458</id><title>
Optimization Techniques for Semi-Supervised Support Vector Machines
</title><author>Olivier Chapelle, Vikas Sindhwani, Sathiya S. Keerthi</author><abstract>

Due to its wide applicability, the problem of semi-supervised
classification is attracting increasing attention in machine learning.
Semi-Supervised Support Vector Machines (S&lt;sup&gt;3&lt;/sup&gt;VMs) are based on applying
the margin maximization principle to both labeled and unlabeled
examples.  Unlike SVMs, their formulation leads to a non-convex
optimization problem.  A suite of algorithms have recently been
proposed for solving S&lt;sup&gt;3&lt;/sup&gt;VMs.  This paper reviews key ideas in this
literature. The performance and behavior of various S&lt;sup&gt;3&lt;/sup&gt;VMs algorithms
is studied together, under a common experimental setting.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chapelle08a/chapelle08a.pdf</url></Article><Article><id>459</id><title>
Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies
</title><author>Andreas Krause, Ajit Singh, Carlos Guestrin</author><abstract>

When monitoring spatial phenomena, which can often be modeled as
Gaussian processes (GPs), choosing sensor locations is a fundamental
task. There are several common strategies to address this task, for
example, geometry or disk models, placing sensors at the points of
highest entropy (variance) in the GP model, and A-, D-, or E-optimal
design. In this paper, we tackle the combinatorial optimization
problem of maximizing the &lt;i&gt;mutual information&lt;/i&gt; between the
chosen locations and the locations which are not selected. We prove
that the problem of finding the configuration that maximizes mutual
information is NP-complete. To address this issue, we describe a
polynomial-time approximation that is within (1-1/&lt;i&gt;e&lt;/i&gt;) of the
optimum by exploiting the &lt;i&gt;submodularity&lt;/i&gt; of mutual
information. We also show how submodularity can be used to obtain
online bounds, and design branch and bound search procedures. We
then extend our algorithm to exploit lazy evaluations and local
structure in the GP, yielding significant speedups. We also extend
our approach to find placements which are robust against node
failures and uncertainties in the model. These extensions are again
associated with rigorous theoretical approximation guarantees,
exploiting the submodularity of the objective function. We
demonstrate the advantages of our approach towards optimizing mutual
information in a very extensive empirical study on two real-world
data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/krause08a/krause08a.pdf</url></Article><Article><id>460</id><title>
Support Vector Machinery for Infinite Ensemble Learning
</title><author>Hsuan-Tien Lin, Ling Li</author><abstract>

Ensemble learning algorithms such as boosting can achieve better
performance by averaging over the predictions of some base hypotheses.
Nevertheless, most existing algorithms are limited to combining only a
finite number of hypotheses, and the generated ensemble is usually
sparse.  Thus, it is not clear whether we should construct an ensemble
classifier with a larger or even an infinite number of hypotheses.  In
addition, constructing an infinite ensemble itself is a challenging
task.  In this paper, we formulate an infinite ensemble learning
framework based on the support vector machine (SVM).  The framework
can output an infinite and nonsparse ensemble through embedding
infinitely many hypotheses into an SVM kernel.  We use the framework
to derive two novel kernels, the stump kernel and the perceptron
kernel.  The stump kernel embodies infinitely many decision stumps,
and the perceptron kernel embodies infinitely many perceptrons.  We
also show that the Laplacian radial basis function kernel embodies
infinitely many decision trees, and can thus be explained through
infinite ensemble learning.  Experimental results show that SVM with
these kernels is superior to boosting with the same base hypothesis
set.  In addition, SVM with the stump kernel or the perceptron kernel
performs similarly to SVM with the Gaussian radial basis function
kernel, but enjoys the benefit of faster parameter selection.  These
properties make the novel kernels favorable choices in practice.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/lin08a/lin08a.pdf</url></Article><Article><id>461</id><title>
Algorithms for Sparse Linear Classifiers in the Massive Data Setting
</title><author>Suhrid Balakrishnan, David Madigan</author><abstract>

Classifiers favoring sparse solutions, such as support vector
machines, relevance vector machines, LASSO-regression based
classifiers, etc., provide competitive methods for
classification problems in high dimensions.  However, current
algorithms for training sparse classifiers typically scale quite
unfavorably with respect to the number of training examples. This
paper proposes online and multi-pass algorithms for training
sparse linear classifiers for high dimensional data. These
algorithms have computational complexity and memory requirements
that make learning on massive data sets feasible. The central idea
that makes this possible is a straightforward quadratic
approximation to the likelihood function.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/balakrishnan08a/balakrishnan08a.pdf</url></Article><Article><id>462</id><title>
Generalization from Observed to Unobserved Features by Clustering
</title><author>Eyal Krupka, Naftali Tishby</author><abstract>

We argue that when objects are characterized by many attributes, clustering
them on the basis of a &lt;i&gt;random&lt;/i&gt; subset of these attributes can
capture information on the unobserved attributes as well. Moreover,
we show that under mild technical conditions, clustering the objects
on the basis of such a random subset performs almost as well as clustering
with the full attribute set. We prove finite sample generalization
theorems for this novel learning scheme that extends analogous results
from the supervised learning setting. We use our framework to analyze
generalization to unobserved features of two well-known clustering
algorithms: &lt;i&gt;k&lt;/i&gt;-means and the maximum likelihood multinomial mixture
model. The scheme is demonstrated for collaborative filtering of users
with movie ratings as attributes and document clustering with words
as attributes.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/krupka08a/krupka08a.pdf</url></Article><Article><id>463</id><title>
A Tutorial on Conformal Prediction
</title><author>Glenn Shafer, Vladimir Vovk</author><abstract>

&lt;p&gt;
Conformal prediction uses past experience to determine precise levels
of confidence in new predictions.  Given an error probability
&amp;#949;, together with a method that makes a prediction &lt;i&gt;&amp;#375;&lt;/i&gt;
of a label &lt;i&gt;y&lt;/i&gt;, it produces a set of labels, typically containing
&lt;i&gt;&amp;#375;&lt;/i&gt;, that also contains &lt;i&gt;y&lt;/i&gt; with probability 1 &amp;#150; &amp;#949;.
Conformal prediction can be applied to any method for producing
&lt;i&gt;&amp;#375;&lt;/i&gt;: a nearest-neighbor method, a support-vector machine, ridge
regression, etc.
&lt;/p&gt;
&lt;p&gt;      
Conformal prediction is designed for an on-line setting in which
labels are predicted successively, each one being revealed before the
next is predicted.  The most novel and valuable feature of conformal
prediction is that if the successive examples are sampled
independently from the same distribution, then the successive
predictions will be right 1 &amp;#150; &amp;#949; of the time, even though they
are based on an accumulating data set rather than on independent data
sets.
&lt;/p&gt;
&lt;p&gt;
In addition to the model under which successive examples are sampled
independently, other on-line compression models can also use conformal
prediction.  The widely used Gaussian linear model is one of these.
&lt;/p&gt;
&lt;p&gt;
This tutorial presents a self-contained account of the theory of
conformal prediction and works through several numerical examples.  A
more comprehensive treatment of the topic is provided in
&lt;i&gt;Algorithmic Learning in a Random World&lt;/i&gt;, by Vladimir Vovk,
Alex Gammerman, and Glenn Shafer (Springer, 2005).
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/shafer08a/shafer08a.pdf</url></Article><Article><id>464</id><title>
Theoretical Advantages of Lenient Learners:  An Evolutionary Game Theoretic Perspective
</title><author>Liviu Panait, Karl Tuyls, Sean Luke</author><abstract>

This paper presents the dynamics of multiple learning agents from an
evolutionary game theoretic perspective.  We provide replicator
dynamics models for cooperative coevolutionary algorithms and for
traditional multiagent Q-learning, and we extend these differential
equations to account for lenient learners: agents that forgive
possible mismatched teammate actions that resulted in low rewards.  We
use these extended formal models to study the convergence guarantees
for these algorithms, and also to visualize the basins of attraction
to optimal and suboptimal solutions in two benchmark coordination
problems.  The paper demonstrates that lenience provides learners with
more accurate information about the benefits of performing their
actions, resulting in higher likelihood of convergence to the globally
optimal solution.  In addition, the analysis indicates that the choice
of learning algorithm has an insignificant impact on the overall
performance of multiagent learning algorithms; rather, the performance
of these algorithms depends primarily on the level of lenience that
the agents exhibit to one another.  Finally, the research herein
supports the strength and generality of evolutionary game theory as a
backbone for multiagent learning.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/panait08a/panait08a.pdf</url></Article><Article><id>465</id><title>
A Recursive Method for Structural Learning of Directed Acyclic Graphs
</title><author>Xianchao Xie, Zhi Geng</author><abstract>

In this paper, we propose a recursive method for structural learning
of directed acyclic graphs (DAGs), in which a problem of structural
learning for a large DAG is first decomposed into two problems of
structural learning for two small vertex subsets, each of which is
then decomposed recursively into two problems of smaller subsets
until none subset can be decomposed further. In our approach, search
for separators of a pair of variables in a large DAG is localized to
small subsets, and thus the approach can improve the efficiency of
searches and the power of statistical tests for structural learning.
We show how the recent advances in the learning of undirected
graphical models can be employed to facilitate the decomposition.
Simulations are given to demonstrate the performance of the proposed
method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/xie08a/xie08a.pdf</url></Article><Article><id>466</id><title>
Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or Binary Data
</title><author>Onureena Banerjee, Laurent El Ghaoui, Alexandre d'Aspremont</author><abstract>

We consider the problem of estimating the parameters of a Gaussian or
binary distribution in such a way that the resulting undirected
graphical model is sparse.  Our approach is to solve a maximum
likelihood problem with an added &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm penalty term.  The
problem as formulated is convex but the memory requirements and
complexity of existing interior point methods are prohibitive for
problems with more than tens of nodes.  We present two new algorithms
for solving problems with at least a thousand nodes in the Gaussian
case.  Our first algorithm uses block coordinate descent, and can be
interpreted as recursive &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm penalized regression.  Our
second algorithm, based on Nesterov's first order method, yields a
complexity estimate with a better dependence on problem size than
existing interior point methods.  Using a log determinant relaxation
of the log partition function (Wainwright and Jordan, 2006), we show that these
same algorithms can be used to solve an approximate sparse maximum
likelihood problem for the binary case.  We test our algorithms on
synthetic data, as well as on gene expression and senate voting
records data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/banerjee08a/banerjee08a.pdf</url></Article><Article><id>467</id><title>
Comments on the Complete Characterization of a Family of Solutions to a Generalized &lt;i&gt;Fisher&lt;/i&gt; Criterion 
</title><author>Jieping Ye</author><abstract>

Loog (2007) provided a complete characterization of the
family of solutions to a generalized &lt;i&gt;Fisher&lt;/i&gt; criterion. We show
that this characterization is essentially equivalent to the original
characterization proposed in Ye (2005). The computational
advantage of the original characterization over the new one is
discussed, which justifies its practical use.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/ye08a/ye08a.pdf</url></Article><Article><id>468</id><title>
Estimating the Confidence Interval for Prediction Errors of Support Vector Machine Classifiers
</title><author>Bo Jiang, Xuegong Zhang, Tianxi Cai</author><abstract>

Support vector machine (SVM) is one of the most popular and
promising classification algorithms. After a classification rule is
constructed via the SVM, it is essential to evaluate its prediction
accuracy. In this paper, we develop procedures for obtaining both
point and interval estimators for the prediction error. Under mild
regularity conditions, we derive the consistency and asymptotic
normality of the prediction error estimators for SVM with
finite-dimensional kernels. A perturbation-resampling procedure is
proposed to obtain interval estimates for the prediction error in
practice. With numerical studies on simulated data and a benchmark
repository, we recommend the use of interval estimates centered at
the cross-validated point estimates for the prediction error.
Further applications of the proposed procedure in model evaluation
and feature selection are illustrated with two examples.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/jiang08a/jiang08a.pdf</url></Article><Article><id>469</id><title>
An Information Criterion for Variable Selection in Support Vector Machines
</title><author>Gerda Claeskens, Christophe Croux, Johan Van Kerckhoven</author><abstract>

Support vector machines for classification have the advantage that
the curse of dimensionality is circumvented. It has been shown that
a reduction of the dimension of the input space leads to even better
results. For this purpose, we propose two information criteria which
can be computed directly from the definition of the support vector
machine. We assess the predictive performance of the models selected
by our new criteria and compare them to existing variable selection
techniques in a simulation study. The simulation results show that
the new criteria are competitive in terms of generalization error
rate while being much easier to compute. We arrive at the same
findings for comparison on some real-world benchmark data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/claeskens08a/claeskens08a.pdf</url></Article><Article><id>470</id><title>
Closed Sets for Labeled Data
</title><author>Gemma C. Garriga, Petra Kralj, Nada Lavra&amp;#269;</author><abstract>

Closed sets have been proven successful in the context of compacted
data representation for association rule learning. However, their use
is mainly descriptive, dealing only with unlabeled data. This paper
shows that when considering labeled data, closed sets can be adapted
for classification and discrimination purposes by conveniently
contrasting covering properties on positive and negative examples. We
formally prove that these sets characterize the space of relevant
combinations of features for discriminating the target class. In
practice, identifying relevant/irrelevant combinations of features
through closed sets is useful in many applications:
to compact emerging
patterns of typical descriptive mining applications, to reduce the number
of essential rules in classification, and to efficiently learn 
subgroup descriptions, as demonstrated in real-life subgroup discovery
experiments on a high dimensional microarray data set.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/garriga08a/garriga08a.pdf</url></Article><Article><id>471</id><title>
Learning Reliable Classifiers From Small or Incomplete Data Sets: The Naive Credal Classifier 2
</title><author>Giorgio Corani, Marco Zaffalon</author><abstract>

In this paper, the naive credal classifier, which is a
set-valued counterpart of naive Bayes, is extended to a general and
flexible treatment of incomplete data, yielding a new classifier
called &lt;i&gt;naive credal classifier 2&lt;/i&gt; (NCC2). The new classifier delivers
classifications that are reliable even in the presence of small sample
sizes and missing values.  Extensive empirical evaluations show that,
by issuing set-valued classifications, NCC2 is able to isolate and
properly deal with instances that are hard to classify (on which naive
Bayes accuracy drops considerably), and to perform as well as naive
Bayes on the other instances. The experiments point to a general
problem: they show that with missing values, empirical evaluations may
not reliably estimate the accuracy of a traditional classifier, such
as naive Bayes. This phenomenon adds even more value to the robust
approach to classification implemented by NCC2.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/corani08a/corani08a.pdf</url></Article><Article><id>472</id><title>
A Library for Locally Weighted Projection Regression
</title><author>Stefan Klanke, Sethu Vijayakumar, Stefan Schaal</author><abstract>

In this paper we introduce an improved implementation of locally weighted
projection regression (LWPR), a supervised learning algorithm that is
capable of handling high-dimensional input data. As the key features,
our code supports multi-threading, is available for multiple
platforms, and provides wrappers for several programming languages.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/klanke08a/klanke08a.pdf</url></Article><Article><id>473</id><title>
Trust Region Newton Method for Logistic Regression
</title><author>Chih-Jen Lin, Ruby C. Weng, S. Sathiya Keerthi</author><abstract>

Large-scale logistic regression arises in many applications such as
document classification and natural language processing.  In this
paper, we apply a trust region Newton method to maximize the
log-likelihood of the logistic regression model. The proposed method
uses only approximate Newton steps in the beginning, but achieves fast
convergence in the end. Experiments show that it is faster than the
commonly used quasi Newton approach for logistic regression.  We also
extend the proposed method to large-scale L2-loss linear support
vector machines (SVM).

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/lin08b/lin08b.pdf</url></Article><Article><id>474</id><title>
Graphical Models for Structured Classification, with an Application to Interpreting Images of Protein Subcellular Location Patterns
</title><author>Shann-Ching Chen, Geoffrey J. Gordon, Robert F. Murphy</author><abstract>

In structured classification problems, there is a direct conflict
between expressive models and efficient inference: while graphical
models such as Markov random fields or factor graphs can represent
arbitrary dependences among instance labels, the cost of inference via
belief propagation in these models grows rapidly as the graph
structure becomes more complicated.  One important source of
complexity in belief propagation is the need to marginalize large
factors to compute messages.  This operation takes time exponential in
the number of variables in the factor, and can limit the
expressiveness of the models we can use.  In this paper, we study a
new class of potential functions, which we call decomposable
&lt;i&gt;k&lt;/i&gt;-way potentials, and provide efficient algorithms for
computing messages from these potentials during belief propagation.
We believe these new potentials provide a good balance between
expressive power and efficient inference in practical structured
classification problems.  We discuss three instances of decomposable
potentials: the associative Markov network potential, the nested
junction tree, and a new type of potential which we call the voting
potential.  We use these potentials to classify images of protein
subcellular location patterns in groups of cells.  Classifying
subcellular location patterns can help us answer many important
questions in computational biology, including questions about how
various treatments affect the synthesis and behavior of proteins and
networks of proteins within a cell.  Our new representation and
algorithm lead to substantial improvements in both inference speed and
classification accuracy.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chen08a/chen08a.pdf</url></Article><Article><id>475</id><title>
Learning Control Knowledge for Forward Search Planning
</title><author>Sungwook Yoon, Alan Fern, Robert Givan</author><abstract>

A number of today's state-of-the-art planners are based on forward
state-space search.  The impressive performance can be attributed to
progress in computing domain independent heuristics that perform well
across many domains.  However, it is easy to find domains where such
heuristics provide poor guidance, leading to planning failure.
Motivated by such failures, the focus of this paper is to investigate
mechanisms for learning domain-specific knowledge to better control
forward search in a given domain.  While there has been a large body
of work on inductive learning of control knowledge for AI planning,
there is a void of work aimed at forward-state-space search.  One
reason for this may be that it is challenging to specify a knowledge
representation for compactly representing important concepts across a
wide range of domains.  One of the main contributions of this work is
to introduce a novel feature space for representing such control
knowledge.  The key idea is to define features in terms of information
computed via relaxed plan extraction, which has been a major source of
success for non-learning planners.  This gives a new way of leveraging
relaxed planning techniques in the context of learning.  Using this
feature space, we describe three forms of control knowledge---reactive
policies (decision list rules and measures of progress) and linear
heuristics---and show how to learn them and incorporate them into
forward state-space search.  Our empirical results show that our
approaches are able to surpass state-of-the-art non-learning planners
across a wide range of planning competition domains.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/yoon08a/yoon08a.pdf</url></Article><Article><id>476</id><title>
Multi-class Discriminant Kernel Learning via Convex Programming
</title><author>Jieping Ye, Shuiwang Ji, Jianhui Chen</author><abstract>

Regularized kernel discriminant analysis (RKDA) performs linear
discriminant analysis in the feature space via the kernel trick. Its
performance depends on the selection of kernels. In this paper, we
consider the problem of multiple kernel learning (MKL) for RKDA, in
which the optimal kernel matrix is obtained as a linear combination
of pre-specified kernel matrices. We show that the kernel learning
problem in RKDA can be formulated as convex programs. First, we show
that this problem can be formulated as a semidefinite program (SDP).
Based on the equivalence relationship between RKDA and least square
problems in the binary-class case, we propose a convex quadratically
constrained quadratic programming (QCQP) formulation for kernel
learning in RKDA. A semi-infinite linear programming (SILP)
formulation is derived to further improve the efficiency. We extend
these formulations to the multi-class case based on a key result
established in this paper. That is, the multi-class RKDA kernel
learning problem can be decomposed into a set of binary-class kernel
learning problems which are constrained to share a common kernel.
Based on this decomposition property, SDP formulations are proposed
for the multi-class case. Furthermore, it leads naturally to QCQP
and SILP formulations. As the performance of RKDA depends on the
regularization parameter, we show that this parameter can also be
optimized in a joint framework with the kernel. Extensive
experiments have been conducted and analyzed, and connections to
other algorithms are discussed.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/ye08b/ye08b.pdf</url></Article><Article><id>477</id><title>
Bayesian Inference and Optimal Design for the Sparse Linear Model
</title><author>Matthias W. Seeger</author><abstract>
&lt;p&gt;
The linear model with sparsity-favouring prior on the coefficients has
important applications in many different domains. In machine learning,
most methods to date search for maximum a posteriori sparse solutions and
neglect to represent posterior uncertainties. In this paper, we address
problems of Bayesian optimal design (or experiment planning), for which
accurate estimates of uncertainty are essential. To this end, we employ
expectation propagation approximate inference for the linear model with
Laplace prior, giving new insight into numerical stability properties and
proposing a robust algorithm. We also show how to estimate model
hyperparameters by empirical Bayesian maximisation of the marginal likelihood,
and propose ideas in order to scale up the method to very large
underdetermined problems.
&lt;/p&gt;
&lt;p&gt;
We demonstrate the versatility of our framework on the application of
gene regulatory network identification from micro-array expression data,
where both the Laplace prior and the active experimental design approach are
shown to result in significant improvements. We also address the problem of
sparse coding of natural images, and show how our framework can be used
for compressive sensing tasks.
&lt;/p&gt;
&lt;p&gt;
Part of this work appeared in Seeger et al. (2007b).  The gene network
identification application appears in Steinke et al. (2007). 

&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/seeger08a/seeger08a.pdf</url></Article><Article><id>478</id><title>
Finite-Time Bounds for Fitted Value Iteration
</title><author>R&amp;#233;mi Munos, Csaba Szepesv&amp;#225;ri</author><abstract>

In this paper we develop a theoretical analysis of the performance of
sampling-based fitted value iteration (FVI) to solve infinite
state-space, discounted-reward Markovian decision processes (MDPs)
under the assumption that a generative model of the environment is
available. Our main results come in the form of finite-time bounds on
the performance of two versions of sampling-based FVI.  The
convergence rate results obtained allow us to show that both versions
of FVI are well behaving in the sense that by using a sufficiently
large number of samples for a large class of MDPs, arbitrary good
performance can be achieved with high probability.  An important
feature of our proof technique is that it permits the study of
weighted &lt;i&gt;L&lt;sup&gt;p&lt;/sup&gt;&lt;/i&gt;-norm performance bounds. As a result, our technique
applies to a large class of function-approximation methods (e.g.,
neural networks, adaptive regression trees, kernel machines, locally
weighted learning), and our bounds scale well with the effective
horizon of the MDP. The bounds show a dependence on the stochastic
stability properties of the MDP: they scale with the
discounted-average concentrability of the future-state
distributions. They also depend on a new measure of the approximation
power of the function space, the inherent Bellman residual, which
reflects how well the function space is "aligned" with the dynamics
and rewards of the MDP.  The conditions of the main result, as well as
the concepts introduced in the analysis, are extensively discussed and
compared to previous theoretical results.  Numerical experiments are
used to substantiate the theoretical findings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/munos08a/munos08a.pdf</url></Article><Article><id>479</id><title>
An Error Bound Based on a Worst Likely Assignment
</title><author>Eric Bax, Augusto Callejas</author><abstract>

This paper introduces a new PAC transductive error bound for
classification. The method uses information from the training examples
and inputs of working examples to develop a set of likely assignments
to outputs of the working examples. A likely assignment with maximum
error determines the bound. The method is very effective for small
data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bax08a/bax08a.pdf</url></Article><Article><id>480</id><title>
Graphical Methods for Efficient Likelihood Inference in Gaussian Covariance Models
</title><author>Mathias Drton, Thomas S. Richardson</author><abstract>

In graphical modelling, a bi-directed graph encodes marginal
independences among random variables that are identified with the
vertices of the graph.  We show how to transform a bi-directed graph
into a maximal ancestral graph that (i) represents the same
independence structure as the original bi-directed graph, and (ii)
minimizes the number of arrowheads among all ancestral graphs
satisfying (i). Here the number of arrowheads of an ancestral graph is
the number of directed edges plus twice the number of bi-directed
edges. In Gaussian models, this construction can be used for more
efficient iterative maximization of the likelihood function and to
determine when maximum likelihood estimates are equal to empirical
counterparts.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/drton08a/drton08a.pdf</url></Article><Article><id>481</id><title>
Bouligand Derivatives and Robustness of Support Vector Machines for Regression
</title><author>Andreas Christmann, Arnout Van Messem</author><abstract>

We investigate robustness properties for a broad
class of support vector machines with non-smooth loss functions.
These kernel methods are inspired by convex risk minimization in
infinite dimensional Hilbert spaces. Leading examples are the
support vector machine based on the &lt;u&gt;&amp;#949;&lt;/u&gt;-insensitive loss function,
and kernel based quantile regression based on the pinball loss
function. Firstly, we propose with the Bouligand influence function
(BIF) a modification of F.R. Hampel's influence function. The BIF
has the advantage of being positive homogeneous which is in general
not true for Hampel's influence function. Secondly, we show that
many support vector machines based on a Lipschitz continuous loss
function and a bounded kernel have a bounded BIF and are thus robust
in the sense of robust statistics based on influence functions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/christmann08a/christmann08a.pdf</url></Article><Article><id>482</id><title>
Accelerated Neural Evolution through Cooperatively Coevolved Synapses
</title><author>Faustino Gomez, J&amp;#252;rgen Schmidhuber, Risto Miikkulainen</author><abstract>

Many complex control problems require sophisticated solutions that are not
amenable to traditional controller design.  Not only is it difficult
to model real world systems, but often it is unclear  what kind of
behavior is required to solve the task.  Reinforcement learning (RL)
approaches have made progress by using  direct interaction with
the task environment, but have so far not scaled well to large state
spaces and environments that are not fully observable.  In recent
years, neuroevolution, the artificial evolution of  neural networks,
has had remarkable success in tasks that exhibit these two properties.
In this paper, we compare a neuroevolution method
called Cooperative Synapse Neuroevolution (CoSyNE), that uses
cooperative coevolution at the level of individual synaptic weights,
to a broad range of reinforcement learning
algorithms on very difficult versions of the pole balancing problem
that involve large (continuous) state spaces and
hidden state.  CoSyNE is shown to be significantly more efficient and powerful
than the other methods on these tasks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/gomez08a/gomez08a.pdf</url></Article><Article><id>483</id><title>
Search for Additive Nonlinear Time Series Causal Models
</title><author>Tianjiao Chu, Clark Glymour</author><abstract>

Pointwise consistent, feasible procedures for estimating
contemporaneous linear causal structure from time series data have
been developed using multiple conditional independence tests, but no
such procedures are available for non-linear systems.  We describe a
feasible procedure for learning a class of non-linear time series
structures, which we call additive non-linear time series. We show
that for data generated from stationary models of this type, two
classes of conditional independence relations among time series
variables and their lags can be tested efficiently and consistently
using tests based on additive model regression. Combining results of
statistical tests for these two classes of conditional independence
relations and the temporal structure of time series data, a new
consistent model specification procedure is able to extract relatively
detailed causal information. We investigate the finite sample behavior
of the procedure through simulation, and illustrate the application of
this method through analysis of the possible causal connections among
four ocean indices. Several variants of the procedure are also
discussed.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chu08a/chu08a.pdf</url></Article><Article><id>484</id><title>
Shark
</title><author>Christian Igel, Verena Heidrich-Meisner, Tobias Glasmachers</author><abstract>

SHARK is an object-oriented library for the design of adaptive
systems. It comprises methods for single- and multi-objective
optimization (e.g., evolutionary and gradient-based algorithms) as
well as kernel-based methods, neural networks, and other machine
learning techniques.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/igel08a/igel08a.pdf</url></Article><Article><id>485</id><title>
Hit Miss Networks with Applications to Instance Selection
</title><author>Elena Marchiori</author><abstract>

In supervised learning, a training set consisting of labeled instances
is used by a learning algorithm for generating a model (classifier)
that is subsequently employed for deciding the class label of new
instances (for generalization).  Characteristics of the training set,
such as presence of noisy instances and size, influence the learning
algorithm and affect generalization performance. This paper introduces
a new network-based representation of a training set, called hit miss
network (HMN), which provides a compact description of the nearest
neighbor relation over pairs of instances from each pair of classes.
We show that structural properties of HMN's correspond to properties
of training points related to the one nearest neighbor (1-NN) decision
rule, such as being border or central point. This motivates us to use
HMN's for improving the performance of a 1-NN, classifier by removing
instances from the training set (instance selection).  We introduce
three new HMN-based algorithms for instance selection.  HMN-C, which
removes instances without affecting accuracy of 1-NN on the original
training set, HMN-E, based on a more aggressive storage reduction, and
HMN-EI, which applies iteratively HMN-E. Their performance is assessed
on 22 data sets with different characteristics, such as input
dimension, cardinality, class balance, number of classes, noise
content, and presence of redundant variables.  Results of experiments
on these data sets show that accuracy of 1-NN classifier increases
significantly when HMN-EI is applied. Comparison with
state-of-the-art editing algorithms for instance selection on these
data sets indicates best generalization performance of HMN-EI and no
significant difference in storage requirements. In general, these
results indicate that HMN's provide a powerful graph-based
representation of a training set, which can be successfully applied
for performing noise and redundance reduction in instance-based
learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/marchiori08a/marchiori08a.pdf</url></Article><Article><id>486</id><title>
Consistency of Trace Norm Minimization
</title><author>Francis R. Bach</author><abstract>

Regularization by the sum of singular values, also referred to as the
&lt;i&gt;trace norm&lt;/i&gt;, is a popular technique for estimating low rank
rectangular matrices. In this paper, we extend some of the consistency
results of the Lasso to provide necessary and sufficient conditions
for rank consistency of trace norm minimization with the square loss.
We also provide an adaptive version that is rank consistent even when
the necessary condition for the non adaptive version is not fulfilled.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bach08a/bach08a.pdf</url></Article><Article><id>487</id><title>
Learning Similarity with Operator-valued Large-margin Classifiers
</title><author>Andreas Maurer</author><abstract>

A method is introduced to learn and represent similarity with linear
operators in kernel induced Hilbert spaces. Transferring error bounds for
vector valued large-margin classifiers to the setting of Hilbert-Schmidt
operators leads to dimension free bounds on a risk functional for linear
representations and motivates a regularized objective functional.
Minimization of this objective is effected by a simple technique of
stochastic gradient descent. The resulting representations are tested on
transfer problems in image processing, involving plane and spatial geometric
invariants, handwritten characters and face recognition.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/maurer08a/maurer08a.pdf</url></Article><Article><id>488</id><title>
Ranking Categorical Features Using Generalization Properties
</title><author>Sivan Sabato, Shai Shalev-Shwartz</author><abstract>

Feature ranking is a fundamental machine learning task with various
applications, including feature selection and decision tree learning.
We describe and analyze a new feature ranking method that supports
categorical features with a large number of possible values. We show
that existing ranking criteria rank a feature according to the
&lt;i&gt;training&lt;/i&gt; error of a predictor based on the feature.  This
approach can fail when ranking categorical features with many values.
We propose the Ginger ranking criterion, that estimates the
&lt;i&gt;generalization&lt;/i&gt; error of the predictor associated with the Gini
index.  We show that for almost all training sets, the Ginger
criterion produces an accurate estimation of the true generalization
error, regardless of the number of values in a categorical feature. We
also address the question of finding the optimal predictor that is
based on a single categorical feature. It is shown that the predictor
associated with the misclassification error criterion has the minimal
expected generalization error. We bound the bias of this predictor
with respect to the generalization error of the Bayes optimal
predictor, and analyze its concentration properties.  We demonstrate
the efficiency of our approach for feature selection and for learning
decision trees in a series of experiments with synthetic and natural
data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/sabato08a/sabato08a.pdf</url></Article><Article><id>489</id><title>
A Multiple Instance Learning Strategy for Combating Good Word Attacks on Spam Filters
</title><author>Zach Jorgensen, Yan Zhou, Meador Inge</author><abstract>

Statistical spam filters are known to be vulnerable to adversarial
attacks. One of the more common adversarial attacks, known as
the &lt;i&gt;good word attack&lt;/i&gt;, thwarts spam filters by appending to
spam messages sets of "good" words, which are words that are common
in legitimate email but rare in spam. We present a counterattack
strategy that attempts to differentiate spam from
legitimate email in the input space by transforming each email
into a bag of multiple segments, and subsequently applying
multiple instance logistic regression on the bags. We
treat each segment in the bag as an instance. An email
is classified as spam if at least one instance in the corresponding
bag is spam, and as legitimate if all the instances
in it are legitimate. We show that a classifier using our
multiple instance counterattack strategy is more robust
to good word attacks than its single instance counterpart
and other single instance learners commonly used in the spam filtering domain.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/jorgensen08a/jorgensen08a.pdf</url></Article><Article><id>490</id><title>
Cross-Validation Optimization for Large Scale Structured Classification Kernel Methods
</title><author>Matthias W. Seeger</author><abstract>
&lt;p&gt;
We propose a highly efficient framework for penalized likelihood kernel
methods applied to multi-class models with a large, structured set of classes.
As opposed to many previous approaches which try to decompose the fitting
problem into many smaller ones, we focus on a Newton optimization of the
complete model, making use of model structure and linear conjugate gradients
in order to approximate Newton search directions. Crucially, our learning
method is based entirely on matrix-vector multiplication primitives with the
kernel matrices and their derivatives, allowing straightforward specialization
to new kernels, and focusing code optimization efforts to these primitives
only.
&lt;/p&gt;
&lt;p&gt;
Kernel parameters are learned automatically, by maximizing the cross-validation
log likelihood in a gradient-based way, and predictive probabilities are
estimated. We demonstrate our approach on large scale text classification
tasks with hierarchical structure on thousands of classes, achieving
state-of-the-art results in an order of magnitude less time than previous
work.
&lt;/p&gt;
&lt;p&gt;
Parts of this work appeared in the conference paper Seeger (2007).
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/seeger08b/seeger08b.pdf</url></Article><Article><id>491</id><title>
Consistency of the Group Lasso and Multiple Kernel Learning
</title><author>Francis R. Bach</author><abstract>

We consider the least-square regression problem with regularization by
a block &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm, that is, a sum of Euclidean norms over spaces
of dimensions larger than one.  This problem, referred to as the group
Lasso, extends the usual regularization by the &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm where all
spaces have dimension one, where it is commonly referred to as the
Lasso. In this paper, we study the asymptotic group selection
consistency of the group Lasso. We derive necessary and sufficient
conditions for the consistency of group Lasso under practical
assumptions, such as model mis specification. When the linear
predictors and Euclidean norms are replaced by functions and
reproducing kernel Hilbert norms, the problem is usually referred to
as multiple kernel learning and is commonly used for learning from
heterogeneous data sources and for non linear variable
selection. Using tools from functional analysis, and in particular
covar iance operators, we extend the consistency results to this
infinite dimensional case and also propose an adaptive scheme to
obtain a consistent model estimate, even when the necessary condition
required for the non adaptive scheme is not satisfied.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bach08b/bach08b.pdf</url></Article><Article><id>492</id><title>
Maximal Causes for Non-linear Component Extraction
</title><author>J&amp;#246;rg L&amp;#252;cke,  Maneesh Sahani</author><abstract>

We study a generative model in which hidden causes combine
competitively to produce observations.  Multiple active causes combine
to determine the value of an observed variable through a max
function, in the place where algorithms such as sparse coding,
independent component analysis, or non-negative matrix factorization
would use a sum.  This max rule can represent a more realistic
model of non-linear interaction between basic components in many
settings, including acoustic and image data.
While exact maximum-likelihood learning of the parameters of this
model proves to be intractable, we show that efficient
approximations to expectation-maximization (EM) can be found in the
case of sparsely active hidden causes.  One of these approximations
can be formulated as a neural network model with a generalized softmax
activation function and Hebbian learning.
Thus, we show that learning in recent softmax-like neural networks may
be interpreted as approximate maximization of a data likelihood.
We use the bars benchmark test to numerically verify our analytical
results and to demonstrate the competitiveness of the resulting
algorithms.
Finally, we show results of learning model parameters to fit acoustic
and visual data sets in which max-like component combinations arise
naturally.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/luecke08a/luecke08a.pdf</url></Article><Article><id>493</id><title>
Optimal Solutions for Sparse Principal Component Analysis
</title><author>Alexandre d'Aspremont, Francis Bach, Laurent El Ghaoui</author><abstract>

Given a sample covariance matrix, we examine the problem of maximizing
the variance explained by a linear combination of the input variables
while constraining the number of nonzero coefficients in this
combination. This is known as sparse principal component analysis and
has a wide array of applications in machine learning and
engineering. We formulate a new semidefinite relaxation to this
problem and derive a greedy algorithm that computes a &lt;i&gt;full set&lt;/i&gt;
of good solutions for all target numbers of non zero coefficients,
with total complexity &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;3&lt;/sup&gt;), where &lt;i&gt;n&lt;/i&gt;
is the number of variables. We then use the same relaxation to derive
sufficient conditions for global optimality of a solution, which can
be tested in &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;3&lt;/sup&gt;), per pattern. We discuss
applications in subset selection and sparse recovery and show on
artificial examples and biological data that our algorithm does
provide globally optimal solutions in many cases.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/aspremont08a/aspremont08a.pdf</url></Article><Article><id>494</id><title>
Using Markov Blankets for Causal Structure Learning
</title><author>Jean-Philippe Pellet, Andr&amp;#233; Elisseeff</author><abstract>

We show how a generic feature-selection algorithm returning strongly
relevant variables can be turned into a causal structure-learning
algorithm. We prove this under the Faithfulness assumption for the
data distribution. In a causal graph, the strongly relevant variables
for a node &lt;i&gt;X&lt;/i&gt; are its parents, children, and children's parents (or
spouses), also known as the Markov blanket of &lt;i&gt;X&lt;/i&gt;. Identifying the
spouses leads to the detection of the V-structure patterns and thus to
causal orientations. Repeating the task for all variables yields a
valid partially oriented causal graph. We first show an efficient way
to identify the spouse links. We then perform several experiments in
the continuous domain using the Recursive Feature Elimination
feature-selection algorithm with Support Vector Regression and
empirically verify the intuition of this direct (but computationally
expensive) approach. Within the same framework, we then devise a fast
and consistent algorithm, Total Conditioning (TC), and a variant,
TC&lt;sub&gt;bw&lt;/sub&gt;, with an explicit backward feature-selection heuristics, for
Gaussian data. After running a series of comparative experiments on
five artificial networks, we argue that Markov blanket algorithms such
as TC/TC&lt;sub&gt;bw&lt;/sub&gt; or Grow-Shrink scale better than the reference PC
algorithm and provides higher structural accuracy.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/pellet08a/pellet08a.pdf</url></Article><Article><id>495</id><title>
A Bahadur Representation of the Linear Support Vector Machine
</title><author>Ja-Yong Koo, Yoonkyung Lee, Yuwon Kim, Changyi Park</author><abstract>

The support vector machine has been successful in a variety of
applications. Also on the theoretical front, statistical properties
of the support vector machine have been studied quite extensively
with a particular attention to its Bayes risk consistency under some
conditions. In this paper, we study somewhat basic statistical
properties of the support vector machine yet to be investigated,
namely the asymptotic behavior of the coefficients of the linear
support vector machine. A Bahadur type representation of the
coefficients is established under appropriate conditions, and their
asymptotic normality and statistical variability are derived on the
basis of the representation. These asymptotic results do not only
help further our understanding of the support vector machine, but
also they can be useful for related statistical inferences.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/koo08a/koo08a.pdf</url></Article><Article><id>496</id><title>
Coordinate Descent Method for Large-scale L2-loss Linear Support Vector Machines
</title><author>Kai-Wei Chang, Cho-Jui Hsieh, Chih-Jen Lin</author><abstract>

Linear support vector machines (SVM) are useful for classifying
large-scale sparse data.  Problems with sparse features are common
in applications such as document classification and natural language
processing.  In this paper, we propose a novel coordinate descent
algorithm for training linear SVM with the L2-loss function.  
At each step, the proposed method minimizes a one-variable sub-problem
while fixing other variables.  The sub-problem is solved by Newton
steps with the line search technique.  The procedure globally
converges at the linear rate. 
As each sub-problem involves only values of a corresponding feature, the 
proposed approach is 
suitable when accessing a feature is 
more convenient than accessing an instance.
Experiments show that our method is more
efficient and stable than state of the art methods such as Pegasos
and TRON.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chang08a/chang08a.pdf</url></Article><Article><id>497</id><title>
Online Learning of Complex Prediction Problems Using Simultaneous Projections
</title><author>Yonatan Amit, Shai Shalev-Shwartz, Yoram Singer</author><abstract>

We describe and analyze an algorithmic framework for online classification
where each online trial consists of &lt;i&gt;multiple&lt;/i&gt; prediction tasks that are
tied together. We tackle the problem of updating the online predictor by
defining a projection problem in which each prediction task corresponds to a
single linear constraint. These constraints are tied together through a single
slack parameter. We then introduce a general method for approximately solving
the problem by projecting &lt;i&gt;simultaneously&lt;/i&gt; and independently on each
constraint which corresponds to a prediction sub-problem, and then averaging
the individual solutions. We show that this approach constitutes a feasible,
albeit not necessarily optimal, solution of the original projection problem.
We derive concrete simultaneous projection schemes and analyze them in the mistake
bound model. We demonstrate the power of the proposed algorithm in experiments
with synthetic data and with multiclass text categorization tasks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/amit08a/amit08a.pdf</url></Article><Article><id>498</id><title>
Causal Reasoning with Ancestral Graphs
</title><author>Jiji Zhang</author><abstract>

Causal reasoning is primarily concerned with what would
happen to a system under external interventions. In particular, we
are often interested in predicting the probability distribution of
some random variables that would result if some other variables
were &lt;i&gt;forced&lt;/i&gt; to take certain values. One prominent approach
to tackling this problem is based on causal Bayesian networks,
using directed acyclic graphs as &lt;i&gt;causal&lt;/i&gt; diagrams to relate
post-intervention probabilities to pre-intervention probabilities
that are estimable from observational data. However, such causal
diagrams are seldom fully testable given observational data. In
consequence, many causal discovery algorithms based on data-mining
can only output an equivalence class of causal diagrams (rather
than a single one). This paper is concerned with causal reasoning
given an equivalence class of causal diagrams, represented by a
(partial) &lt;i&gt;ancestral graph&lt;/i&gt;. We present two main results. The
first result extends Pearl (1995)'s celebrated &lt;i&gt;do-calculus&lt;/i&gt;
to the context of ancestral graphs. In the second result, we focus
on a key component of Pearl's calculus---the property of 
&lt;i&gt;invariance under interventions&lt;/i&gt;, and give stronger graphical
conditions for this property than those implied by the first
result. The second result also improves the earlier, similar
results due to Spirtes et al. (1993).

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/zhang08a/zhang08a.pdf</url></Article><Article><id>499</id><title>
Incremental Identification of Qualitative Models of Biological Systems using Inductive Logic Programming
</title><author>Ashwin Srinivasan, Ross D. King</author><abstract>

The use of computational models is
increasingly expected to play an important role in predicting the
behaviour of biological systems.
Models are being sought at different scales of biological
organisation namely: sub-cellular,
cellular, tissue, organ, organism and ecosystem; with a view of
identifying how different components are connected together, how they
are controlled and how they behave when functioning as a system. Except
for very simple biological processes, system identification from
first principles can be extremely difficult. This has brought into
focus automated techniques for constructing
models using data of system behaviour. Such techniques face three
principal issues: (1) The model representation language must be rich enough
to capture system behaviour; (2) The system identification technique
must be powerful enough to identify substantially complex models; and (3)
There may not be sufficient data to obtain both the model's structure
and precise estimates of all of its parameters. In this paper, we
address these issues
in the following ways: (1) Models are represented in an expressive
subset of first-order logic. Specifically, they are expressed as
logic programs; (2) System identification is done using techniques
developed in Inductive Logic Programming (ILP). This allows the
identification of first-order logic models from data. Specifically, we
employ an incremental approach in which increasingly complex models are
constructed from simpler ones using snapshots of system behaviour; and
(3) We restrict ourselves to "qualitative" models. These are
non-parametric: thus, usually less data are required than for
identifying parametric quantitative models. A further advantage
is that the data need not be precise numerical observations
(instead, they are abstractions like positive, negative, zero,
increasing, decreasing and so on).
We describe incremental construction
of qualitative models
using a simple physical system and demonstrate its application
to identification of models at four scales of biological
organisation, namely: (a) a predator-prey model at the ecosystem level;
(b) a model for the human lung at the organ level; (c) a model for regulation
of glucose by insulin in the human body at the extra-cellular
level; and (d) a model for
the glycolysis metabolic pathway at the cellular level.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/srinivasan08a/srinivasan08a.pdf</url></Article><Article><id>500</id><title>
Learning to Combine Motor Primitives Via Greedy Additive Regression
</title><author>Manu Chhabra, Robert A. Jacobs</author><abstract>

The computational complexities arising in motor control can be
ameliorated through the use of a library of motor synergies. We
present a new model, referred to as the Greedy Additive Regression
(GAR) model, for learning a library of torque sequences, and for
learning the coefficients of a linear combination of sequences
minimizing a cost function. From the perspective of numerical
optimization, the GAR model is interesting because it creates a
library of "local features"---each sequence in the library is a
solution to a single training task---and learns to combine these
sequences using a local optimization procedure, namely, additive
regression. We speculate that learners with local representational
primitives and local optimization procedures will show good
performance on nonlinear tasks. The GAR model is also interesting
from the perspective of motor control because it outperforms several
competing models. Results using a simulated two-joint arm suggest
that the GAR model consistently shows excellent performance in the
sense that it rapidly learns to perform novel, complex motor tasks.
Moreover, its library is overcomplete and sparse, meaning that only
a small fraction of the stored torque sequences are used when
learning a new movement. The library is also robust in the sense
that, after an initial training period, nearly all novel movements
can be learned as additive combinations of sequences in the library,
and in the sense that it shows good generalization when an arm's
dynamics are altered between training and test conditions, such as
when a payload is added to the arm. Lastly, the GAR model works well
regardless of whether motor tasks are specified in joint space or
Cartesian space. We conclude that learning techniques using local
primitives and optimization procedures are viable and potentially
important methods for motor control and possibly other domains, and
that these techniques deserve further examination by the artificial
intelligence and cognitive science communities.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/chhabra08a/chhabra08a.pdf</url></Article><Article><id>501</id><title>
Aggregation of SVM Classifiers Using Sobolev Spaces
</title><author>S&amp;#233;bastien Loustau</author><abstract>

&lt;p&gt;
This paper investigates statistical performances of Support Vector
Machines (SVM) and considers the problem of adaptation to the margin
parameter and to complexity. In particular we provide a classifier
with no tuning parameter. It is a combination of SVM classifiers.
&lt;/p&gt;
&lt;p&gt;
Our contribution is two-fold: (1) we propose learning rates for SVM
using Sobolev spaces and build a numerically realizable aggregate that
converges with same rate; (2) we present practical experiments of this
method of aggregation for SVM using both Sobolev spaces and Gaussian
kernels.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/loustau08a/loustau08a.pdf</url></Article><Article><id>502</id><title>
Dynamic Hierarchical Markov Random Fields for Integrated Web Data Extraction
</title><author>Jun Zhu, Zaiqing Nie, Bo Zhang, Ji-Rong Wen</author><abstract>

Existing template-independent web data extraction approaches adopt
highly ineffective decoupled strategies---attempting to do data
record detection and attribute labeling in two separate phases. In
this paper, we propose an integrated web data extraction paradigm
with hierarchical models. The proposed model is called Dynamic
Hierarchical Markov Random Fields (DHMRFs). DHMRFs take structural
uncertainty into consideration and define a joint distribution of
both model structure and class labels. The joint distribution is an
exponential family distribution. As a conditional model, DHMRFs
relax the independence assumption as made in directed models. Since
exact inference is intractable, a variational method is developed to
learn the model's parameters and to find the MAP model structure and
label assignments. We apply DHMRFs to a real-world web data
extraction task. Experimental results show that: (1) integrated web
data extraction models can achieve significant improvements on both
record detection and attribute labeling compared to decoupled
models; (2) in diverse web data extraction DHMRFs can potentially
address the blocky artifact issue which is suffered by
fixed-structured hierarchical models.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/zhu08a/zhu08a.pdf</url></Article><Article><id>503</id><title>
Universal Multi-Task Kernels
</title><author>Andrea Caponnetto, Charles A. Micchelli, Massimiliano Pontil, Yiming Ying</author><abstract>

In this paper we are concerned with reproducing kernel Hilbert
spaces &lt;i&gt;H&lt;sub&gt;K&lt;/sub&gt;&lt;/i&gt; of functions from an input space into a Hilbert
space &lt;i&gt;Y&lt;/i&gt;, an environment appropriate for multi-task
learning. The reproducing kernel &lt;i&gt;K&lt;/i&gt; associated to &lt;i&gt;H&lt;sub&gt;K&lt;/sub&gt;&lt;/i&gt; has
its values as operators on &lt;i&gt;Y&lt;/i&gt;. Our primary goal here is to
derive conditions which ensure that the kernel &lt;i&gt;K&lt;/i&gt; is universal.
This means that on every compact subset of the input space, every
continuous function with values in &lt;i&gt;Y&lt;/i&gt; can be uniformly
approximated by sections of the kernel. We provide various
characterizations of universal kernels and highlight them with
several concrete examples of some practical importance. Our analysis
uses basic principles of functional analysis and especially the
useful notion of vector measures which we describe in sufficient
detail to clarify our results.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/caponnetto08a/caponnetto08a.pdf</url></Article><Article><id>504</id><title>
A New Algorithm for Estimating the Effective Dimension-Reduction Subspace
</title><author>Arnak S. Dalalyan, Anatoly Juditsky, Vladimir Spokoiny</author><abstract>
&lt;p&gt;
The statistical problem of estimating the effective
dimension-reduction (EDR) subspace in the multi-index regression model
with deterministic design and additive noise is considered. A new
procedure for recovering the directions of the EDR subspace is
proposed.  Many methods for estimating the EDR subspace perform
principal component analysis on a family of vectors, say
&amp;#946;&lt;sub&gt;1&lt;/sub&gt;,...,&amp;#946;&lt;sub&gt;&lt;i&gt;L&lt;/i&gt;&lt;/sub&gt;, nearly lying in the EDR
subspace. This is in particular the case for the structure-adaptive
approach proposed by Hristache et al. (2001a). In the present work, we propose to
estimate the projector onto the EDR subspace by the solution to the
optimization problem 
&lt;/p&gt;
&lt;center&gt;
minimize max&lt;sub&gt;&lt;i&gt;l&lt;/i&gt;=1,...,&lt;i&gt;L&lt;/i&gt;&lt;/sub&gt;
&amp;#946;&lt;sub&gt;&lt;i&gt;l&lt;/i&gt;&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt; (&lt;i&gt;I&lt;/i&gt;-A)&amp;#946;&lt;sub&gt;&lt;i&gt;l&lt;/i&gt;&lt;/sub&gt;&amp;#160;&amp;#160;&amp;#160; subject to A &amp;#8712; &lt;i&gt;A&lt;sub&gt;m&lt;/sub&gt;&lt;/i&gt;
&lt;/center&gt;
&lt;p&gt;
where &lt;i&gt;A&lt;sub&gt;m&lt;/sub&gt;&lt;/i&gt; is the set of all
symmetric matrices with eigenvalues in [0,1] and trace less than or
equal to &lt;i&gt;m&lt;/i&gt;, with &lt;i&gt;m&lt;/i&gt; being the true structural dimension. Under
mild assumptions, &amp;#8730;&lt;i&gt;n&lt;/i&gt;-consistency of the proposed procedure is
proved (up to a logarithmic factor) in the case when the structural
dimension is not larger than 4.  Moreover, the stochastic error of
the estimator of the projector onto the EDR subspace is shown to
depend on &lt;i&gt;L&lt;/i&gt; logarithmically. This enables us to use a large number
of vectors &amp;#946;&lt;sub&gt;&lt;i&gt;l&lt;/i&gt;&lt;/sub&gt; for estimating the EDR subspace. The
empirical behavior of the algorithm is studied through numerical
simulations.
&lt;/p&gt;


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/dalalyan08a/dalalyan08a.pdf</url></Article><Article><id>505</id><title>
Value Function Based Reinforcement Learning in Changing Markovian Environments
</title><author>Bal&amp;#225;zs Csan&amp;#225;d Cs&amp;#225;ji, L&amp;#225;szl&amp;#243; Monostori</author><abstract>

The paper investigates the possibility of applying value function
based reinforcement learning (RL) methods in cases when the
environment may change over time. First, theorems are presented which
show that the optimal value function of a discounted Markov decision
process (MDP) Lipschitz continuously depends on the immediate-cost
function and the transition-probability function. Dependence on the
discount factor is also analyzed and shown to be
non-Lipschitz. Afterwards, the concept of (&amp;#949;,&amp;#948;)-MDPs
is introduced, which is a generalization of MDPs and
&amp;#949;-MDPs.  In this model the environment may change over
time, more precisely, the transition function and the cost function
may vary from time to time, but the changes must be bounded in the
limit. Then, learning algorithms in changing environments are
analyzed. A general relaxed convergence theorem for stochastic
iterative algorithms is presented. We also demonstrate the results
through three classical RL methods: asynchronous value iteration,
Q-learning and temporal difference learning. Finally, some numerical
experiments concerning changing environments are presented.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/csaji08a/csaji08a.pdf</url></Article><Article><id>506</id><title>
Regularization on Graphs with Function-adapted Diffusion Processes
</title><author>Arthur D. Szlam, Mauro Maggioni, Ronald R. Coifman</author><abstract>

Harmonic analysis and diffusion on discrete data has been shown to
lead to state-of-the-art algorithms for machine learning tasks,
especially in the context of semi-supervised and transductive
learning.  The success of these algorithms rests on the assumption
that the function(s) to be studied (learned, interpolated, etc.) are
smooth with respect to the geometry of the data. In this paper we
present a method for modifying the given geometry so the function(s)
to be studied are smoother with respect to the modified geometry,
and thus more amenable to treatment using harmonic analysis methods.
Among the many possible applications, we consider the problems of
image denoising and transductive classification.  In both settings,
our approach improves on standard diffusion based methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/szlam08a/szlam08a.pdf</url></Article><Article><id>507</id><title>
Nearly Uniform Validation Improves Compression-Based Error Bounds
</title><author>Eric Bax</author><abstract>

This paper develops bounds on out-of-sample error rates for support
vector machines (SVMs). The bounds are based on the numbers of support
vectors in the SVMs rather than on VC dimension. The bounds developed
here improve on support vector counting bounds derived using
Littlestone and Warmuth's compression-based bounding technique.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bax08b/bax08b.pdf</url></Article><Article><id>508</id><title>
Learning from Multiple Sources
</title><author>Koby Crammer, Michael Kearns, Jennifer Wortman</author><abstract>

We consider the problem of learning accurate models from multiple
sources of "nearby" data. Given distinct samples from multiple data
sources and estimates of the dissimilarities between these sources, we
provide a general theory of which samples should be used to learn
models for each source. This theory is applicable in a broad
decision-theoretic learning framework, and yields general results for
classification and regression.  A key component of our approach is the
development of approximate triangle inequalities for expected loss,
which may be of independent interest.  We discuss the related problem
of learning parameters of a distribution from multiple data sources.
Finally, we illustrate our theory through a series of synthetic
simulations.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/crammer08a/crammer08a.pdf</url></Article><Article><id>509</id><title>
Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks
</title><author>Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras, Peter L. Bartlett</author><abstract>

Log-linear and maximum-margin models are two commonly-used methods in
supervised machine learning, and are frequently used in structured
prediction problems.  Efficient learning of parameters in these models
is therefore an important problem, and becomes a key factor when
learning from very large data sets.  This paper describes
exponentiated gradient (EG) algorithms for training such models, where
EG updates are applied to the convex dual of either the log-linear or
max-margin objective function; the dual in both the log-linear and
max-margin cases corresponds to minimizing a convex function with
simplex constraints.  We study both batch and online variants of the
algorithm, and provide rates of convergence for both cases.  In the
max-margin case, &lt;i&gt;O&lt;/i&gt;(1/&amp;#949;) EG updates are required to
reach a given accuracy &amp;#949; in the dual; in contrast, for
log-linear models only &lt;i&gt;O&lt;/i&gt;(log(1/&amp;#949;)) updates are
required. For both the max-margin and log-linear cases, our bounds
suggest that the online EG algorithm requires a factor of &lt;i&gt;n&lt;/i&gt; less
computation to reach a desired accuracy than the batch EG algorithm,
where &lt;i&gt;n&lt;/i&gt; is the number of training examples. Our experiments confirm
that the online algorithms are much faster than the batch algorithms
in practice.  We describe how the EG updates factor in a convenient
way for structured prediction problems, allowing the algorithms to be
efficiently applied to problems such as sequence learning or natural
language parsing.  We perform extensive evaluation of the algorithms,
comparing them to L-BFGS and stochastic gradient descent for
log-linear models, and to SVM-Struct for max-margin
models. The algorithms are applied to a multi-class
problem as well as to a more complex large-scale parsing task. In all
these settings, the EG algorithms presented here outperform the other
methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/collins08a/collins08a.pdf</url></Article><Article><id>510</id><title>
Classification with a Reject Option using a Hinge Loss
</title><author>Peter L. Bartlett, Marten H. Wegkamp</author><abstract>

We consider the problem of binary classification where the
classifier can, for a particular cost, choose not to classify an
observation. Just as in the conventional classification problem,
minimization of the sample average of the cost is a difficult
optimization problem. As an alternative, we propose the optimization
of a certain convex loss function &amp;#966;, analogous to the hinge
loss used in support vector machines (SVMs). Its convexity ensures
that the sample average of this surrogate loss can be efficiently
minimized. We study its statistical properties. We show that
minimizing the expected surrogate loss&amp;#151;the &amp;#966;-risk&amp;#151;also
minimizes the risk.  We also study the rate at which the &amp;#966;-risk
approaches its minimum value. We show that fast rates are possible
when the conditional probability &lt;i&gt;P&lt;/i&gt;(&lt;i&gt;Y&lt;/i&gt;=1|&lt;i&gt;X&lt;/i&gt;) is unlikely to be
close to certain critical values.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bartlett08a/bartlett08a.pdf</url></Article><Article><id>511</id><title>
Learning Balls of Strings from Edit Corrections
</title><author>Leonor Becerra-Bonache, Colin de la Higuera, Jean-Christophe Janodet, Fr&amp;#233;d&amp;#233;ric Tantini</author><abstract>

When facing the question of learning languages in realistic settings,
one has to tackle several problems that do not admit simple
solutions. On the one hand, languages are usually defined by complex
grammatical mechanisms for which the learning results are
predominantly negative, as the few algorithms are not really able to
cope with noise. On the other hand, the learning settings themselves
rely either on too simple information (text) or on unattainable one
(query systems that do not exist in practice, nor can be
simulated). We consider simple but sound classes of languages defined
via the widely used edit distance: the balls of strings. We propose to
learn them with the help of a new sort of queries, called the
correction queries: when a string is submitted to the Oracle, either
she accepts it if it belongs to the target language, or she proposes a
correction, that is, a string of the language close to the query with
respect to the edit distance. We show that even if the good balls are
not learnable in Angluin's M&lt;small&gt;AT&lt;/small&gt; model, they can be learned
from a polynomial number of correction queries. Moreover, experimental
evidence simulating a human Expert shows that this algorithm is
resistant to approximate answers.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/becerra-bonache08a/becerra-bonache08a.pdf</url></Article><Article><id>512</id><title>
LIBLINEAR: A Library for Large Linear Classification
</title><author>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, Chih-Jen Lin</author><abstract>

LIBLINEAR is an open source library for large-scale linear
classification.  It supports logistic regression and linear support
vector machines.  We provide easy-to-use command-line tools and
library calls for users and developers.  
Comprehensive documents are available for both beginners and advanced
users.  Experiments demonstrate that LIBLINEAR is very efficient on
large sparse data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/fan08a/fan08a.pdf</url></Article><Article><id>513</id><title>
On Relevant Dimensions in Kernel Feature Spaces
</title><author>Mikio L. Braun, Joachim M. Buhmann, Klaus-Robert M&amp;#252;ller</author><abstract>

We show that the relevant information of a supervised learning problem
is contained up to negligible error in a finite number of leading
kernel PCA components if the kernel matches the underlying learning
problem in the sense that it can asymptotically represent the function
to be learned and is sufficiently smooth.  Thus, kernels do not only
transform data sets such that good generalization can be achieved
using only linear discriminant functions, but this transformation is
also performed in a manner which makes economical use of feature space
dimensions. In the best case, kernels provide efficient implicit
representations of the data for supervised learning problems.
Practically, we propose an algorithm which enables us to recover the
number of leading kernel PCA components relevant for good
classification. Our algorithm can therefore be applied (1) to analyze
the interplay of data set and kernel in a geometric fashion, (2) to
aid in model selection, and (3) to denoise in feature space in order
to yield better classification results.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/braun08a/braun08a.pdf</url></Article><Article><id>514</id><title>
Manifold Learning: The Price of Normalization
</title><author>Yair Goldberg, Alon Zakai, Dan Kushnir, Ya'acov Ritov</author><abstract>

We analyze the performance of a class of manifold-learning
algorithms that find their output by minimizing a quadratic form
under some normalization constraints. This class consists of
Locally Linear Embedding (LLE), Laplacian Eigenmap, Local Tangent
Space Alignment (LTSA), Hessian Eigenmaps (HLLE), and Diffusion
maps. We present and prove conditions on the manifold that are
necessary for the success of the algorithms. Both the finite
sample case and the limit case are analyzed. We show that there
are simple manifolds in which the necessary conditions are
violated, and hence the algorithms cannot recover the underlying
manifolds. Finally, we present numerical results that demonstrate
our claims.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/goldberg08a/goldberg08a.pdf</url></Article><Article><id>515</id><title>
Complete Identification Methods for the Causal Hierarchy
</title><author>Ilya Shpitser, Judea Pearl</author><abstract>

We consider a hierarchy of queries about causal relationships in
graphical models, where each level in the hierarchy
requires more detailed information than the one below.
The hierarchy consists of three
levels: associative relationships, derived from a joint distribution
over the observable variables;
cause-effect relationships, derived from distributions resulting
from external interventions; and
counterfactuals, derived from distributions that span multiple
"parallel worlds" and resulting from simultaneous, possibly
conflicting observations and interventions.
We completely characterize cases where a given causal query can be computed
from information lower in the hierarchy, and provide algorithms that
accomplish this computation.  Specifically, we show when effects of
interventions can be computed from observational studies, and when
probabilities of counterfactuals can be computed from experimental
studies.  We also provide a graphical characterization of those queries which
cannot be computed (by any method) from queries at a lower layer of the
hierarchy.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/shpitser08a/shpitser08a.pdf</url></Article><Article><id>516</id><title>
Mixed Membership Stochastic Blockmodels
</title><author>Edoardo M. Airoldi, David M. Blei, Stephen E. Fienberg, Eric P. Xing</author><abstract>

Consider data consisting of pairwise measurements, such as presence or
absence of links between pairs of objects.  These data arise, for
instance, in the analysis of protein interactions and gene regulatory
networks, collections of author-recipient email, and social networks.
Analyzing pairwise measurements with probabilistic models requires
special assumptions, since the usual independence or exchangeability
assumptions no longer hold.  Here we introduce a class of variance
allocation models for pairwise measurements: mixed membership
stochastic blockmodels.  These models combine global parameters that
instantiate dense patches of connectivity (blockmodel) with local
parameters that instantiate node-specific variability in the
connections (mixed membership). We develop a general variational
inference algorithm for fast approximate posterior inference. We
demonstrate the advantages of mixed membership stochastic blockmodels
with applications to social networks and protein interaction networks.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/airoldi08a/airoldi08a.pdf</url></Article><Article><id>517</id><title>
Consistency of Random Forests and Other Averaging Classifiers
</title><author>G&amp;#233;rard Biau, Luc Devroye, G&amp;#225;bor Lugosi</author><abstract>

In the last years of his life, Leo Breiman promoted random forests for
use in classification. He suggested using averaging as a means of
obtaining good discrimination rules.  The base classifiers used for
averaging are simple and randomized, often based on random samples
from the data.  He left a few questions unanswered regarding the
consistency of such rules. In this paper, we give a number of theorems
that establish the universal consistency of averaging rules. We also
show that some popular classifiers, including one suggested by
Breiman, are not universally consistent.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/biau08a/biau08a.pdf</url></Article><Article><id>518</id><title>
Approximations for Binary Gaussian Process Classification
</title><author>Hannes Nickisch, Carl Edward Rasmussen</author><abstract>

We provide a comprehensive overview of many recent algorithms
for approximate inference in Gaussian process models for probabilistic
binary classification. The relationships between several approaches
are elucidated theoretically, and the properties of the different
algorithms are corroborated by experimental results. We examine both
1) the quality of the predictive distributions and 2) the suitability
of the different marginal likelihood approximations for model selection
(selecting hyperparameters) and compare to a gold standard based on
MCMC. Interestingly, some methods produce good predictive distributions
although their marginal likelihood approximations are poor. Strong
conclusions are drawn about the methods: The Expectation Propagation
algorithm is almost always the method of choice unless the computational
budget is very tight. We also extend existing methods in various ways,
and provide unifying code implementing all approaches.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/nickisch08a/nickisch08a.pdf</url></Article><Article><id>519</id><title>
Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management
</title><author>Abraham George, Warren B. Powell, Sanjeev R. Kulkarni</author><abstract>

We consider the problem of estimating the value of a multiattribute
resource, where the attributes are categorical or discrete in nature
and the number of potential attribute vectors is very large. The
problem arises in approximate dynamic programming when we need to
estimate the value of a multiattribute resource from estimates based
on Monte-Carlo simulation. These problems have been traditionally
solved using aggregation, but choosing the right level of aggregation
requires resolving the classic tradeoff between aggregation error and
sampling error.  We propose a method that estimates the value of a
resource at different levels of aggregation simultaneously, and then
uses a weighted combination of the estimates.  Using the optimal
weights, which minimizes the variance of the estimate while accounting
for correlations between the estimates, is computationally too
expensive for practical applications.  We have found that a simple
inverse variance formula (adjusted for bias), which effectively
assumes the estimates are independent, produces near-optimal
estimates.  We use the setting of two levels of aggregation to explain
why this approximation works so well.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/george08a/george08a.pdf</url></Article><Article><id>520</id><title>
Gradient Tree Boosting for Training Conditional Random Fields
</title><author>Thomas G. Dietterich, Guohua Hao, Adam Ashenfelter</author><abstract>

Conditional random fields (CRFs) provide a flexible and powerful model
for sequence labeling problems.  However, existing learning algorithms
are slow, particularly in problems with large numbers of potential
input features and feature combinations.  This paper describes a new
algorithm for training CRFs via gradient tree boosting. In tree
boosting, the CRF potential functions are represented as weighted sums
of regression trees, which provide compact representations of feature
interactions.  So the algorithm does not explicitly consider the
potentially large parameter space.  As a result, gradient tree
boosting scales linearly in the order of the Markov model and in the
order of the feature interactions, rather than exponentially as in
previous algorithms based on iterative scaling and gradient descent.
Gradient tree boosting also makes it possible to use instance
weighting (as in C4.5) and surrogate splitting (as in CART) to handle
missing values.  Experimental studies of the effectiveness of these
two methods (as well as standard imputation and indicator feature
methods) show that instance weighting is the best method in most cases
when feature values are missing at random.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/dietterich08a/dietterich08a.pdf</url></Article><Article><id>521</id><title>
HPB: A Model for Handling BN Nodes with High Cardinality Parents
</title><author>Jorge Jambeiro Filho, Jacques Wainer</author><abstract>

We replaced the conditional probability tables of Bayesian network
nodes whose parents have high cardinality with a multilevel empirical
hierarchical Bayesian model called hierarchical pattern Bayes (HPB).
The resulting Bayesian networks achieved significant performance
improvements over Bayesian networks with the same structure and
traditional conditional probability tables, over Bayesian networks
with simpler structures like na&amp;#239;ve Bayes and tree augmented na&amp;#239;ve
Bayes, over Bayesian networks where traditional conditional
probability tables were substituted by noisy-OR gates, default tables,
decision trees and decision graphs and over Bayesian networks
constructed after a cardinality reduction preprocessing phase using
the agglomerative information bottleneck method. Our main tests took
place in important fraud detection domains, which are characterized by
the presence of high cardinality attributes and by the existence of
relevant interactions among them. Other tests, over UCI data sets,
show that HPB may have a quite wide applicability.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/jambeiro08a/jambeiro08a.pdf</url></Article><Article><id>522</id><title>
A Moment Bound for Multi-hinge Classifiers
</title><author>Bernadetta Tarigan, Sara A. van de Geer</author><abstract>

The success of support vector machines in binary classification relies on
the fact that hinge loss employed in the risk minimization targets the
Bayes rule. Recent research explores some extensions of this large margin
based method to the multicategory case. We show a moment bound for
the so-called multi-hinge loss minimizers based on
two kinds of complexity constraints: entropy with bracketing and empirical
entropy. Obtaining such a result based on the latter is harder than finding
one based on the former. We obtain fast rates of convergence that adapt to the 
unknown margin.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/tarigan08a/tarigan08a.pdf</url></Article><Article><id>523</id><title>
Ranking Individuals by Group Comparisons
</title><author>Tzu-Kuo Huang, Chih-Jen Lin, Ruby C. Weng</author><abstract>

This paper proposes new approaches to rank individuals from their
group comparison results. Many real-world problems are of this
type. For example, ranking players from team comparisons is important
in some sports.  In machine learning, a closely related application is
classification using coding matrices. Group comparison results are
usually in two types: binary indicator outcomes (wins/losses) or
measured outcomes (scores).  For each type of results, we propose new
models for estimating individuals' abilities, and hence a ranking of
individuals. The estimation is carried out by solving convex
minimization problems, for which we develop easy and efficient
solution procedures. Experiments on real bridge records and
multi-class classification demonstrate the viability of the proposed
models.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/huang08a/huang08a.pdf</url></Article><Article><id>524</id><title>
Forecasting Web Page Views: Methods and Observations
</title><author>Jia Li, Andrew W. Moore</author><abstract>

Web sites must forecast Web page views in order to plan computer
resource allocation and estimate upcoming revenue and advertising
growth.  In this paper, we focus on extracting trends and seasonal
patterns from page view series, two dominant factors in the variation
of such series.  We investigate the Holt-Winters procedure and a state
space model for making relatively short-term prediction.  It is found
that Web page views exhibit strong impulsive changes occasionally.
The impulses cause large prediction errors long after their
occurrences.  A method is developed to identify impulses and to
alleviate their damage on prediction.  We also develop a long-range
trend and season extraction method, namely the &lt;i&gt;Elastic Smooth
Season Fitting (ESSF)&lt;/i&gt; algorithm, to compute scalable and smooth
yearly seasons.  ESSF derives the yearly season by minimizing the
residual sum of squares under smoothness regularization, a quadratic
optimization problem.  It is shown that for long-term prediction, ESSF
improves accuracy significantly over other methods that ignore the
yearly seasonality.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/li08a/li08a.pdf</url></Article><Article><id>525</id><title>
Finding Optimal Bayesian Network Given a Super-Structure
</title><author>Eric Perrier, Seiya Imoto, Satoru Miyano</author><abstract>

Classical approaches used to learn Bayesian network structure from
data have disadvantages in terms of complexity and lower accuracy of
their results. However, a recent empirical study has shown that a
hybrid algorithm improves sensitively accuracy and speed: it learns a
skeleton with an independency test (IT) approach and constrains on the
directed acyclic graphs (DAG) considered during the search-and-score
phase. Subsequently, we theorize the structural constraint by
introducing the concept of super-structure &lt;i&gt;S&lt;/i&gt;, which is an
undirected graph that restricts the search to networks whose skeleton
is a subgraph of &lt;i&gt;S&lt;/i&gt;. We develop a super-structure constrained
optimal search (COS): its time complexity is upper bounded by
&lt;i&gt;O&lt;/i&gt;(&amp;#947;&lt;i&gt;&lt;sub&gt;m&lt;/sub&gt;&lt;sup&gt;n&lt;/sup&gt;&lt;/i&gt;), where
&amp;#947;&lt;sub&gt;&lt;i&gt;m&lt;/i&gt;&lt;/sub&gt;&amp;lt;2 depends on the maximal degree &lt;i&gt;m&lt;/i&gt; of
&lt;i&gt;S&lt;/i&gt;. Empirically, complexity depends on the average degree
&lt;i&gt;m-tilde&lt;/i&gt; and sparse structures allow larger graphs to be
calculated. Our algorithm is faster than an optimal search by several
orders and even finds more accurate results when given a sound
super-structure. Practically, &lt;i&gt;S&lt;/i&gt; can be approximated by IT
approaches; significance level of the tests controls its sparseness,
enabling to control the trade-off between speed and accuracy. For
incomplete super-structures, a greedily post-processed version (COS+)
still enables to significantly outperform other heuristic searches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/perrier08a/perrier08a.pdf</url></Article><Article><id>526</id><title>
Randomized Online PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension
</title><author>Manfred K. Warmuth, Dima Kuzmin</author><abstract>
&lt;p&gt;
We design an online algorithm for Principal Component
Analysis. In each trial
the current instance is centered and projected into
a probabilistically chosen low dimensional subspace.
The regret of our online algorithm,
that is, the total expected quadratic compression loss of the
online algorithm minus the total quadratic compression loss
of the batch algorithm, is bounded 
by a term whose dependence on the dimension of the 
instances is only logarithmic.
&lt;/p&gt;
&lt;p&gt;
We first develop our methodology in the expert setting of online
learning by giving an algorithm for learning as well
as the best subset of experts of a certain size. 
This algorithm is then lifted to the matrix setting where
the subsets of experts correspond to subspaces.
The algorithm represents the uncertainty over the best subspace
as a density matrix whose eigenvalues are bounded.
The running time is &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;) per trial, where
&lt;i&gt;n&lt;/i&gt; is the dimension of the instances.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/warmuth08a/warmuth08a.pdf</url></Article><Article><id>527</id><title>
Probabilistic Characterization of Random Decision Trees
</title><author>Amit Dhurandhar, Alin Dobra</author><abstract>

In this paper we use the methodology introduced by Dhurandhar and Dobra (2009) for
analyzing the error of classifiers and the model selection measures,
to analyze decision tree algorithms. The methodology consists of
obtaining parametric expressions for the moments of the generalization
error (GE) for the classification model of interest, followed by
plotting these expressions for interpretability. The major challenge
in applying the methodology to decision trees, the main theme of this
work, is customizing the generic expressions for the moments of GE to
this particular classification algorithm.  The specific contributions
we make in this paper are: (a) we primarily characterize a subclass of
decision trees namely, Random decision trees, (b) we discuss how the
analysis extends to other decision tree algorithms and (c) in order to
extend the analysis to certain model selection measures, we generalize
the relationships between the moments of GE and moments of the model
selection measures given in (Dhurandhar and Dobra, 2009) to randomized classification
algorithms.  An empirical comparison of the proposed method with Monte
Carlo and distribution free bounds obtained using Breiman's formula,
depicts the advantages of the method in terms of running time and
accuracy. It thus showcases the use of the deployed methodology as an
exploratory tool to study learning algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/dhurandhar08a/dhurandhar08a.pdf</url></Article><Article><id>528</id><title>
Learning to Select Features using their Properties
</title><author>Eyal Krupka, Amir Navot, Naftali Tishby</author><abstract>

Feature selection is the task of choosing a small subset of features
that is sufficient to predict the target labels well. Here, instead
of trying to directly determine which features are better, we attempt
to learn the properties of good features. For this purpose we assume
that each feature is represented by a set of properties, referred
to as &lt;i&gt;meta-features&lt;/i&gt;. This approach enables prediction of the
quality of features without measuring their value on the training
instances. We use this ability to devise new selection algorithms
that can efficiently search for new good features in the presence
of a huge number of features, and to dramatically reduce the number
of feature measurements needed. We demonstrate our algorithms on a
handwritten digit recognition problem and a visual object category
recognition problem. In addition, we show how this novel viewpoint
enables derivation of better generalization bounds for the joint learning
problem of selection and classification, and how it contributes to
a better understanding of the problem. Specifically, in the context
of object recognition, previous works showed that it is possible to
find one set of features which fits most object categories (aka a
&lt;i&gt;universal dictionary&lt;/i&gt;). Here we use our framework to analyze
one such universal dictionary and find that the quality of features
in this dictionary can be predicted accurately by its meta-features.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/krupka08b/krupka08b.pdf</url></Article><Article><id>529</id><title>
Model Selection in Kernel Based Regression using the Influence Function
</title><author>Michiel Debruyne, Mia Hubert, Johan A.K. Suykens</author><abstract>

Recent results about the robustness of kernel methods involve the
analysis of influence functions. By definition the influence function
is closely related to leave-one-out criteria.  In statistical
learning, the latter is often used to assess the generalization of a
method. In statistics, the influence function is used in a similar way
to analyze the statistical efficiency of a method. Links between both
worlds are explored. The influence function is related to the first
term of a Taylor expansion. Higher order influence functions are
calculated. A recursive relation between these terms is found
characterizing the full Taylor expansion. It is shown how to evaluate
influence functions at a specific sample distribution to obtain an
approximation of the leave-one-out error. A specific implementation is
proposed using a &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; loss in the selection of the hyperparameters
and a Huber loss in the estimation procedure.  The parameter in the
Huber loss controlling the degree of robustness is optimized as
well. The resulting procedure gives good results, even when outliers
are present in the data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/debruyne08a/debruyne08a.pdf</url></Article><Article><id>530</id><title>
Non-Parametric Modeling of Partially Ranked Data
</title><author>Guy Lebanon, Yi Mao</author><abstract>

Statistical models on full and partial rankings of &lt;i&gt;n&lt;/i&gt; items are
often of limited practical use for large &lt;i&gt;n&lt;/i&gt; due to computational
consideration. We explore the use of non-parametric models for
partially ranked data and derive computationally efficient
procedures for their use for large &lt;i&gt;n&lt;/i&gt;. The derivations are
largely possible through combinatorial and algebraic manipulations
based on the lattice of partial rankings. A bias-variance analysis
and an experimental study demonstrate the applicability of the
proposed method.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/lebanon08a/lebanon08a.pdf</url></Article><Article><id>531</id><title>
On the Size and Recovery of Submatrices of Ones in a Random Binary Matrix
</title><author>Xing Sun, Andrew B. Nobel</author><abstract>

Binary matrices, and their associated submatrices of 1s, play a
central role in the study of random bipartite graphs and in core data
mining problems such as frequent itemset mining (FIM).  Motivated by
these connections, this paper addresses several statistical questions
regarding submatrices of 1s in a random binary matrix with independent
Bernoulli entries.  We establish a three-point concentration result,
and a related probability bound, for the size of the largest square
submatrix of 1s in a square Bernoulli matrix, and extend these results
to non-square matrices and submatrices with fixed aspect ratios.  We
then consider the noise sensitivity of frequent itemset mining under a
simple binary additive noise model, and show that, even at small noise
levels, large blocks of 1s leave behind fragments of only logarithmic
size.  As a result, standard FIM algorithms, which search only for
submatrices of 1s, cannot directly recover such blocks when noise is
present.  On the positive side, we show that an error-tolerant
frequent itemset criterion can recover a submatrix of 1s against a
background of 0s plus noise, even when the size of the submatrix of 1s
is very small.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/sun08a/sun08a.pdf</url></Article><Article><id>532</id><title>
Minimal Nonlinear Distortion Principle for Nonlinear Independent Component Analysis
</title><author>Kun Zhang, Laiwan Chan</author><abstract>

It is well known that solutions to the nonlinear independent
component analysis (ICA) problem are highly non-unique. In this
paper we propose the "minimal nonlinear distortion" (MND)
principle for tackling the ill-posedness of nonlinear ICA
problems. MND prefers the nonlinear ICA solution with the
estimated mixing procedure as close as possible to linear,
among all possible solutions.
 It also helps to avoid local optima in the
solutions. To achieve MND, we exploit a regularization term to
minimize the mean square error between the nonlinear mixing
mapping and the best-fitting linear one. The effect of MND on
the inherent trivial and non-trivial indeterminacies in
nonlinear ICA solutions is investigated. Moreover, we show that
local MND is closely related to the smoothness regularizer
penalizing large curvature, which provides another useful
regularization
condition for nonlinear ICA.
Experiments on synthetic data show the usefulness of the MND
principle for separating various nonlinear mixtures.
Finally, as an application, we use nonlinear ICA with MND to
separate daily returns of a set of stocks in Hong Kong, and the
linear causal relations among them are successfully discovered.
The resulting causal relations give some interesting insights
into the stock market. Such a result can not be achieved by
linear ICA. Simulation studies also verify that when doing
causality discovery, sometimes one should not ignore the
nonlinear distortion in the data generation procedure, even if
it is weak.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/zhang08b/zhang08b.pdf</url></Article><Article><id>533</id><title>
On the Equivalence of Linear Dimensionality-Reducing Transformations
</title><author>Marco Loog</author><abstract>

In this JMLR volume, Ye (2008) demonstrates the essential
equivalence of two sets of solutions to a generalized Fisher criterion
used for linear dimensionality reduction (see Ye, 2005; Loog, 2007).
Here, I point out the basic flaw in this new contribution.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/loog08a/loog08a.pdf</url></Article><Article><id>534</id><title>
SimpleMKL
</title><author>Alain Rakotomamonjy, Francis R. Bach, St&amp;#233;phane Canu, Yves Grandvalet</author><abstract>

Multiple kernel learning (MKL) aims at simultaneously learning a
kernel and the associated predictor in supervised learning
settings. For the support vector machine, an efficient and general
multiple kernel learning algorithm, based on semi-infinite linear
programming, has been recently proposed.  This approach has opened new
perspectives since it makes MKL tractable for large-scale problems, by
iteratively using existing support vector machine code. However, it
turns out that this iterative algorithm needs numerous iterations for
converging towards a reasonable solution.  In this paper, we address
the MKL problem through a weighted 2-norm regularization formulation
with an additional constraint on the weights that encourages sparse
kernel combinations.  Apart from learning the combination, we solve a
standard SVM optimization problem, where the kernel is defined as a
linear combination of multiple kernels.  We propose an algorithm,
named SimpleMKL, for solving this MKL problem and provide a new
insight on MKL algorithms based on mixed-norm regularization by
showing that the two approaches are equivalent.  We show how SimpleMKL
can be applied beyond binary classification, for problems like
regression, clustering (one-class classification) or multiclass
classification.  Experimental results show that the proposed algorithm
converges rapidly and that its efficiency compares favorably to other
MKL algorithms.  Finally, we illustrate the usefulness of MKL for some
regressors based on wavelet kernels and on some model selection
problems related to multiclass classification problems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/rakotomamonjy08a/rakotomamonjy08a.pdf</url></Article><Article><id>535</id><title>
Active Learning of Causal Networks with Intervention Experiments and Optimal Designs
</title><author>Yang-Bo He, Zhi Geng</author><abstract>

The causal discovery from data is important for various scientific
investigations. Because we cannot distinguish the different directed
acyclic graphs (DAGs) in a Markov equivalence class learned from
observational data, we have to collect further information on causal
structures from experiments with external interventions. In this
paper, we propose an active learning approach for discovering causal
structures in which we first find a Markov equivalence class from
observational data, and then we orient undirected edges in every
chain component via intervention experiments separately. In the
experiments, some variables are manipulated through external
interventions. We discuss two kinds of intervention experiments,
randomized experiment and quasi-experiment. Furthermore, we give two
optimal designs of experiments, a batch-intervention design and a
sequential-intervention design, to minimize the number of
manipulated variables and the set of candidate structures based on
the minimax and the maximum entropy criteria. We show theoretically
that structural learning can be done locally in subgraphs of chain
components without need of checking illegal v-structures and cycles
in the whole network and that a Markov equivalence subclass obtained
after each intervention can still be depicted as a chain graph.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/he08a/he08a.pdf</url></Article><Article><id>536</id><title>
Stationary Features and Cat Detection
</title><author>Fran&amp;#231;ois Fleuret, Donald Geman</author><abstract>
&lt;p&gt;
Most discriminative techniques for detecting instances from object
categories in still images consist of looping over a partition of a
pose space with dedicated binary classifiers. The efficiency of this
strategy for a complex pose, that is, for fine-grained descriptions, can
be assessed by measuring the effect of sample size and pose resolution
on accuracy and computation. Two conclusions emerge: (1) fragmenting
the training data, which is inevitable in dealing with high in-class
variation, severely reduces accuracy; (2) the computational cost at
high resolution is prohibitive due to visiting a massive pose
partition.
&lt;/p&gt;
&lt;p&gt;
To overcome data-fragmentation we propose a novel framework centered
on pose-indexed features which assign a response to a pair consisting
of an image and a pose, and are designed to be stationary: the
probability distribution of the response is always the same if an
object is actually present. Such features allow for efficient,
one-shot learning of pose-specific classifiers. To avoid expensive
scene processing, we arrange these classifiers in a hierarchy based on
nested partitions of the pose; as in previous work on coarse-to-fine
search, this allows for efficient processing.
&lt;/p&gt;
&lt;p&gt;
The hierarchy is then "folded" for training: all the classifiers at
each level are derived from one base predictor learned from all the
data. The hierarchy is "unfolded" for testing: parsing a scene amounts
to examining increasingly finer object descriptions only when there is
sufficient evidence for coarser ones. In this way, the detection
results are equivalent to an exhaustive search at high resolution. We
illustrate these ideas by detecting and localizing cats in highly
cluttered greyscale scenes.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/fleuret08a/fleuret08a.pdf</url></Article><Article><id>537</id><title>
Visualizing Data using t-SNE
</title><author>Laurens van der Maaten, Geoffrey Hinton</author><abstract>

We present a new technique called "t-SNE" that visualizes
high-dimensional data by giving each datapoint a location in a two or
three-dimensional map. The technique is a variation of Stochastic
Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize,
and produces significantly better visualizations by reducing the
tendency to crowd points together in the center of the map. t-SNE is
better than existing techniques at creating a single map that reveals
structure at many different scales. This is particularly important for
high-dimensional data that lie on several different, but related,
low-dimensional manifolds, such as images ofobjects from multiple
classes seen from multiple viewpoints. For visualizing the structure
of very large data sets, we show how t-SNE can use random walks on
neighborhood graphs to allow the implicit structure of all of the data
to influence the way in which a subset of the data is displayed. We
illustrate the performance of t-SNE on a wide variety of data sets and
compare it with many other non-parametric visualization techniques,
including Sammon mapping, Isomap, and Locally Linear Embedding. The
visualizations produced by t-SNE are significantly better than those
produced by the other techniques on almost all of the data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf</url></Article><Article><id>538</id><title>
Model Selection for Regression with Continuous Kernel Functions Using the Modulus of Continuity
</title><author>Imhoi Koo, Rhee Man Kil</author><abstract>

This paper presents a new method of model selection for regression
problems using the modulus of continuity.  For this purpose, we
suggest the prediction risk bounds of regression models using the
modulus of continuity which can be interpreted as the complexity of
functions. We also present the model selection criterion referred to
as the modulus of continuity information criterion (MCIC) which is
derived from the suggested prediction risk bounds.  The suggested
MCIC provides a risk estimate using the modulus of continuity for a
trained regression model (or an estimation function) while other
model selection criteria such as the AIC and BIC use structural
information such as the number of training parameters. As a result,
the suggested MCIC is able to discriminate the performances of
trained regression models, even with the same structure of training
models.  To show the effectiveness of the proposed method, the
simulation for function approximation using the multilayer
perceptrons (MLPs) was conducted.  Through the simulation for
function approximation, it was demonstrated that the suggested MCIC
provides a good selection tool for nonlinear regression models, even
with the limited size of data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/koo08b/koo08b.pdf</url></Article><Article><id>539</id><title>
Multi-Agent Reinforcement Learning in Common Interest and Fixed Sum Stochastic Games: An Experimental Study
</title><author>Avraham Bab, Ronen I. Brafman</author><abstract>

Multi Agent Reinforcement Learning (MARL) has received continually
growing attention in the past decade. Many algorithms that vary in
their approaches to the different subtasks of MARL have been
developed. However, the theoretical convergence results for these
algorithms do not give a clue as to their practical performance nor
supply insights to the dynamics of the learning process itself. This
work is a comprehensive empirical study conducted on &lt;i&gt;MGS&lt;/i&gt;, a
simulation system developed for this purpose. It surveys the
important algorithms in the field, demonstrates the strengths and
weaknesses of the different approaches to MARL through application
of FriendQ, OAL, WoLF, FoeQ, Rmax, and other algorithms to a variety
of fully cooperative and fully competitive domains in self and
heterogeneous play, and supplies an informal analysis of the
resulting learning processes. The results can aid in the design of
new learning algorithms, in matching existing algorithms to specific
tasks, and may guide further research and formal analysis of the
learning processes.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/bab08a/bab08a.pdf</url></Article><Article><id>540</id><title>
An Extension on "Statistical Comparisons of Classifiers over Multiple Data Sets" for all Pairwise Comparisons
</title><author>Salvador Garc&amp;#237;a, Francisco Herrera</author><abstract>

In a recently published paper in JMLR, Dem&amp;#154;ar (2006) recommends
a set of non-parametric statistical tests and procedures which can
be safely used for comparing the performance of classifiers over
multiple data sets. After studying the paper, we realize that the
paper correctly introduces the basic procedures and some of the
most advanced ones when comparing a control method. However, it
does not deal with some advanced topics in depth. Regarding these
topics, we focus on more powerful proposals of statistical
procedures for comparing &lt;i&gt;n&lt;/i&gt; &amp;#215; &lt;i&gt;n&lt;/i&gt; classifiers. Moreover, we
illustrate an easy way of obtaining adjusted and comparable
&lt;i&gt;p&lt;/i&gt;-values in multiple comparison procedures.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/garcia08a/garcia08a.pdf</url></Article><Article><id>541</id><title>
JNCC2: The Java Implementation Of Naive Credal Classifier 2
</title><author>Giorgio Corani, Marco Zaffalon</author><abstract>

JNCC2 implements the &lt;i&gt;naive credal classifier 2&lt;/i&gt; (NCC2). This is
an extension of naive Bayes to imprecise probabilities that aims at
delivering robust classifications also when dealing with small or
incomplete data sets. Robustness is achieved by delivering set-valued
classifications (that is, returning multiple classes) on the
instances for which (i) the learning set is not informative enough to
smooth the effect of choice of the prior density or (ii) the
uncertainty arising from missing data prevents the reliable
indication of a single class. JNCC2 is released under the GNU GPL
license.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/corani08b/corani08b.pdf</url></Article><Article><id>542</id><title>
Learning Bounded Treewidth Bayesian Networks
</title><author>Gal Elidan, Stephen Gould</author><abstract>

With the increased availability of data for complex domains, it is
desirable to learn Bayesian network structures that are sufficiently
expressive for generalization while at the same time allow for
tractable inference. While the method of thin junction trees can, in
principle, be used for this purpose, its fully greedy nature makes it
prone to overfitting, particularly when data is scarce. In this work
we present a novel method for learning Bayesian networks of bounded
treewidth that employs global structure modifications and that is
polynomial both in the size of the graph and the treewidth bound. At
the heart of our method is a dynamic triangulation that we update in a
way that facilitates the addition of chain structures that increase
the bound on the model's treewidth by at most one.  We demonstrate the
effectiveness of our "treewidth-friendly" method on several
real-life data sets and show that it is superior to the greedy
approach as soon as the bound on the treewidth is nontrivial.
Importantly, we also show that by making use of global operators, we
are able to achieve better generalization even when learning Bayesian
networks of unbounded treewidth.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/elidan08a/elidan08a.pdf</url></Article><Article><id>543</id><title>
Automatic PCA Dimension Selection for High Dimensional Data and Small Sample Sizes
</title><author>David C. Hoyle</author><abstract>

Bayesian inference from high-dimensional data involves the
integration over a large number of model parameters. Accurate
evaluation of such high-dimensional integrals raises a unique set
of issues. These issues are illustrated using the exemplar of
model selection for principal component analysis (PCA). A Bayesian
model selection criterion, based on a Laplace approximation to the
model evidence for determining the number of signal principal
components present in a data set, has previously been show to
perform well on various test data sets. Using simulated data we
show that for &lt;i&gt;d&lt;/i&gt;-dimensional data and small sample sizes, &lt;i&gt;N&lt;/i&gt;,
the accuracy of this model selection method is strongly affected
by increasing values of &lt;i&gt;d&lt;/i&gt;. By taking proper account of the
contribution to the evidence from the large number of
model parameters we show that model selection accuracy is
substantially improved. The accuracy of the improved model evidence is studied
in the asymptotic limit &lt;i&gt;d&lt;/i&gt; &amp;#8594; &amp;#8734; at fixed ratio
&amp;#945; = &lt;i&gt;N&lt;/i&gt;/&lt;i&gt;d&lt;/i&gt;, with &amp;#945; &lt; 1. In this limit, model selection
based upon the improved model evidence agrees with a frequentist
hypothesis testing approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/hoyle08a/hoyle08a.pdf</url></Article><Article><id>544</id><title>
Robust Submodular Observation Selection
</title><author>Andreas Krause, H. Brendan McMahan, Carlos Guestrin, Anupam Gupta</author><abstract>

In many applications, one has to actively select among a set of
expensive observations before making an informed decision. For
example, in environmental monitoring, we want to select locations to
measure in order to most effectively predict spatial phenomena.
Often, we want to select observations which are robust against a
number of possible objective functions. Examples include minimizing
the maximum posterior variance in Gaussian Process regression,
robust experimental design, and sensor placement for outbreak
detection. In this paper, we present the &lt;i&gt;Submodular
Saturation&lt;/i&gt; algorithm, a simple and efficient algorithm with strong
theoretical approximation guarantees for cases where the possible
objective functions exhibit &lt;i&gt;submodularity&lt;/i&gt;, an intuitive
diminishing returns property. Moreover, we prove that better
approximation algorithms do not exist unless NP-complete
problems admit efficient algorithms. We show how our algorithm can
be extended to handle complex cost functions (incorporating non-unit
observation cost or communication and path costs). We also show how
the algorithm can be used to near-optimally trade off expected-case
(e.g., the Mean Square Prediction Error in Gaussian Process
regression) and worst-case (e.g., maximum predictive variance)
performance. We show that many important machine learning problems
fit our robust submodular observation selection formalism, and
provide extensive empirical evaluation on several real-world
problems. For Gaussian Process regression, our algorithm compares
favorably with state-of-the-art heuristics described in the
geostatistics literature, while being simpler, faster and providing
theoretical guarantees. For robust experimental design, our
algorithm performs favorably compared to SDP-based algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/krause08b/krause08b.pdf</url></Article><Article><id>545</id><title>
Magic Moments for Structured Output Prediction
</title><author>Elisa Ricci, Tijl De Bie, Nello Cristianini</author><abstract>

Most approaches to structured output prediction rely on a hypothesis space
of &lt;i&gt;prediction functions&lt;/i&gt; that compute their output by maximizing
a linear &lt;i&gt;scoring function&lt;/i&gt;.
In this paper we present two novel learning algorithms for this
hypothesis class, and a statistical analysis of their performance.
The methods rely on efficiently computing the first two moments
of the scoring function over the output space, and using them to
create convex objective functions for training.
We report extensive experimental results for sequence alignment,
named entity recognition, and RNA secondary structure prediction.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/ricci08a/ricci08a.pdf</url></Article><Article><id>546</id><title>
Structural Learning of Chain Graphs via Decomposition
</title><author>Zongming Ma, Xianchao Xie, Zhi Geng</author><abstract>

Chain graphs present a broad class of graphical models for description
of conditional independence structures, including both Markov networks
and Bayesian networks as special cases.  In this paper, we propose a
computationally feasible method for the structural learning of chain
graphs based on the idea of decomposing the learning problem into a
set of smaller scale problems on its decomposed subgraphs. The
decomposition requires conditional independencies but does not require
the separators to be complete subgraphs. Algorithms for both skeleton
recovery and complex arrow orientation are presented. Simulations
under a variety of settings demonstrate the competitive performance of
our method, especially when the underlying graph is sparse.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume9/ma08a/ma08a.pdf</url></Article><Article><id>547</id><title>
Exploring Strategies for Training Deep Neural Networks
</title><author>Hugo Larochelle, Yoshua Bengio, J&amp;#233;r&amp;#244;me Louradour, Pascal Lamblin</author><abstract>

Deep multi-layer neural networks have many levels of non-linearities
allowing them to compactly represent highly non-linear and
highly-varying functions. However, until recently it was not clear how
to train such deep networks, since gradient-based optimization
starting from random initialization often appears to get stuck in poor
solutions.  Hinton et al. recently proposed a greedy layer-wise
unsupervised learning procedure relying on the training algorithm of
restricted Boltzmann machines (RBM) to initialize the parameters of a
deep belief network (DBN), a generative model with many layers of
hidden causal variables. This was followed by the proposal of another
greedy layer-wise procedure, relying on the usage of autoassociator
networks. In the context of the above optimization problem, we study
these algorithms empirically to better understand their success.  Our
experiments confirm the hypothesis that the greedy layer-wise
unsupervised training strategy helps the optimization by initializing
weights in a region near a good local minimum, but also implicitly
acts as a sort of regularization that brings better generalization and
encourages internal distributed representations that are high-level
abstractions of the input.  We also present a series of experiments
aimed at evaluating the link between the performance of deep neural
networks and practical aspects of their topology, for example,
demonstrating cases where the addition of more depth helps.  Finally,
we empirically explore simple variants of these training algorithms,
such as the use of different RBM input unit distributions, a simple
way of combining gradient estimators to improve performance, as well
as on-line versions of those algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/larochelle09a/larochelle09a.pdf</url></Article><Article><id>548</id><title>
Markov Properties for Linear Causal Models with Correlated Errors
</title><author>Changsung Kang, Jin Tian</author><abstract>

A linear causal model with correlated errors, represented by a DAG
with bi-directed edges, can be tested by the set of conditional
independence relations implied by the model. A global Markov property
specifies, by the d-separation criterion, the set of all conditional
independence relations holding in any model associated with a graph. A
local Markov property specifies a much smaller set of conditional
independence relations which will imply all other conditional
independence relations which hold under the global Markov
property. For DAGs with bi-directed edges associated with arbitrary
probability distributions, a local Markov property is given in
Richardson (2003) which may invoke an exponential number of
conditional independencies. In this paper, we show that for a class of
linear structural equation models with correlated errors, there is a
local Markov property which will invoke only a linear number of
conditional independence relations. For general linear models, we
provide a local Markov property that often invokes far fewer
conditional independencies than that in Richardson (2003). The
results have applications in testing linear structural equation models
with correlated errors.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kang09a/kang09a.pdf</url></Article><Article><id>549</id><title>
An Analysis of Convex Relaxations for MAP Estimation of Discrete MRFs
</title><author>M. Pawan Kumar, Vladimir Kolmogorov, Philip H.S. Torr</author><abstract>
&lt;p&gt;
The problem of obtaining the maximum &lt;i&gt;a posteriori&lt;/i&gt; estimate of a
general discrete Markov random field (i.e., a Markov random field
defined using a discrete set of labels) is known to be 
NP-hard. However, due to its central importance in many applications,
several approximation algorithms have been proposed in the
literature. In this paper, we present an analysis of three such
algorithms based on convex relaxations: (i) LP-S: the linear
programming (LP) relaxation proposed by Schlesinger (1976)
for a special case and independently in  Chekuri et al. (2001), 
Koster et al. (1998), and Wainwright et al. (2005) for the general case;
(ii) QP-RL: the quadratic programming (QP) relaxation of
Ravikumar and Lafferty (2006); and (iii) SOCP-MS: the second order
cone programming (SOCP) relaxation first proposed by
Muramatsu and Suzuki (2003) for two label problems and later extended by
Kumar et al. (2006) for a general label set.
&lt;/p&gt;
&lt;p&gt;
We show that the SOCP-MS and the QP-RL relaxations are
equivalent. Furthermore, we prove that despite the flexibility in the
form of the constraints/objective function offered by QP and
SOCP, the LP-S relaxation &lt;i&gt;strictly dominates&lt;/i&gt; (i.e.,
provides a better approximation than) QP-RL and SOCP-MS.
We generalize these results by defining a large class of SOCP
(and equivalent QP) relaxations which is dominated by the 
LP-S relaxation. Based on these results we propose some novel 
SOCP relaxations which define constraints using random variables that
form cycles or cliques in the graphical model representation of the
random field. Using some examples we show that the new SOCP
relaxations strictly dominate the previous approaches.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kumar09a/kumar09a.pdf</url></Article><Article><id>550</id><title>
Refinement of Reproducing Kernels
</title><author>Yuesheng Xu, Haizhang Zhang</author><abstract>

We continue our recent study on constructing a &lt;i&gt;refinement
kernel&lt;/i&gt; for a given kernel so that the reproducing kernel Hilbert
space associated with the refinement kernel contains that with the
original kernel as a subspace. To motivate this study, we first
develop a refinement kernel method for learning, which gives an
efficient algorithm for updating a learning predictor. Several
characterizations of refinement kernels are then presented. It is
shown that a nontrivial refinement kernel for a given kernel always
exists if the input space has an infinite cardinal number.
Refinement kernels for translation invariant kernels and
Hilbert-Schmidt kernels are investigated. Various concrete examples
are provided.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/xu09a/xu09a.pdf</url></Article><Article><id>551</id><title>
Subgroup Analysis via Recursive Partitioning
</title><author>Xiaogang Su, Chih-Ling Tsai, Hansheng Wang, David M. Nickerson, Bogong Li</author><abstract>

Subgroup analysis is an integral part of comparative analysis
where assessing the treatment effect on a response is of central
interest. Its goal is to determine the heterogeneity of the
treatment effect across subpopulations. In this paper, we adapt
the idea of recursive partitioning and introduce an interaction
tree (IT) procedure to conduct subgroup analysis. The IT procedure
automatically facilitates a number of objectively defined
subgroups, in some of which the treatment effect is found
prominent while in others the treatment has a negligible or even
negative effect. The standard CART (Breiman et al., 1984)
methodology is inherited to construct the tree structure. Also, in
order to extract factors that contribute to the heterogeneity of
the treatment effect, variable importance measure is made
available via random forests of the interaction trees. Both
simulated experiments and analysis of census wage data are
presented for illustration.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/su09a/su09a.pdf</url></Article><Article><id>552</id><title>
Python Environment for Bayesian Learning: Inferring the Structure of Bayesian Networks from Knowledge and Data
</title><author>Abhik Shah, Peter Woolf</author><abstract>

&lt;p&gt;
In this paper, we introduce PEBL, a Python library and
application for learning Bayesian network structure from data and prior knowledge that
provides features unmatched by alternative software packages: the ability to use
interventional data, flexible specification of structural priors, modeling with
hidden variables and exploitation of parallel processing.
&lt;/p&gt;
&lt;p&gt;
PEBL is released under the MIT open-source license, can
 be installed from the Python Package Index and is available at
 &lt;a href="http://pebl-project.googlecode.com"&gt;http://pebl-project.googlecode.com&lt;/a&gt;.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/shah09a/shah09a.pdf</url></Article><Article><id>553</id><title>
On The Power of Membership Queries in Agnostic Learning
</title><author>Vitaly Feldman</author><abstract>

&lt;p&gt;
We study the properties of the agnostic learning framework of
Haussler (1992) and Kearns, Schapire, and Sellie (1994). In particular, we
address the question: is there any situation in which membership
queries are useful in agnostic learning?
&lt;/p&gt;

&lt;p&gt;
Our results show that the answer is negative for
distribution-independent agnostic learning and positive for agnostic
learning with respect to a specific marginal distribution. Namely, we
give a simple proof that any concept class learnable agnostically by a
distribution-independent algorithm with access to membership queries
is also learnable agnostically without membership queries. This
resolves an open problem posed by Kearns et al. (1994). For agnostic
learning with respect to the uniform distribution over {0,1}&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; we show
a concept class that is learnable with membership queries but
computationally hard to learn from random examples alone (assuming
that one-way functions exist).
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/feldman09a/feldman09a.pdf</url></Article><Article><id>554</id><title>
Using Local Dependencies within Batches to Improve Large Margin Classifiers
</title><author>Volkan Vural, Glenn Fung, Balaji Krishnapuram, Jennifer G. Dy, Bharat Rao</author><abstract>

Most classification methods assume that the samples are drawn
independently and identically from an unknown data generating
distribution, yet this assumption is violated in several real life
problems. In order to relax this assumption, we consider the case
where batches or groups of samples may have internal correlations,
whereas the samples from different batches may be considered to be
uncorrelated.  This paper introduces three algorithms for classifying
all the samples in a batch jointly: one based on a probabilistic
formulation, and two based on mathematical programming analysis.
Experiments on three real-life &lt;i&gt;computer aided diagnosis&lt;/i&gt; (CAD)
problems demonstrate that the proposed algorithms are significantly
more accurate than a naive support vector machine which ignores the
correlations among the samples.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/vural09a/vural09a.pdf</url></Article><Article><id>555</id><title>
Distance Metric Learning for Large Margin Nearest Neighbor Classification
</title><author>Kilian Q. Weinberger, Lawrence K. Saul</author><abstract>

The accuracy of &lt;i&gt;k&lt;/i&gt;-nearest neighbor (kNN) classification depends
significantly on the metric used to compute distances between
different examples.  In this paper, we show how to learn a Mahalanobis
distance metric for kNN classification from labeled examples.  The
Mahalanobis metric can equivalently be viewed as a global linear
transformation of the input space that precedes kNN classification
using Euclidean distances.  In our approach, the metric is trained
with the goal that the &lt;i&gt;k&lt;/i&gt;-nearest neighbors always belong to the same
class while examples from different classes are separated by a large
margin.  As in support vector machines (SVMs), the margin criterion
leads to a convex optimization based on the hinge loss.  Unlike
learning in SVMs, however, our approach requires no modification or
extension for problems in multiway (as opposed to binary)
classification.  In our framework, the Mahalanobis distance metric is
obtained as the solution to a semidefinite program.  On several data
sets of varying size and difficulty, we find that metrics trained in
this way lead to significant improvements in kNN classification.
Sometimes these results can be further improved by clustering the
training examples and learning an individual metric within each
cluster. We show how to learn and combine these local metrics in a
globally integrated manner.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/weinberger09a/weinberger09a.pdf</url></Article><Article><id>556</id><title>
Data-driven Calibration of Penalties for Least-Squares Regression
</title><author>Sylvain Arlot, Pascal Massart</author><abstract>
&lt;p&gt;
Penalization procedures often suffer from their dependence on
multiplying factors, whose optimal values are either unknown or hard
to estimate from data. We propose a completely data-driven calibration
algorithm for these parameters in the least-squares regression
framework, without assuming a particular shape for the penalty.  Our
algorithm relies on the concept of minimal penalty, recently
introduced by Birg&amp;#233; and Massart (2007) in the context of penalized
least squares for Gaussian homoscedastic regression.  On the positive
side, the minimal penalty can be evaluated from the data themselves,
leading to a data-driven estimation of an optimal penalty which can be
used in practice; on the negative side, their approach heavily relies
on the homoscedastic Gaussian nature of their stochastic framework.
&lt;/p&gt;
&lt;p&gt;
The purpose of this paper is twofold: stating a more general
heuristics for designing a data-driven penalty (the &lt;i&gt;slope
heuristics&lt;/i&gt;) and proving that it works for penalized least-squares
regression with a random design, even for heteroscedastic non-Gaussian
data.  For technical reasons, some exact mathematical results will be
proved only for regressogram bin-width selection. This is at least a
first step towards further results, since the approach and the method
that we use are indeed general.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/arlot09a/arlot09a.pdf</url></Article><Article><id>557</id><title>
Analysis of Perceptron-Based Active Learning
</title><author>Sanjoy Dasgupta, Adam Tauman Kalai, Claire Monteleoni</author><abstract>

We start by showing that in an active learning setting, the Perceptron algorithm
needs &amp;#937;(1/&amp;#949;&lt;sup&gt;2&lt;/sup&gt;) labels to learn linear
separators within generalization error &amp;#949;. We then present
a simple active learning algorithm for this problem, which
combines a modification of the Perceptron update with an adaptive
filtering rule for deciding which
points to query. For data distributed uniformly over the unit
sphere, we show that our algorithm reaches generalization error
&amp;#949; after asking for just &lt;i&gt;&amp;#213;&lt;/i&gt;(&lt;i&gt;d&lt;/i&gt; log 1/&amp;#949;) labels. 
This exponential improvement over the
usual sample complexity of supervised learning had previously been
demonstrated only for the computationally more complex
query-by-committee algorithm.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/dasgupta09a/dasgupta09a.pdf</url></Article><Article><id>558</id><title>
Improving the Reliability of Causal Discovery from Small Data Sets Using Argumentation
</title><author>Facundo Bromberg, Dimitris Margaritis</author><abstract>

We address the problem of improving the reliability of
independence-based causal discovery algorithms that results from the
execution of statistical independence tests on small data sets, which
typically have low reliability.  We model the problem as a knowledge
base containing a set of independence facts that are related through
Pearl's well-known axioms.  Statistical tests on finite data sets may
result in errors in these tests and inconsistencies in the knowledge
base.  We resolve these inconsistencies through the use of an instance
of the class of defeasible logics called argumentation, augmented with
a preference function, that is used to reason about and possibly
correct errors in these tests.  This results in a more robust
conditional independence test, called an &lt;i&gt;argumentative
independence test&lt;/i&gt;.  Our experimental evaluation shows clear positive
improvements in the accuracy of argumentative over purely statistical
tests.  We also demonstrate significant improvements on the accuracy
of causal structure discovery from the outcomes of independence tests
both on sampled data from randomly generated causal models and on
real-world data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/bromberg09a/bromberg09a.pdf</url></Article><Article><id>559</id><title>
Low-Rank Kernel Learning with Bregman Matrix Divergences
</title><author>Brian Kulis, M&amp;#225;ty&amp;#225;s A. Sustik, Inderjit S. Dhillon</author><abstract>

In this paper, we study low-rank matrix nearness problems, with a
focus on learning low-rank positive semidefinite (kernel) matrices for
machine learning applications.  We propose efficient algorithms that
scale linearly in the number of data points and quadratically in the
rank of the input matrix.  Existing algorithms for learning kernel
matrices often scale poorly, with running times that are cubic in the
number of data points. We employ Bregman matrix divergences as the
measures of nearness---these divergences are natural for learning
low-rank kernels since they preserve rank as well as positive
semidefiniteness.  Special cases of our framework yield faster
algorithms for various existing learning problems, and experimental
results demonstrate that our algorithms can effectively learn both
low-rank and full-rank kernel matrices.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kulis09a/kulis09a.pdf</url></Article><Article><id>560</id><title>
Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining 
</title><author>Petra Kralj Novak, Nada Lavra&amp;#269;, Geoffrey I. Webb</author><abstract>

This paper gives a survey of contrast set mining (CSM), emerging
pattern mining (EPM), and subgroup discovery (SD) in a unifying
framework named &lt;i&gt;supervised descriptive rule discovery&lt;/i&gt;. While all
these research areas aim at discovering patterns in the form of rules
induced from labeled data, they use different terminology and task
definitions, claim to have different goals, claim to use different
rule learning heuristics, and use different means for selecting
subsets of induced patterns. This paper contributes a novel
understanding of these subareas of data mining by presenting a unified
terminology, by explaining the apparent differences between the
learning tasks as variants of a unique supervised descriptive rule
discovery task and by exploring the apparent differences between the
approaches. It also shows that various rule learning heuristics used
in CSM, EPM and SD algorithms all aim at optimizing a trade off
between rule coverage and precision.  The commonalities (and
differences) between the approaches are showcased on a selection of
best known variants of CSM, EPM and SD algorithms. The paper
also provides a critical survey of existing supervised descriptive
rule discovery visualization methods.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kralj-novak09a/kralj-novak09a.pdf</url></Article><Article><id>561</id><title>
Particle Swarm Model Selection
</title><author>Hugo Jair Escalante, Manuel Montes, Luis Enrique Sucar</author><abstract>

This paper proposes the application of particle swarm optimization
(&lt;i&gt;PSO&lt;/i&gt;) to the problem of &lt;i&gt;full model selection, FMS,&lt;/i&gt; for
classification tasks. &lt;i&gt;FMS&lt;/i&gt; is defined as follows: given a pool
of preprocessing methods, feature selection and learning algorithms,
to select the combination of these that obtains the lowest
classification error for a given data set; the task also includes the
selection of hyperparameters for the considered methods. This problem
generates a vast search space to be explored, well suited for
stochastic optimization techniques.  &lt;i&gt;FMS&lt;/i&gt; can be applied to any
classification domain as it does not require domain knowledge.
Different model types and a variety of algorithms can be considered
under this formulation.  Furthermore, competitive yet simple models
can be obtained with &lt;i&gt;FMS&lt;/i&gt;.  We adopt &lt;i&gt;PSO&lt;/i&gt; for the search
because of its proven performance in different problems and because of
its simplicity, since neither expensive computations nor complicated
operations are needed.  Interestingly, the way the search is guided
allows &lt;i&gt;PSO&lt;/i&gt; to avoid overfitting to some extend.  Experimental
results on benchmark data sets give evidence that the proposed
approach is very effective, despite its simplicity.  Furthermore,
results obtained in the framework of a model selection challenge show
the competitiveness of the models selected with &lt;i&gt;PSO&lt;/i&gt;, compared
to models selected with other techniques that focus on a single
algorithm and that use domain knowledge.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/escalante09a/escalante09a.pdf</url></Article><Article><id>562</id><title>
Generalization Bounds for Ranking Algorithms via Algorithmic Stability
</title><author>Shivani Agarwal, Partha Niyogi</author><abstract>

The problem of ranking, in which the goal is to learn a real-valued
ranking function that induces a ranking or ordering over an instance
space, has recently gained much attention in machine learning.  We
study generalization properties of ranking algorithms using the notion
of algorithmic stability; in particular, we derive generalization
bounds for ranking algorithms that have good stability properties. We
show that kernel-based ranking algorithms that perform regularization
in a reproducing kernel Hilbert space have such stability properties,
and therefore our bounds can be applied to these algorithms; this is
in contrast with generalization bounds based on uniform convergence,
which in many cases cannot be applied to these algorithms. Our results
generalize earlier results that were derived in the special setting of
bipartite ranking (Agarwal and Niyogi, 2005) to a more general setting of the
ranking problem that arises frequently in applications.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/agarwal09a/agarwal09a.pdf</url></Article><Article><id>563</id><title>
Controlling the False Discovery Rate of the Association/Causality Structure Learned with the PC Algorithm
</title><author>Junning Li, Z. Jane Wang</author><abstract>

In real world applications, graphical statistical models are not only
a tool for operations such as classification or prediction, but
usually the network structures of the models themselves are also of
great interest (e.g., in modeling brain connectivity).  The false
discovery rate (FDR), the expected ratio of falsely claimed
connections to all those claimed, is often a reasonable error-rate
criterion in these applications.  However, current learning algorithms
for graphical models have not been adequately adapted to the concerns
of the FDR.  The traditional practice of controlling the type I error
rate and the type II error rate under a conventional level does not
necessarily keep the FDR low, especially in the case of sparse
networks.  In this paper, we propose embedding an FDR-control
procedure into the PC algorithm to curb the FDR of the skeleton of the
learned graph.  We prove that the proposed method can control the FDR
under a user-specified level at the limit of large sample sizes.  In
the cases of moderate sample size (about several hundred), empirical
experiments show that the method is still able to control the FDR
under the user-specified level, and a heuristic modification of the
method is able to control the FDR more accurately around the
user-specified level.  The proposed method is applicable to any models
for which statistical tests of conditional independence are available,
such as discrete models and Gaussian models.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/li09a/li09a.pdf</url></Article><Article><id>564</id><title>
Identification of Recurrent Neural Networks by Bayesian Interrogation Techniques
</title><author>Barnab&amp;#225;s P&amp;#243;czos, Andr&amp;#225;s Lo&amp;#779;rincz</author><abstract>

We introduce novel online Bayesian methods for the identification of
a family of noisy recurrent neural networks (RNNs). We present
Bayesian active learning techniques for stimulus selection given
past experiences. In particular, we consider the unknown parameters
as stochastic variables and use A-optimality and D-optimality
principles to choose optimal stimuli. We derive myopic cost
functions in order to maximize the information gain concerning
network parameters at each time step. We also derive the A-optimal
and D-optimal estimations of the additive noise that perturbs the
dynamical system of the RNN. Here we investigate myopic as well as
non-myopic estimations, and study the problem of simultaneous
estimation of both the system parameters and the noise. Employing
conjugate priors our derivations remain approximation-free and give
rise to simple update rules for the online learning of the
parameters. The efficiency of our method is demonstrated for a
number of selected cases, including the task of controlled
independent component analysis.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/poczos09a/poczos09a.pdf</url></Article><Article><id>565</id><title>
On the Consistency of Feature Selection using Greedy Least Squares Regression
</title><author>Tong Zhang</author><abstract>
&lt;p&gt;
This paper studies the feature selection problem using
a greedy least squares regression algorithm.
We show that under a certain irrepresentable condition on the 
design matrix (but independent of the sparse target),
the greedy algorithm can select features consistently when the
sample size approaches infinity. The condition is identical
to  a corresponding condition for Lasso.
&lt;/p&gt;
&lt;p&gt;
Moreover, under a sparse eigenvalue condition,
the greedy algorithm can reliably identify 
features as long as each nonzero coefficient is larger than a constant
times the noise level.
In comparison, Lasso may require the coefficients to be larger than
&lt;i&gt;O&lt;/i&gt;(&amp;#8730;&lt;i&gt;s&lt;/i&gt;) times the noise level in the worst case, 
where &lt;i&gt;s&lt;/i&gt; is the number of nonzero coefficients. 
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/zhang09a/zhang09a.pdf</url></Article><Article><id>566</id><title>
Online Learning with Sample Path Constraints
</title><author>Shie Mannor, John N. Tsitsiklis, Jia Yuan Yu</author><abstract>

We study online learning where a decision maker interacts with Nature
with the objective of maximizing her long-term average reward subject
to some sample path average constraints.  We define the
reward-in-hindsight as the highest reward the decision maker could
have achieved, while satisfying the constraints, had she known
Nature's choices in advance. We show that in general the
reward-in-hindsight is &lt;i&gt;not&lt;/i&gt; attainable. The convex hull of the
reward-in-hindsight function is, however, attainable. For the
important case of a single constraint, the convex hull turns out to be
the highest attainable function. Using a calibrated forecasting rule,
we provide an explicit strategy that attains this convex hull. We also
measure the performance of heuristic methods based on non-calibrated
forecasters in experiments involving a CPU power management problem.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/mannor09a/mannor09a.pdf</url></Article><Article><id>567</id><title>
NEUROSVM: An Architecture to Reduce the Effect of the Choice of Kernel on the Performance of SVM
</title><author>Pradip Ghanty, Samrat Paul, Nikhil R. Pal</author><abstract>

In this paper we propose a new multilayer classifier architecture. The
proposed hybrid architecture has two cascaded modules: feature
extraction module and classification module. In the feature extraction
module we use the multilayered perceptron (MLP) neural networks,
although other tools such as radial basis function (RBF) networks can
be used. In the classification module we use support vector machines
(SVMs)---here also other tool such as MLP or RBF can be used. The
feature extraction module has several sub-modules each of which is
expected to extract features capturing the discriminating
characteristics of different areas of the input space. The
classification module classifies the data based on the extracted
features. The resultant architecture with MLP in feature extraction
module and SVM in classification module is called NEUROSVM. The
NEUROSVM is tested on twelve benchmark data sets and the performance
of the NEUROSVM is found to be better than both MLP and SVM. We also
compare the performance of proposed architecture with that of two
ensemble methods: majority voting and averaging. Here also the
NEUROSVM is found to perform better than these two ensemble
methods. Further we explore the use of MLP and RBF in the
classification module of the proposed architecture. The most
attractive feature of NEUROSVM is that it practically eliminates the
severe dependency of SVM on the choice of kernel. This has been
verified with respect to both linear and non-linear kernels. We have
also demonstrated that for the feature extraction module, the full
training of MLPs is not needed.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/ghanty09a/ghanty09a.pdf</url></Article><Article><id>568</id><title>
Scalable Collaborative Filtering Approaches for Large Recommender Systems
</title><author>G&amp;#225;bor Tak&amp;#225;cs, Istv&amp;#225;n Pil&amp;#225;szy, Botty&amp;#225;n N&amp;#233;meth, Domonkos Tikk</author><abstract>

The collaborative filtering (CF) using known user ratings of items has
proved to be effective for predicting user preferences in item
selection. This thriving subfield of machine learning became popular
in the late 1990s with the spread of online services that use
recommender systems, such as Amazon, Yahoo! Music, and Netflix. CF
approaches are usually designed to work on very large data
sets. Therefore the scalability of the methods is crucial. In this
work, we propose various scalable solutions that are validated against
the Netflix Prize data set, currently the largest publicly available
collection. First, we propose various matrix factorization (MF) based
techniques. Second, a neighbor correction method for MF is outlined,
which alloys the global perspective of MF and the localized property
of neighbor based approaches efficiently. In the experimentation
section, we first report on some implementation issues, and we suggest
on how parameter optimization can be performed efficiently for MFs. We
then show that the proposed scalable approaches compare favorably with
existing ones in terms of prediction accuracy and/or required training
time. Finally, we report on some experiments performed on MovieLens
and Jester data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/takacs09a/takacs09a.pdf</url></Article><Article><id>569</id><title>
Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions
</title><author>S&amp;#233;bastien Bubeck, Ulrike von Luxburg</author><abstract>

Clustering is often formulated as a discrete optimization problem. The
objective is to find, among all partitions of the data set, the best
one according to some quality measure.  However, in the statistical
setting where we assume that the finite data set has been sampled from
some underlying space, the goal is not to find the best partition of
the given sample, but to approximate the true partition of the
underlying space. We argue that the discrete optimization approach
usually does not achieve this goal, and instead can lead to
inconsistency. We construct examples which provably have this
behavior.  As in the case of supervised learning, the cure is to
restrict the size of the function classes under consideration. For
appropriate "small" function classes we can prove very general
consistency theorems for clustering optimization schemes.  As one
particular algorithm for clustering with a restricted function space
we introduce "nearest neighbor clustering". Similar to the k-nearest
neighbor classifier in supervised learning, this algorithm can be seen
as a general baseline algorithm to minimize arbitrary clustering
objective functions. We prove that it is statistically consistent for
all commonly used clustering objective functions.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/bubeck09a/bubeck09a.pdf</url></Article><Article><id>570</id><title>
Properties of Monotonic Effects on Directed Acyclic Graphs
</title><author>Tyler J. VanderWeele, James M. Robins</author><abstract>

Various relationships are shown hold between monotonic effects and weak
monotonic effects and the monotonicity of certain conditional expectations.
Counterexamples are provided to show that the results do not hold under less
restrictive conditions. Monotonic effects are furthermore used to relate
signed edges on a causal directed acyclic graph to qualitative effect
modification. The theory is applied to an example concerning the direct
effect of smoking on cardiovascular disease controlling for
hypercholesterolemia. Monotonicity assumptions are used to construct a test
for whether there is a variable that confounds the relationship between the
mediator, hypercholesterolemia, and the outcome, cardiovascular disease.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/vanderweele09a/vanderweele09a.pdf</url></Article><Article><id>571</id><title>
On Efficient Large Margin Semisupervised Learning: Method and Theory
</title><author>Junhui Wang, Xiaotong Shen, Wei Pan</author><abstract>

In classification, semisupervised learning usually involves a large
amount of unlabeled data with only a small number of labeled
data. This imposes a great challenge in that it is difficult to
achieve good classification performance through labeled data alone. To
leverage unlabeled data for enhancing classification, this article
introduces a large margin semisupervised learning method within the
framework of regularization, based on an efficient margin loss for
unlabeled data, which seeks efficient extraction of the information
from unlabeled data for estimating the Bayes decision boundary for
classification. For implementation, an iterative scheme is derived
through conditional expectations. Finally, theoretical and numerical
analyses are conducted, in addition to an application to gene function
prediction. They suggest that the proposed method enables to recover
the performance of its supervised counterpart based on complete data
in rates of convergence, when possible.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/wang09a/wang09a.pdf</url></Article><Article><id>572</id><title>
Nieme: Large-Scale Energy-Based Models
</title><author>Francis Maes</author><abstract>

In this paper we introduce N&lt;small&gt;IEME&lt;/small&gt;, a machine learning library for
large-scale classification, regression and ranking.  N&lt;small&gt;IEME&lt;/small&gt;, relies on
the framework of &lt;i&gt;energy-based models&lt;/i&gt; (LeCun et al., 2006) which
unifies several learning algorithms ranging from simple perceptrons to
recent models such as the pegasos support vector machine or
l1-regularized maximum entropy models. This framework also unifies
batch and stochastic learning which are both seen as energy
minimization problems.  N&lt;small&gt;IEME&lt;/small&gt;, can hence be used in a wide range of
situations, but is particularly interesting for large-scale learning
tasks where both the examples and the features are processed
incrementally. Being able to deal with new incoming features at any
time within the learning process is another original feature of the
 N&lt;small&gt;IEME&lt;/small&gt;, toolbox.  N&lt;small&gt;IEME&lt;/small&gt;, is released under the GPL license. It is
efficiently implemented in C++, it works on Linux, Mac OS X and
Windows and provides interfaces for C++, Java and Python.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/maes09a/maes09a.pdf</url></Article><Article><id>573</id><title>
Similarity-based Classification: Concepts and Algorithms
</title><author>Yihua Chen, Eric K. Garcia, Maya R. Gupta, Ali Rahimi, Luca Cazzanti</author><abstract>

This paper reviews and extends the field of similarity-based classification,
presenting new analyses, algorithms, data sets, and a comprehensive set of
experimental results for a rich collection of classification problems.
Specifically, the generalizability of using similarities as features is
analyzed, design goals and methods for weighting nearest-neighbors for
similarity-based learning are proposed, and different methods for consistently
converting similarities into kernels are compared. Experiments on eight real
data sets compare eight approaches and their variants to similarity-based
learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/chen09a/chen09a.pdf</url></Article><Article><id>574</id><title>
Sparse Online Learning via Truncated Gradient
</title><author>John Langford, Lihong Li, Tong Zhang</author><abstract>

We propose a general method called &lt;i&gt;truncated gradient&lt;/i&gt;
to induce sparsity in the weights of
online-learning algorithms with convex loss functions.  This
method has several essential properties:
&lt;ol&gt;
&lt;li&gt; The degree of sparsity is continuous---a parameter controls the
rate of sparsification from no sparsification to total sparsification.
&lt;li&gt; The approach is theoretically motivated, and an instance of it
can be regarded as an online counterpart of the popular
&lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-regularization method in the batch setting.  We prove that small
rates of sparsification result in only small additional regret with
respect to typical online-learning guarantees.
&lt;li&gt; The approach works well empirically.
&lt;/ol&gt;
We apply the approach to several data sets and find for data sets with
large numbers of features, substantial sparsity is discoverable.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/langford09a/langford09a.pdf</url></Article><Article><id>575</id><title>
A New Approach to Collaborative Filtering: Operator Estimation with Spectral Regularization
</title><author>Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert</author><abstract>

We present a general approach for collaborative filtering (CF) using
spectral regularization to learn linear operators mapping a set of
"users" to a set of possibly desired "objects". In particular,
several recent low-rank type matrix-completion methods for CF are
shown to be special cases of our proposed framework. Unlike existing
regularization-based CF, our approach can be used to incorporate
additional information such as attributes of the users/objects---a
feature currently lacking in existing regularization-based CF
approaches---using popular and well-known &lt;i&gt;kernel methods&lt;/i&gt;. We
provide novel representer theorems that we use to develop new
estimation methods. We then provide learning algorithms based on
low-rank decompositions and test them on a standard CF data set.  The
experiments indicate the advantages of generalizing the existing
regularization-based CF methods to incorporate related information
about users and objects. Finally, we show that certain multi-task
learning methods can be also seen as special cases of our proposed
approach.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/abernethy09a/abernethy09a.pdf</url></Article><Article><id>576</id><title>
Consistency and Localizability
</title><author>Alon Zakai, Ya'acov Ritov</author><abstract>

We show that all consistent learning methods---that is, that
asymptotically achieve the lowest possible expected loss for any
distribution on (&lt;i&gt;X&lt;/i&gt;,&lt;i&gt;Y&lt;/i&gt;)---are necessarily localizable, by which we
mean that they do not significantly change their response at a
particular point when we show them only the part of the training set
that is close to that point. This is true in particular for methods
that appear to be defined in a non-local manner, such as support
vector machines in classification and least-squares estimators in
regression. Aside from showing that consistency implies a specific
form of localizability, we also show that consistency is logically
equivalent to the combination of two properties: (1) a form of
localizability, and (2) that the method's global mean (over the entire
&lt;i&gt;X&lt;/i&gt; distribution) correctly estimates the true mean. Consistency can
therefore be seen as comprised of two aspects, one local and one
global.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/zakai09a/zakai09a.pdf</url></Article><Article><id>577</id><title>
Stable and Efficient Gaussian Process Calculations
</title><author>Leslie Foster, Alex Waagen, Nabeela Aijaz, Michael Hurley, Apolonio Luis, Joel Rinsky, Chandrika Satyavolu, Michael J. Way, Paul Gazis, Ashok Srivastava</author><abstract>

The use of Gaussian processes can be an effective approach to
prediction in a supervised learning environment.  For large data
sets, the standard Gaussian process approach requires solving very
large systems of linear equations and approximations are required
for the calculations to be practical.   We will focus on the
subset of regressors approximation technique. We will demonstrate
that there can be numerical instabilities in a well known
implementation of the technique. We discuss alternate
implementations that have better numerical stability properties
and can lead to better predictions. Our results will be
illustrated by looking at an application involving prediction of
galaxy redshift from broadband spectrum data.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/foster09a/foster09a.pdf</url></Article><Article><id>578</id><title>
Estimation of Sparse Binary Pairwise Markov Networks using Pseudo-likelihoods
</title><author>Holger H&amp;#246;fling, Robert Tibshirani</author><abstract>

We consider the problems of estimating the parameters as well as the
structure of binary-valued Markov networks. For maximizing the
penalized log-likelihood, we implement an approximate procedure based
on the pseudo-likelihood of Besag (1975) and generalize it to a
fast exact algorithm. The exact algorithm starts with the
pseudo-likelihood solution and then adjusts the pseudo-likelihood
criterion so that each additional iterations moves it closer to the
exact solution. Our results show that this procedure is faster than
the competing exact method proposed by Lee, Ganapathi, and Koller (2006a). 
However, we also find that the approximate pseudo-likelihood as well as the 
approaches of Wainwright et al. (2006), when
implemented using the coordinate descent procedure of
Friedman, Hastie, and Tibshirani (2008b), are much faster than the exact methods, and only
slightly less accurate.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/hoefling09a/hoefling09a.pdf</url></Article><Article><id>579</id><title>
Polynomial-Delay Enumeration of Monotonic Graph Classes
</title><author>Jan Ramon, Siegfried Nijssen</author><abstract>

Algorithms that list graphs such that no two listed graphs are
isomorphic, are important building blocks of systems for mining and
learning in graphs. Algorithms are already known that solve this
problem efficiently for many classes of graphs of restricted topology,
such as trees.  In this article we introduce the concept of a dense
augmentation schema, and introduce an algorithm that can be used to
enumerate any class of graphs with polynomial delay, as long as the
class of graphs can be described using a monotonic predicate operating
on a dense augmentation schema.  In practice this means that this is
the first enumeration algorithm that can be applied theoretically
efficiently in any frequent subgraph mining algorithm, and that this
algorithm generalizes to situations beyond the standard frequent
subgraph mining setting.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/ramon09a/ramon09a.pdf</url></Article><Article><id>580</id><title>
Java-ML: A Machine Learning Library
</title><author>Thomas Abeel, Yves Van de Peer, Yvan Saeys</author><abstract>

Java-ML is a collection of machine learning and data mining
algorithms, which aims to be a readily usable and easily extensible
API for both software developers and research scientists. The
interfaces for each type of algorithm are kept simple and algorithms
strictly follow their respective interface. Comparing different
classifiers or clustering algorithms is therefore straightforward, and
implementing new algorithms is also easy.  The implementations of the
algorithms are clearly written, properly documented and can thus be
used as a reference. The library is written in Java and is available
from &lt;a href="http://java-ml.sourceforge.net/"&gt;http://java-ml.sourceforge.net/&lt;/a&gt; 
under the GNU GPL license.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/abeel09a/abeel09a.pdf</url></Article><Article><id>581</id><title>
Nonextensive Information Theoretic Kernels on Measures
</title><author>Andr&amp;#233; F. T. Martins, Noah A. Smith, Eric P. Xing, Pedro M. Q. Aguiar, M&amp;#225;rio A. T. Figueiredo</author><abstract>

Positive definite kernels on probability measures
have been recently applied to classification problems involving
text, images, and other types of structured data.
Some of these kernels are related to classic information
theoretic quantities, such as (Shannon's) mutual information
and the Jensen-Shannon (JS) divergence. Meanwhile, there have
been recent advances in  nonextensive generalizations of Shannon's
information theory. This paper bridges these
two trends by introducing  nonextensive information theoretic
kernels on probability measures, based on new JS-type divergences.
These new divergences result from extending the
the two building blocks of the classical JS divergence:
convexity and Shannon's entropy. The notion of
convexity is extended to the wider concept of &lt;i&gt;q&lt;/i&gt;-convexity,
for which we prove a Jensen &lt;i&gt;q&lt;/i&gt;-inequality. Based on
this inequality, we introduce Jensen-Tsallis (JT) &lt;i&gt;q&lt;/i&gt;-differences, a
nonextensive generalization of the JS divergence, and define
a &lt;i&gt;k&lt;/i&gt;-th order JT &lt;i&gt;q&lt;/i&gt;-difference between stochastic processes.
We then define a new family of nonextensive mutual information
kernels, which allow weights to be assigned to their arguments,
and which includes the Boolean, JS, and linear kernels
as particular cases. Nonextensive string kernels are also defined
that generalize the &lt;i&gt;p&lt;/i&gt;-spectrum kernel. We illustrate the performance
of these kernels on text categorization tasks, in which documents
are modeled both as bags of words and as sequences of characters.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/martins09a/martins09a.pdf</url></Article><Article><id>582</id><title>
On Uniform Deviations of General Empirical Risks with Unboundedness, Dependence, and High Dimensionality 
</title><author>Wenxin Jiang</author><abstract>

The statistical learning theory of risk minimization depends heavily on
probability bounds for uniform deviations of the empirical risks.
Classical probability bounds using Hoeffding's inequality cannot
accommodate more general situations with unbounded loss and
dependent data. The current paper introduces an inequality that
extends Hoeffding's inequality to handle these more general situations.
We will apply this inequality to provide probability bounds for
uniform deviations in a very general framework, which
can involve discrete decision rules, unbounded loss, and a dependence 
structure that can be more general than either martingale or strong mixing. 
We will consider two examples with high dimensional predictors: 
autoregression (AR) with &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-loss,
 and ARX model  with variable selection for sign classification,
 which uses both lagged responses and exogenous predictors. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/jiang09a/jiang09a.pdf</url></Article><Article><id>583</id><title>
Fourier Theoretic Probabilistic Inference over Permutations
</title><author>Jonathan Huang, Carlos Guestrin, Leonidas Guibas</author><abstract>

Permutations are ubiquitous in many real-world problems, such as
voting, ranking, and data association.  Representing uncertainty
over permutations is challenging, since there are &lt;i&gt;n&lt;/i&gt;!
possibilities, and typical compact and factorized probability
distribution representations, such as graphical models, cannot
capture the mutual exclusivity constraints associated with
permutations. In this paper, we use the "low-frequency" terms of a
Fourier decomposition to represent distributions over permutations
compactly.  We present &lt;i&gt;Kronecker conditioning&lt;/i&gt;, a novel  
approach for maintaining and updating these
distributions directly in the Fourier domain, allowing 
for polynomial time bandlimited approximations. Low order
Fourier-based approximations, however, may lead to functions that do
not correspond to valid distributions. To address this problem, we
present a quadratic program defined directly in the
Fourier domain for projecting the approximation onto a relaxation of
the polytope of legal marginal distributions. We demonstrate the 
effectiveness of our approach on a real camera-based multi-person 
tracking scenario.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/huang09a/huang09a.pdf</url></Article><Article><id>584</id><title>
An Algorithm for Reading Dependencies from the Minimal Undirected Independence Map of a Graphoid that Satisfies Weak Transitivity
</title><author>Jose M. Pe&amp;#241;a, Roland Nilsson, Johan Bj&amp;#246;rkegren, Jesper Tegn&amp;#233;r</author><abstract>

We present a sound and complete graphical criterion for reading
dependencies from the minimal undirected independence map &lt;i&gt;G&lt;/i&gt; of a
graphoid &lt;i&gt;M&lt;/i&gt; that satisfies weak transitivity. Here, complete means
that it is able to read all the dependencies in &lt;i&gt;M&lt;/i&gt; that can be
derived by applying the graphoid properties and weak transitivity to
the dependencies used in the construction of &lt;i&gt;G&lt;/i&gt; and the
independencies obtained from &lt;i&gt;G&lt;/i&gt; by vertex separation. We argue that
assuming weak transitivity is not too restrictive. As an intermediate
step in the derivation of the graphical criterion, we prove that for
any undirected graph &lt;i&gt;G&lt;/i&gt; there exists a strictly positive discrete
probability distribution with the prescribed sample spaces that is
faithful to &lt;i&gt;G&lt;/i&gt;. We also report an algorithm that implements the
graphical criterion and whose running time is considered to be at most
&lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;(&lt;i&gt;e&lt;/i&gt;+&lt;i&gt;n&lt;/i&gt;)) for &lt;i&gt;n&lt;/i&gt; nodes 
and &lt;i&gt;e&lt;/i&gt; edges. Finally, we illustrate how
the graphical criterion can be used within bioinformatics to identify
biologically meaningful gene dependencies.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/pena09a/pena09a.pdf</url></Article><Article><id>585</id><title>
Universal Kernel-Based Learning with Applications to Regular Languages
</title><author>Leonid (Aryeh) Kontorovich, Boaz Nadler</author><abstract>
&lt;p&gt;
We propose a novel framework for supervised learning of discrete
concepts.  Since the 1970's, the standard computational primitive has
been to find the most consistent hypothesis in a given complexity
class. In contrast, in this paper we propose a new basic operation:
for each pair of input instances, count how many concepts of bounded
complexity contain both of them.
&lt;/p&gt;

&lt;p&gt;
Our approach maps instances to a Hilbert space, whose metric is
induced by a universal kernel coinciding with our computational
primitive, and identifies concepts with half-spaces.  We prove that
all concepts are linearly separable under this mapping.  Hence, given
a labeled sample and an oracle for evaluating the universal kernel, we
can efficiently compute a linear classifier (via SVM, for example) and
use margin bounds to control its generalization error.  Even though
exact evaluation of the universal kernel may be infeasible, in various
natural situations it is efficiently approximable.
&lt;/p&gt;

&lt;p&gt;
Though our approach is general, our main application is to regular
languages.  Our approach presents a substantial departure from current
learning paradigms and in particular yields a novel method for
learning this fundamental concept class. Unlike existing techniques,
we make no structural assumptions on the corresponding unknown
automata, the string distribution or the completeness of the training
set.  Instead, given a labeled sample our algorithm outputs a
classifier with guaranteed distribution-free generalization bounds; to
our knowledge, the proposed framework is the only one capable of
achieving the latter.  Along the way, we touch upon several
fundamental questions in complexity, automata, and machine learning.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kontorovich09a/kontorovich09a.pdf</url></Article><Article><id>586</id><title>
Multi-task Reinforcement Learning in Partially Observable Stochastic Environments
</title><author>Hui Li, Xuejun Liao, Lawrence Carin</author><abstract>

We consider the problem of multi-task reinforcement learning (MTRL)
in multiple partially observable stochastic environments. We
introduce the regionalized policy representation (RPR) to
characterize the agent's behavior in each environment. The RPR is a
parametric model of the conditional distribution over current
actions given the history of past actions and observations; the
agent's choice of actions is directly based on this conditional
distribution, without an intervening model to characterize the
environment itself. We propose off-policy batch algorithms to learn
the parameters of the RPRs, using episodic data collected when
following a behavior policy, and show their linkage to policy
iteration. We employ the Dirichlet process as a nonparametric prior
over the RPRs across multiple environments. The intrinsic clustering
property of the Dirichlet process imposes sharing of episodes among
similar environments, which effectively reduces the number of
episodes required for learning a good policy in each environment,
when data sharing is appropriate. The number of distinct RPRs and
the associated clusters (the sharing patterns) are automatically
discovered by exploiting the episodic data as well as the
nonparametric nature of the Dirichlet process. We demonstrate the
effectiveness of the proposed RPR as well as the RPR-based MTRL
framework on various problems, including grid-world navigation and
multi-aspect target classification. The experimental results show
that the RPR is a competitive reinforcement learning algorithm in
partially observable domains, and the MTRL consistently achieves
better performance than single task reinforcement learning.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/li09b/li09b.pdf</url></Article><Article><id>587</id><title>
The Hidden Life of Latent Variables: Bayesian Learning with Mixed Graph Models
</title><author>Ricardo Silva, Zoubin Ghahramani</author><abstract>

Directed acyclic graphs (DAGs) have been widely used as a representation of
conditional independence in machine learning and statistics. Moreover,
hidden or latent variables are often an important component of graphical
models. However,  DAG models suffer from an important limitation: the family
of DAGs is not closed under marginalization of hidden variables.  This means
that in general we cannot use a DAG to represent the independencies over a
subset of variables in a larger DAG.  Directed mixed graphs (DMGs) are a
representation that includes DAGs as a special case, and overcomes this
limitation. This paper introduces algorithms for performing Bayesian
inference in Gaussian and probit DMG models. An important requirement for
inference is the specification of the distribution over parameters of the
models. We introduce a new distribution for covariance matrices of Gaussian
DMGs.  We discuss and illustrate how several Bayesian machine learning tasks
can benefit from the principle presented here: the power to model
dependencies that are generated from hidden  variables, but without
necessarily modeling such variables explicitly.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/silva09a/silva09a.pdf</url></Article><Article><id>588</id><title>
Incorporating Functional Knowledge in Neural Networks
</title><author>Charles Dugas, Yoshua Bengio, Fran&amp;#231;ois B&amp;#233;lisle, Claude Nadeau, Ren&amp;#233; Garcia</author><abstract>

Incorporating prior knowledge of a particular task into the
architecture of a learning algorithm can greatly improve
generalization performance. We study here a case where we know that
the function to be learned is non-decreasing in its two arguments and
convex in one of them. For this purpose we propose a class of
functions similar to multi-layer neural networks but (1) that has
those properties, (2) is a universal approximator of
Lipschitz functions with these and other
properties. We apply this new class of functions to the task of
modelling the price of call options. Experiments show improvements on
regressing the price of call options using the new types of function
classes that incorporate the &lt;i&gt;a priori&lt;/i&gt; constraints.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/dugas09a/dugas09a.pdf</url></Article><Article><id>589</id><title>
Perturbation Corrections in Approximate Inference: Mixture Modelling Applications
</title><author>Ulrich Paquet, Ole Winther, Manfred Opper</author><abstract>

Bayesian inference is intractable for many interesting models, making
deterministic algorithms for approximate inference highly desirable.
Unlike stochastic methods, which are exact in the limit,
the accuracy of these approaches cannot be reasonably judged.
In this paper we show how low order perturbation corrections to
an expectation-consistent (EC) approximation can provide the necessary tools
to ameliorate inference accuracy, and to give
an indication of the quality of approximation without having to resort
to Monte Carlo methods.
Further comparisons are given with variational Bayes and
parallel tempering (PT) combined with
thermodynamic integration on a Gaussian mixture
model. To obtain practical results we further generalize PT to temper from
arbitrary distributions rather than a prior in Bayesian inference.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/paquet09a/paquet09a.pdf</url></Article><Article><id>590</id><title>
Robust Process Discovery with Artificial Negative Events
</title><author>Stijn Goedertier, David Martens, Jan Vanthienen, Bart Baesens</author><abstract>

Process discovery is the automated construction of structured
process models from information system event logs. Such event logs
often contain positive examples only. Without negative examples,
it is a challenge to strike the right balance between recall and
specificity, and to deal with problems such as expressiveness,
noise, incomplete event logs, or the inclusion of prior knowledge.
In this paper, we present a configurable technique that deals with
these challenges by representing process discovery as a
multi-relational classification problem on event logs supplemented
with Artificially Generated Negative Events (AGNEs). This problem
formulation allows using learning algorithms and evaluation
techniques that are well-know in the machine learning community.
Moreover, it allows users to have a declarative control over the
inductive bias and language bias.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/goedertier09a/goedertier09a.pdf</url></Article><Article><id>591</id><title>
Feature Selection with Ensembles, Artificial Variables, and Redundancy Elimination
</title><author>Eugene Tuv, Alexander Borisov, George Runger, Kari Torkkola</author><abstract>

Predictive models benefit from a compact, non-redundant subset of
features that improves interpretability and generalization.
Modern data sets are wide, dirty, mixed with both numerical and
categorical predictors, and may contain interactive effects
that require complex models. This is a challenge for filters,
wrappers, and embedded feature selection methods. We
describe details of an algorithm using tree-based ensembles to
generate a compact subset of non-redundant features.
Parallel and serial ensembles of trees
are combined into a mixed method that can uncover masking
and detect features of secondary effect.
Simulated and actual
examples illustrate the effectiveness of the approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/tuv09a/tuv09a.pdf</url></Article><Article><id>592</id><title>
A Parameter-Free Classification Method for Large Scale Learning
</title><author>Marc Boull&amp;#233;</author><abstract>
&lt;p&gt;
With the rapid growth of computer storage capacities, available data
and demand for scoring models both follow an increasing trend, sharper
than that of the processing power. However, the main limitation to a
wide spread of data mining solutions is the non-increasing
availability of skilled data analysts, which play a key role in data
preparation and model selection.
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a parameter-free scalable classification
method, which is a step towards fully automatic data mining.  The
method is based on Bayes optimal univariate conditional density
estimators, naive Bayes classification enhanced with a Bayesian
variable selection scheme, and averaging of models using a logarithmic
smoothing of the posterior distribution.  We focus on the complexity
of the algorithms and show how they can cope with data sets that are
far larger than the available central memory. We finally report
results on the Large Scale Learning challenge, where our method
obtains state of the art performance within practicable computation
time.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/boulle09a/boulle09a.pdf</url></Article><Article><id>593</id><title>
Model Monitor (&lt;i&gt;M&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;): Evaluating, Comparing, and Monitoring Models
</title><author>Troy Raeder, Nitesh V. Chawla</author><abstract>

This paper presents Model Monitor (&lt;i&gt;M&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;), a Java toolkit for robustly
evaluating machine learning algorithms in the presence of changing
data distributions.  &lt;i&gt;M&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt; provides a simple and intuitive framework
in which users can evaluate classifiers under hypothesized shifts in
distribution and therefore determine the best model (or models) for
their data under a number of potential scenarios.  Additionally, &lt;i&gt;M&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;
is fully integrated with the WEKA machine learning environment, so
that a variety of commodity classifiers can be used if desired.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/raeder09a/raeder09a.pdf</url></Article><Article><id>594</id><title>
A Least-squares Approach to Direct Importance Estimation
</title><author>Takafumi Kanamori, Shohei Hido, Masashi Sugiyama</author><abstract>

We address the problem of estimating the ratio of two probability density functions,
which is often referred to as the &lt;i&gt;importance&lt;/i&gt;.
The importance values can be used for various succeeding tasks such as
&lt;i&gt;covariate shift adaptation&lt;/i&gt; or &lt;i&gt;outlier detection&lt;/i&gt;.
In this paper, we propose a new importance estimation method
that has a closed-form solution;
the leave-one-out cross-validation score
can also be computed analytically.
Therefore, the proposed method is computationally highly efficient and simple 
to implement.
We also elucidate theoretical properties of the proposed method such as the convergence
rate and approximation error bounds. 
Numerical experiments show that the proposed method
is comparable to the best existing method in accuracy,
while it is computationally more efficient
than competing approaches.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/kanamori09a/kanamori09a.pdf</url></Article><Article><id>595</id><title>
Classification with Gaussians and Convex Loss
</title><author>Dao-Hong Xiang, Ding-Xuan Zhou</author><abstract>

This paper considers binary classification algorithms generated
from Tikhonov regularization schemes associated with general
convex loss functions and varying Gaussian kernels. Our main goal
is to provide fast convergence rates for the excess
misclassification error. Allowing varying Gaussian kernels in the
algorithms improves learning rates measured by regularization
error and sample error. Special structures of Gaussian kernels
enable us to construct, by a nice approximation scheme with a
Fourier analysis technique, uniformly bounded regularizing
functions achieving polynomial decays of the regularization error
under a Sobolev smoothness condition. The sample error is
estimated by using a projection operator and a tight bound for the
covering numbers of reproducing kernel Hilbert spaces generated by
Gaussian kernels. The convexity of the general loss function plays
a very important role in our analysis.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/xiang09a/xiang09a.pdf</url></Article><Article><id>596</id><title>
Entropy Inference and the James-Stein Estimator, with Application to Nonlinear Gene Association Networks
</title><author>Jean Hausser, Korbinian Strimmer</author><abstract>

We present a procedure for effective estimation of entropy and mutual
information from small-sample data, and apply it to the problem of
inferring high-dimensional gene association networks. Specifically, we
develop a James-Stein-type shrinkage estimator, resulting in a procedure
that is highly efficient statistically as well as computationally.
Despite its simplicity, we show that it outperforms eight other entropy
estimation procedures across a diverse range of sampling scenarios and
data-generating models, even in cases of severe undersampling. We
illustrate the approach by analyzing &lt;i&gt;E. coli&lt;/i&gt; gene expression data and
computing an entropy-based gene-association network from gene expression
data. A computer program is available that implements the proposed
shrinkage estimator.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/hausser09a/hausser09a.pdf</url></Article><Article><id>597</id><title>
Robustness and Regularization of Support Vector Machines
</title><author>Huan Xu, Constantine Caramanis, Shie Mannor</author><abstract>

We consider regularized support vector machines (SVMs) and show that
they are precisely equivalent to a new robust optimization
formulation. We show that this equivalence of robust optimization
and regularization has implications for both algorithms, and
analysis. In terms of algorithms, the equivalence suggests more
general SVM-like algorithms for classification that explicitly build
in protection to noise, and at the same time control overfitting. On
the analysis front, the equivalence of robustness and regularization
provides a robust optimization interpretation for the success of
regularized SVMs. We use this new robustness interpretation of SVMs
to give a new proof of consistency of (kernelized) SVMs, thus
establishing robustness as the &lt;i&gt;reason&lt;/i&gt; regularized SVMs
generalize well.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/xu09b/xu09b.pdf</url></Article><Article><id>598</id><title>
Strong Limit Theorems for the Bayesian Scoring Criterion in Bayesian Networks
</title><author>Nikolai Slobodianik, Dmitry Zaporozhets, Neal Madras</author><abstract>

In the machine learning community, the Bayesian scoring criterion is
widely used for model selection problems. One of the fundamental
theoretical properties justifying the usage of the Bayesian scoring
criterion is its consistency. In this paper we refine this property
for the case of binomial Bayesian network models. As a by-product of
our derivations we establish strong consistency and obtain the law of
iterated logarithm for the Bayesian scoring criterion.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/slobodianik09a/slobodianik09a.pdf</url></Article><Article><id>599</id><title>
Bayesian Network Structure Learning by Recursive Autonomy Identification
</title><author>Raanan Yehezkel, Boaz Lerner</author><abstract>

We propose the recursive autonomy identification (RAI) algorithm for
constraint-based (CB) Bayesian network structure learning. The RAI
algorithm learns the structure by sequential application of
conditional independence (CI) tests, edge direction and structure
decomposition into autonomous sub-structures. The sequence of
operations is performed recursively for each autonomous sub-structure
while simultaneously increasing the order of the CI test. While other
CB algorithms d-separate structures and then direct the resulted
undirected graph, the RAI algorithm combines the two processes from
the outset and along the procedure. By this means and due to structure
decomposition, learning a structure using RAI requires a smaller
number of CI tests of high orders. This reduces the complexity and
run-time of the algorithm and increases the accuracy by diminishing
the curse-of-dimensionality. When the RAI algorithm learned structures
from databases representing synthetic problems, known networks and
natural problems, it demonstrated superiority with respect to
computational complexity, run-time, structural correctness and
classification accuracy over the PC, Three Phase Dependency Analysis,
Optimal Reinsertion, greedy search, Greedy Equivalence Search, Sparse
Candidate, and Max-Min Hill-Climbing algorithms.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/yehezkel09a/yehezkel09a.pdf</url></Article><Article><id>600</id><title>
Learning Linear Ranking Functions for Beam Search with Application to Planning
</title><author>Yuehua Xu, Alan Fern, Sungwook Yoon</author><abstract>

Beam search is commonly used to help maintain tractability
in large search spaces at the expense of completeness and optimality.  Here we
study supervised learning of linear ranking functions for controlling
beam search. The goal is to learn ranking functions that allow for beam search to
perform nearly as well as unconstrained search, and hence gain computational
efficiency without seriously sacrificing optimality. In this paper, we develop
theoretical aspects of this learning problem and investigate the application of
this framework to learning in the context of automated planning. We first study
the computational complexity of the learning problem, showing that even for
exponentially large search spaces the general consistency problem is in NP. We
also identify tractable and intractable subclasses of the learning problem,
giving insight into the problem structure. Next, we analyze the convergence
of recently proposed and modified online learning algorithms, where we introduce
several notions of problem margin that imply convergence for the various algorithms.
Finally, we present empirical results in automated planning, where ranking
functions are learned to guide beam search in a number of benchmark planning
domains. The results show that our approach is often able to outperform an existing
state-of-the-art planning heuristic as well as a recent approach to learning such
heuristics.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/xu09c/xu09c.pdf</url></Article><Article><id>601</id><title>
Marginal Likelihood Integrals for Mixtures of Independence Models
</title><author>Shaowei Lin, Bernd Sturmfels, Zhiqiang Xu</author><abstract>

Inference in Bayesian statistics involves the
evaluation of marginal likelihood integrals.
We present algebraic algorithms for computing
such integrals exactly for discrete data of small sample size.
Our methods apply to
both  uniform priors and Dirichlet priors.
The underlying statistical models are
mixtures of independent distributions, or,
in geometric language, 
secant varieties of Segre-Veronese varieties. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/lin09a/lin09a.pdf</url></Article><Article><id>602</id><title>
Transfer Learning for Reinforcement Learning Domains: A Survey
</title><author>Matthew E. Taylor, Peter Stone</author><abstract>

The reinforcement learning paradigm is a popular way to address
problems that have only limited environmental feedback, rather than
correctly labeled examples, as is common in other machine learning
contexts. While significant progress has been made to improve learning
in a single task, the idea of &lt;i&gt;transfer learning&lt;/i&gt; has only
recently been applied to reinforcement learning tasks. The core idea
of transfer is that experience gained in learning to perform one task
can help improve learning performance in a related, but different,
task. In this article we present a framework that classifies transfer
learning methods in terms of their capabilities and goals, and then
use it to survey the existing literature, as well as to suggest future
directions for transfer learning work.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/taylor09a/taylor09a.pdf</url></Article><Article><id>603</id><title>
Application of Non Parametric Empirical Bayes Estimation to High Dimensional Classification
</title><author>Eitan Greenshtein, Junyong Park</author><abstract>
&lt;p&gt;
We consider the problem of classification using high dimensional
features' space. In a paper by Bickel and Levina (2004), it is
recommended to use naive-Bayes classifiers, that is, to treat the
features as if they are statistically independent.
&lt;/p&gt;
&lt;p&gt;
Consider now a sparse setup, where only a few of the features
are informative for classification. Fan and Fan (2008),
suggested a variable selection and classification method, called FAIR.
The FAIR method improves the design of naive-Bayes classifiers in
sparse setups. The improvement is due to
reducing the noise in estimating the features' means. This reduction is since
that only the means of a few selected variables should be estimated.
&lt;/p&gt;
&lt;p&gt;
We also consider the design of  naive Bayes classifiers. We show that a good alternative to
variable selection is estimation of the means
through a certain non parametric  empirical Bayes procedure. In sparse
setups the empirical Bayes implicitly performs an efficient variable
selection. It also adapts very well to non sparse setups, and has the advantage
of making use of the information from many "weakly informative" variables, which
variable selection type of classification procedures give up on using.
&lt;/p&gt;
&lt;p&gt;
We compare our method with FAIR and other classification methods in
simulation for sparse and non sparse setups, and
in real data examples 
involving  classification of normal versus malignant tissues based on microarray data.
&lt;/p&gt;
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/greenshtein09a/greenshtein09a.pdf</url></Article><Article><id>604</id><title>
Learning Permutations with Exponential Weights
</title><author>David P. Helmbold, Manfred K. Warmuth</author><abstract>

We give an algorithm for the on-line learning of permutations.
The algorithm maintains its uncertainty about the
target permutation as a doubly stochastic weight matrix, and makes predictions using
an efficient method for decomposing the weight matrix into a convex combination
of permutations.
The weight matrix is updated by multiplying the current
matrix entries by exponential factors, 
and an iterative procedure is needed to restore double stochasticity.
Even though the result of this procedure
does not have a closed form, a new analysis approach
allows us to prove an optimal (up to small constant factors) bound on 
the regret of our algorithm.
This regret bound is significantly better than that of either
Kalai and Vempala's 
more efficient Follow the Perturbed Leader algorithm or
the computationally expensive method of explicitly representing each permutation as
an expert.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/helmbold09a/helmbold09a.pdf</url></Article><Article><id>605</id><title>
SGD-QN: Careful Quasi-Newton Stochastic Gradient Descent
</title><author>Antoine Bordes, L&amp;#233;on Bottou, Patrick Gallinari</author><abstract>

The SGD-QN algorithm is a stochastic gradient descent algorithm that
makes careful use of second-order information and splits the parameter
update into independently scheduled components. Thanks to this design,
SGD-QN iterates nearly as fast as a first-order stochastic gradient
descent but requires less iterations to achieve the same accuracy.
This algorithm won the "Wild Track" of the first PASCAL Large Scale
Learning Challenge (Sonnenburg et al., 2008).

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/bordes09a/bordes09a.pdf</url></Article><Article><id>606</id><title>
Dlib-ml: A Machine Learning Toolkit
</title><author>Davis E. King</author><abstract>

There are many excellent toolkits which provide support for developing
machine learning software in Python, R, Matlab, and similar
environments.  Dlib-ml is an open source library, targeted at both
engineers and research scientists, which aims to provide a similarly
rich environment for developing machine learning software in the C++
language.  Towards this end, dlib-ml contains an extensible linear
algebra toolkit with built in BLAS support.  It also houses
implementations of algorithms for performing inference in Bayesian
networks and kernel-based methods for classification, regression,
clustering, anomaly detection, and feature ranking.  To enable easy
use of these tools, the entire library has been developed with
contract programming, which provides complete and precise
documentation as well as powerful debugging tools.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/king09a/king09a.pdf</url></Article><Article><id>607</id><title>
Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning
</title><author>Halbert White, Karim Chalak</author><abstract>

Judea Pearl's Causal Model is a rich framework that provides deep insight
into the nature of causal relations. As yet, however, the Pearl Causal Model
(PCM) has had a lesser impact on economics or econometrics than on other
disciplines. This may be due in part to the fact that the PCM is not as well
suited to analyzing structures that exhibit features of central interest to
economists and econometricians: optimization, equilibrium, and learning. We
offer the settable systems framework as an extension of the PCM that permits
causal discourse in systems embodying optimization, equilibrium, and
learning. Because these are common features of physical, natural, or social
systems, our framework may prove generally useful for machine learning.
Important features distinguishing the settable system framework from the PCM
are its countable dimensionality and the use of partitioning and
partition-specific response functions to accommodate the behavior of
optimizing and interacting agents and to eliminate the requirement of a
unique fixed point for the system. Refinements of the PCM include the
settable systems treatment of attributes, the causal role of exogenous
variables, and the dual role of variables as causes and responses. A series
of closely related machine learning examples and examples from game theory
and machine learning with feedback demonstrates some limitations of the PCM
and motivates the distinguishing features of settable systems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/white09a/white09a.pdf</url></Article><Article><id>608</id><title>
Distributed Algorithms for Topic Models
</title><author>David Newman, Arthur Asuncion, Padhraic Smyth, Max Welling</author><abstract>

We describe distributed algorithms for two widely-used topic models,
namely the Latent Dirichlet Allocation (LDA) model, and the
Hierarchical Dirichet Process (HDP) model.  In our distributed
algorithms the data is partitioned across separate processors and
inference is done in a parallel, distributed fashion.  We propose two
distributed algorithms for LDA.  The first algorithm is a
straightforward mapping of LDA to a distributed processor setting.  In
this algorithm
processors concurrently perform Gibbs sampling over local data
followed by a global update of topic counts.  The algorithm is
simple to implement and can be viewed as an approximation to
Gibbs-sampled LDA.  The second version is a model that uses a
hierarchical Bayesian extension of LDA to directly account for
distributed data.  This model has a theoretical guarantee of
convergence but is more complex to implement than the first algorithm.
Our distributed algorithm for HDP takes the straightforward mapping
approach, and merges newly-created topics either by matching or
by topic-id.  Using five real-world text corpora we show that
distributed learning works well in practice.  For both LDA and HDP, we
show that the converged test-data log probability for distributed learning is
indistinguishable from that obtained with single-processor learning.
Our extensive experimental results include learning topic models for
two multi-million document collections using a 1024-processor parallel
computer.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/newman09a/newman09a.pdf</url></Article><Article><id>609</id><title>
Nonlinear Models Using Dirichlet Process Mixtures
</title><author>Babak Shahbaba, Radford Neal</author><abstract>

We introduce a new nonlinear model for classification, in which we
model the joint distribution of response variable, &lt;i&gt;y&lt;/i&gt;, and
covariates, &lt;i&gt;x&lt;/i&gt;, non-parametrically using Dirichlet process
mixtures. We keep the relationship between &lt;i&gt;y&lt;/i&gt; and &lt;i&gt;x&lt;/i&gt; linear within
each component of the mixture. The overall relationship becomes
nonlinear if the mixture contains more than one component, with
different regression coefficients. We use simulated data to compare the
performance of this new approach to alternative methods such as
multinomial logit (MNL) models, decision trees, and support vector
machines. We also evaluate our approach on two classification
problems: identifying the folding class of protein sequences and
detecting Parkinson's disease. Our model can sometimes improve
predictive accuracy. Moreover, by grouping observations into
sub-populations (i.e., mixture components), our model can sometimes provide
insight into hidden structure in the data. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/shahbaba09a/shahbaba09a.pdf</url></Article><Article><id>610</id><title>
CarpeDiem: Optimizing the Viterbi Algorithm and Applications to Supervised Sequential Learning
</title><author>Roberto Esposito, Daniele P. Radicioni</author><abstract>

&lt;p&gt;
The growth of information available to learning systems and the
increasing complexity of learning tasks determine the need for
devising algorithms that scale well with respect to all learning
parameters. In the context of supervised sequential learning, the
Viterbi algorithm plays a fundamental role, by allowing the evaluation
of the best (most probable) sequence of labels with a time complexity
linear in the number of time events, and quadratic in the number of
labels.
&lt;/p&gt;
&lt;p&gt;
In this paper we propose CarpeDiem, a novel algorithm allowing the
evaluation of the best possible sequence of labels with a
sub-quadratic time complexity.
We provide theoretical grounding together with solid empirical results
supporting two chief facts. CarpeDiem always finds the optimal solution
requiring, in most cases, only a small fraction of the time taken by
the Viterbi algorithm; meantime, CarpeDiem is never asymptotically
worse than the Viterbi algorithm, thus confirming it as a sound
replacement.
&lt;/p&gt;

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/esposito09a/esposito09a.pdf</url></Article><Article><id>611</id><title>
Learning Acyclic Probabilistic Circuits Using Test Paths
</title><author>Dana Angluin, James Aspnes, Jiang Chen, David Eisenstat, Lev Reyzin</author><abstract>

We define a model of learning probabilistic acyclic circuits using
value injection queries, in which fixed values are assigned to an
arbitrary subset of the wires and the value on the single output wire
is observed.  We adapt the approach of using test paths from the
Circuit Builder algorithm  (Angluin et al., 2009) to show that there is
a polynomial time algorithm that uses value injection queries to learn
acyclic Boolean probabilistic circuits of constant fan-in and log
depth.  We establish upper and lower bounds on the attenuation factor
for general and transitively reduced Boolean probabilistic circuits of
test paths versus general experiments.  We give computational evidence
that a polynomial time learning algorithm using general value
injection experiments may not do much better than one using test
paths.  For probabilistic circuits with alphabets of size three or
greater, we show that the test path lemmas
(Angluin et al., 2009, 2008b) fail utterly.  To overcome this
obstacle, we introduce function injection queries, in which the values
on a wire may be mapped to other values rather than just to themselves
or constants, and prove a generalized test path lemma for this case.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/angluin09a/angluin09a.pdf</url></Article><Article><id>612</id><title>
Learning Approximate Sequential Patterns for Classification
</title><author>Zeeshan Syed, Piotr Indyk, John Guttag</author><abstract>

In this paper, we present an automated approach to discover patterns
that can distinguish between sequences belonging to different labeled
groups. Our method searches for approximately conserved motifs that
occur with varying statistical properties in positive and negative
training examples. We propose a two-step process to discover such
patterns. Using locality sensitive hashing (LSH), we first estimate
the frequency of all subsequences and their approximate matches within
a given Hamming radius in labeled examples. The discriminative ability
of each pattern is then assessed from the estimated frequencies by
concordance and rank sum testing. The use of LSH to identify
approximate matches for each candidate pattern helps reduce the
runtime of our method. Space requirements are reduced by decomposing
the search problem into an iterative method that uses a single LSH
table in memory. We propose two further optimizations to the search
for discriminative patterns. Clustering with redundancy based on a
2-approximate solution of the &lt;i&gt;k&lt;/i&gt;-center problem decreases the number
of overlapping approximate groups while providing exhaustive coverage
of the search space. Sequential statistical methods allow the search
process to use data from only as many training examples as are needed
to assess significance. We evaluated our algorithm on data sets from
different applications to discover sequential patterns for
classification. On nucleotide sequences from the Drosophila genome
compared with random background sequences, our method was able to
discover approximate binding sites that were preserved upstream of
genes. We observed a similar result in experiments on ChIP-on-chip
data. For cardiovascular data from patients admitted with acute
coronary syndromes, our pattern discovery approach identified
approximately conserved sequences of morphology variations that were
predictive of future death in a test population. Our data showed that
the use of LSH, clustering, and sequential statistics improved the
running time of the search algorithm by an order of magnitude without
any noticeable effect on accuracy. These results suggest that our
methods may allow for an unsupervised approach to efficiently learn
interesting dissimilarities between positive and negative examples
that may have a functional role.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/syed09a/syed09a.pdf</url></Article><Article><id>613</id><title>
Hybrid MPI/OpenMP Parallel Linear Support Vector Machine Training
</title><author>Kristian Woodsend, Jacek Gondzio</author><abstract>

Support vector machines are a powerful machine learning technology,
but the training process involves a dense quadratic optimization
problem and is computationally challenging. A parallel implementation
of linear Support Vector Machine training has been developed, using a
combination of MPI and OpenMP. Using an interior point method for the
optimization and a reformulation that avoids the dense Hessian matrix,
the structure of the augmented system matrix is exploited to partition
data and computations amongst parallel processors efficiently. The new
implementation has been applied to solve problems from the
PASCAL Challenge on Large-scale Learning. 
We show that our approach is competitive, and is able to
solve problems in the Challenge many times faster than other parallel
approaches.  We also demonstrate that the hybrid version performs more
efficiently than the version using pure MPI.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/woodsend09a/woodsend09a.pdf</url></Article><Article><id>614</id><title>
Provably Efficient Learning with Typed Parametric Models
</title><author>Emma Brunskill, Bethany R. Leffler, Lihong Li, Michael L. Littman, Nicholas Roy</author><abstract>

To quickly achieve good performance, reinforcement-learning algorithms
for acting in large continuous-valued domains must use a
representation that is both sufficiently powerful to capture important
domain characteristics, and yet simultaneously allows generalization,
or sharing, among experiences. Our algorithm balances this tradeoff by
using a stochastic, switching, parametric dynamics representation. We
argue that this model characterizes a number of significant,
real-world domains, such as robot navigati on across varying
terrain. We prove that this representational assumption allows our
algorithm to be probably approximately correct with a sample
complexity that scales polynomially with all problem-specific
quantities including the state-space dimension.  We also explicitly
incorporate the error introduced by approximate planning in our sample
complexity bounds, in contrast to prior Probably Approximately Correct
(PAC) Markov Decision Processes (MDP) approaches, which typically
assume the estimated MDP can be solved exactly. Our experimental
results on constructing plans for driving to work using real car
trajectory data, as well as a small robot experiment on navigating
varying terrain, demonstrate that our dynamics representation enables
us to capture real-world dynamics in a sufficient manner to produce
good performance.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/brunskill09a/brunskill09a.pdf</url></Article><Article><id>615</id><title>
Fast Approximate &lt;i&gt;k&lt;/i&gt;NN Graph Construction for High Dimensional Data via Recursive Lanczos Bisection
</title><author>Jie Chen, Haw-ren Fang, Yousef Saad</author><abstract>

Nearest neighbor graphs are widely used in data mining and machine
learning.  A brute-force method to compute the exact &lt;i&gt;k&lt;/i&gt;NN graph
takes &amp;#920;(&lt;i&gt;dn&lt;/i&gt;&lt;sup&gt;2&lt;/sup&gt;) time for &lt;i&gt;n&lt;/i&gt; data points in 
the &lt;i&gt;d&lt;/i&gt; dimensional
Euclidean  space.  We propose two divide and conquer methods for
computing an approximate &lt;i&gt;k&lt;/i&gt;NN graph in &amp;#920;(&lt;i&gt;dn&lt;sup&gt;t&lt;/sup&gt;&lt;/i&gt;) time for high
dimensional data (large  &lt;i&gt;d&lt;/i&gt;).  The exponent &lt;i&gt;t&lt;/i&gt; &amp;#8712; (1,2) is an
increasing function of an internal parameter &amp;#945; which governs the
size of the common region in the divide step. Experiments show that a
high quality graph can usually be obtained with small overlaps, that is,
for small values of &lt;i&gt;t&lt;/i&gt;.
A few of the practical details of the algorithms are as
follows. First, the divide step uses an inexpensive Lanczos procedure
to perform recursive spectral bisection. After each conquer step, an
additional refinement step is performed to improve the accuracy of the
graph.  Finally, a hash table is used to avoid repeating distance
calculations during the divide and conquer process. The combination of
these techniques is shown to yield quite effective algorithms for
building &lt;i&gt;k&lt;/i&gt;NN graphs.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/chen09b/chen09b.pdf</url></Article><Article><id>616</id><title>
Ultrahigh Dimensional Feature Selection: Beyond The Linear Model
</title><author>Jianqing Fan, Richard Samworth, Yichao Wu</author><abstract>

Variable selection in high-dimensional space characterizes many
contemporary problems in scientific discovery and decision making.
Many frequently-used techniques are based on independence screening;
examples include correlation ranking (Fan &amp;#38; Lv, 2008) or feature selection
using a two-sample &lt;i&gt;t&lt;/i&gt;-test in high-dimensional classification
(Tibshirani et al., 2003). Within the context of the linear model, Fan &amp;#38; Lv (2008)
showed that this simple correlation ranking possesses a sure
independence screening property under certain conditions and that its
revision, called iteratively sure independent screening (ISIS), is
needed when the features are marginally unrelated but jointly related
to the response variable. In this paper, we extend ISIS, without
explicit definition of residuals, to a general pseudo-likelihood
framework, which includes generalized linear models as a special
case. Even in the least-squares setting, the new method improves ISIS
by allowing feature deletion in the iterative process.  Our technique
allows us to select important features in high-dimensional
classification where the popularly used two-sample &lt;i&gt;t&lt;/i&gt;-method fails. A
new technique is introduced to reduce the false selection rate in the
feature screening stage.  Several simulated and two real data examples
are presented to illustrate the methodology.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/fan09a/fan09a.pdf</url></Article><Article><id>617</id><title>
Evolutionary Model Type Selection for Global Surrogate Modeling
</title><author>Dirk Gorissen, Tom Dhaene, Filip De Turck</author><abstract>

Due to the scale and computational complexity of currently used simulation
codes, global surrogate (metamodels) models have become indispensable tools for
exploring and understanding the design space. Due to their compact
formulation they are cheap to evaluate and thus readily facilitate
visualization, design space exploration, rapid prototyping, and sensitivity
analysis. They can also be used as accurate building blocks in design
packages or larger simulation environments. Consequently, there is
great interest in techniques that facilitate the construction of such
approximation models while minimizing the computational cost and maximizing
model accuracy. Many surrogate model types exist (Support Vector Machines,
Kriging, Neural Networks, etc.) but no type is optimal in all circumstances.
Nor is there any hard theory available that can help make this choice.
In this paper we present an automatic approach to the model type selection
problem. We describe an adaptive global surrogate modeling environment
with adaptive sampling, driven by speciated evolution. Different model
types are evolved cooperatively using a Genetic Algorithm (heterogeneous
evolution) and compete to approximate the iteratively selected data.
In this way the optimal model type and complexity for a given data set
or simulation code can be dynamically determined. Its utility and
performance is demonstrated on a number of problems where it outperforms
traditional sequential execution of each model type.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/gorissen09a/gorissen09a.pdf</url></Article><Article><id>618</id><title>
An Anticorrelation Kernel for Subsystem Training in Multiple Classifier Systems
</title><author>Luciana Ferrer, Kemal S&amp;#246;nmez, Elizabeth Shriberg</author><abstract>

We present a method for training support vector machine (SVM)-based
classification systems for combination with other classification
systems designed for the same task. Ideally, a new system should be
designed such that, when combined with existing systems, the resulting
performance is optimized. We present a simple model for this problem
and use the understanding gained from this analysis to propose a
method to achieve better combination performance when training SVM
systems. We include a regularization term in the SVM objective
function that aims to reduce the average class-conditional covariance
between the resulting scores and the scores produced by the existing
systems, introducing a trade-off between such covariance and the
system's individual performance. That is, the new system "takes one
for the team", falling somewhat short of its best possible performance
in order to increase the diversity of the ensemble. We report results
on the NIST 2005 and 2006 speaker recognition evaluations (SREs) for a
variety of subsystems. We show a gain of 19% on the equal error rate
(EER) of a combination of four systems when applying the proposed
method with respect to the performance obtained when the four systems
are trained independently of each other.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/ferrer09a/ferrer09a.pdf</url></Article><Article><id>619</id><title>
Deterministic Error Analysis of Support Vector Regression and Related Regularized Kernel Methods
</title><author>Christian Rieger, Barbara Zwicknagl</author><abstract>

We introduce a new technique for the analysis of kernel-based
regression problems. The basic tools are sampling inequalities which
apply to all machine learning problems involving penalty terms induced
by kernels related to Sobolev spaces. They lead to explicit
deterministic results concerning the worst case behaviour of
&amp;#949;- and &amp;#957;-SVRs. Using these, we show how to adjust
regularization parameters to get best possible approximation orders
for regression. The results are illustrated by some numerical
examples.




</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/rieger09a/rieger09a.pdf</url></Article><Article><id>620</id><title>
RL-Glue: Language-Independent Software for Reinforcement-Learning Experiments
</title><author>Brian Tanner, Adam White</author><abstract>

RL-Glue is a standard, language-independent software package for
reinforcement-learning experiments.  The standardization provided by
RL-Glue facilitates code sharing and collaboration.  Code sharing
reduces the need to re-engineer tasks and experimental apparatus, both
common barriers to comparatively evaluating new ideas in the context
of the literature.  Our software features a minimalist interface and
works with several languages and computing platforms. RL-Glue
compatibility can be extended to any programming language that
supports network socket communication. RL-Glue has been used to teach
classes, to run international competitions, and is currently used by
several other open-source software and hardware projects.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/tanner09a/tanner09a.pdf</url></Article><Article><id>621</id><title>
Discriminative Learning Under Covariate Shift
</title><author>Steffen Bickel, Michael Br&amp;#252;ckner, Tobias Scheffer</author><abstract>

We address classification problems for which the training instances
are governed by an input distribution that is allowed to differ
arbitrarily from the test distribution---problems also referred to as
classification under covariate shift.  We derive a solution that is
purely discriminative: neither training nor test distribution are
modeled explicitly.  The problem of learning under covariate shift can
be written as an integrated optimization problem. Instantiating the
general optimization problem leads to a kernel logistic regression and
an exponential model classifier for covariate shift.  The optimization
problem is convex under certain conditions; our findings also clarify
the relationship to the known kernel mean matching procedure.  We
report on experiments on problems of spam filtering, text
classification, and landmine detection.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/bickel09a/bickel09a.pdf</url></Article><Article><id>622</id><title>
Optimized Cutting Plane Algorithm for Large-Scale Risk Minimization
</title><author>Vojt&amp;#x011B;ch Franc, S&amp;#246;ren Sonnenburg</author><abstract>

We have developed an optimized cutting plane algorithm (OCA) for solving large-scale
risk minimization problems. We prove that the number of iterations OCA
requires to converge to a &amp;#949; precise solution is approximately linear
in the sample size. We also derive OCAS, an OCA-based linear binary Support
Vector Machine (SVM) solver, and OCAM, a linear multi-class SVM solver.  In an
extensive empirical evaluation we show that OCAS outperforms current
state-of-the-art SVM solvers like SVM&lt;sup&gt;light&lt;/sup&gt;, SVM&lt;sup&gt;perf&lt;/sup&gt; and BMRM, achieving
speedup factor more than 1,200 over SVM&lt;sup&gt;light&lt;/sup&gt; on some data sets and speedup
factor of 29 over SVM&lt;sup&gt;perf&lt;/sup&gt;, while obtaining the same precise support vector
solution.  OCAS, even in the early optimization steps, often shows faster
convergence than the currently prevailing approximative methods in this domain, SGD
and Pegasos.  In addition, our proposed linear multi-class SVM solver, OCAM,
achieves speedups of factor of up to 10 compared to SVM&lt;sup&gt;multi-class&lt;/sup&gt;. Finally, we
use OCAS and OCAM in two real-world applications, the problem of human acceptor
splice site detection and malware detection.  Effectively parallelizing OCAS, we
achieve state-of-the-art results on an acceptor splice site recognition problem
only by being able to learn from all the available 50 million examples in a 
12-million-dimensional feature space. Source code, data sets and scripts to
reproduce the experiments are available at
&lt;tt&gt;&lt;a href="http://cmp.felk.cvut.cz/~xfrancv/ocas/html/"&gt;http://cmp.felk.cvut.cz/~xfrancv/ocas/html/&lt;/a&gt;&lt;/tt&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/franc09a/franc09a.pdf</url></Article><Article><id>623</id><title>
Margin-based Ranking and an Equivalence between AdaBoost and RankBoost
</title><author>Cynthia Rudin, Robert E. Schapire</author><abstract>

We study boosting algorithms for learning to rank. We give a general
margin-based bound for ranking based on covering numbers for the
hypothesis space. Our bound suggests that algorithms that maximize the
ranking margin will generalize well. We then describe a new algorithm,
smooth margin ranking, that precisely converges to a maximum
ranking-margin solution. The algorithm is a modification of RankBoost,
analogous to "approximate coordinate ascent boosting." Finally, we
prove that AdaBoost and RankBoost are equally good for the problems of
bipartite ranking and classification in terms of their asymptotic
behavior on the training set. Under natural conditions, AdaBoost
achieves an area under the ROC curve that is equally as good as
RankBoost's; furthermore, RankBoost, when given a specific intercept,
achieves a misclassification error that is as good as AdaBoost's. This
may help to explain the empirical observations made by Cortes and
Mohri, and Caruana and Niculescu-Mizil, about the excellent
performance of AdaBoost as a bipartite ranking algorithm, as measured
by the area under the ROC curve.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/rudin09a/rudin09a.pdf</url></Article><Article><id>624</id><title>
The P-Norm Push: A Simple Convex Ranking Algorithm that Concentrates at the Top of the List
</title><author>Cynthia Rudin</author><abstract>

We are interested in supervised ranking algorithms that perform
especially well near the top of the ranked list, and are only required
to perform sufficiently well on the rest of the list.  In this work,
we provide a general form of convex objective that gives high-scoring
examples more importance. This "push" near the top of the list can be
chosen arbitrarily large or small, based on the preference of the
user. We choose &lt;i&gt;l&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-norms to provide a specific type of push; if
the user sets &lt;i&gt;p&lt;/i&gt; larger, the objective concentrates harder on the top
of the list.  We derive a generalization bound based on the &lt;i&gt;p&lt;/i&gt;-norm
objective, working around the natural asymmetry of the problem. We
then derive a boosting-style algorithm for the problem of ranking with
a push at the top.  The usefulness of the algorithm is illustrated
through experiments on repository data. We prove that the minimizer of
the algorithm's objective is unique in a specific sense. Furthermore,
we illustrate how our objective is related to quality measurements for
information retrieval.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/rudin09b/rudin09b.pdf</url></Article><Article><id>625</id><title>
Learning Nondeterministic Classifiers
</title><author>Juan Jos&amp;#x00E9; del Coz, Jorge D&amp;#x00ED;ez, Antonio Bahamonde</author><abstract>

Nondeterministic classifiers are defined as those allowed to predict
more than one class for some entries from an input space. Given that
the true class should be included in predictions and the number of
classes predicted should be as small as possible, these kind of
classifiers can be considered as Information Retrieval (IR)
procedures. In this paper, we propose a family of IR loss functions to
measure the performance of nondeterministic learners.  After
discussing such measures, we derive an algorithm for learning optimal
nondeterministic hypotheses. Given an entry from the input space, the
algorithm requires the posterior probabilities to compute the subset
of classes with the lowest expected loss. From a general point of
view, nondeterministic classifiers provide an improvement in the
proportion of predictions that include the true class compared to
their deterministic counterparts; the price to be paid for this
increase is usually a tiny proportion of predictions with more than
one class.  The paper includes an extensive experimental study using
three deterministic learners to estimate posterior probabilities: a
multiclass Support Vector Machine (SVM), a Logistic Regression, and a
Na&amp;#x00EF;ve Bayes. The data sets considered comprise both UCI
multi-class learning tasks and microarray expressions of different
kinds of cancer. We successfully compare nondeterministic classifiers
with other alternative approaches. Additionally, we shall see how the
quality of posterior probabilities (measured by the Brier score)
determines the goodness of nondeterministic predictions.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/delcoz09a/delcoz09a.pdf</url></Article><Article><id>626</id><title>
The Nonparanormal: Semiparametric Estimation of High Dimensional Undirected Graphs
</title><author>Han Liu, John Lafferty, Larry Wasserman</author><abstract>

Recent methods for estimating sparse undirected graphs for
real-valued data in high dimensional problems rely heavily on the assumption of normality.
We show how to use a semiparametric Gaussian copula---or
"nonparanormal"---for high dimensional inference.  Just as additive
models extend linear models by replacing linear functions with a set
of one-dimensional smooth functions, the nonparanormal extends the
normal by transforming the variables by smooth functions.  We derive a
method for estimating the nonparanormal, study the method's
theoretical properties, and show that it works well in many examples.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/liu09a/liu09a.pdf</url></Article><Article><id>627</id><title>
Computing Maximum Likelihood Estimates in Recursive Linear Models with Correlated Errors
</title><author>Mathias Drton, Michael Eichler, Thomas S. Richardson</author><abstract>

In recursive linear models, the multivariate normal joint distribution
of all variables exhibits a dependence structure induced by a
recursive (or acyclic) system of linear structural equations.  These
linear models have a long tradition and appear in seemingly unrelated
regressions, structural equation modelling, and approaches to causal
inference.  They are also related to Gaussian graphical models via a
classical representation known as a path diagram.  Despite the models'
long history, a number of problems remain open.  In this paper, we
address the problem of computing maximum likelihood estimates in the
subclass of 'bow-free' recursive linear models. The term 'bow-free'
refers to the condition that the errors for variables &lt;i&gt;i&lt;/i&gt; and &lt;i&gt;j&lt;/i&gt; be
uncorrelated if variable &lt;i&gt;i&lt;/i&gt; occurs in the structural equation for
variable &lt;i&gt;j&lt;/i&gt;.  We introduce a new algorithm, termed Residual Iterative
Conditional Fitting (RICF), that can be implemented using only least
squares computations.  In contrast to existing algorithms, RICF has
clear convergence properties and yields exact maximum likelihood
estimates after the first iteration whenever the MLE is available in
closed form.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/drton09a/drton09a.pdf</url></Article><Article><id>628</id><title>
Estimating Labels from Label Proportions
</title><author>Novi Quadrianto, Alex J. Smola, Tib&amp;#x00E9;rio S. Caetano, Quoc V. Le</author><abstract>

Consider the following problem: given sets of unlabeled observations,
each set with known label proportions, predict the labels of another
set of observations, possibly with known label proportions. This
problem occurs in areas like e-commerce, politics, spam filtering and
improper content detection. We present consistent estimators which can
reconstruct the correct labels with high probability in a uniform
convergence sense. Experiments show that our method works well in
practice.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/quadrianto09a/quadrianto09a.pdf</url></Article><Article><id>629</id><title>
Exploiting Product Distributions to Identify Relevant Variables of Correlation Immune Functions
</title><author>Lisa Hellerstein, Bernard Rosell, Eric Bach, Soumya Ray, David Page</author><abstract>

A Boolean function &lt;i&gt;f&lt;/i&gt; is &lt;i&gt;correlation immune&lt;/i&gt; if each input
variable is independent of the output, under the uniform distribution
on inputs.  For example, the parity function is correlation immune.
We consider the problem of identifying relevant variables of a
correlation immune function, in the presence of irrelevant variables.
We address this problem in two different contexts.  First, we analyze
&lt;i&gt;Skewing&lt;/i&gt;, a heuristic method that was developed to improve the
ability of greedy decision tree algorithms to identify relevant
variables of correlation immune Boolean functions, given examples
drawn from the uniform distribution (Page and Ray, 2003).  We present
theoretical results revealing both the capabilities and limitations of
skewing.  Second, we explore the problem of identifying relevant
variables in the &lt;i&gt;Product Distribution Choice&lt;/i&gt; (PDC) learning
model, a model in which the learner can choose product distributions
and obtain examples from them.  We prove a lemma establishing a
property of Boolean functions that may be of independent interest.
Using this lemma, we give two new algorithms for finding relevant
variables of correlation immune functions in the PDC model.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/hellerstein09a/hellerstein09a.pdf</url></Article><Article><id>630</id><title> Reinforcement Learning in Finite MDPs: PAC Analysis </title><author>Alexander L. Strehl, Lihong Li, Michael L. Littman</author><abstract>

We study the problem of learning near-optimal behavior in finite Markov Decision Processes (MDPs) with a polynomial number of samples.  These "PAC-MDP" algorithms include the well-known E&lt;sup&gt;3&lt;/sup&gt; and R-MAX algorithms as well as the more recent Delayed Q-learning algorithm.  We summarize the current state-of-the-art by presenting bounds for the problem in a unified theoretical framework.  A more refined analysis for upper and lower bounds is presented to yield insight into the differences between the model-free Delayed Q-learning and the model-based R-MAX.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/strehl09a/strehl09a.pdf</url></Article><Article><id>631</id><title> Prediction With Expert Advice For The Brier Game </title><author>Vladimir Vovk, Fedor Zhdanov</author><abstract>

  We show that the Brier game of prediction is mixable
  and find the optimal learning rate and substitution function for it.
  The resulting prediction algorithm is applied
  to predict results of football and tennis matches,
  with well-known bookmakers playing the role of experts.
  The theoretical performance guarantee
  is not excessively loose on the football data set
  and is rather tight on the tennis data set.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/vovk09a/vovk09a.pdf</url></Article><Article><id>632</id><title> Bi-Level Path Following for Cross Validated Solution of Kernel Quantile Regression </title><author>Saharon Rosset</author><abstract>

We show how to follow the path of &lt;i&gt;cross validated&lt;/i&gt;
solutions to families of regularized optimization problems, defined
by a combination of a parameterized loss function and a
regularization term. A primary example is kernel quantile
regression, where the parameter of the loss function is the quantile
being estimated. Even though the bi-level optimization problem we
encounter for every quantile is non-convex, the manner in which the
optimal cross-validated solution evolves with the parameter of the
loss function allows tracking of this solution. We prove this
property, construct the resulting algorithm, and demonstrate it on
real and artificial data. This algorithm allows us to
efficiently solve the whole family of bi-level problems. We show how
it can be extended to cover other modeling problems, like support
vector regression, and alternative in-sample model selection
approaches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/rosset09a/rosset09a.pdf</url></Article><Article><id>633</id><title> When Is There a Representer Theorem?  Vector Versus Matrix Regularizers </title><author>Andreas Argyriou, Charles A. Micchelli, Massimiliano Pontil</author><abstract>

We consider a general class of regularization methods which
learn a vector of parameters on the basis of linear measurements. It
is well known that if the regularizer is a nondecreasing function of
the &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt; norm, then the learned vector is a linear combination of
the input data. This result, known as the &lt;i&gt;representer theorem&lt;/i&gt;, lies at
the basis of kernel-based methods in machine learning. In this paper,
we prove the necessity of the above condition, in the case of differentiable regularizers. 
We further extend our analysis to regularization methods which learn a matrix, a
problem which is motivated by the application to multi-task
learning. In this context, we study a more general representer
theorem, which holds for a larger class of regularizers. We provide a
necessary and sufficient condition characterizing this class of matrix
regularizers and we highlight some concrete examples of
practical importance. Our analysis uses basic principles from matrix
theory, especially the useful notion of matrix nondecreasing functions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/argyriou09a/argyriou09a.pdf</url></Article><Article><id>634</id><title> Maximum Entropy Discrimination Markov Networks </title><author>Jun Zhu, Eric P. Xing</author><abstract>

The standard maximum margin approach for structured prediction lacks
a straightforward probabilistic interpretation of the learning
scheme and the prediction rule. Therefore its unique advantages such
as dual sparseness and kernel tricks cannot be easily conjoined with
the merits of a probabilistic model such as Bayesian regularization,
model averaging, and ability to model hidden variables. In this
paper, we present a new general framework called &lt;i&gt;maximum
entropy discrimination Markov networks&lt;/i&gt; (MaxEnDNet, or simply,
MEDN), which integrates these two approaches and combines and
extends their merits. Major innovations of this approach include: 1)
It extends the conventional max-entropy discrimination learning of
classification rules to a new &lt;i&gt;structural&lt;/i&gt; max-entropy
discrimination paradigm of learning a distribution of Markov
networks. 2) It generalizes the extant Markov network
structured-prediction rule based on a point estimator of model
coefficients to an averaging model akin to a Bayesian predictor that
integrates over a learned posterior distribution of model
coefficients. 3) It admits flexible entropic regularization of the
model during learning. By plugging in different prior distributions
of the model coefficients, it subsumes the well-known maximum margin
Markov networks (M&lt;sup&gt;3&lt;/sup&gt;N) as a special case, and leads to a model
similar to an &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-regularized M&lt;sup&gt;3&lt;/sup&gt;N that is simultaneously primal
and dual sparse, or other new types of Markov networks. 4) It
applies a modular learning algorithm that combines existing
variational inference techniques and convex-optimization based
M&lt;sup&gt;3&lt;/sup&gt;N solvers as subroutines.
Essentially, MEDN can be understood as a jointly maximum
likelihood and maximum margin estimate of Markov network. It
represents the first successful attempt to combine maximum entropy
learning (a dual form of maximum likelihood learning) with maximum
margin learning of Markov network for structured input/output
problems; and the basic principle can be generalized to learning
arbitrary graphical models, such as the generative Bayesian networks
or models with structured hidden variables. We discuss a number of
theoretical properties of this approach, and show that empirically it
outperforms a wide array of competing methods for structured
input/output learning on both synthetic and real OCR and web data
extraction data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/zhu09a/zhu09a.pdf</url></Article><Article><id>635</id><title> Learning When Concepts Abound </title><author>Omid Madani, Michael Connor, Wiley Greiner</author><abstract>

  Many learning tasks, such as large-scale text categorization and
  word prediction, can benefit from efficient training and
  classification when the number of classes, in addition to instances
  and features, is large, that is, in the thousands and beyond.  We
  investigate the learning of sparse class &lt;i&gt;indices&lt;/i&gt; to address
  this challenge.  An index is a mapping from features to classes.  We
  compare the index-learning methods against other techniques,
  including one-versus-rest and top-down classification using
  perceptrons and support vector machines.  We find that
  index learning is highly advantageous for space and time efficiency,
  at both training and classification times. Moreover, this approach
  yields similar and at times better accuracies.  On problems with
  hundreds of thousands of instances and thousands of classes, the
  index is learned in minutes, while other methods can take hours or
  days.
As we explain, the design of the learning update
  enables
  conveniently
  constraining each feature to connect to a small subset of the classes
  in the index.  This constraint is crucial for scalability.  Given an
  instance with &lt;i&gt;l&lt;/i&gt; active (positive-valued) features, each feature on
  average connecting to &lt;i&gt;d&lt;/i&gt; classes in the index (in the order of 10s
  in our experiments), update and classification take &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;dl&lt;/i&gt; log(&lt;i&gt;dl&lt;/i&gt;)).


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/madani09a/madani09a.pdf</url></Article><Article><id>636</id><title> Hash Kernels for Structured Data </title><author>Qinfeng Shi, James Petterson, Gideon Dror, John Langford, Alex Smola, S.V.N. Vishwanathan</author><abstract>

  We propose hashing to facilitate efficient kernels. This generalizes
  previous work using sampling and we show a principled way to compute
  the kernel matrix for data streams and sparse feature
  spaces. Moreover, we give deviation bounds from the exact kernel
  matrix. This has applications to estimation on strings and graphs.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/shi09a/shi09a.pdf</url></Article><Article><id>637</id><title> DL-Learner: Learning Concepts in Description Logics </title><author>Jens Lehmann</author><abstract>

In this paper, we introduce DL-Learner, a framework for learning in description logics and OWL. OWL is the official W3C standard ontology language for the Semantic Web. Concepts in this language can be learned for constructing and maintaining OWL ontologies or for solving problems similar to those in Inductive Logic Programming. DL-Learner includes several learning algorithms, support for different OWL formats, reasoner interfaces, and learning problems.
It is a cross-platform framework implemented in Java. The framework allows easy programmatic access and provides a command line interface, a graphical interface as well as a WSDL-based web service.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/lehmann09a/lehmann09a.pdf</url></Article><Article><id>638</id><title> Bounded Kernel-Based Online Learning </title><author>Francesco Orabona, Joseph Keshet, Barbara Caputo</author><abstract>

A common problem of kernel-based online algorithms, such as the kernel-based Perceptron algorithm, is the amount of memory required to store the online hypothesis, which may increase without bound as the algorithm progresses. Furthermore, the computational load of such algorithms grows linearly with the amount of memory used to store the hypothesis. To attack these problems, most previous work has focused on discarding some of the instances, in order to keep the memory bounded. In this paper we present a new algorithm, in which the instances are not discarded, but are instead projected onto the space spanned by the previous online hypothesis. We call this algorithm  Projectron. While the memory size of the Projectron solution cannot be predicted before training, we prove that its solution is guaranteed to be bounded.
We derive a relative mistake bound for the proposed algorithm, and deduce from it a slightly different algorithm which outperforms the Perceptron. We call this second algorithm Projectron++. We show that this algorithm can be extended to handle the multiclass and the structured output settings, resulting, as far as we know, in the first online bounded algorithm that can learn complex classification tasks. The method of bounding the hypothesis representation can be applied to any conservative online algorithm and to other online algorithms, as it is demonstrated for ALMA&lt;sub&gt;2&lt;/sub&gt;. Experimental results on various data sets show the empirical advantage of our technique compared to various bounded online algorithms, both in terms of memory and accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/orabona09a/orabona09a.pdf</url></Article><Article><id>639</id><title> Structure Spaces </title><author>Brijnesh J. Jain, Klaus Obermayer</author><abstract>

Finite structures such as point patterns, strings, trees, and graphs occur
as "natural" representations of structured data in different application
areas of machine learning. We develop the theory of &lt;i&gt;structure spaces&lt;/i&gt;
and derive geometrical and analytical concepts such as the angle between
structures and the derivative of functions on structures. In particular, we
show that the gradient of a differentiable structural function is a
well-defined structure pointing in the direction of steepest
ascent. Exploiting the properties of structure spaces, it will turn out that
a number of problems in structural pattern recognition such as central
clustering or learning in structured output spaces can be formulated as
optimization problems with cost functions that are locally Lipschitz. Hence,
methods from nonsmooth analysis are applicable to optimize those cost
functions. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/jain09a/jain09a.pdf</url></Article><Article><id>640</id><title> Learning Halfspaces with Malicious Noise </title><author>Adam R. Klivans, Philip M. Long, Rocco A. Servedio</author><abstract>

We give new algorithms for learning halfspaces in the challenging &lt;i&gt;
malicious noise&lt;/i&gt; model, where an adversary may corrupt both the labels
and the underlying distribution of examples. Our algorithms can
tolerate malicious noise rates exponentially larger than previous work
in terms of the dependence on the dimension &lt;i&gt;n&lt;/i&gt;, and succeed for the
fairly broad class of all isotropic log-concave distributions.


We give poly(&lt;i&gt;n&lt;/i&gt;, 1/&amp;epsilon;)-time algorithms for solving the following
problems to accuracy &amp;epsilon;:

&lt;ul&gt;

&lt;li&gt; Learning origin-centered halfspaces in &lt;b&gt;R&lt;/b&gt;&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; with respect to the uniform
distribution on the
unit ball with malicious noise rate &amp;eta; = &amp;Omega;(&amp;epsilon;&lt;sup&gt;2&lt;/sup&gt; / log(&lt;i&gt;n&lt;/i&gt;/&amp;epsilon;)). (The
best previous result was &amp;Omega;(&amp;epsilon; / (&lt;i&gt;n&lt;/i&gt; log(&lt;i&gt;n&lt;/i&gt;/&amp;epsilon;))&lt;sup&gt;1/4&lt;/sup&gt;).) &lt;/li&gt;

&lt;li&gt; Learning origin-centered halfspaces with respect to any
isotropic log-concave distribution on &lt;b&gt;R&lt;/b&gt;&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; with malicious noise
rate &amp;eta; = &amp;Omega;(&amp;epsilon;&lt;sup&gt;3&lt;/sup&gt; / log&lt;sup&gt;2&lt;/sup&gt;(&lt;i&gt;n&lt;/i&gt;/&amp;epsilon;)).  This is the first
efficient algorithm for learning under isotropic log-concave
distributions in the presence of malicious noise. &lt;/li&gt;

&lt;/ul&gt;

We also give a poly(&lt;i&gt;n&lt;/i&gt;,1/&amp;epsilon;)-time algorithm for learning
origin-centered halfspaces under any isotropic log-concave
distribution on &lt;b&gt;R&lt;/b&gt;&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; in the presence of &lt;i&gt;adversarial label noise&lt;/i&gt;
at rate &amp;eta; = &amp;Omega;(&amp;epsilon;&lt;sup&gt;3&lt;/sup&gt; / log(1/&amp;epsilon;)).  In the adversarial label
noise setting (or agnostic model), labels can be noisy, but not
example points themselves. Previous results could
handle &amp;eta; = &amp;Omega;(&amp;epsilon;) but had running time exponential in an
unspecified function of 1/&amp;epsilon;.
&lt;br&gt;

Our analysis crucially exploits both concentration and
anti-concentration properties of isotropic log-concave
distributions.  Our algorithms combine an iterative outlier removal
procedure using Principal Component Analysis together with
"smooth" boosting.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/klivans09a/klivans09a.pdf</url></Article><Article><id>641</id><title> Reproducing Kernel Banach Spaces for Machine Learning </title><author>Haizhang Zhang, Yuesheng Xu, Jun Zhang</author><abstract>

We introduce the notion of reproducing kernel Banach spaces (RKBS)
and study special semi-inner-product RKBS by making use of
semi-inner-products and the duality mapping. Properties of an RKBS
and its reproducing kernel are investigated. As applications, we
develop in the framework of RKBS standard learning schemes including
minimal norm interpolation, regularization network, support vector
machines, and kernel principal component analysis. In particular,
existence, uniqueness and representer theorems are established.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/zhang09b/zhang09b.pdf</url></Article><Article><id>642</id><title> Cautious Collective Classification </title><author>Luke K. McDowell, Kalyan Moy Gupta, David W. Aha</author><abstract>

Many collective classification (CC) algorithms have been shown to
increase accuracy when instances are interrelated. However, CC algorithms
must be carefully applied because their use of estimated labels
can in some cases decrease accuracy.  In this article, we show that
managing this label uncertainty through &lt;i&gt;cautious&lt;/i&gt; algorithmic
behavior is essential to achieving maximal, robust performance.
First, we describe &lt;i&gt;cautious inference&lt;/i&gt; and explain how four well-known
families of CC algorithms can be parameterized to use varying degrees of such caution.  
Second, we introduce &lt;i&gt;cautious learning&lt;/i&gt; and show how it can be used to improve the performance of
almost any CC algorithm, with or without cautious inference.  We then
evaluate cautious inference 
and learning for the four collective inference families, 
with three local classifiers and a range of
both synthetic and real-world data.  We find
that cautious learning and cautious inference typically outperform less
cautious approaches. In addition, we identify 
the data characteristics that predict more substantial performance
differences.  Our results reveal that 
&lt;i&gt;the degree of caution used usually has a larger impact on performance than the choice of the underlying inference algorithm&lt;/i&gt;.  
Together, these results identify the most appropriate CC
algorithms to use for particular task characteristics and explain multiple
conflicting findings from prior CC research.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/mcdowell09a/mcdowell09a.pdf</url></Article><Article><id>643</id><title> Adaptive False Discovery Rate Control under Independence and Dependence </title><author>Gilles Blanchard, &amp;Eacute;tienne Roquain</author><abstract>

In the context of multiple hypothesis testing, the proportion &lt;i&gt;&amp;pi;&lt;/i&gt;&lt;sub&gt;0&lt;/sub&gt;
of true null hypotheses in the pool of hypotheses to test 
often plays a crucial role, although it is generally
unknown &lt;i&gt;a priori&lt;/i&gt;. A testing procedure using an implicit or explicit estimate
of this quantity in order to improve its efficency is called &lt;i&gt;adaptive&lt;/i&gt;.
In this paper, we focus on
the issue of false discovery rate (FDR) control and we present new
adaptive multiple testing procedures with control of the FDR.
In a first part, assuming independence of the &lt;i&gt;p&lt;/i&gt;-values, we present two new procedures and
give a unified review of other existing adaptive procedures that have provably
controlled FDR. We report
extensive simulation results comparing these procedures
and testing their robustness when the independence
assumption is violated. The new proposed procedures appear
competitive with existing ones. The overall best, though, is reported to
be Storey's estimator, albeit for a specific parameter setting that does not
appear to have been considered before.
  In a second part, we propose adaptive versions of step-up procedures that have provably
  controlled FDR under positive dependence and unspecified dependence of the &lt;i&gt;p&lt;/i&gt;-values, respectively. 
  In the latter case, while simulations only show an improvement over non-adaptive
  procedures in limited situations, these are to our knowledge among the
  first theoretically founded adaptive multiple testing procedures that control the FDR when the &lt;i&gt;p&lt;/i&gt;-values
are not independent.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/blanchard09a/blanchard09a.pdf</url></Article><Article><id>644</id><title> Online Learning with Samples Drawn from Non-identical Distributions </title><author>Ting Hu, Ding-Xuan Zhou</author><abstract>

Learning algorithms are based on samples which are often drawn
independently from an identical distribution (i.i.d.). In this
paper we consider a different setting with samples drawn according
to a non-identical sequence of probability distributions. Each
time a sample is drawn from a different distribution. In this
setting we investigate a fully online learning algorithm
associated with a general convex loss function and a reproducing
kernel Hilbert space (RKHS). Error analysis is conducted under the
assumption that the sequence of marginal distributions converges
polynomially in the dual of a H&amp;ouml;lder space. For regression with
least square or insensitive loss, learning rates are given in both
the RKHS norm and the L&lt;sup&gt;2&lt;/sup&gt; norm. For classification with hinge
loss and support vector machine &lt;i&gt;q&lt;/i&gt;-norm loss, rates are
explicitly stated with respect to the excess misclassification
error.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/hu09a/hu09a.pdf</url></Article><Article><id>645</id><title> Efficient Online and Batch Learning Using Forward Backward Splitting </title><author>John Duchi, Yoram Singer</author><abstract>

We describe, analyze, and experiment with a framework for empirical
loss minimization with regularization. Our algorithmic framework
alternates between two phases. On each iteration we first perform an
&lt;i&gt;unconstrained&lt;/i&gt; gradient descent step. We then cast and solve an
instantaneous optimization problem that trades off minimization of a
regularization term while keeping close proximity to the result of
the first phase. This view yields a simple yet effective algorithm
that can be used for batch penalized risk minimization and online
learning. Furthermore, the two phase approach enables sparse
solutions when used in conjunction with regularization functions
that promote sparsity, such as &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;. We derive concrete and very
simple algorithms for minimization of loss functions with &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;,
&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;, &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;, and &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;&amp;infin;&lt;/sub&gt; regularization. We also show
how to construct efficient algorithms for mixed-norm &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;/&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;q&lt;/sub&gt;
regularization. We further extend the algorithms and give efficient
implementations for very high-dimensional data with sparsity. We
demonstrate the potential of the proposed framework in a series of
experiments with synthetic and natural data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/duchi09a/duchi09a.pdf</url></Article><Article><id>646</id><title> A Survey of Accuracy Evaluation Metrics of Recommendation Tasks </title><author>Asela Gunawardana, Guy Shani</author><abstract>

&lt;i&gt;Recommender systems&lt;/i&gt; are now popular both commercially
and in the research community, where many algorithms have been
suggested for providing recommendations. These algorithms typically
perform differently in various domains and tasks. Therefore, it is
important from the research perspective, as well as from a practical
view, to be able to decide on an algorithm that matches the domain
and the task of interest. The standard way to make such decisions is
by comparing a number of algorithms offline using some evaluation
metric. Indeed, many evaluation metrics have been suggested for
comparing recommendation algorithms. The decision on the proper
evaluation metric is often critical, as each metric may favor a
different algorithm. In this paper we review the proper
construction of offline experiments for deciding on the most
appropriate algorithm. We discuss three important tasks of
recommender systems, and classify a set of appropriate well known
evaluation metrics for each task. We demonstrate how using an
improper evaluation metric can lead to the selection of an improper
algorithm for the task of interest. We also discuss other important
considerations when designing offline experiments.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume10/gunawardana09a/gunawardana09a.pdf</url></Article><Article><id>647</id><title> An Efficient Explanation of Individual Classifications using Game Theory </title><author>Erik Å trumbelj, Igor Kononenko</author><abstract>

We present a general method for explaining individual predictions
of classification models. The method is based on fundamental
concepts from coalitional game theory and predictions are
explained with contributions of individual feature values. We
overcome the method's initial exponential time complexity with a
sampling-based approximation. In the experimental part of the
paper we use the developed method on models generated by several
well-known machine learning algorithms on both synthetic and
real-world data sets. The results demonstrate that the method is
efficient and that the explanations are intuitive and useful.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/strumbelj10a/strumbelj10a.pdf</url></Article><Article><id>648</id><title> Online Learning for Matrix Factorization and Sparse Coding </title><author>Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro</author><abstract>

Sparse coding&amp;minus;that is, modelling data vectors as sparse linear
combinations of basis elements&amp;minus;is widely used in machine learning,
neuroscience, signal processing, and statistics. This paper focuses on the
large-scale matrix factorization problem that consists of &lt;i&gt;learning&lt;/i&gt;
the basis set in order to adapt it to specific data. Variations of this
problem include dictionary learning in signal processing, non-negative
matrix factorization and sparse principal component analysis. In this
paper, we propose to address these tasks with a new online optimization
algorithm, based on stochastic approximations, which scales up gracefully
to large data sets with millions of training samples, and extends naturally
to various  matrix factorization formulations, making it suitable for a
wide range of learning problems. A proof of convergence is presented,
along with experiments with natural images and genomic data demonstrating
that it leads to state-of-the-art performance in terms of speed and
optimization for both small and large data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mairal10a/mairal10a.pdf</url></Article><Article><id>649</id><title> Model Selection: Beyond the Bayesian/Frequentist Divide </title><author>Isabelle Guyon, Amir Saffari, Gideon Dror, Gavin Cawley</author><abstract>

The principle of parsimony also known as "Ockham's razor" has inspired many
theories of  model selection. Yet such theories, all making arguments in favor
of parsimony, are based on very different premises and have developed distinct
methodologies to derive algorithms.  We have organized challenges and
edited a special issue of JMLR and several conference proceedings around the
theme of model selection. In this editorial, we revisit the problem of
avoiding overfitting in light of the latest
results. We note the remarkable convergence of theories as different as
Bayesian theory, Minimum Description Length, bias/variance tradeoff,
Structural Risk Minimization, and regularization, in some
approaches.  We also present new and
interesting examples of the complementarity of theories leading to
hybrid algorithms, neither frequentist, nor Bayesian, or perhaps
both frequentist and Bayesian!


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/guyon10a/guyon10a.pdf</url></Article><Article><id>650</id><title> On-Line Sequential Bin Packing</title><author>Andr&amp;#225;s Gy&amp;#246;rgy, G&amp;#225;bor Lugosi, Gy&amp;#246;rgy Ottucs&amp;#224;k</author><abstract>

We consider a sequential version of the classical bin packing problem
in which items are received one by one. Before the size of the next
item is revealed, the decision maker needs to decide whether
the next item is packed in the currently open bin or the bin is
closed and a new bin is opened. If the new item does not fit, it is
lost. If a bin is closed, the remaining free space in the bin accounts
for a loss. The goal of the decision maker is to minimize the
loss accumulated over &lt;i&gt;n&lt;/i&gt; periods. We present
an algorithm that has a cumulative loss not much larger than any
strategy in a finite class of reference strategies
for any sequence of items.
Special attention is payed to reference strategies
that use a fixed threshold at each step to decide whether a new bin
is opened. Some positive and negative results are presented for this case. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/gyorgy10a/gyorgy10a.pdf</url></Article><Article><id>651</id><title> Classification Methods with Reject Option Based on Convex Risk Minimization</title><author>Ming Yuan, Marten Wegkamp</author><abstract>

In this paper, we investigate the problem of binary classification with a reject option in which one can withhold the decision of classifying an observation at a cost lower than that of misclassification. Since the natural loss function is non-convex so that empirical risk minimization easily becomes infeasible, the paper proposes minimizing convex risks based on surrogate convex loss functions. A necessary and sufficient condition for  infinite sample consistency (both risks share the same minimizer)  is provided. Moreover, we show that the excess risk can be bounded through the excess surrogate risk under appropriate conditions. These bounds can be tightened by a generalized margin condition. The impact of the results is illustrated on several commonly used surrogate loss functions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yuan10a/yuan10a.pdf</url></Article><Article><id>652</id><title> An Investigation of Missing Data Methods for Classification Trees Applied to Binary Response Data</title><author>Yufeng Ding, Jeffrey S. Simonoff</author><abstract>

There are many different methods used by classification tree
algorithms when missing data occur in the predictors, but few
studies have been done comparing their appropriateness and
performance. This paper provides both analytic and Monte Carlo
evidence regarding the effectiveness of six popular missing data
methods for classification trees applied to binary response data. We
show that in the context of classification trees, the relationship
between the missingness and the dependent variable, as well as the
existence or non-existence of missing values in the testing data,
are the most helpful criteria to distinguish different missing data
methods. In particular, separate class is clearly the best
method to use when the testing set has missing values and the
missingness is related to the response variable. A real data set
related to modeling bankruptcy of a firm is then analyzed. The paper
concludes with discussion of adaptation of these results to logistic
regression, and other potential generalizations.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ding10a/ding10a.pdf</url></Article><Article><id>653</id><title> Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part I: Algorithms and Empirical Evaluation </title><author>Constantin F. Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani, Xenofon D. Koutsoukos</author><abstract>

We present an algorithmic framework for learning local causal structure around target variables of interest
in the form of direct causes/effects and Markov blankets applicable to very large data sets with relatively small samples.
The selected feature sets can be used for causal discovery and classification. The framework (&lt;i&gt;Generalized Local Learning&lt;/i&gt;, or GLL)
can be instantiated in numerous ways, giving rise to both existing state-of-the-art as well as novel algorithms.
The resulting algorithms are sound under well-defined sufficient conditions. In a first set of experiments we evaluate
 several algorithms derived from this framework in terms of predictivity and feature set parsimony and compare to other
  local causal discovery methods and to state-of-the-art non-causal feature selection methods using real data.
  A second set of experimental evaluations compares the algorithms in terms of ability to induce local causal neighborhoods
  using simulated and resimulated data and examines the relation of predictivity with causal induction performance.

&lt;br&gt;

Our experiments demonstrate, consistently with causal feature selection theory, that local causal feature selection methods
 (under broad assumptions encompassing appropriate family of distributions, types of classifiers, and loss functions)
 exhibit strong feature set parsimony, high predictivity and local causal interpretability.  Although non-causal feature selection
 methods are often used in practice to shed light on causal relationships, we find that they cannot be interpreted causally even
 when they achieve excellent predictivity. Therefore we conclude that only local causal techniques should be used when insight into
 causal structure is sought.

&lt;br&gt;

 In a companion paper we examine in depth the behavior of GLL algorithms, provide extensions, and show how local techniques
 can be used for scalable and accurate global causal graph learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/aliferis10a/aliferis10a.pdf</url></Article><Article><id>654</id><title> Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part II: Analysis and Extensions</title><author>Constantin F. Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani, Xenofon D. Koutsoukos</author><abstract>

In part I of this work we introduced and evaluated the &lt;i&gt;Generalized
Local Learning&lt;/i&gt; (GLL) framework for producing local causal and Markov
blanket induction algorithms. In the present second part we analyze
the behavior of GLL algorithms and provide extensions to the core
methods. Specifically, we investigate the empirical convergence of
GLL to the true local neighborhood as a function of sample size.
Moreover, we study how predictivity improves with increasing sample
size. Then we investigate how sensitive are the algorithms to
multiple statistical testing, especially in the presence of many
irrelevant features. Next we discuss the role of the algorithm
parameters and also show that Markov blanket and causal graph
concepts can be used to understand deviations from optimality of
state-of-the-art non-causal algorithms. The present paper also
introduces the following extensions to the core GLL framework:
parallel and distributed versions of GLL algorithms, versions with
false discovery rate control, strategies for constructing novel
heuristics for specific domains, and divide-and-conquer
&lt;i&gt;local-to-global learning&lt;/i&gt; (LGL) strategies. We test the
generality of the LGL approach by deriving a novel LGL-based
algorithm that compares favorably to the state-of-the-art global
learning algorithms. In addition, we investigate the use of
non-causal feature selection methods to facilitate global learning.
Open problems and future research paths related to local and
local-to-global causal learning are discussed.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/aliferis10b/aliferis10b.pdf</url></Article><Article><id>655</id><title> Optimal Search on Clustered Structural Constraint for Learning Bayesian Network Structure</title><author>Kaname Kojima, Eric Perrier, Seiya Imoto, Satoru Miyano</author><abstract>

We study the problem of learning an optimal Bayesian network in a constrained search space; skeletons are compelled to be subgraphs of a given undirected graph called the super-structure.
The previously derived constrained optimal search (COS) remains limited even for sparse super-structures.
To extend its feasibility, we propose to divide the super-structure into several clusters and perform an optimal search on each of them.
Further, to ensure acyclicity, we introduce the concept of ancestral constraints (ACs) and derive an optimal algorithm satisfying a given set of ACs.
Finally, we theoretically derive the necessary and sufficient sets of ACs to be considered for finding an optimal constrained graph.
Empirical evaluations demonstrate that our algorithm can learn optimal Bayesian networks for some graphs containing several hundreds of vertices, and even for super-structures having a high average degree (up to four), which is a drastic improvement in feasibility over the previous optimal algorithm.
Learnt networks are shown to largely outperform state-of-the-art heuristic algorithms both in terms of score and structural hamming distance.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/kojima10a/kojima10a.pdf</url></Article><Article><id>656</id><title> Bundle Methods for Regularized Risk Minimization</title><author>Choon Hui Teo, S.V.N. Vishwanthan, Alex J. Smola, Quoc V. Le</author><abstract>

  A wide variety of machine learning problems can be described as
  minimizing a regularized risk functional, with different algorithms
  using different notions of risk and different regularizers. Examples
  include linear Support Vector Machines (SVMs), Gaussian Processes,
  Logistic Regression, Conditional Random Fields (CRFs), and Lasso
  amongst others. This paper describes the theory and implementation of
  a scalable and modular convex solver which solves all these estimation
  problems. It can be parallelized on a cluster of workstations, allows
  for data-locality, and can deal with regularizers such as &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt; and
  &lt;i&gt;L&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt; penalties. In addition to the unified framework we present tight
  convergence bounds, which show that our algorithm converges in
  &lt;i&gt;O&lt;/i&gt;(1/&amp;#949;) steps to &amp;#949; precision for general convex
  problems and in &lt;i&gt;O&lt;/i&gt;(log (1/&amp;#949;)) steps for continuously
  differentiable problems. We demonstrate the performance of our general
  purpose solver on a variety of publicly available data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/teo10a/teo10a.pdf</url></Article><Article><id>657</id><title> A Convergent Online Single Time Scale Actor Critic Algorithm</title><author>Dotan Di Castro, Ron Meir</author><abstract>

Actor-Critic based approaches were among the first to address reinforcement
learning in a general setting. Recently, these algorithms have gained
renewed interest due to their generality, good convergence properties,
and possible biological relevance. In this paper, we introduce an
online temporal difference based actor-critic algorithm which is proved
to converge to a neighborhood of a local maximum of the average reward.
Linear function approximation is used by the critic in order estimate
the value function, and the temporal difference signal, which is passed
from the critic to the actor. The main distinguishing feature of the
present convergence proof is that both the actor and the critic operate
on a similar time scale, while in most current convergence proofs
they are required to have very different time scales in order to converge.
Moreover, the same temporal difference signal is used to update the
parameters of both the actor and the critic. A limitation of the proposed
approach, compared to results available for two time scale convergence,
is that convergence is guaranteed only to a neighborhood of an optimal
value, rather to an optimal value itself. The single time scale and
identical temporal difference signal used by the actor and the critic,
may provide a step towards constructing more biologically realistic
models of reinforcement learning in the brain.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/dicastro10a/dicastro10a.pdf</url></Article><Article><id>658</id><title> Dimensionality Estimation, Manifold Learning and Function Approximation using Tensor Voting</title><author>Philippos Mordohai, G&amp;#233;rard Medioni</author><abstract>

We address instance-based learning from a perceptual organization
standpoint and present methods for dimensionality estimation,
manifold learning and function approximation. Under our approach, manifolds in high-dimensional spaces
are inferred by estimating geometric relationships among the input
instances. Unlike conventional manifold learning, we do not perform dimensionality reduction, but
instead perform all operations in the original input space. For this
purpose we employ a novel formulation of tensor voting, which allows an &lt;i&gt;N&lt;/i&gt;-D
implementation. Tensor voting is a perceptual organization
framework that has mostly been applied to computer vision problems.
Analyzing the estimated local structure at the inputs, we are able
to obtain reliable dimensionality estimates at each instance,
instead of a global estimate for the entire data set. Moreover, these
local dimensionality and structure estimates enable us to measure
geodesic distances and perform nonlinear interpolation for data sets
with varying density, outliers, perturbation and intersections, that
cannot be handled by state-of-the-art methods. Quantitative
results on the estimation of local manifold structure using ground truth data are presented. In addition, we compare our
approach with several leading methods for manifold learning at the
task of measuring geodesic distances. Finally, we show competitive
function approximation results on real data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mordohai10a/mordohai10a.pdf</url></Article><Article><id>659</id><title> Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization</title><author>Jarkko Venna, Jaakko Peltonen, Kristian Nybo, Helena Aidos, Samuel Kaski</author><abstract>

Nonlinear dimensionality reduction methods are often used to visualize
high-dimensional data, although the existing methods have been
designed for other related tasks such as manifold learning. It has
been difficult to assess the quality of visualizations since the task
has not been well-defined. We give a rigorous definition for a
specific visualization task, resulting in quantifiable goodness
measures and new visualization methods. The task is &lt;i&gt;information
retrieval&lt;/i&gt; given the visualization: to find similar data based on the
similarities shown on the display. The fundamental tradeoff between
precision and recall of information retrieval can then be quantified
in visualizations as well. The user needs to give the relative cost of
missing similar points vs. retrieving dissimilar points, after which
the total cost can be measured. We then introduce a new method NeRV
(&lt;i&gt;neighbor retrieval visualizer&lt;/i&gt;) which produces an optimal 
visualization by minimizing the cost. We further derive a variant for supervised
visualization; class information is taken rigorously into account when
computing the similarity relationships. We show empirically that the
unsupervised version outperforms existing unsupervised dimensionality
reduction methods in the visualization task, and the supervised
version outperforms existing supervised methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/venna10a/venna10a.pdf</url></Article><Article><id>660</id><title> Classification Using Geometric Level Sets</title><author>Kush R. Varshney, Alan S. Willsky</author><abstract>

A variational level set method is developed for the supervised classification problem.  Nonlinear classifier decision boundaries are obtained by minimizing an energy functional that is composed of an empirical risk term with a margin-based loss and a geometric regularization term new to machine learning: the surface area of the decision boundary.  This geometric level set classifier is analyzed in terms of consistency and complexity through the calculation of its &amp;#949;-entropy.  For multicategory classification, an efficient scheme is developed using a logarithmic number of decision functions in the number of classes rather than the typical linear number of decision functions.  Geometric level set classification yields performance results on benchmark data sets that are competitive with well-established methods.  


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/varshney10a/varshney10a.pdf</url></Article><Article><id>661</id><title> Generalized Power Method for Sparse Principal Component Analysis</title><author>Michel Journ&amp;#233;e, Yurii Nesterov, Peter Richt&amp;#225;rik, Rodolphe Sepulchre</author><abstract>

In this paper we develop a new approach to sparse principal component analysis (sparse PCA). We propose two single-unit and two block optimization formulations of the sparse PCA problem, aimed at extracting a single sparse dominant principal component of a data matrix, or more components at once, respectively. While the initial formulations involve nonconvex functions, and are therefore computationally intractable, we rewrite them into the form of an optimization program involving maximization of a convex function on a compact set. The dimension of the search space is decreased enormously if the data matrix has many more columns (variables) than rows. We then propose and analyze a simple gradient method suited for the task. It appears that our algorithm has best convergence properties in the case when either the objective function or the feasible set are strongly convex, which is the case with our single-unit formulations and can be enforced in the block case. Finally, we demonstrate numerically on a set of random and gene expression test problems that our approach outperforms existing algorithms both in quality of the obtained solution and in computational speed.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/journee10a/journee10a.pdf</url></Article><Article><id>662</id><title> Approximate Tree Kernels</title><author>Konrad Rieck, Tammo Krueger, Ulf Brefeld, Klaus-Robert M&amp;#252;ller</author><abstract>

Convolution kernels for trees provide simple means for learning with
  tree-structured data. The computation time of tree kernels is
  quadratic in the size of the trees, since all pairs of nodes need to
  be compared. Thus, large parse trees, obtained from HTML documents
  or structured network data, render convolution kernels inapplicable.
  In this article, we propose an effective approximation technique for
  parse tree kernels. The approximate tree kernels (ATKs) limit kernel
  computation to a sparse subset of relevant subtrees and discard
  redundant structures, such that training and testing of kernel-based
  learning methods are significantly accelerated. We devise linear
  programming approaches for identifying such subsets for supervised
  and unsupervised learning tasks, respectively. Empirically, the
  approximate tree kernels attain run-time improvements up to three
  orders of magnitude while preserving the predictive accuracy of
  regular tree kernels. For unsupervised tasks, the approximate tree
  kernels even lead to more accurate predictions by identifying
  relevant dimensions in feature space.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/rieck10a/rieck10a.pdf</url></Article><Article><id>663</id><title> On Finding Predictors for Arbitrary Families of Processes</title><author>Daniil Ryabko</author><abstract>

The problem is sequence prediction in the following setting. 
A sequence &lt;i&gt;x&lt;sub&gt;1&lt;/sub&gt;,...,x&lt;sub&gt;n&lt;/sub&gt;,...&lt;/i&gt; of discrete-valued observations is generated 
according to some unknown probabilistic law (measure) &amp;#956;. After observing each outcome, 
it is required to give the conditional probabilities of the next observation.
The measure  &amp;#956; belongs to an arbitrary but known class &lt;i&gt;C&lt;/i&gt; of stochastic process measures.
We are interested in predictors &amp;#961; whose conditional probabilities converge (in some sense) to the
"true" &amp;#956;-conditional probabilities, if any &amp;#956;&amp;#8712;&lt;i&gt;C&lt;/i&gt; is chosen to generate the sequence.
The contribution of this work is in characterizing the families &lt;i&gt;C&lt;/i&gt; for which such predictors exist, 
and in providing a specific and simple form in which to look for a solution. We show that if any predictor works, then 
there exists a Bayesian predictor,  whose   prior is discrete, and which works too.
 We also find several sufficient and necessary conditions
for the existence of a predictor, in terms of topological characterizations of the family &lt;i&gt;C&lt;/i&gt;, as well as in terms
of local behaviour of the measures in &lt;i&gt;C&lt;/i&gt;,  which in some cases lead to procedures for constructing such predictors.

&lt;br&gt;

It should be  emphasized that the framework is completely general: the stochastic processes considered are not required to be 
i.i.d., stationary, or to belong to any parametric or countable family.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ryabko10a/ryabko10a.pdf</url></Article><Article><id>664</id><title> A Rotation Test to Verify Latent Structure</title><author>Patrick O. Perry, Art B. Owen</author><abstract>

In multivariate regression models we have the opportunity to look for hidden
structure unrelated to the observed predictors. However, when one fits a model
involving such latent variables it is important to be able to tell if the
structure is real, or just an artifact of correlation in the regression errors.
We develop a new statistical test based on random rotations for verifying the 
existence of latent variables. The rotations are carefully constructed to
rotate orthogonally to the column space of the regression model. We find that only non-Gaussian
latent variables are detectable, a finding that parallels a well known
phenomenon in independent components analysis. We base our test on a measure
of non-Gaussianity in the histogram
of the principal eigenvector components instead of on the eigenvalue.
The method finds and
verifies some latent dichotomies in the microarray data from the
AGEMAP consortium.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/perry10a/perry10a.pdf</url></Article><Article><id>665</id><title> Why Does Unsupervised Pre-training Help Deep Learning?</title><author>Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, Samy Bengio</author><abstract>

Much recent research has been devoted to learning algorithms for deep
 architectures such as Deep Belief Networks and stacks of auto-encoder
 variants, 
  with impressive results obtained in several
  areas, mostly on vision and language data sets.  The best results obtained
  on supervised learning tasks involve an unsupervised learning component,
  usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep
models, many questions remain as to the nature of this difficult learning problem. The main question
  investigated here is the following: how does unsupervised pre-training
  work? Answering this questions
is important if learning in deep architectures is to be further improved.  
We propose several explanatory hypotheses and test them through extensive simulations. 
We empirically show the influence of pre-training with respect to
architecture depth, model capacity, and number of training examples.
The experiments confirm and clarify the advantage of unsupervised pre-training.
  The results suggest that unsupervised pre-training
  guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf</url></Article><Article><id>666</id><title> Error-Correcting Output Codes Library</title><author>Sergio Escalera, Oriol Pujol, Petia Radeva</author><abstract>

In this paper, we present an open source Error-Correcting Output
Codes (ECOC) library. The ECOC framework is a powerful tool to
deal with multi-class categorization problems. This library
contains both state-of-the-art coding (one-versus-one,
one-versus-all, dense random, sparse random, DECOC, forest-ECOC,
and ECOC-ONE) and decoding designs (hamming, euclidean, inverse
hamming, laplacian, &amp;#946;-density, attenuated, loss-based,
probabilistic kernel-based, and loss-weighted) with the parameters
defined by the authors, as well as the option to include your own
coding, decoding, and base classifier.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/escalera10a/escalera10a.pdf</url></Article><Article><id>667</id><title> Second-Order Bilinear Discriminant Analysis</title><author>Christoforos Christoforou, Robert Haralick, Paul Sajda, Lucas C. Parra</author><abstract>

Traditional analysis methods for single-trial classification of
electro-encephalography (EEG) focus on two types of paradigms: phase-locked
methods, in which the amplitude of the signal is used as the
feature for classification, that is, event related potentials; and
second-order methods, in which the feature of interest is the power
of the signal, that is, event related (de)synchronization. The process of
deciding which paradigm to use is &lt;i&gt;ad hoc&lt;/i&gt; and is driven by
assumptions regarding the underlying neural generators. Here we
propose a method that provides an unified framework for the analysis
of EEG, combining  first and second-order spatial and temporal
features based on a bilinear model. Evaluation of the proposed
method on simulated data shows that the technique outperforms
state-of-the art techniques for single-trial classification for a
broad range of signal-to-noise ratios. Evaluations on human EEG&amp;minus;including
one benchmark data set from the Brain Computer Interface
(BCI) competition&amp;minus;show statistically significant gains in
classification accuracy, with a reduction in overall classification
error from 26%-28% to 19%.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/christoforou10a/christoforou10a.pdf</url></Article><Article><id>668</id><title> On the Rate of Convergence of the Bagged Nearest Neighbor Estimate</title><author>G&amp;#233;rard Biau, Fr&amp;#233;d&amp;#233;ric C&amp;#233;rou, Arnaud Guyader</author><abstract>

Bagging is a simple way to combine estimates in order to improve their performance. This method, suggested by Breiman in 1996, proceeds by resampling from the original data set, constructing a predictor from each subsample, and decide by combining. By bagging an &lt;i&gt;n&lt;/i&gt;-sample, the crude nearest neighbor regression estimate is turned into a consistent weighted nearest neighbor regression estimate, which is amenable to statistical analysis. Letting the resampling size &lt;i&gt;k&lt;sub&gt;n&lt;/sub&gt;&lt;/i&gt; grows appropriately with &lt;i&gt;n&lt;/i&gt;, it is shown that this estimate may achieve optimal rate of convergence, independently from the fact that resampling is done with or without replacement. Since the estimate with the optimal rate of convergence depends on the unknown distribution of the observations, adaptation results by data-splitting are presented.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/biau10a/biau10a.pdf</url></Article><Article><id>669</id><title> A Fast Hybrid Algorithm for Large-Scale &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-Regularized Logistic Regression</title><author>Jianing Shi, Wotao Yin, Stanley Osher, Paul Sajda</author><abstract>

&lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-regularized logistic regression, also known as sparse logistic regression, is widely used in machine learning, computer vision, data mining, bioinformatics and neural signal processing. The use of &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; regularization attributes attractive properties to the classifier, such as feature selection, robustness to noise, and as a result, classifier generality in the context of supervised learning.  When a sparse logistic regression problem has large-scale data in high dimensions, it is computationally expensive to minimize the non-differentiable &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm in the objective function. Motivated by recent work (Koh et al., 2007; Hale et al., 2008), we propose a novel hybrid algorithm based on combining two types of optimization iterations: one being very fast and memory friendly while the other being slower but more accurate. Called hybrid iterative shrinkage (HIS), the resulting algorithm is comprised of a fixed point continuation phase and an interior point phase.  The first phase is based completely on memory efficient operations such as matrix-vector multiplications, while the second phase is based on a truncated Newton's method.  Furthermore, we show that various optimization techniques, including line search and continuation, can significantly accelerate convergence. The algorithm has global convergence at a geometric rate (a Q-linear rate in  optimization terminology). We present a  numerical comparison with several existing algorithms, including an analysis using benchmark data from the UCI machine learning repository, and show our algorithm is the most computationally efficient without loss of accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/shi10a/shi10a.pdf</url></Article><Article><id>670</id><title> PyBrain</title><author>Tom Schaul, Justin Bayer, Daan Wierstra, Yi Sun, Martin Felder, Frank Sehnke, Thomas R&amp;#252;ckstie&amp;#223;, J&amp;#252;rgen Schmidhuber</author><abstract>

PyBrain is a versatile machine learning library for Python. Its goal is to provide
flexible, easy-to-use yet still powerful algorithms for machine learning tasks, including
a variety of predefined environments and benchmarks to test and compare 
algorithms. 
Implemented algorithms include Long Short-Term Memory (LSTM), policy gradient methods, (multidimensional) 
recurrent neural networks and deep belief networks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/schaul10a/schaul10a.pdf</url></Article><Article><id>671</id><title> Maximum Relative Margin and Data-Dependent Regularization</title><author>Pannagadatta K. Shivaswamy, Tony Jebara</author><abstract>

Leading classification methods such as support vector machines
  (SVMs) and their counterparts achieve strong generalization
  performance by maximizing the margin of separation between data
  classes. While the maximum margin approach has achieved promising
  performance, this article identifies its sensitivity to affine
  transformations of the data and to directions with large data
  spread. Maximum margin solutions may be misled by the spread of data
  and preferentially separate classes along large spread directions.
  This article corrects these weaknesses by measuring margin not in
  the absolute sense but rather only relative to the spread of data in
  any projection direction. Maximum relative margin corresponds to a
  data-dependent regularization on the classification function while
  maximum absolute margin corresponds to an &lt;i&gt;l&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt; norm constraint
  on the classification function.  Interestingly, the proposed
  improvements only require simple extensions to existing maximum
  margin formulations and preserve the computational efficiency of
  SVMs. Through the maximization of relative margin, surprising
  performance gains are achieved on real-world problems such as digit,
  text classification and on several other benchmark data sets.  In addition, 
  risk bounds are derived for the new formulation based on Rademacher averages.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/shivaswamy10a/shivaswamy10a.pdf</url></Article><Article><id>672</id><title> Stability Bounds for Stationary &amp;#966;-mixing and &amp;#946;-mixing Processes</title><author>Mehryar Mohri, Afshin Rostamizadeh</author><abstract>

Most generalization bounds in learning theory are based on some
  measure of the complexity of the hypothesis class used,
  independently of any algorithm. In contrast, the notion of
  algorithmic stability can be used to derive tight generalization
  bounds that are tailored to specific learning algorithms by
  exploiting their particular properties. However, as in much of
  learning theory, existing stability analyses and bounds apply only
  in the scenario where the samples are independently and identically
  distributed. In many machine learning applications, however, this
  assumption does not hold. The observations received by the learning
  algorithm often have some inherent temporal dependence.

&lt;br&gt;

  This paper studies the scenario where the observations are drawn
  from a stationary &amp;#966;-mixing or &amp;#946;-mixing sequence, a
  widely adopted assumption in the study of non-i.i.d. processes that
  implies a dependence between observations weakening over time.  We
  prove novel and distinct stability-based generalization bounds for
  stationary &amp;#966;-mixing and &amp;#946;-mixing sequences. These
  bounds strictly generalize the bounds given in the i.i.d. case and
  apply to all stable learning algorithms, thereby extending the
  use of stability-bounds to non-i.i.d. scenarios.

&lt;br&gt;

  We also illustrate the application of our &amp;#966;-mixing
  generalization bounds to general classes of learning algorithms,
  including Support Vector Regression, Kernel Ridge Regression, and
  Support Vector Machines, and many other kernel regularization-based
  and relative entropy-based regularization algorithms.  These novel
  bounds can thus be viewed as the first theoretical basis for the use
  of these algorithms in non-i.i.d. scenarios.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mohri10a/mohri10a.pdf</url></Article><Article><id>673</id><title> Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models</title><author>Fang-Lan Huang, Cho-Jui Hsieh, Kai-Wei Chang, Chih-Jen Lin</author><abstract>

Maximum entropy (Maxent) is useful in natural language processing and
many other areas.  Iterative scaling (IS) methods are one of the most
popular approaches to solve Maxent.  With many variants of IS
methods, it is difficult to understand them and see the differences.
In this paper, we create a general and unified framework for iterative
scaling methods. This framework also connects iterative scaling and
coordinate descent methods.  We prove general convergence results for
IS methods and analyze their computational complexity. Based on the
proposed framework, we extend a coordinate descent method for linear
SVM to Maxent. Results show that it is faster than existing iterative
scaling methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/huang10a/huang10a.pdf</url></Article><Article><id>674</id><title> A Streaming Parallel Decision Tree Algorithm</title><author>Yael Ben-Haim, Elad Tom-Tov</author><abstract>

We propose a new algorithm for building decision tree classifiers. The algorithm is executed in a distributed environment and is especially designed for classifying large data sets and streaming data. It is empirically shown to be as accurate as a standard decision tree classifier, while being scalable for processing of streaming data on multiple processors. These findings are supported by a rigorous analysis of the algorithm's accuracy.

&lt;br&gt;

The essence of the algorithm is to quickly construct histograms at the processors, which compress the data to a fixed amount of memory. A master processor uses this information to find near-optimal split points to terminal tree nodes. Our analysis shows that guarantees on the local accuracy of split points imply guarantees on the overall tree accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf</url></Article><Article><id>675</id><title> Image Denoising with Kernels Based on Natural Image Relations</title><author>Valero Laparra, Juan Guti&amp;#233;rrez, Gustavo Camps-Valls, Jes&amp;#250;s Malo</author><abstract>

A successful class of image denoising methods is based on Bayesian approaches working in
wavelet representations. The performance of these methods improves when relations among the local frequency coefficients are explicitly included. However, in these techniques, analytical
estimates can be obtained &lt;i&gt;only&lt;/i&gt; for particular combinations of analytical models
of signal and noise, thus precluding its straightforward extension to deal with other arbitrary noise sources.

&lt;br&gt;

In this paper,
we propose an alternative non-explicit way to take into account the relations
among natural image wavelet coefficients for denoising: we use support vector regression
(SVR) in the wavelet domain to enforce these relations in the estimated signal.
Since relations
among the coefficients are specific to the signal, the
regularization property of SVR is exploited to remove the noise, which does not
share this feature. The specific signal relations
are encoded in an anisotropic kernel obtained from mutual information measures computed on a
representative image database. In the proposed scheme,
training considers minimizing the Kullback-Leibler divergence (KLD) between the estimated
and actual probability functions (or histograms) of signal and noise in order
to enforce similarity up to the higher (computationally estimable) order.
Due to its non-parametric nature, the method can eventually cope
with different noise sources without the need of an explicit re-formulation, as it is
strictly necessary under parametric Bayesian formalisms.

&lt;br&gt;

Results under several noise levels and noise sources show that:
(1) the proposed method outperforms conventional wavelet
methods that assume coefficient independence, (2) it is similar to state-of-the-art methods
that do explicitly include these relations when the noise source is Gaussian, and (3)
it gives better numerical and visual performance when more complex, realistic
noise sources are considered. Therefore, the
proposed machine learning approach can be seen as a more
flexible (model-free) alternative to the explicit description
of wavelet coefficient relations for image denoising.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/laparra10a/laparra10a.pdf</url></Article><Article><id>676</id><title> On Learning with Integral Operators</title><author>Lorenzo Rosasco, Mikhail Belkin, Ernesto De Vito</author><abstract>

A large number of learning algorithms, for example, spectral clustering, kernel Principal Components Analysis and many 
manifold methods are based on estimating eigenvalues and eigenfunctions of operators defined 
by a similarity function or a kernel, given empirical data. Thus for the analysis of algorithms, it is an important 
problem to be able to assess the  quality of such approximations.
The contribution of our paper is two-fold:
&lt;br&gt;
1. We use a technique based on a concentration inequality for Hilbert spaces to provide 
new much simplified proofs for a number of results in  spectral approximation.
&lt;br&gt;
2. Using these methods we provide several new results for estimating spectral properties of the graph 
Laplacian operator extending and strengthening results from von Luxburg et al. (2008).


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/rosasco10a/rosasco10a.pdf</url></Article><Article><id>677</id><title> On Spectral Learning</title><author>Andreas Argyriou, Charles A. Micchelli, Massimiliano Pontil</author><abstract>

In this paper, we study the problem of learning a matrix
&lt;i&gt;W&lt;/i&gt; from a set of linear measurements. Our formulation consists in
solving an optimization problem which involves regularization with a
spectral penalty term. That is, the penalty term is a function of the
spectrum of the covariance of &lt;i&gt;W&lt;/i&gt;. Instances of this problem in
machine learning include multi-task learning, collaborative filtering
and multi-view learning, among others. Our goal is to elucidate the
form of the optimal solution of spectral learning. The theory of
spectral learning relies on the von Neumann characterization of
orthogonally invariant norms and their association with symmetric
gauge functions. Using this tool we formulate a representer theorem
for spectral regularization and specify it to several useful example,
such as Schatten &lt;i&gt;p&lt;/i&gt;-norms, trace norm and spectral norm, which should
proved useful in applications.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/argyriou10a/argyriou10a.pdf</url></Article><Article><id>678</id><title> Generalized Expectation Criteria for Semi-Supervised Learning with Weakly Labeled Data</title><author>Gideon S. Mann, Andrew McCallum</author><abstract>

In this paper, we present an overview of &lt;i&gt;generalized expectation criteria (GE)&lt;/i&gt;, a simple, robust,  scalable method for semi-supervised training using weakly-labeled data.  GE fits model parameters by favoring models that match certain expectation constraints, such as marginal label distributions, on the unlabeled data.  This paper shows how to apply generalized expectation criteria to two classes of parametric models: maximum entropy models and conditional random fields.  Experimental results demonstrate accuracy improvements over supervised training and a number of other state-of-the-art semi-supervised learning methods for these models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mann10a/mann10a.pdf</url></Article><Article><id>679</id><title> Kronecker Graphs: An Approach to Modeling Networks</title><author>Jure Leskovec, Deepayan Chakrabarti, Jon Kleinberg, Christos Faloutsos, Zoubin Ghahramani</author><abstract>

How can we generate realistic networks? In addition, how can we do so with
a mathematically tractable model that allows for rigorous analysis of
network properties? Real networks exhibit a long list of surprising
properties: Heavy tails for the in- and out-degree distribution, heavy
tails for the eigenvalues and eigenvectors, small diameters, and
densification and shrinking diameters over time.
Current network models and generators either fail to match several of the above
properties, are complicated to analyze mathematically, or both. Here
we propose a generative model for networks that is both
mathematically tractable and can generate networks that have all the above
mentioned structural properties. Our main idea here is to use a
non-standard matrix operation, the &lt;i&gt;Kronecker product&lt;/i&gt;, to generate
graphs which we refer to as "Kronecker graphs".

&lt;br&gt;

First, we show that Kronecker graphs naturally obey common network
properties. In fact, we rigorously &lt;i&gt;prove&lt;/i&gt; that they do so. We also
provide empirical evidence showing that Kronecker graphs can effectively
model the structure of real networks.

&lt;br&gt;

We then present KRONFIT, a fast and scalable algorithm for fitting the
Kronecker graph generation model to large real networks. A naive approach
to fitting would take super-exponential time. In contrast, KRONFIT takes
&lt;i&gt;linear&lt;/i&gt; time, by exploiting the structure of Kronecker matrix
multiplication and by using statistical simulation techniques.

&lt;br&gt;

Experiments on a wide range of large real and synthetic networks show that KRONFIT finds accurate parameters that very well mimic the properties of target
networks. In fact, using just four parameters we can accurately
model several aspects of global network structure.
Once fitted, the model parameters can be used to gain insights
about the network structure, and the resulting synthetic graphs can be
used for null-models, anonymization, extrapolations, and graph
summarization.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/leskovec10a/leskovec10a.pdf</url></Article><Article><id>680</id><title> Message-passing for Graph-structured Linear Programs: Proximal Methods and Rounding Schemes</title><author>Pradeep Ravikumar, Alekh Agarwal, Martin J. Wainwright</author><abstract>

The problem of computing a maximum a posteriori (MAP) configuration is
a central computational challenge associated with Markov random
fields. There has been some focus on "tree-based" linear
programming (LP) relaxations for the MAP problem. This paper develops
a family of super-linearly convergent algorithms for solving these
LPs, based on proximal minimization schemes using Bregman divergences.
As with standard message-passing on graphs, the algorithms are
distributed and exploit the underlying graphical structure, and so
scale well to large problems.  Our algorithms have a double-loop
character, with the outer loop corresponding to the proximal sequence,
and an inner loop of cyclic Bregman projections used to compute each
proximal update. We establish convergence guarantees for our algorithms, and illustrate their
performance via some simulations.  We also develop two classes of
rounding schemes, deterministic and randomized, for obtaining integral configurations from the LP solutions.
Our deterministic rounding schemes use a "re-parameterization" property
of our algorithms so that when the LP solution is integral, the MAP
solution can be obtained even before the LP-solver converges to the
optimum.  We also propose graph-structured randomized rounding schemes applicable to iterative LP-solving algorithms in general.
We analyze the performance of and report simulations comparing these rounding schemes.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ravikumar10a/ravikumar10a.pdf</url></Article><Article><id>681</id><title> Analysis of Multi-stage Convex Relaxation for Sparse Regularization</title><author>Tong Zhang</author><abstract>

We consider learning formulations with non-convex objective functions that often occur in practical applications. There are two approaches to this problem:

&lt;ul&gt;
&lt;li&gt; Heuristic methods such as gradient descent that only find a local minimum. A drawback of this approach is the lack of theoretical guarantee showing that the local minimum gives a good solution. &lt;/li&gt;
&lt;li&gt; Convex relaxation such as &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-regularization that solves the problem under some conditions. However it often leads to a sub-optimal solution in reality. &lt;/li&gt;
&lt;/ul&gt;

This paper tries to remedy the above gap between theory and practice.
In particular, we present a multi-stage convex relaxation scheme for solving problems with non-convex objective functions.
For learning formulations with
sparse regularization, we analyze the behavior of a specific
multi-stage relaxation scheme.
Under appropriate conditions, we show that the local solution obtained by this procedure is superior to the global solution of the standard &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; convex relaxation for learning sparse targets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/zhang10a/zhang10a.pdf</url></Article><Article><id>682</id><title> Large Scale Online Learning of Image Similarity Through Ranking</title><author>Gal Chechik, Varun Sharma, Uri Shalit, Samy Bengio</author><abstract>

Learning a measure of similarity between pairs of objects is an
important generic problem in machine learning. It is particularly
useful in large scale applications like searching for an image that
is similar to a given image or finding videos that are relevant to a
given video. In these tasks, users look for objects that are not
only visually similar but also semantically related to a given
object.  Unfortunately, the approaches that exist today for learning
such semantic similarity do not scale to large data sets. This is
both because typically their CPU and storage requirements grow
quadratically with the sample size, and because many methods impose
complex positivity constraints on the space of learned similarity
functions.

&lt;br&gt;

The current paper presents OASIS, an &lt;i&gt;Online Algorithm for
Scalable Image Similarity&lt;/i&gt; learning that learns a bilinear
similarity measure over sparse representations. OASIS is an online
dual approach using the passive-aggressive family of learning
algorithms with a large margin criterion and an efficient hinge loss
cost. Our experiments show that OASIS is both fast and accurate at a
wide range of scales: for a data set with thousands of images, it
achieves better results than existing state-of-the-art methods,
while being an order of magnitude faster. For large, web scale,
data sets, OASIS can be trained on more than two million images from
150K text queries within 3 days on a single CPU.  On this large
scale data set, human evaluations showed that 35% of the ten nearest
neighbors of a given test image, as found by OASIS, were
semantically relevant to that image. This suggests that query
independent similarity could be accurately learned even for large
scale data sets that could not be handled before.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/chechik10a/chechik10a.pdf</url></Article><Article><id>683</id><title> Continuous Time Bayesian Network Reasoning and Learning Engine</title><author>Christian R. Shelton, Yu Fan, William Lam, Joon Lee, Jing Xu</author><abstract>

We present a continuous time Bayesian network reasoning and learning
engine (CTBN-RLE).  A continuous time Bayesian network (CTBN) provides
a compact (factored) description of a continuous-time Markov process.
This software provides libraries and programs for most of the algorithms
developed for CTBNs.  For learning, CTBN-RLE implements structure and
parameter learning for both complete and partial data.  For inference,
it implements exact inference and Gibbs and importance sampling
approximate inference for any type of evidence pattern.  Additionally,
the library supplies visualization methods for graphically displaying CTBNs
or trajectories of evidence.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/shelton10a/shelton10a.pdf</url></Article><Article><id>684</id><title> SFO: A Toolbox for Submodular Function Optimization</title><author>Andreas Krause</author><abstract>

In recent years, a fundamental problem structure has emerged as very useful in a variety of machine learning applications: Submodularity is an intuitive diminishing returns property, stating that adding an element to a smaller set helps more than adding it to a larger set. Similarly to convexity, submodularity allows one to efficiently find provably (near-) optimal solutions for large problems.
We present SFO, a toolbox for use in MATLAB or Octave that implements algorithms for minimization and maximization of submodular functions. A tutorial script illustrates the application of submodularity to machine learning and AI problems such as feature selection, clustering, inference and optimized information gathering.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/krause10a/krause10a.pdf</url></Article><Article><id>685</id><title> A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning</title><author>Jin Yu, S.V.N. Vishwanathan, Simon G&amp;#252;nter, Nicol N. Schraudolph</author><abstract>

We extend the well-known BFGS quasi-Newton method and its
memory-limited variant LBFGS to the optimization of nonsmooth convex
objectives. This is done in a rigorous fashion by generalizing three
components of BFGS to subdifferentials: the local quadratic model,
the identification of a descent direction, and the Wolfe line search
conditions. We prove that under some technical conditions, the
resulting subBFGS algorithm is globally convergent in objective
function value.  We apply its memory-limited variant (subLBFGS)
to &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;-regularized risk minimization with the binary hinge
loss. To extend our algorithm to the multiclass and multilabel
settings, we develop a new, efficient, exact line search
algorithm. We prove its worst-case time complexity bounds, and show
that our line search can also be used to extend a recently developed
bundle method to the multiclass and multilabel settings.
We also apply the direction-finding component of our algorithm to
&lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-regularized risk minimization with logistic loss. In all these
contexts our methods perform comparable to or better than
specialized state-of-the-art solvers on a number of publicly
available data sets.  An open source implementation of our
algorithms is freely available.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yu10a/yu10a.pdf</url></Article><Article><id>686</id><title> Graph Kernels</title><author>S.V.N. Vishwanathan, Nicol N. Schraudolph, Risi Kondor, Karsten M. Borgwardt</author><abstract>

We present a unified framework to study graph kernels, special cases
of which include the random walk (G&amp;#228;rtner et al., 2003; Borgwardt et al., 2005)
and marginalized (Kashima et al., 2003, 2004; Mah&amp;#233;t al., 2004) 
graph kernels. Through reduction to a Sylvester equation we improve the
time complexity of kernel computation between unlabeled graphs with 
&lt;i&gt;n&lt;/i&gt; vertices from &lt;i&gt;O(n&lt;sup&gt;6&lt;/sup&gt;)&lt;/i&gt; to &lt;i&gt;O(n&lt;sup&gt;3&lt;/sup&gt;)&lt;/i&gt;. We find a spectral
decomposition approach even more efficient when computing entire kernel
matrices. For labeled graphs we develop conjugate gradient and fixed-point
methods that take &lt;i&gt;O(dn&lt;sup&gt;3&lt;/sup&gt;)&lt;/i&gt; time per iteration, where &lt;i&gt;d&lt;/i&gt; is the size of the
label set. By extending the necessary linear algebra to Reproducing Kernel
Hilbert Spaces (RKHS) we obtain the same result for &lt;i&gt;d&lt;/i&gt;-dimensional edge
kernels, and &lt;i&gt;O(n&lt;sup&gt;4&lt;/sup&gt;)&lt;/i&gt; in the infinite-dimensional case; on sparse graphs
these algorithms only take &lt;i&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; time per iteration in all cases. Experiments
on graphs from bioinformatics and other application domains show that
these techniques can speed up computation of the kernel by an order of
magnitude or more. We also show that certain rational kernels
(Cortes et al., 2002, 2003, 2004) when specialized to graphs
reduce to our random walk graph kernel. Finally, we relate our
framework to R-convolution kernels (Haussler, 1999) and provide a
kernel that is close to the optimal assignment kernel of
kernel of Fr&amp;#246;hlich et al. (2006) yet provably positive semi-definite.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/vishwanathan10a/vishwanathan10a.pdf</url></Article><Article><id>687</id><title> Stochastic Complexity and Generalization Error of a Restricted Boltzmann Machine in Bayesian Estimation</title><author>Miki Aoyagi</author><abstract>

In this paper, we consider the asymptotic 
form of the generalization error 
for the restricted Boltzmann machine 
in Bayesian estimation.
It has been shown that 
obtaining the maximum pole of 
zeta functions is related to the asymptotic 
form of the generalization error for 
hierarchical learning models (Watanabe, 2001a,b).
The
zeta function
is defined by using a Kullback function.
We use two methods to obtain  the maximum pole:
a new eigenvalue analysis method and 
a recursive blowing up process.
We show that these methods are effective 
for obtaining the asymptotic 
form of the generalization error
of hierarchical learning models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/aoyagi10a/aoyagi10a.pdf</url></Article><Article><id>688</id><title> Approximate Inference on Planar Graphs using Loop Calculus and Belief Propagation</title><author>Vicen&amp;#231; G&amp;#243;mez, Hilbert J. Kappen, Michael Chertkov</author><abstract>

We introduce novel results for approximate inference on planar graphical models
using the loop calculus framework.  The loop calculus (Chertkov and Chernyak, 2006a)
allows to express the exact partition function of a graphical model as a finite
sum of terms that can be evaluated once the belief propagation (BP) solution is
known.  In general, full summation over all correction terms is intractable.
We develop an algorithm for the approach presented in Chertkov et al. (2008) which
represents an efficient truncation scheme on planar graphs and a new
representation of the series in terms of Pfaffians of matrices.  We analyze the
performance of the algorithm for models with binary variables and pairwise
interactions on grids and other planar graphs.  We study in detail both the
loop series and the equivalent Pfaffian series and show that the first term of
the Pfaffian series for the general, intractable planar model, can provide very
accurate approximations.  The algorithm outperforms previous truncation schemes
of the loop series and is competitive with other state of the art methods for
approximate inference.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/gomez10a/gomez10a.pdf</url></Article><Article><id>689</id><title> Learning From Crowds</title><author>Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca Bogoni, Linda Moy</author><abstract>

For many supervised learning tasks it may be infeasible (or very
expensive) to obtain objective and reliable labels. Instead, we can collect subjective (possibly noisy)
labels from multiple experts or annotators. In practice, there is  a
substantial amount of disagreement among the annotators, and hence it is
of great practical interest to address conventional supervised learning problems in
this scenario. In this paper we describe a probabilistic approach for supervised learning when we have multiple annotators providing (possibly noisy) labels but no absolute gold standard. The proposed algorithm evaluates the different experts and also gives an estimate of the actual hidden labels. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/raykar10a/raykar10a.pdf</url></Article><Article><id>690</id><title> Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels</title><author>Pinar Donmez, Guy Lebanon, Krishnakumar Balasubramanian</author><abstract>

Estimating the error rates of classifiers or regression models is a fundamental task in machine learning which has thus far been studied exclusively using supervised learning techniques. We propose a novel  unsupervised framework for estimating these error rates using only unlabeled data and mild assumptions. We prove consistency results for the framework and demonstrate its practical applicability on both synthetic and real world data.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/donmez10a/donmez10a.pdf</url></Article><Article><id>691</id><title> Learning Translation Invariant Kernels for Classification</title><author>Kamaledin Ghiasi-Shirazi, Reza Safabakhsh, Mostafa Shamsi</author><abstract>

Appropriate selection of the kernel function, which implicitly defines the feature space of an algorithm, has a crucial role in the success of kernel methods. In this paper, we consider the problem of optimizing a kernel function over the class of translation invariant kernels for the task of binary classification. The learning capacity of this class is invariant with respect to rotation and scaling of the features and it encompasses the set of radial kernels. We show that how translation invariant kernel functions can be embedded in a nested set of sub-classes and consider the kernel learning problem over one of these sub-classes. This allows the choice of an appropriate sub-class based on the problem at hand. We use the criterion proposed by Lanckriet et al. (2004) to obtain a functional formulation for the problem. It will be proven that the optimal kernel is a finite mixture of cosine functions. The kernel learning problem is then formulated as a semi-infinite programming (SIP) problem which is solved by a sequence of quadratically constrained quadratic programming (QCQP) sub-problems. Using the fact that the cosine kernel is of rank two, we propose a formulation of a QCQP sub-problem which does not require the kernel matrices to be loaded into memory, making the method applicable to large-scale problems. We also address the issue of including other classes of kernels, such as individual kernels and isotropic Gaussian kernels, in the learning process. Another interesting feature of the proposed method is that the optimal classifier has an expansion in terms of the number of cosine kernels, instead of support vectors, leading to a remarkable speedup at run-time. As a by-product, we also generalize the kernel trick to complex-valued kernel functions. Our experiments on artificial and real-world benchmark data sets, including the USPS and the MNIST digit recognition data sets, show the usefulness of the proposed method.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ghiasi-shirazi10a/ghiasi-shirazi10a.pdf</url></Article><Article><id>692</id><title> Consistent Nonparametric Tests of Independence</title><author>Arthur Gretton, L&amp;#225;szl&amp;#243; Gy&amp;#246;rfi</author><abstract>

Three simple and explicit procedures for testing the independence
of two multi-dimensional  random variables are described.  Two 
of the associated test statistics (&lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;,
log-likelihood) are defined when the empirical
distribution of the variables is restricted to finite partitions.  
A third test statistic is defined as a kernel-based independence measure.
Two kinds of tests are provided.
 Distribution-free strong consistent tests are derived 
on the basis of large deviation bounds on the test statistics: these tests
make almost surely no Type I or Type II error
after a random sample size.
Asymptotically
&lt;i&gt;&amp;#945;&lt;/i&gt;-level tests are obtained from the limiting distribution of the test statistics.
For the latter tests, the Type I error converges
to a fixed non-zero value &lt;i&gt;&amp;#945;&lt;/i&gt;, and the Type II error drops to zero, 
for increasing sample size.
All tests reject the null hypothesis of independence if the test
statistics become large. 
The performance of the tests is evaluated experimentally on
benchmark data.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/gretton10a/gretton10a.pdf</url></Article><Article><id>693</id><title> Characterization, Stability and Convergence of Hierarchical Clustering Methods</title><author>Gunnar Carlsson, Facundo M&amp;#233;moli</author><abstract>

We study hierarchical clustering schemes under an axiomatic view. We
  show that within this framework, one can prove a theorem analogous
  to one of Kleinberg (2002), in which one obtains an
  existence and uniqueness theorem instead of a non-existence
  result. We explore further properties of this unique scheme:
  stability and convergence are established. We represent dendrograms
  as ultrametric spaces and use tools from metric geometry, namely the
  Gromov-Hausdorff distance, to quantify the degree to which
  perturbations in the input metric space affect the result of
  hierarchical methods. 



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/carlsson10a/carlsson10a.pdf</url></Article><Article><id>694</id><title> Training and Testing Low-degree Polynomial Data Mappings via Linear SVM</title><author>Yin-Wen Chang, Cho-Jui Hsieh, Kai-Wei Chang, Michael Ringgaard, Chih-Jen Lin</author><abstract>

Kernel techniques have long been used in SVM to handle linearly inseparable 
problems by transforming data to a high dimensional space,
but training and testing large data sets is often time consuming. In contrast, we 
can efficiently train and test much larger data sets using linear SVM without 
kernels. In this work, we apply fast linear-SVM methods to the explicit form 
of polynomially mapped data and investigate implementation issues.
The approach enjoys fast training and testing,
but may sometimes achieve accuracy close to that of
using highly nonlinear kernels.
Empirical experiments show that the proposed method is useful 
for certain large-scale data sets.
We successfully apply the proposed method to a natural language processing 
(NLP) application by improving the testing accuracy 
under some training/testing speed requirements. 



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/chang10a/chang10a.pdf</url></Article><Article><id>695</id><title> Quadratic Programming Feature Selection</title><author>Irene Rodriguez-Lujan, Ramon Huerta, Charles Elkan, Carlos Santa Cruz</author><abstract>

Identifying a subset of features that preserves classification accuracy
is a problem of growing importance,
because of the increasing size and dimensionality of real-world data sets. 
We propose a new feature selection method,
named Quadratic Programming Feature Selection (QPFS),
that reduces the task to a quadratic optimization problem.
In order to limit the computational complexity of 
solving the optimization problem,
QPFS uses the Nystr&amp;#246;m method for approximate matrix diagonalization.
QPFS is thus capable of dealing with very large data sets,
for which the use of other methods is computationally expensive. 
In experiments with small and medium data sets,
the QPFS method leads to classification accuracy similar to 
that of other successful techniques. 
For large data sets, QPFS is superior in terms of computational efficiency.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/rodriguez-lujan10a/rodriguez-lujan10a.pdf</url></Article><Article><id>696</id><title> Hilbert Space Embeddings and Metrics on Probability Measures</title><author>Bharath K. Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard Sch&amp;#246;lkopf, Gert R.G. Lanckriet</author><abstract>

A Hilbert space embedding for probability measures has recently been proposed, with applications including dimensionality reduction, homogeneity testing, and independence testing. This embedding represents any probability measure as a mean element in a reproducing kernel Hilbert space (RKHS). A pseudometric on the space of probability measures can be defined as the distance between distribution embeddings: we denote this as &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, indexed by the kernel function &lt;i&gt;k&lt;/i&gt; that defines the inner product in the RKHS.

&lt;br&gt;

We present three theoretical properties of &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;. First, we consider the question of determining the conditions on the kernel &lt;i&gt;k&lt;/i&gt;
for which &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; is a metric: such &lt;i&gt;k&lt;/i&gt; are denoted &lt;i&gt;characteristic kernels&lt;/i&gt;. Unlike pseudometrics, a metric is zero only when two distributions
coincide, thus ensuring the RKHS embedding maps all distributions uniquely (i.e., the embedding is injective). While previously published conditions may apply only in restricted circumstances (e.g., on compact domains), and are difficult to check, our conditions are straightforward and intuitive: &lt;i&gt;integrally strictly positive definite kernels&lt;/i&gt; are characteristic. Alternatively, if a bounded continuous kernel is translation-invariant on &lt;i&gt;&amp;#8476;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;, then it is characteristic if and only if the support of its Fourier transform is the entire &lt;i&gt;&amp;#8476;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;. Second, we show that the distance between distributions under &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; results from an interplay between the properties of the kernel and the distributions, by demonstrating that distributions are close in the embedding space when their differences occur at higher frequencies. Third, to understand the nature of the topology induced by &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt;, we relate &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; to other popular metrics on probability measures, and present conditions on the kernel &lt;i&gt;k&lt;/i&gt; under which &lt;i&gt;&amp;#947;&lt;sub&gt;k&lt;/sub&gt;&lt;/i&gt; metrizes the weak topology.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/sriperumbudur10a/sriperumbudur10a.pdf</url></Article><Article><id>697</id><title> Near-optimal Regret Bounds for Reinforcement Learning</title><author>Thomas Jaksch, Ronald Ortner, Peter Auer</author><abstract>

For undiscounted reinforcement learning in Markov decision
processes (MDPs) we consider the &lt;i&gt;total regret&lt;/i&gt; of
a learning algorithm with respect to an optimal policy.
In order to describe the transition structure of an MDP we propose a new parameter:
An MDP has &lt;i&gt;diameter&lt;/i&gt; &lt;i&gt;D&lt;/i&gt; if for any pair of states &lt;i&gt;s,s'&lt;/i&gt; there is
a policy which moves from &lt;i&gt;s&lt;/i&gt; to &lt;i&gt;s'&lt;/i&gt; in at most &lt;i&gt;D&lt;/i&gt; steps (on average).
We present a reinforcement learning algorithm with total regret
&lt;i&gt;&amp;#213;(DS&amp;#8730;AT)&lt;/i&gt; after &lt;i&gt;T&lt;/i&gt; steps for any unknown MDP
with &lt;i&gt;S&lt;/i&gt; states, &lt;i&gt;A&lt;/i&gt; actions per state, and diameter &lt;i&gt;D&lt;/i&gt;.
A corresponding lower bound of &lt;i&gt;&amp;#937;(&amp;#8730;DSAT)&lt;/i&gt; on the
total regret of any learning algorithm is given as well.

&lt;br&gt;

These results are complemented by a sample complexity bound on the
number of suboptimal steps taken by our algorithm. This bound can be
used to achieve a (gap-dependent) regret bound that is logarithmic in &lt;i&gt;T&lt;/i&gt;.

&lt;br&gt;

Finally, we also consider a setting where the MDP is allowed to change
a fixed number of &lt;i&gt;l&lt;/i&gt; times. We present a modification of our algorithm
that is able to deal with this setting and show a regret bound of
&lt;i&gt;&amp;#213;(l&lt;sup&gt;1/3&lt;/sup&gt;T&lt;sup&gt;2/3&lt;/sup&gt;DS&amp;#8730;A)&lt;/i&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/jaksch10a/jaksch10a.pdf</url></Article><Article><id>698</id><title> MOA: Massive Online Analysis</title><author>Albert Bifet, Geoff Holmes, Richard Kirkby, Bernhard Pfahringer</author><abstract>

&lt;b&gt;M&lt;/b&gt;assive &lt;b&gt;O&lt;/b&gt;nline &lt;b&gt;A&lt;/b&gt;nalysis (MOA)
is a 
software environment for implementing algorithms and running experiments
for online learning from 
evolving data streams.
MOA includes a collection of offline and online methods as well as tools for evaluation. 
In particular, it implements boosting, bagging, and Hoeffding Trees, all 
with and without Na&amp;#239;ve Bayes classifiers at the leaves.
MOA supports bi-directional interaction with WEKA, the Waikato
Environment for Knowledge Analysis,
and is released under the GNU GPL license.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/bifet10a/bifet10a.pdf</url></Article><Article><id>699</id><title> On the Foundations of Noise-free Selective Classification</title><author>Ran El-Yaniv, Yair Wiener</author><abstract>

We consider &lt;i&gt;selective classification&lt;/i&gt;, a term we adopt here to refer to 'classification with a reject option.' The essence in selective classification is to trade-off classifier
coverage for higher accuracy.  We term this trade-off the &lt;i&gt;risk-coverage (RC) trade-off&lt;/i&gt;.
Our main objective is to characterize this trade-off and to construct algorithms that can optimally or near
optimally achieve the best possible trade-offs in a controlled manner.
For noise-free models we present in this paper
a thorough analysis of selective classification including characterizations of RC trade-offs
in various interesting settings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/el-yaniv10a/el-yaniv10a.pdf</url></Article><Article><id>700</id><title> Introduction to Causal Inference</title><author>Peter Spirtes</author><abstract>

The goal of many sciences is to understand the mechanisms by which
variables came to take on the values they have (that is, to find a
generative model), and to predict what the values of those variables
would be if the naturally occurring mechanisms were subject to outside
manipulations. The past 30 years has seen a number of conceptual
developments that are partial solutions to the problem of causal
inference from observational sample data or a mixture of observational
sample and experimental data, particularly in the area of graphical
causal modeling. However, in many domains, problems such as the large
numbers of variables, small samples sizes, and possible presence of
unmeasured causes, remain serious impediments to practical applications
of these developments. The articles in the Special Topic on Causality
address these and other problems in applying graphical causal modeling
algorithms. This introduction to the Special Topic on Causality
provides a brief introduction to graphical causal modeling, places the
articles in a broader context, and describes the differences between
causal inference and ordinary machine learning classification and prediction problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/spirtes10a/spirtes10a.pdf</url></Article><Article><id>701</id><title> Consensus-Based Distributed Support Vector Machines</title><author>Pedro A. Forero, Alfonso Cano, Georgios B. Giannakis</author><abstract>

This paper develops algorithms to train support vector machines when
training data are distributed across different nodes,
and their communication to a centralized processing unit is
prohibited due to, for example, communication complexity, scalability, or
privacy reasons. To accomplish this goal, the centralized linear SVM
problem is cast as a set of decentralized convex optimization
sub-problems (one per node) with consensus constraints on the wanted
classifier parameters. Using the alternating direction method of
multipliers, fully distributed training algorithms are obtained
without exchanging training data among nodes. Different from
existing incremental approaches, the overhead associated with
inter-node communications is fixed and solely dependent on the
network topology rather than the size of the training sets available
per node. Important generalizations to train nonlinear SVMs in a
distributed fashion are also developed along with sequential variants
capable of online processing. Simulated tests illustrate the
performance of the novel
algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/forero10a/forero10a.pdf</url></Article><Article><id>702</id><title> Estimation of a Structural Vector Autoregression Model Using Non-Gaussianity</title><author>Aapo Hyv&amp;#228;rinen, Kun Zhang, Shohei Shimizu, Patrik O. Hoyer</author><abstract>

Analysis of causal effects between continuous-valued variables
  typically uses either autoregressive models or structural equation
  models with instantaneous effects. Estimation of Gaussian, linear
  structural equation models poses serious identifiability problems,
  which is why it was recently proposed to use non-Gaussian
  models. Here, we show how to combine the non-Gaussian instantaneous
  model with autoregressive models. This is effectively what is called
  a structural vector autoregression (SVAR) model, and thus our work
  contributes to the long-standing problem of how to estimate
  SVAR's. We show that such a non-Gaussian model is identifiable
  without prior knowledge of network structure. We propose
  computationally efficient methods for estimating the model, as well
  as methods to assess the significance of the causal influences. The
  model is successfully applied on financial and brain imaging data.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/hyvarinen10a/hyvarinen10a.pdf</url></Article><Article><id>703</id><title> FastInf: An Efficient Approximate Inference Library</title><author>Ariel Jaimovich, Ofer Meshi, Ian McGraw, Gal Elidan</author><abstract>

  The FastInf C++ library is designed to perform memory and time
  efficient approximate inference in large-scale discrete undirected
  graphical models.  The focus of the library is propagation based
  approximate inference methods, ranging from the basic loopy belief
  propagation algorithm to propagation based on convex free energies.
  Various message scheduling schemes that improve on the standard
  synchronous or asynchronous approaches are included. Also
  implemented are a clique tree based exact inference, Gibbs sampling,
  and the mean field algorithm.  In addition to inference, FastInf
  provides parameter estimation capabilities as well as representation
  and learning of shared parameters. It offers a rich interface that
  facilitates extension of the basic classes to other inference and
  learning methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/jaimovich10a/jaimovich10a.pdf</url></Article><Article><id>704</id><title> Evolving Static Representations for Task Transfer</title><author>Phillip Verbancsics, Kenneth O. Stanley</author><abstract>

An important goal for machine learning is to transfer knowledge between tasks. For example, learning to play RoboCup Keepaway should contribute to learning the full game of RoboCup soccer. Previous approaches to transfer in Keepaway have focused on transforming the original representation to fit the new task. In contrast, this paper explores the idea that transfer is most effective if the representation is designed to be the &lt;i&gt;same&lt;/i&gt; even across different tasks. To demonstrate this point, a &lt;i&gt;bird's eye view&lt;/i&gt; (BEV) representation is introduced that can represent different tasks on the same two-dimensional map.  For example, both the 3 vs. 2 and 4 vs. 3 Keepaway tasks can be represented on the same BEV. Yet the problem is that a raw two-dimensional map is high-dimensional and unstructured. This paper shows how this problem is addressed naturally by an idea from evolutionary computation called &lt;i&gt;indirect encoding&lt;/i&gt;, which compresses the representation by exploiting its geometry. The result is that the BEV learns a Keepaway policy that transfers &lt;i&gt;without further learning&lt;/i&gt; or manipulation. It also facilitates transferring knowledge learned in a different domain, Knight Joust, into Keepaway.  Finally, the indirect encoding of the BEV means that its geometry can be changed without altering the solution.  Thus static representations facilitate several kinds of transfer.  


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/verbancsics10a/verbancsics10a.pdf</url></Article><Article><id>705</id><title> Bayesian Learning in Sparse Graphical Factor Models via Variational Mean-Field Annealing</title><author>Ryo Yoshida, Mike West</author><abstract>

We describe a class of sparse latent factor models, called graphical factor models (GFMs), and relevant sparse learning algorithms for posterior mode estimation. Linear, Gaussian GFMs have &lt;i&gt;sparse, orthogonal&lt;/i&gt; factor loadings matrices, that, in addition to sparsity of the implied covariance matrices, also
induce conditional independence structures via zeros in the implied precision matrices.  We describe the models
and their use for robust estimation of sparse latent factor structure and data/signal reconstruction. We develop computational
algorithms for model exploration and posterior mode search, addressing the hard combinatorial optimization involved in the search over a huge space of potential sparse configurations. A mean-field variational technique coupled with annealing is
developed to successively generate "artificial" posterior distributions that, at the limiting temperature
in the annealing schedule, define required posterior modes in the GFM parameter space. Several detailed
 empirical studies and comparisons to related approaches are discussed, including
analyses of handwritten digit image and cancer gene expression data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yoshida10a/yoshida10a.pdf</url></Article><Article><id>706</id><title> The SHOGUN Machine Learning Toolbox</title><author>S&amp;#246;ren Sonnenburg, Gunnar R&amp;#228;tsch, Sebastian Henschel, Christian Widmer, Jonas Behr, Alexander Zien, Fabio de Bona, Alexander Binder, Christian Gehl, Vojt&amp;#x011B;ch Franc</author><abstract>

We have developed a machine learning toolbox, called SHOGUN, which is
designed for unified large-scale learning for a broad range of feature
types and learning settings. It offers a considerable number of machine
learning models such as support vector machines, hidden Markov models, multiple kernel learning, linear
discriminant analysis, and
more. Most of the specific algorithms are able to deal with
several different data classes. We
have used this toolbox in several applications from computational
biology, some of them coming with no less than 50 million training
examples and others with 7 billion test examples. With more than a
thousand installations worldwide, SHOGUN is already widely adopted in
the machine learning community and beyond.

SHOGUN is implemented in C++ and interfaces to &lt;i&gt;MATLAB&lt;/i&gt;&lt;sup&gt;TM&lt;/sup&gt;, &lt;i&gt;R&lt;/i&gt;, &lt;i&gt;Octave&lt;/i&gt;, &lt;i&gt;Python&lt;/i&gt;, and
has a stand-alone command line interface.  The source code is freely available under the GNU General Public License, Version 3 at http://www.shogun-toolbox.org.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/sonnenburg10a/sonnenburg10a.pdf</url></Article><Article><id>707</id><title> How to Explain Individual Classification Decisions</title><author>David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, Klaus-Robert M&amp;#252;ller</author><abstract>

After building a classifier with modern tools of machine learning we
typically have a black box at hand that is able to predict well for
unseen data. Thus, we get an answer to the question &lt;i&gt;what&lt;/i&gt; is
the most likely label of a given unseen data point.  However, most methods will provide no answer &lt;i&gt;why&lt;/i&gt; the model predicted a particular label for a single instance and what features were most influential for that particular instance.  The only method that is currently able to provide such explanations are decision trees.  This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of &lt;i&gt;any&lt;/i&gt; classification method.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf</url></Article><Article><id>708</id><title> Permutation Tests for Studying Classifier Performance</title><author>Markus Ojala, Gemma C. Garriga</author><abstract>

We explore the framework of permutation-based &lt;i&gt;p&lt;/i&gt;-values for assessing the performance of classifiers. In this paper we study two simple permutation tests. The first test assess whether the classifier has found a real class structure in the data; the corresponding null distribution is estimated by permuting the labels in the data. This test has been used extensively in classification problems in computational biology. The second test studies whether the classifier is exploiting the dependency between the features in classification; the corresponding null distribution is estimated by permuting the features within classes, inspired by restricted randomization techniques traditionally used in statistics. This new test can serve to identify descriptive features which can be valuable information in improving the classifier performance. We study the properties of these tests and present an extensive empirical evaluation on real and synthetic data. Our analysis shows that studying the classifier performance via permutation tests is effective. In particular, the restricted permutation test clearly reveals whether the classifier exploits the interdependency between the features in the data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf</url></Article><Article><id>709</id><title> Sparse Spectrum Gaussian Process Regression</title><author>Miguel L&amp;#225;zaro-Gredilla, Joaquin Qui&amp;#241;onero-Candela, Carl Edward Rasmussen, An&amp;#237;bal R. Figueiras-Vidal</author><abstract>

We present a new sparse Gaussian Process (GP) model for
regression. The key novel idea is to sparsify the &lt;i&gt;spectral
  representation&lt;/i&gt; of the GP. This leads to a simple, practical
algorithm for regression tasks. We compare the achievable trade-offs
between predictive accuracy and computational requirements, and show
that these are typically superior to existing state-of-the-art
sparse approximations. We discuss both the weight space and function
space representations, and note that the new construction implies
priors over functions which are always stationary, and can
approximate any covariance function in this class.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/lazaro-gredilla10a/lazaro-gredilla10a.pdf</url></Article><Article><id>710</id><title> Fast and Scalable Local Kernel Machines</title><author>Nicola Segata, Enrico Blanzieri</author><abstract>

A computationally efficient approach to local learning with kernel methods is
presented. The &lt;b&gt;Fa&lt;/b&gt;st &lt;b&gt;L&lt;/b&gt;ocal &lt;b&gt;K&lt;/b&gt;ernel &lt;b&gt;S&lt;/b&gt;upport
&lt;b&gt;V&lt;/b&gt;ector &lt;b&gt;M&lt;/b&gt;achine (FaLK-SVM) trains a set of local SVMs on
redundant neighbourhoods in the training set and an appropriate model for each
query point is selected at testing time according to a proximity strategy.
Supported by a recent result by Zakai and Ritov (2009) relating consistency and
localizability, our approach achieves high classification accuracies by dividing
the separation function in local optimisation problems that can be handled very
efficiently from the computational viewpoint. The introduction of a fast local
model selection further speeds-up
the learning process. Learning and complexity bounds are derived for FaLK-SVM,
and the empirical evaluation of the approach (with data sets up to 3 million
points) showed that it is much faster and more accurate and scalable  than
state-of-the-art accurate and approximated SVM solvers at least for non
high-dimensional data sets. More generally, we show that locality can be an
important factor to sensibly speed-up learning approaches and kernel methods,
differently from other recent techniques that tend to dismiss local information
in order to improve scalability.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/segata10a/segata10a.pdf</url></Article><Article><id>711</id><title> Chromatic PAC-Bayes Bounds for Non-IID Data: Applications to Ranking and Stationary &amp;#946;-Mixing Processes</title><author>Liva Ralaivola, Marie Szafranski, Guillaume Stempfel</author><abstract>

PAC-Bayes bounds are among the most accurate
  generalization bounds for classifiers learned from independently and
  identically distributed (IID) data, and it
  is particularly so for margin classifiers: there have been recent
  contributions showing how practical these bounds can be either to
  perform model selection (Ambroladze et al., 2007) or even to directly guide the
  learning of linear classifiers (Germain et al., 2009). However, there are many
  practical situations where the training data show some dependencies and
  where the traditional IID assumption does not hold. Stating
  generalization bounds for such frameworks is therefore of the utmost
  interest, both from theoretical and practical standpoints.  In this
  work, we propose the first&amp;minus;to the best of our
  knowledge&amp;minus;PAC-Bayes  generalization bounds for classifiers trained on data
  exhibiting interdependencies. The approach undertaken to establish our
  results is based on the decomposition of a so-called dependency
  graph that encodes the dependencies within the data, in sets of
  independent data, thanks to graph &lt;i&gt;fractional covers&lt;/i&gt;.  Our
  bounds are very general, since being able to find an upper bound on
  the fractional chromatic number of the dependency graph is
  sufficient to get new PAC-Bayes bounds for specific settings.
  We show how our results can be used to derive bounds for
  ranking statistics (such as AUC) and classifiers trained on data
  distributed according to a stationary
  &amp;#946;-mixing process. In the way, we show how our approach
  seamlessly allows us to deal with U-processes. As a side note, we
  also provide a PAC-Bayes generalization bound for classifiers
  learned on data from stationary &amp;#966;-mixing distributions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ralaivola10a/ralaivola10a.pdf</url></Article><Article><id>712</id><title> Practical Approaches to Principal Component Analysis in the Presence of Missing Values</title><author>Alexander Ilin, Tapani Raiko</author><abstract>

  Principal component analysis (PCA) is a classical data analysis
  technique that finds linear transformations of data that retain the
  maximal amount of variance. We study a case where some of the data
  values are missing, and show that this problem has many features
  which are usually associated with nonlinear models, such as
  overfitting and bad locally optimal solutions. A probabilistic
  formulation of PCA provides a good foundation for handling missing
  values, and we provide formulas for doing that. In case of high
  dimensional and very sparse data, overfitting becomes a severe
  problem and traditional algorithms for PCA are very slow. We
  introduce a novel fast algorithm and extend it to variational
  Bayesian learning. Different versions of PCA are compared in
  artificial experiments, demonstrating the effects of regularization
  and modeling of posterior variance. The scalability of the proposed
  algorithm is demonstrated by applying it to the Netflix problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ilin10a/ilin10a.pdf</url></Article><Article><id>713</id><title> Posterior Regularization for Structured Latent Variable Models</title><author>Kuzman Ganchev, Jo&amp;#227;o Gra&amp;#231;a, Jennifer Gillenwater, Ben Taskar</author><abstract>

We present posterior regularization, a probabilistic framework for
structured, weakly supervised learning.  Our framework efficiently
incorporates indirect supervision via constraints on posterior
distributions of probabilistic models with latent variables. Posterior
regularization &lt;i&gt;separates&lt;/i&gt; model complexity from the complexity
of structural constraints it is desired to satisfy.  By directly
imposing decomposable regularization on the posterior moments of
latent variables during learning, we retain the computational
efficiency of the unconstrained model while ensuring desired
constraints hold in expectation. We present an efficient algorithm for
learning with posterior regularization and illustrate its versatility
on a diverse set of structural constraints such as bijectivity,
symmetry and group sparsity in several large scale experiments,
including multi-view learning, cross-lingual dependency grammar
induction, unsupervised part-of-speech induction, and bitext word
alignment.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ganchev10a/ganchev10a.pdf</url></Article><Article><id>714</id><title> A Surrogate Modeling and Adaptive Sampling Toolbox for Computer Based Design</title><author>Dirk Gorissen, Ivo Couckuyt, Piet Demeester, Tom Dhaene, Karel Crombecq</author><abstract>

An exceedingly large number of scientific and engineering fields are
confronted with the need for computer simulations to study complex,
real world phenomena or solve challenging design problems. However,
due to the computational cost of these high fidelity simulations,
the use of neural networks, kernel methods, and other surrogate modeling
techniques have become indispensable. Surrogate models are compact
and cheap to evaluate, and have proven very useful for tasks such
as optimization, design space exploration, prototyping, and sensitivity
analysis. Consequently, in many fields there is great interest in
tools and techniques that facilitate the construction of such regression
models, while minimizing the computational cost and maximizing model
accuracy. This paper presents a mature, flexible, and adaptive machine
learning toolkit for regression modeling and active learning to tackle
these issues. The toolkit brings together algorithms for data fitting,
model selection, sample selection (active learning), hyperparameter
optimization, and distributed computing in order to empower a domain
expert to efficiently generate an accurate model for the problem or
data at hand.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/gorissen10a/gorissen10a.pdf</url></Article><Article><id>715</id><title> Matrix Completion from  Noisy Entries</title><author>Raghunandan H. Keshavan, Andrea Montanari, Sewoong Oh</author><abstract>

Given a matrix &lt;i&gt;M&lt;/i&gt; of low-rank, we consider the problem of
reconstructing it from noisy observations of a small,
random subset of its entries. The problem arises in a variety
of applications, from collaborative filtering (the 'Netflix problem')
to structure-from-motion and positioning. We study a low complexity algorithm
introduced by Keshavan, Montanari, and Oh (2010), based on a combination
of spectral techniques and manifold optimization, that we call 
here OPTSPACE. We prove performance guarantees that are 
order-optimal in a number of circumstances.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/keshavan10a/keshavan10a.pdf</url></Article><Article><id>716</id><title> On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation</title><author>Gavin C. Cawley, Nicola L. C. Talbot</author><abstract>

Model selection strategies for machine learning algorithms typically involve
the numerical optimisation of an appropriate model selection criterion, often
based on an estimator of generalisation performance, such as &lt;i&gt;k&lt;/i&gt;-fold 
cross-validation.  The error of such an estimator can be broken down into bias 
and variance components.  While unbiasedness is often cited as a beneficial 
quality of a model selection criterion, we demonstrate that a low variance is 
at least as important, as a non-negligible variance introduces the potential 
for over-fitting in model selection as well as in training the model.  While 
this observation is in hindsight perhaps rather obvious, the degradation in 
performance due to over-fitting the model selection criterion can be 
surprisingly large, an observation that appears to have received little 
attention in the machine learning literature to date.  In this paper, we show 
that the effects of this form of over-fitting are often of comparable 
magnitude to differences in performance between learning algorithms, and thus 
cannot be ignored in empirical evaluation.  Furthermore, we show that some 
common performance evaluation practices are susceptible to a form of selection 
bias as a result of this form of over-fitting and hence are unreliable.  We 
discuss methods to avoid over-fitting in model selection and subsequent 
selection bias in performance evaluation, which we hope will be incorporated 
into best practice.  While this study concentrates on cross-validation based 
model selection, the findings are quite general and apply to any model 
selection practice involving the optimisation of a model selection criterion 
evaluated over a finite sample of data, including maximisation of the Bayesian 
evidence and optimisation of performance bounds.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf</url></Article><Article><id>717</id><title> Model-based Boosting 2.0</title><author>Torsten Hothorn, Peter B&amp;#252;hlmann, Thomas Kneib, Matthias Schmid, Benjamin Hofner</author><abstract>

We describe version 2.0 of the R add-on package &lt;i&gt;mboost&lt;/i&gt;.
The package implements boosting for optimizing general risk functions using
component-wise (penalized) least squares estimates or regression
trees as base-learners for fitting generalized linear, additive
and interaction models to potentially high-dimensional data.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/hothorn10a/hothorn10a.pdf</url></Article><Article><id>718</id><title> Importance Sampling for Continuous Time Bayesian Networks</title><author>Yu Fan, Jing Xu, Christian R. Shelton</author><abstract>

A continuous time Bayesian network (CTBN) uses a structured representation
to describe a dynamic system with a finite number of states which evolves
in continuous time.  Exact inference in a CTBN is often intractable
as the state space of the dynamic system grows exponentially with the
number of variables. In this paper, we first present an approximate
inference algorithm based on importance sampling. We then extend it to
continuous-time particle filtering and smoothing algorithms. These three
algorithms can estimate the expectation of any function of a trajectory,
conditioned on any evidence set constraining the values of subsets of the
variables over subsets of the time line. We present experimental results
on both synthetic networks and a network learned from a real data set on
people's life history events. We show the accuracy as well as the time
efficiency of our algorithms, and compare them to other approximate
algorithms: expectation propagation and Gibbs sampling.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/fan10a/fan10a.pdf</url></Article><Article><id>719</id><title> Matched Gene Selection and Committee Classifier for Molecular Classification of Heterogeneous Diseases</title><author>Guoqiang Yu, Yuanjian Feng, David J. Miller, Jianhua Xuan, Eric P. Hoffman, Robert Clarke, Ben Davidson, Ie-Ming Shih, Yue Wang</author><abstract>

Microarray gene expressions provide new opportunities for molecular classification of heterogeneous diseases. Although various reported classification schemes show impressive performance, most existing gene selection methods are suboptimal and are not well-matched to the unique characteristics of the multicategory classification problem. Matched design of the gene selection method and a committee classifier is needed for identifying a small set of gene markers that achieve accurate multicategory classification while being both statistically reproducible and biologically plausible. We report a simpler and yet more accurate strategy than previous works for multicategory classification of heterogeneous diseases. Our method selects the union of one-versus-everyone (OVE) &lt;i&gt;phenotypic up-regulated&lt;/i&gt; genes (PUGs) and matches this gene selection with a one-versus-rest support vector machine (OVRSVM). Our approach provides even-handed gene resources for discriminating both neighboring and well-separated classes. Consistent with the OVRSVM structure, we evaluated the fold changes of OVE gene expressions and found that only a small number of high-ranked genes were required to achieve superior accuracy for multicategory classification. We tested the proposed PUG-OVRSVM method on six real microarray gene expression data sets (five public benchmarks and one in-house data set) and two simulation data sets, observing significantly improved performance with lower error rates, fewer marker genes, and higher performance sustainability, as compared to several widely-adopted gene selection and classification methods. The MATLAB toolbox, experiment data and supplement files are available at http://www.cbil.ece.vt.edu/software.htm.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yu10b/yu10b.pdf</url></Article><Article><id>720</id><title> libDAI: A Free and Open Source C++ Library for Discrete Approximate Inference in Graphical Models</title><author>Joris M. Mooij</author><abstract>

This paper describes the software package libDAI, a free &amp; open source
C++ library that provides implementations of various exact and approximate
inference methods for graphical models with discrete-valued variables. libDAI
supports directed graphical models (Bayesian networks) as well as undirected
ones (Markov random fields and factor graphs). It offers various
approximations of the partition sum, marginal probability distributions and
maximum probability states. Parameter learning is also supported. A
feature comparison with other open source software packages for approximate
inference is given. libDAI is licensed under the GPL v2+ license and is
available at http://www.libdai.org.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mooij10a/mooij10a.pdf</url></Article><Article><id>721</id><title> Learning Gradients: Predictive Models that Infer Geometry and Statistical Dependence</title><author>Qiang Wu, Justin Guinney, Mauro Maggioni, Sayan Mukherjee</author><abstract>

The problems of dimension reduction and inference of statistical
dependence are addressed by the modeling framework of learning
gradients. The models we propose hold for Euclidean spaces as well
as the manifold setting. The central quantity in this approach is an
estimate of the gradient of the regression or classification
function. Two quadratic forms are constructed from gradient
estimates: the gradient outer product and gradient based diffusion
maps. The first quantity can be used for supervised dimension
reduction on manifolds as well as inference of a graphical model
encoding dependencies that are predictive of a response variable.
The second quantity can be used for nonlinear projections that
incorporate both the geometric structure of the manifold as well as
variation of the response variable on the manifold. We relate the
gradient outer product to standard statistical quantities such as
covariances and provide a simple and precise comparison of a variety
of supervised dimensionality reduction methods. We provide rates of
convergence for both inference of informative directions as well as
inference of a graphical model of variable dependencies.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/wu10a/wu10a.pdf</url></Article><Article><id>722</id><title> Regularized Discriminant Analysis, Ridge Regression and Beyond</title><author>Zhihua Zhang, Guang Dai, Congfu Xu, Michael I. Jordan</author><abstract>

Fisher linear discriminant analysis (FDA) and its kernel
extension&amp;minus;kernel discriminant analysis (KDA)&amp;minus;are well known
methods that consider dimensionality reduction and classification
jointly.  While widely deployed in practical problems, there are
still unresolved issues surrounding their efficient implementation
and their relationship with least mean squares procedures.  In
this paper we address these issues within the framework of
regularized estimation. Our approach leads to a flexible and
efficient implementation of FDA as well as KDA.  We also uncover a
general relationship between regularized discriminant analysis and
ridge regression. This relationship yields variations on
conventional FDA based on the pseudoinverse and a direct equivalence
to an ordinary least squares estimator.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/zhang10b/zhang10b.pdf</url></Article><Article><id>723</id><title> Erratum: SGDQN is Less Careful than Expected</title><author>Antoine Bordes, L&amp;#233;on Bottou, Patrick Gallinari, Jonathan Chang, S. Alex Smith</author><abstract>

The SGD-QN algorithm described in Bordes et al. (2009)
contains a subtle flaw that prevents it from reaching its design goals.
Yet the flawed SGD-QN algorithm has worked well enough to be a winner of the first
Pascal Large Scale Learning Challenge (Sonnenburg et al., 2008).
This document clarifies the situation, proposes a corrected algorithm,
and evaluates its performance.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/bordes10a/bordes10a.pdf</url></Article><Article><id>724</id><title> Restricted Eigenvalue Properties for Correlated Gaussian Designs</title><author>Garvesh Raskutti, Martin J. Wainwright, Bin Yu</author><abstract>

Methods based on &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-relaxation, such as basis pursuit and the
Lasso, are very popular for sparse regression in high dimensions.  The
conditions for success of these methods are now well-understood: (1)
exact recovery in the noiseless setting is possible if and only if the
design matrix &lt;i&gt;X&lt;/i&gt; satisfies the restricted nullspace property, and (2)
the squared &lt;i&gt;l&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;-error of a Lasso estimate decays at the minimax
optimal rate &lt;i&gt;k log p / n&lt;/i&gt;, where &lt;i&gt;k&lt;/i&gt; is the
sparsity of the &lt;i&gt;p&lt;/i&gt;-dimensional regression problem with additive
Gaussian noise, whenever the design satisfies a restricted eigenvalue
condition.  The key issue is thus to determine when the design matrix
&lt;i&gt;X&lt;/i&gt; satisfies these desirable properties. Thus far, there have been
numerous results showing that the restricted isometry property, which
implies both the restricted nullspace and eigenvalue conditions, is
satisfied when all entries of &lt;i&gt;X&lt;/i&gt; are independent and identically
distributed (i.i.d.), or the rows are unitary. This paper proves
directly that the restricted nullspace and eigenvalue conditions hold
with high probability for quite general classes of Gaussian matrices
for which the predictors may be highly dependent, and hence restricted
isometry conditions can be violated with high probability. In this
way, our results extend the attractive theoretical guarantees on
&lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-relaxations to a much broader class of problems than the case
of completely independent or unitary designs.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/raskutti10a/raskutti10a.pdf</url></Article><Article><id>725</id><title> High Dimensional Inverse Covariance Matrix Estimation via Linear Programming</title><author>Ming Yuan</author><abstract>

This paper considers the problem of estimating a high dimensional inverse covariance matrix that can be well approximated by "sparse" matrices. Taking advantage of the connection between multivariate linear regression and entries of the inverse covariance matrix, we propose an estimating procedure that can effectively exploit such "sparsity".  The proposed method can be computed using linear programming and therefore has the potential to be used in very high dimensional problems. Oracle inequalities are established for the estimation error in terms of several operator norms, showing that the method is adaptive to different types of sparsity of the problem.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yuan10b/yuan10b.pdf</url></Article><Article><id>726</id><title> Spectral Regularization Algorithms for Learning Large Incomplete Matrices</title><author>Rahul Mazumder, Trevor Hastie, Robert Tibshirani</author><abstract>

  We use convex relaxation techniques to provide a sequence of
regularized low-rank solutions for large-scale matrix completion
problems. Using the nuclear norm as a regularizer, we provide a
simple and very efficient convex algorithm for minimizing the
reconstruction error subject to a bound on the nuclear norm. Our
algorithm SOFT-IMPUTE iteratively replaces the missing
elements with those obtained from a soft-thresholded SVD. With warm
starts this allows us to efficiently compute an entire
regularization path of solutions on a grid of values of the
regularization parameter. The computationally intensive part of our
algorithm is in computing a low-rank SVD of a dense matrix.
Exploiting the problem structure, we show that the task can be
performed with a complexity of order linear in the matrix dimensions.  Our
semidefinite-programming algorithm is readily scalable to large
matrices; for example SOFT-IMPUTE takes a few hours to compute low-rank approximations
of a &lt;i&gt;10&lt;sup&gt;6&lt;/sup&gt;&lt;/i&gt; X &lt;i&gt;10&lt;sup&gt;6&lt;/sup&gt;&lt;/i&gt; incomplete matrix with &lt;i&gt;10&lt;sup&gt;7&lt;/sup&gt;&lt;/i&gt; observed entries, and fits a rank-&lt;i&gt;95&lt;/i&gt; approximation to the
full Netflix training set in &lt;i&gt;3.3&lt;/i&gt; hours.
Our methods achieve good training and test errors and exhibit superior timings when compared to other competitive state-of-the-art
techniques.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/mazumder10a/mazumder10a.pdf</url></Article><Article><id>727</id><title> Efficient Heuristics for Discriminative Structure Learning of Bayesian Network Classifiers</title><author>Franz Pernkopf, Jeff A. Bilmes</author><abstract>

We introduce a simple order-based greedy heuristic for learning
discriminative structure within generative Bayesian network
classifiers.  We propose two methods for establishing an order of &lt;i&gt;N&lt;/i&gt;
features. They are based on the conditional mutual information and
classification rate (i.e., risk), respectively. Given an ordering, we
can find a discriminative structure with
&lt;i&gt;O(N&lt;sup&gt;k+1&lt;/sup&gt;)&lt;/i&gt; score evaluations (where constant &lt;i&gt;k&lt;/i&gt;
is the tree-width of the sub-graph over the attributes).  We present results on 25
data sets from the UCI repository, for phonetic classification using
the TIMIT database, for a visual surface inspection task, and for two
handwritten digit recognition tasks. We provide classification
performance for &lt;i&gt;both&lt;/i&gt; discriminative &lt;i&gt;and&lt;/i&gt;
generative parameter learning on &lt;i&gt;both&lt;/i&gt; discriminatively
&lt;i&gt;and&lt;/i&gt; generatively structured networks. The discriminative
structure found by our new procedures significantly outperforms
generatively produced structures, and achieves a classification
accuracy on par with the best discriminative (greedy) Bayesian
network learning approach, but does so with a factor of ~10-40
speedup. We also show that the advantages of generative
discriminatively structured Bayesian network classifiers still hold in
the case of missing features, a case where generative classifiers have
an advantage over discriminative classifiers.



</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/pernkopf10a/pernkopf10a.pdf</url></Article><Article><id>728</id><title> High-dimensional Variable Selection with Sparse Random Projections: Measurement Sparsity and Statistical Efficiency</title><author>Dapo Omidiran, Martin J. Wainwright</author><abstract>

We consider the problem of high-dimensional variable selection: given
&lt;i&gt;n&lt;/i&gt; noisy observations of a &lt;i&gt;k&lt;/i&gt;-sparse vector &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt; &amp;#8712; R&lt;sup&gt;p&lt;/sup&gt;&lt;/i&gt;,
estimate the subset of non-zero entries of &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt;.
A significant body of work has studied behavior of
&lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-relaxations when applied to random measurement matrices that
are dense (e.g., Gaussian, Bernoulli).  In this paper, we analyze
&lt;i&gt;sparsified&lt;/i&gt; measurement ensembles, and consider the trade-off
between measurement sparsity, as measured by the fraction &lt;i&gt;&amp;#947;&lt;/i&gt; of
non-zero entries, and the statistical efficiency, as measured by the
minimal number of observations &lt;i&gt;n&lt;/i&gt; required for correct variable
selection with probability converging to one.  Our main result is to
prove that it is possible to let the fraction on non-zero entries
&lt;i&gt;&amp;#947; &amp;#8594; 0&lt;/i&gt; at some rate, yielding measurement matrices
with a vanishing fraction of non-zeros per row, while retaining the
same statistical efficiency as dense ensembles.  A variety of
simulation results confirm the sharpness of our theoretical
predictions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/omidiran10a/omidiran10a.pdf</url></Article><Article><id>729</id><title> Composite Binary Losses</title><author>Mark D. Reid, Robert C. Williamson</author><abstract>

We study losses for binary classification and class probability estimation
and extend the understanding of them from margin losses to general
composite losses which are the composition of a proper loss with a link
function.  We characterise when margin losses can be proper composite
losses, explicitly show how to determine a symmetric loss in full from half
of one of its partial losses, introduce an intrinsic parametrisation of
composite binary losses and give a complete characterisation of the
relationship between proper losses and "classification calibrated"
losses. We also consider the question of the "best" surrogate binary
loss. We introduce a precise notion of "best" and show there exist
situations where two convex surrogate losses are incommensurable. We
provide a complete explicit characterisation of the convexity of composite
binary losses in terms of the link function and the weight function
associated with the proper loss which make up the composite loss. This
characterisation suggests new ways of "surrogate tuning" as well as
providing an explicit characterisation of when Bregman divergences on the
unit interval are convex in their second argument. Finally, in an
appendix we present some new algorithm-independent results on the
relationship between properness,  convexity and robustness to
misclassification noise for binary losses and show that all convex proper
losses are non-robust to misclassification noise.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/reid10a/reid10a.pdf</url></Article><Article><id>730</id><title> Sparse Semi-supervised Learning Using Conjugate Functions</title><author>Shiliang Sun, John Shawe-Taylor</author><abstract>

In this paper, we propose a general framework for sparse
semi-supervised learning, which concerns using a small portion of
unlabeled data and a few labeled data to represent target functions
and thus has the merit of accelerating function evaluations when
predicting the output of a new example. This framework makes use of
Fenchel-Legendre conjugates to rewrite a convex insensitive loss
involving a regularization with unlabeled data, and is applicable to
a family of semi-supervised learning methods such as multi-view
co-regularized least squares and single-view Laplacian support
vector machines (SVMs). As an instantiation of this framework, we
propose sparse multi-view SVMs which use a squared
&amp;#949;-insensitive loss. The resultant optimization is an
inf-sup problem and the optimal solutions have arguably
saddle-point properties. We present a globally optimal iterative
algorithm to optimize the problem. We give the margin bound on the
generalization error of the sparse multi-view SVMs, and derive the
empirical Rademacher complexity for the induced function class.
Experiments on artificial and real-world data show their
effectiveness. We further give a sequential training approach to
show their possibility and potential for uses in large-scale
problems and provide encouraging experimental results indicating the
efficacy of the margin bound and empirical Rademacher complexity on
characterizing the roles of unlabeled data for semi-supervised
learning.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/sun10a/sun10a.pdf</url></Article><Article><id>731</id><title> Rademacher Complexities and Bounding the Excess Risk in Active Learning</title><author>Vladimir Koltchinskii</author><abstract>

Sequential algorithms of active learning based on the estimation of the
level sets of the empirical risk are discussed in the paper. Localized
Rademacher complexities are used in the algorithms to estimate
the sample sizes
needed to achieve the required accuracy of learning in an adaptive way.
Probabilistic
bounds on the number of active examples have been proved and several
applications to binary classification problems are considered.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/koltchinskii10a/koltchinskii10a.pdf</url></Article><Article><id>732</id><title> Hubs in Space: Popular Nearest Neighbors in High-Dimensional Data</title><author>Milo&amp;#353; Radovanovi&amp;#263;, Alexandros Nanopoulos, Mirjana Ivanovi&amp;#263;</author><abstract>

Different aspects of the curse of dimensionality are known to present serious
challenges to various machine-learning methods and tasks. This paper explores
a new aspect of the dimensionality curse, referred to as &lt;i&gt;hubness&lt;/i&gt;, that
affects the distribution of &lt;i&gt;k&lt;/i&gt;-occurrences: the number of times a point
appears among the &lt;i&gt;k&lt;/i&gt; nearest neighbors of other points in a data set. Through
theoretical and empirical analysis involving synthetic and real data sets
we show that under commonly used assumptions this distribution becomes
considerably skewed as dimensionality increases, causing the emergence of
&lt;i&gt;hubs&lt;/i&gt;, that is, points with very high &lt;i&gt;k&lt;/i&gt;-occurrences which
effectively represent "popular" nearest neighbors. We examine the origins of
this phenomenon, showing that it is an inherent property of data distributions
in high-dimensional vector space, discuss its interaction with dimensionality
reduction, and explore its influence on a wide range of machine-learning tasks
directly or indirectly based on measuring distances, belonging to supervised,
semi-supervised, and unsupervised learning families.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/radovanovic10a/radovanovic10a.pdf</url></Article><Article><id>733</id><title> WEKA&amp;minus;Experiences with a Java Open-Source Project</title><author>Remco R. Bouckaert, Eibe Frank, Mark A. Hall, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, Ian H. Witten</author><abstract>

WEKA is a popular machine learning workbench with a development life
of nearly two decades.  This article provides an overview of the factors
that we believe to be important to its success. Rather than focussing on the software's functionality, we review aspects of
project management and historical development decisions that likely
had an impact on the uptake of the project.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/bouckaert10a/bouckaert10a.pdf</url></Article><Article><id>734</id><title> Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization</title><author>Lin Xiao</author><abstract>

We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-norm for promoting sparsity.  We develop extensions of Nesterov's dual averaging method, that can exploit the regularization structure in an online setting.  At each iteration of these methods, the learning variables are adjusted by solving a simple minimization problem that involves the running average of all past subgradients of the loss function and the whole regularization term, not just its subgradient.  In the case of &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-regularization, our method is particularly effective in obtaining sparse solutions.  We show that these methods achieve the optimal convergence rates or regret bounds that are standard in the literature on stochastic and online convex optimization.  For stochastic learning problems in which the loss functions have Lipschitz continuous gradients, we also present an accelerated version of the dual averaging method.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/xiao10a/xiao10a.pdf</url></Article><Article><id>735</id><title> Stochastic Composite Likelihood</title><author>Joshua V. Dillon, Guy Lebanon</author><abstract>

Maximum likelihood estimators are often of limited practical use due to the intensive computation they require. We propose a family of alternative estimators that maximize a stochastic variation of the composite likelihood function. Each of the estimators resolve the computation-accuracy tradeoff differently, and taken together they span a continuous spectrum of computation-accuracy tradeoff resolutions. We prove the consistency of the estimators, provide formulas for their asymptotic variance, statistical robustness, and computational complexity. We discuss experimental results in the context of Boltzmann machines and conditional random fields. The theoretical and experimental studies demonstrate the effectiveness of the estimators when the computational resources are insufficient. They also demonstrate that in some cases reduced computational complexity is associated with robustness thereby increasing statistical accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/dillon10a/dillon10a.pdf</url></Article><Article><id>736</id><title> Learnability, Stability and Uniform Convergence</title><author>Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, Karthik Sridharan</author><abstract>

The problem of characterizing learnability is the most basic question of statistical learning theory. A fundamental and long-standing answer, at least for the case of supervised classification and regression, is that learnability is equivalent to uniform convergence of the empirical risk to the population risk, and that if a problem is learnable, it is learnable via empirical risk minimization.  In this paper, we consider the General Learning Setting (introduced by Vapnik), which includes most statistical learning problems as special cases.  We show that in this setting, there are non-trivial learning problems where uniform convergence does not hold, empirical risk minimization fails, and yet they are learnable using alternative mechanisms. Instead of uniform convergence, we identify stability as the key necessary and sufficient condition for learnability. Moreover, we show that the conditions for learnability in the general setting are significantly more complex than in supervised classification and regression.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/shalev-shwartz10a/shalev-shwartz10a.pdf</url></Article><Article><id>737</id><title> Topology Selection in Graphical Models of Autoregressive Processes</title><author>Jitkomut Songsiri, Lieven Vandenberghe</author><abstract>

An algorithm is presented for topology selection in graphical models of autoregressive Gaussian time series.  The graph topology of the model represents the sparsity pattern of the inverse spectrum of the time series and characterizes conditional independence relations between the variables.  The method proposed in the paper is based on an &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-type nonsmooth regularization of the conditional maximum likelihood estimation problem.   We show that this reduces to a convex optimization problem and describe a large-scale algorithm that solves the dual problem via the gradient projection method.  Results of experiments with randomly generated and real data sets are also included.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/songsiri10a/songsiri10a.pdf</url></Article><Article><id>738</id><title> Using Contextual Representations to Efficiently Learn Context-Free Languages</title><author>Alexander Clark, R&amp;#233;mi Eyraud, Amaury Habrard</author><abstract>

We present a polynomial update time algorithm for the inductive inference of a large class of context-free languages  using the paradigm of positive data and a membership oracle.  We achieve this result by moving to a novel representation, called Contextual Binary Feature Grammars (CBFGs),  which are capable of representing richly structured context-free languages as well as some context sensitive languages.  These representations explicitly model the lattice structure of the &lt;i&gt;distribution&lt;/i&gt; of a set of substrings and can be inferred using a generalisation of distributional learning.  This formalism is an attempt to bridge the gap between simple learnable classes and the sorts of highly  expressive  representations necessary for linguistic representation: it allows the learnability of a large class of context-free languages, that includes all regular languages and those context-free languages that satisfy two simple constraints.  The formalism and the algorithm seem well suited to natural language and in particular to the modeling of first language acquisition. Preliminary experimental results confirm the effectiveness of this approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/clark10a/clark10a.pdf</url></Article><Article><id>739</id><title> Mean Field Variational Approximation for Continuous-Time Bayesian Networks</title><author>Ido Cohn, Tal El-Hay, Nir Friedman, Raz Kupferman</author><abstract>

&lt;i&gt;Continuous-time Bayesian networks&lt;/i&gt; is a natural structured representation language for multi-component stochastic processes that evolve continuously over time.  Despite the compact representation provided by this language, inference in such models is intractable even in relatively simple structured networks. We introduce a mean field variational approximation in which we use a product of &lt;i&gt;inhomogeneous&lt;/i&gt; Markov processes to approximate a joint distribution over trajectories.  This variational approach leads to a globally consistent distribution, which  can be efficiently queried.  Additionally, it provides a lower bound on the probability of observations, thus making it attractive for learning tasks.  Here we describe the theoretical foundations for the approximation, an efficient implementation that exploits the wide range of highly optimized ordinary differential equations (ODE) solvers, experimentally explore characterizations of processes for which this approximation is suitable, and show applications to a large-scale real-world inference problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/cohn10a/cohn10a.pdf</url></Article><Article><id>740</id><title> Regret Bounds and Minimax Policies under Partial Monitoring</title><author>Jean-Yves Audibert, S&amp;#233;bastien Bubeck</author><abstract>

This work deals with four classical prediction settings, namely full information, bandit, label efficient and bandit label efficient as well as four different notions of regret: pseudo-regret, expected regret, high probability regret and tracking the best expert regret. We introduce a new forecaster, INF (Implicitly Normalized Forecaster) based on an arbitrary function &amp;#968; for which we propose a unified analysis of its pseudo-regret in the four games we consider. In particular, for &lt;i&gt;&amp;#968;(x)&lt;/i&gt;=exp&lt;i&gt;(&amp;#951; x) + &amp;#947;/K&lt;/i&gt;, INF reduces to the classical exponentially weighted average forecaster and our analysis of the pseudo-regret recovers known results while for the expected regret we slightly tighten the bounds. On the other hand with &lt;i&gt;&amp;#968;(x)=(&amp;#951;/-x)&lt;sup&gt;q&lt;/sup&gt; + &amp;#947;/K&lt;/i&gt;, which defines a new forecaster, we are able to remove the extraneous logarithmic factor in the pseudo-regret bounds for bandits games, and thus fill in a long open gap in the characterization of the minimax rate for the pseudo-regret in the bandit game. We also provide high probability bounds depending on the cumulative reward of the optimal action.  
&lt;br&gt;
Finally, we consider the stochastic bandit game, and prove that an appropriate modification of the upper confidence bound policy UCB1 (Auer et al., 2002a) achieves the distribution-free optimal rate while still having a distribution-dependent rate logarithmic in the number of plays.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/audibert10a/audibert10a.pdf</url></Article><Article><id>741</id><title> Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance</title><author>Nguyen Xuan Vinh, Julien Epps, James Bailey</author><abstract>

Information theoretic  measures form a fundamental class of measures for comparing clusterings, and have recently received increasing interest. Nevertheless, a number of questions concerning their properties and inter-relationships remain unresolved. In this paper, we perform an organized study of information theoretic measures for clustering comparison, including several existing popular measures in the literature, as well as some newly proposed ones. We discuss and prove their important properties, such as the metric property and the normalization property. We then highlight to the clustering community the importance of correcting information theoretic measures for chance, especially when the data size is small compared to the number of clusters present therein. Of the available information theoretic based measures, we advocate the normalized information distance (NID) as a general measure of choice, for it possesses concurrently several important properties, such as being both a metric and a normalized measure, admitting an exact analytical adjusted-for-chance form, and using the nominal [0,1] range better than other normalized variants.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/vinh10a/vinh10a.pdf</url></Article><Article><id>742</id><title> Expectation Truncation and the Benefits of Preselection In Training Generative Models</title><author>J&amp;#246;rg L&amp;#252;cke, Julian Eggert</author><abstract>

We show how a preselection of hidden variables can be used to efficiently train generative models with binary hidden variables.  The approach is based on Expectation Maximization (EM) and uses an efficiently computable approximation to the sufficient statistics of a given model.  The computational cost to compute the sufficient statistics is strongly reduced by selecting, for each data point, the relevant hidden causes.  The approximation is applicable to a wide range of generative models and provides an interpretation of the benefits of preselection in terms of a variational EM approximation. To empirically show that the method maximizes the data likelihood, it is applied to different types of generative models including: a version of non-negative matrix factorization (NMF), a model for non-linear component extraction (MCA), and a linear generative model similar to sparse coding.  The derived algorithms are applied to both artificial and realistic data, and are compared to other models in the literature.  We find that the training scheme can reduce computational costs by orders of magnitude and allows for a reliable extraction of hidden causes.  


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/lucke10a/lucke10a.pdf</url></Article><Article><id>743</id><title> Linear Algorithms for Online Multitask Classification</title><author>Giovanni Cavallanti, Nicol&amp;#242; Cesa-Bianchi, Claudio Gentile</author><abstract>

We introduce new Perceptron-based algorithms for the online multitask binary classification problem. Under suitable regularity conditions, our algorithms are shown to improve on their baselines by a factor proportional to the number of tasks.  We achieve these improvements using various types of regularization that bias our algorithms towards specific notions of task relatedness. More specifically, similarity among tasks is either measured in terms of the geometric closeness of the task reference vectors or as a function of the dimension of their spanned subspace.  In addition to adapting to the online setting a mix of known techniques, such as the multitask kernels of Evgeniou &lt;i&gt;et al.&lt;/i&gt;, our analysis also introduces a matrix-based multitask extension of the &lt;i&gt;p&lt;/i&gt;-norm Perceptron, which is used to implement spectral co-regularization.  Experiments on real-world data sets complement and support our theoretical findings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/cavallanti10a/cavallanti10a.pdf</url></Article><Article><id>744</id><title> Tree Decomposition for Large-Scale SVM Problems</title><author>Fu Chang, Chien-Yang Guo, Xiao-Rong Lin, Chi-Jen Lu</author><abstract>

To handle problems created by large data sets, we propose a method that uses a decision tree to decompose a given data space and train SVMs on the decomposed regions. Although there are other means of decomposing a data space, we show that the decision tree has several merits for large-scale SVM training. First, it can classify some data points by its own means, thereby reducing the cost of SVM training for the remaining data points. Second, it is efficient in determining the parameter values that maximize the validation accuracy, which helps maintain good test accuracy. Third, the tree decomposition method can derive a generalization error bound for the classifier. For data sets whose size can be handled by current non-linear, or kernel-based, SVM training techniques, the proposed method can speed up the training by a factor of thousands, and still achieve comparable test accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/chang10b/chang10b.pdf</url></Article><Article><id>745</id><title> Semi-Supervised Novelty Detection </title><author>Gilles Blanchard, Gyemin Lee, Clayton Scott</author><abstract>

A common setting for novelty detection assumes that labeled examples from the nominal class are available, but that labeled examples of novelties are unavailable. The standard (inductive) approach is to declare novelties where the nominal density is low, which reduces the problem to density level set estimation. In this paper, we consider the setting where an unlabeled and possibly contaminated sample is also available at learning time. We argue that novelty detection in this semi-supervised setting is naturally solved by a general reduction to a binary classification problem. In particular, a detector with a desired false positive rate can be achieved through a reduction to Neyman-Pearson classification. Unlike the inductive approach, semi-supervised novelty detection (SSND) yields detectors that are optimal (e.g., statistically consistent) regardless of the distribution on novelties. Therefore, in novelty detection, unlabeled data have a substantial impact on the theoretical properties of the decision rule. We validate the practical utility of SSND with an extensive experimental study.
&lt;br&gt;
We also show that SSND provides distribution-free, learning-theoretic solutions to two well known problems in hypothesis testing. First, our results provide a general solution to the general two-sample problem, that is, the problem of determining whether two random samples arise from the same distribution. Second, a specialization of SSND coincides with the standard &lt;i&gt;p&lt;/i&gt;-value approach to multiple testing under the so-called random effects model. Unlike standard rejection regions based on thresholded &lt;i&gt;p&lt;/i&gt;-values, the general SSND framework allows for adaptation to arbitrary alternative distributions in multiple dimensions.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/blanchard10a/blanchard10a.pdf</url></Article><Article><id>746</id><title> Gaussian Processes for Machine Learning (GPML) Toolbox </title><author>Carl Edward Rasmussen, Hannes Nickisch</author><abstract>

The GPML toolbox provides a wide range of functionality for Gaussian process (GP) inference and prediction. GPs are specified by mean and covariance functions; we offer a library of simple mean and covariance functions and mechanisms to compose more complex ones. Several likelihood functions are supported including Gaussian and heavy-tailed for regression as well as others suitable for classification.  Finally, a range of inference methods is provided, including exact and variational inference, Expectation Propagation, and Laplace's method dealing with non-Gaussian likelihoods and FITC for dealing with large regression tasks. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/rasmussen10a/rasmussen10a.pdf</url></Article><Article><id>747</id><title> Covariance in Unsupervised Learning of Probabilistic Grammars </title><author>Shay B. Cohen, Noah A. Smith</author><abstract>

Probabilistic grammars offer great flexibility in modeling discrete sequential data like natural language text.  Their symbolic component is amenable to inspection by humans, while their probabilistic component helps resolve ambiguity. They also permit the use of well-understood, general-purpose learning algorithms. There has been an increased interest in using probabilistic grammars in the Bayesian setting.  To date, most of the literature has focused on using a Dirichlet prior.  The Dirichlet prior has several limitations, including that it cannot directly model covariance between the probabilistic grammar's parameters. Yet, various grammar parameters are expected to be correlated because the elements in language they represent share linguistic properties.  In this paper, we suggest an alternative to the Dirichlet prior, a family of logistic normal distributions.  We derive an inference algorithm for this family of distributions and experiment with the task of dependency grammar induction, demonstrating  performance improvements with our priors on a set of six treebanks in different natural languages.  Our covariance framework permits soft parameter tying within grammars and &lt;i&gt;across&lt;/i&gt; grammars for text in different languages, and we show empirical gains in a novel learning setting using bilingual, non-parallel data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/cohen10a/cohen10a.pdf</url></Article><Article><id>748</id><title> Inducing Tree-Substitution Grammars </title><author>Trevor Cohn, Phil Blunsom, Sharon Goldwater</author><abstract>

Inducing a grammar from text has proven to be a notoriously challenging learning task despite decades of research.  The primary reason for its difficulty is that in order to induce plausible grammars, the underlying model must be capable of representing the intricacies of language while also ensuring that it can be readily learned from data.  The majority of existing work on grammar induction has favoured model simplicity (and thus learnability) over representational capacity by using context free grammars and first order dependency grammars, which are not sufficiently expressive to model many common linguistic constructions.  We propose a novel compromise by inferring a probabilistic &lt;i&gt;tree substitution grammar&lt;/i&gt;, a formalism which allows for arbitrarily large tree fragments and thereby better represent complex linguistic structures.  To limit the model's complexity we employ a Bayesian non-parametric prior which biases the model towards a sparse grammar with shallow productions.  We demonstrate the model's efficacy on supervised phrase-structure parsing, where we induce a latent segmentation of the training treebank, and on unsupervised dependency grammar induction.  In both cases the model uncovers interesting latent linguistic structures while producing competitive results.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/cohn10b/cohn10b.pdf</url></Article><Article><id>749</id><title> Collective Inference for  Extraction MRFs Coupled with Symmetric Clique Potentials </title><author>Rahul Gupta, Sunita Sarawagi, Ajit A. Diwan</author><abstract>

Many structured information extraction tasks employ collective graphical models that capture inter-instance associativity by coupling them with various clique potentials.  We propose tractable families of such potentials that are invariant under permutations of their arguments, and call them &lt;i&gt;symmetric clique potentials&lt;/i&gt;.  We present three families of symmetric potentials&amp;minus;MAX, SUM, and MAJORITY.
&lt;br&gt;
We propose cluster message passing for collective inference with symmetric clique potentials, and present message computation algorithms tailored to such potentials.  Our first message computation algorithm, called &amp;#945;-pass, is sub-quadratic in the clique size, outputs exact messages for MAX, and computes 13/15-approximate messages for Potts, a popular member of the SUM family.  Empirically, it is upto two orders of magnitude faster than existing algorithms based on graph-cuts or belief propagation.  Our second algorithm, based on Lagrangian relaxation, operates on MAJORITY potentials and provides close to exact solutions while being two orders of magnitude faster. We show that the cluster message passing framework is more principled, accurate and converges faster than competing approaches.
&lt;br&gt;
We extend our collective inference framework to exploit associativity of more general &lt;i&gt;intra-domain properties&lt;/i&gt; of instance labelings, which opens up interesting applications in domain adaptation.  Our approach leads to significant error reduction on unseen domains without incurring any overhead of model retraining.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/gupta10a/gupta10a.pdf</url></Article><Article><id>750</id><title> A Generalized Path Integral Control Approach to Reinforcement Learning </title><author>Evangelos Theodorou, Jonas Buchli, Stefan Schaal</author><abstract>

With the goal to generate more scalable algorithms with higher efficiency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests to use the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parameterized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-Jacobi-Bellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open algorithmic parameters other than the exploration noise. The resulting algorithm can be conceived of as model-based, semi-model-based, or even model free, depending on how the learning problem is structured.  The update equations have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required.  Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a simulated 12 degree-of-freedom robot dog illustrates the functionality of our algorithm in a complex robot learning scenario. We believe that &lt;b&gt;P&lt;/b&gt;olicy &lt;b&gt;I&lt;/b&gt;mprovement with &lt;b&gt;P&lt;/b&gt;ath &lt;b&gt;I&lt;/b&gt;ntegrals (&lt;b&gt;PI&lt;/b&gt;&lt;sup&gt;2&lt;/sup&gt;) offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/theodorou10a/theodorou10a.pdf</url></Article><Article><id>751</id><title> A Comparison of Optimization Methods and Software for Large-scale L1-regularized Linear Classification </title><author>Guo-Xun Yuan, Kai-Wei Chang, Cho-Jui Hsieh, Chih-Jen Lin</author><abstract>

Large-scale linear classification is widely used in many areas.  The L1-regularized form can be applied for feature selection; however, its non-differentiability causes more difficulties in training.  Although various optimization methods have been proposed in recent years, these have not yet been compared suitably.  In this paper, we first broadly review existing methods.  Then, we discuss state-of-the-art software packages in detail and propose two efficient implementations.  Extensive comparisons indicate that carefully implemented coordinate descent methods are very suitable for training large document data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/yuan10c/yuan10c.pdf</url></Article><Article><id>752</id><title> Approximate Riemannian Conjugate Gradient Learning for Fixed-Form Variational Bayes </title><author>Antti Honkela, Tapani Raiko, Mikael Kuusela, Matti Tornio, Juha Karhunen</author><abstract>

Variational Bayesian (VB) methods are typically only applied to models in the conjugate-exponential family using the variational Bayesian expectation maximisation (VB EM) algorithm or one of its variants.  In this paper we present an efficient algorithm for applying VB to more general models.  The method is based on specifying the functional form of the approximation, such as multivariate Gaussian.  The parameters of the approximation are optimised using a conjugate gradient algorithm that utilises the Riemannian geometry of the space of the approximations.  This leads to a very efficient algorithm for suitably structured approximations. It is shown empirically that the proposed method is comparable or superior in efficiency to the VB EM in a case where both are applicable. We also apply the algorithm to learning a nonlinear state-space model and a nonlinear factor analysis model for which the VB EM is not applicable. For these models, the proposed algorithm outperforms alternative gradient-based methods by a significant margin.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/honkela10a/honkela10a.pdf</url></Article><Article><id>753</id><title> Classification with Incomplete Data Using Dirichlet Process Priors</title><author>Chunping Wang, Xuejun Liao, Lawrence Carin, David B. Dunson</author><abstract>

A non-parametric hierarchical Bayesian framework is developed for designing a classifier, based on a mixture of simple (linear) classifiers. Each simple classifier is termed a local "expert", and the number of experts and their construction are manifested via a Dirichlet process formulation. The simple form of the "experts" allows analytical handling of incomplete data. The model is extended to allow simultaneous design of classifiers on multiple data sets, termed multi-task learning, with this also performed non-parametrically via the Dirichlet process. Fast inference is performed using variational Bayesian (VB) analysis, and example results are presented for several data sets. We also perform inference via Gibbs sampling, to which we compare the VB results.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/wang10a/wang10a.pdf</url></Article><Article><id>754</id><title> Maximum Likelihood in Cost-Sensitive Learning: Model Specification, Approximations, and Upper Bounds</title><author>Jacek P. Dmochowski, Paul Sajda, Lucas C. Parra</author><abstract>

The presence of asymmetry in the misclassification costs or class prevalences is a common occurrence in the pattern classification domain.  While much interest has been devoted to the study of &lt;i&gt;cost-sensitive learning&lt;/i&gt; techniques, the relationship between cost-sensitive learning and the specification of the model set in a parametric estimation framework remains somewhat unclear.  To that end, we differentiate between the case of the model including the true posterior, and that in which the model is misspecified.  In the former case, it is shown that thresholding the maximum likelihood (ML) estimate is an asymptotically optimal solution to the risk minimization problem.  On the other hand, under model misspecification, it is demonstrated that thresholded ML is suboptimal and that the risk-minimizing solution varies with the misclassification cost ratio.  Moreover, we analytically show that the negative weighted log likelihood (Elkan, 2001) is a tight, convex upper bound of the empirical loss.  Coupled with empirical results on several real-world data sets, we argue that weighted ML is the preferred cost-sensitive technique.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/dmochowski10a/dmochowski10a.pdf</url></Article><Article><id>755</id><title> Learning Instance-Specific Predictive Models</title><author>Shyam Visweswaran, Gregory F. Cooper</author><abstract>

This paper introduces a Bayesian algorithm for constructing predictive models from data that are optimized to predict a target variable well for a particular instance. This algorithm learns Markov blanket models, carries out Bayesian model averaging over a set of models to predict a target variable of the instance at hand, and employs an instance-specific heuristic to locate a set of suitable models to average over. We call this method the instance-specific Markov blanket (ISMB) algorithm. The ISMB algorithm was evaluated on 21 UCI data sets using five different performance measures and its performance was compared to that of several commonly used predictive algorithms, including naive Bayes, C4.5 decision tree, logistic regression, neural networks, &lt;i&gt;k&lt;/i&gt;-Nearest Neighbor, Lazy Bayesian Rules, and AdaBoost. Over all the data sets, the ISMB algorithm performed better on average on all performance measures against all the comparison algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/visweswaran10a/visweswaran10a.pdf</url></Article><Article><id>756</id><title> Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</title><author>Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine Manzagol</author><abstract>

We explore an original strategy for building deep networks, based on stacking layers of &lt;i&gt;denoising autoencoders&lt;/i&gt; which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf</url></Article><Article><id>757</id><title> &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-Nested Symmetric Distributions</title><author>Fabian Sinz, Matthias Bethge</author><abstract>

In this paper, we introduce a new family of probability densities called &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric distributions. The common property, shared by all members of the new class, is the same functional form &lt;i&gt;&amp;#961;(&lt;b&gt;x&lt;/b&gt;) = ~&amp;#961;(f(&lt;b&gt;x&lt;/b&gt;))&lt;/i&gt;, where &lt;i&gt;f&lt;/i&gt; is a nested cascade of &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-norms &lt;i&gt;||&lt;b&gt;x&lt;/b&gt;||&lt;sub&gt;p&lt;/sub&gt; = (&amp;#8721; |x&lt;sub&gt;i&lt;/sub&gt;|&lt;sup&gt;p&lt;/sup&gt;)&lt;sup&gt;1/p&lt;/sup&gt;&lt;/i&gt;. &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric distributions thereby are a special case of &lt;i&gt;&amp;#957;&lt;/i&gt;-spherical distributions for which &lt;i&gt;f&lt;/i&gt; is only required to be positively homogeneous of degree one. While both, &lt;i&gt;&amp;#957;&lt;/i&gt;-spherical and &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric distributions, contain many widely used families of probability models such as the Gaussian, spherically and elliptically symmetric distributions, &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-spherically symmetric distributions, and certain types of independent component analysis (ICA) and independent subspace analysis (ISA) models, &lt;i&gt;&amp;#957;&lt;/i&gt;-spherical distributions are usually computationally intractable.  Here we demonstrate that &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric distributions are still computationally feasible by deriving an analytic expression for its normalization constant, gradients for maximum likelihood estimation, analytic expressions for certain types of marginals, as well as an exact and efficient sampling algorithm. We discuss the tight links of &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric distributions to well known machine learning methods such as ICA, ISA and mixed norm regularizers, and introduce the nested radial factorization algorithm (NRF), which is a form of non-linear ICA that transforms any linearly mixed, non-factorial &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested symmetric source into statistically independent signals. As a corollary, we also introduce the uniform distribution on the &lt;i&gt;L&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-nested unit sphere.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/sinz10a/sinz10a.pdf</url></Article><Article><id>758</id><title> Efficient Algorithms for Conditional Independence Inference</title><author>Remco Bouckaert, Raymond Hemmecke, Silvia Lindner, Milan Studen&amp;#253;</author><abstract>

The topic of the paper is computer testing of (probabilistic) &lt;i&gt;conditional independence&lt;/i&gt; (CI) implications by an algebraic method of structural imsets. The basic idea is to transform (sets of) CI statements into certain integral vectors and to verify by a computer the corresponding algebraic relation between the vectors, called the &lt;i&gt;independence implication&lt;/i&gt;.  We interpret the previous methods for computer testing of this implication from the point of view of polyhedral geometry. However, the main contribution of the paper is a new method, based on &lt;i&gt;linear programming&lt;/i&gt; (LP). The new method overcomes the limitation of former methods to the number of involved variables.  We recall/describe the theoretical basis for all four methods involved in our computational experiments, whose aim was to compare the efficiency of the algorithms. The experiments show that the LP method is clearly the fastest one.  As an example of possible application of such algorithms we show that testing inclusion of Bayesian network structures or whether a CI statement is encoded in an acyclic directed graph can be done by the algebraic method.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/bouckaert10b/bouckaert10b.pdf</url></Article><Article><id>759</id><title> An Exponential Model for Infinite Rankings</title><author>Marina Meil&amp;#259;, Le Bao</author><abstract>

This paper presents a statistical model for expressing preferences through rankings, when the number of alternatives (items to rank) is large.  A human ranker will then typically rank only the most preferred items, and may not even examine the whole set of items, or know how many they are. Similarly, a user presented with the ranked output of a search engine, will only consider the highest ranked items. We model such situations by introducing a stagewise ranking model that operates with finite ordered lists called top-&lt;i&gt;t&lt;/i&gt; orderings over an infinite space of items. We give algorithms to estimate this model from data, and demonstrate that it has sufficient statistics, being thus an exponential family model with continuous and discrete parameters. We describe its conjugate prior and other statistical properties. Then, we extend the estimation problem to multimodal data by introducing an &lt;i&gt;Exponential-Blurring-Mean-Shift&lt;/i&gt; nonparametric clustering algorithm. The experiments highlight the properties of our model and demonstrate that infinite models over permutations can be simple, elegant and practical.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/meila10a/meila10a.pdf</url></Article><Article><id>760</id><title> Rate Minimaxity of the Lasso and Dantzig Selector for the &lt;i&gt;l&lt;sub&gt;q&lt;/sub&gt;&lt;/i&gt; Loss in &lt;i&gt;l&lt;sub&gt;r&lt;/sub&gt;&lt;/i&gt; Balls</title><author>Fei Ye, Cun-Hui Zhang</author><abstract>

We consider the estimation of regression coefficients in a high-dimensional linear model. For regression coefficients in &lt;i&gt;l&lt;sub&gt;r&lt;/sub&gt;&lt;/i&gt; balls, we provide lower bounds for the minimax &lt;i&gt;l&lt;sub&gt;q&lt;/sub&gt;&lt;/i&gt; risk and minimax quantiles of the &lt;i&gt;l&lt;sub&gt;q&lt;/sub&gt;&lt;/i&gt; loss for all design matrices. Under an &lt;i&gt;l&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; sparsity condition on a target coefficient vector, we sharpen and unify existing oracle inequalities for the Lasso and Dantzig selector. We derive oracle inequalities for target coefficient vectors with many small elements and smaller threshold levels than the universal threshold. These oracle inequalities provide sufficient conditions on the design matrix for the rate minimaxity of the Lasso and Dantzig selector for the &lt;i&gt;l&lt;sub&gt;q&lt;/sub&gt;&lt;/i&gt; risk and loss in &lt;i&gt;l&lt;sub&gt;r&lt;/sub&gt;&lt;/i&gt; balls, &lt;i&gt;0&amp;#8804; r&amp;#8804; 1&amp;#8804; q&amp;#8804; &amp;#8734;&lt;/i&gt;. By allowing &lt;i&gt;q=&amp;#8734;&lt;/i&gt;, our risk bounds imply the variable selection consistency of threshold Lasso and Dantzig selectors.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/ye10a/ye10a.pdf</url></Article><Article><id>761</id><title> Incremental Sigmoid Belief Networks for Grammar Learning</title><author>James Henderson, Ivan Titov</author><abstract>

We propose a class of Bayesian networks appropriate for structured prediction problems where the Bayesian network's model structure is a function of the predicted output structure.  These incremental sigmoid belief networks (ISBNs) make decoding possible because inference with partial output structures does not require summing over the unboundedly many compatible model structures, due to their directed edges and incrementally specified model structure.  ISBNs are specifically targeted at challenging structured prediction problems such as natural language parsing, where learning the domain's complex statistical dependencies benefits from large numbers of latent variables.  While exact inference in ISBNs with large numbers of latent variables is not tractable, we propose two efficient approximations.  First, we demonstrate that a previous neural network parsing model can be viewed as a coarse mean-field approximation to inference with ISBNs.  We then derive a more accurate but still tractable variational approximation, which proves effective in artificial experiments.  We compare the effectiveness of these models on a benchmark natural language parsing task, where they achieve accuracy competitive with the state-of-the-art.  The model which is a closer approximation to an ISBN has better parsing accuracy, suggesting that ISBNs are an appropriate abstract model of natural language grammar learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/henderson10a/henderson10a.pdf</url></Article><Article><id>762</id><title> Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory</title><author>Sumio Watanabe</author><abstract>

In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown.  In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss.  In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems.  First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable.  Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent.  Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to &lt;i&gt;2&amp;#955;/n&lt;/i&gt;, where &lt;i&gt;&amp;#955;&lt;/i&gt; is the real log canonical threshold and &lt;i&gt;n&lt;/i&gt; is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine.  We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf</url></Article><Article><id>763</id><title> PAC-Bayesian Analysis of Co-clustering and Beyond</title><author>Yevgeny Seldin, Naftali Tishby</author><abstract>

We derive PAC-Bayesian generalization bounds for supervised and unsupervised learning models based on clustering, such as co-clustering, matrix tri-factorization, graphical models, graph clustering, and pairwise clustering. We begin with the analysis of co-clustering, which is a widely used approach to the analysis of data matrices. We distinguish among two tasks in matrix data analysis: discriminative prediction of the missing entries in data matrices and estimation of the joint probability distribution of row and column variables in co-occurrence matrices. We derive PAC-Bayesian generalization bounds for the expected out-of-sample performance of co-clustering-based solutions for these two tasks. The analysis yields regularization terms that were absent in the previous formulations of co-clustering. The bounds suggest that the expected performance of co-clustering is governed by a trade-off between its empirical performance and the mutual information preserved by the cluster variables on row and column IDs. We derive an iterative projection algorithm for finding a local optimum of this trade-off for discriminative prediction tasks. This algorithm achieved state-of-the-art performance in the MovieLens collaborative filtering task. Our co-clustering model can also be seen as matrix tri-factorization and the results provide generalization bounds, regularization terms, and new algorithms for this form of matrix factorization.
&lt;br&gt;
The analysis of co-clustering is extended to tree-shaped graphical models, which can be used to analyze high dimensional tensors. According to the bounds, the generalization abilities of tree-shaped graphical models depend on a trade-off between their empirical data fit and the mutual information that is propagated up the tree levels.
&lt;br&gt;
We also formulate weighted graph clustering as a prediction problem: given a subset of edge weights we analyze the ability of graph clustering to predict the remaining edge weights. The analysis of co-clustering easily extends to this problem and suggests that graph clustering should optimize the trade-off between empirical data fit and the mutual information that clusters preserve on graph nodes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/seldin10a/seldin10a.pdf</url></Article><Article><id>764</id><title> Learning Non-Stationary Dynamic Bayesian Networks</title><author>Joshua W. Robinson, Alexander J. Hartemink</author><abstract>

Learning dynamic Bayesian network structures provides a principled mechanism for identifying conditional dependencies in time-series data.  An important assumption of traditional DBN structure learning is that the data are generated by a stationary process, an assumption that is not true in many important settings.  In this paper, we introduce a new class of graphical model called a non-stationary dynamic Bayesian network, in which the conditional dependence structure of the underlying data-generation process is permitted to change over time.  Non-stationary dynamic Bayesian networks represent a new framework for studying problems in which the structure of a network is evolving over time.  Some examples of evolving networks are transcriptional regulatory networks during an organism's development, neural pathways during learning, and traffic patterns during the day.  We define the non-stationary DBN model, present an MCMC sampling algorithm for learning the structure of the model from time-series data under different assumptions, and demonstrate the effectiveness of the algorithm on both simulated and biological data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume11/robinson10a/robinson10a.pdf</url></Article><Article><id>765</id><title> Exploitation of Machine Learning Techniques in Modelling Phrase Movements for Machine Translation</title><author>Yizhao Ni, Craig Saunders, Sandor Szedmak, Mahesan Niranjan</author><abstract>

We propose a distance phrase reordering model (DPR) for statistical machine translation (SMT), where the aim is to learn the grammatical rules and context dependent changes using a phrase reordering classification framework. We consider a variety of machine learning techniques, including state-of-the-art structured prediction methods. Techniques are compared and evaluated on a Chinese-English corpus, a language pair known for the high reordering characteristics which cannot be adequately captured with current models. In the reordering classification task, the method significantly outperforms the baseline against which it was tested, and further, when integrated as a component of the state-of-the-art machine translation system, MOSES, it achieves improvement in translation results.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ni11a/ni11a.pdf</url></Article><Article><id>766</id><title> Improved Moves for Truncated Convex Models</title><author>M. Pawan Kumar, Olga Veksler, Philip H.S. Torr</author><abstract>

We consider the problem of obtaining an approximate maximum &lt;i&gt;a posteriori&lt;/i&gt; estimate of a discrete random field characterized by pairwise potentials that form a truncated convex model. For this problem, we propose two &lt;i&gt;st&lt;/i&gt;-MINCUT based move making algorithms that we call Range Swap and Range Expansion. Our algorithms can be thought of as extensions of &lt;i&gt;&amp;#945;&amp;#946;&lt;/i&gt;-Swap and &lt;i&gt;&amp;#945;&lt;/i&gt;-Expansion respectively that fully exploit the form of the pairwise potentials. Specifically, instead of dealing with one or two labels at each iteration, our methods explore a large search space by considering a range of labels (that is, an interval of consecutive labels).  Furthermore, we show that Range Expansion provides the same multiplicative bounds as the standard linear programming (LP) relaxation in polynomial time.  Compared to previous approaches based on the LP relaxation, for example interior-point algorithms or tree-reweighted message passing (TRW), our methods are faster as they use only the efficient &lt;i&gt;st&lt;/i&gt;-MINCUT algorithm in their design.  We demonstrate the usefulness of the proposed approaches on both synthetic and standard real data problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/kumar11a/kumar11a.pdf</url></Article><Article><id>767</id><title> CARP: Software for Fishing Out Good Clustering Algorithms</title><author>Volodymyr Melnykov, Ranjan Maitra</author><abstract>

This paper presents the CLUSTERING ALGORITHMS' REFEREE PACKAGE or CARP,  an open source GNU GPL-licensed C package for evaluating clustering algorithms. Calibrating performance of such algorithms is important and CARP addresses this need by generating datasets of different clustering complexity and by assessing the performance of the concerned algorithm in terms of its ability to classify each dataset relative to the true grouping. This paper briefly describes the software and its capabilities. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/melnykov11a/melnykov11a.pdf</url></Article><Article><id>768</id><title> Multitask Sparsity via Maximum Entropy Discrimination</title><author>Tony Jebara</author><abstract>

A multitask learning framework is developed for discriminative classification and regression where multiple large-margin linear classifiers are estimated for different prediction problems. These classifiers operate in a common input space but are coupled as they recover an unknown shared representation. A maximum entropy discrimination (MED) framework is used to derive the multitask algorithm which involves only convex optimization problems that are straightforward to implement.  Three multitask scenarios are described. The first multitask method produces multiple support vector machines that learn a shared sparse feature selection over the input space. The second multitask method produces multiple support vector machines that learn a shared conic kernel combination. The third multitask method produces a pooled classifier as well as adaptively specialized individual classifiers. Furthermore, extensions to regression, graphical model structure estimation and other sparse methods are discussed. The maximum entropy optimization problems are implemented via a sequential quadratic programming method which leverages recent progress in fast SVM solvers. Fast monotonic convergence bounds are provided by bounding the MED sparsifying cost function with a quadratic function and ensuring only a constant factor runtime increase above standard independent SVM solvers. Results are shown on multitask data sets and favor multitask learning over single-task or tabula rasa methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/jebara11a/jebara11a.pdf</url></Article><Article><id>769</id><title> Bayesian Generalized Kernel Mixed Models</title><author>Zhihua Zhang, Guang Dai, Michael I. Jordan</author><abstract>

We propose a fully Bayesian methodology for generalized kernel mixed models (GKMMs), which are extensions of generalized linear mixed models in the feature space induced by a reproducing kernel. We place a mixture of a point-mass distribution and Silverman's &lt;i&gt;g&lt;/i&gt;-prior on the regression vector of a generalized kernel model (GKM). This mixture prior allows a fraction of the components of the regression vector to be zero. Thus, it serves for sparse modeling and is useful for Bayesian computation. In particular, we exploit data augmentation methodology to develop a Markov chain Monte Carlo (MCMC) algorithm in which the reversible jump method is used for model selection and a Bayesian model averaging method is used for posterior prediction.  When the feature basis expansion in the reproducing kernel Hilbert space is treated as a stochastic process, this approach can be related to the Karhunen-Lo&amp;#232;ve expansion of a Gaussian process  (GP).  Thus, our sparse modeling framework leads to a flexible approximation method for GPs.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zhang11a/zhang11a.pdf</url></Article><Article><id>770</id><title> Training SVMs Without Offset</title><author>Ingo Steinwart, Don Hush, Clint Scovel</author><abstract>

We develop, analyze, and test a  training algorithm for support vector machine classifiers without offset.  Key features of this algorithm are a new, statistically motivated  stopping criterion, new warm start options, and a set of inexpensive working set selection strategies that significantly reduce the number of iterations.  For these working set strategies, we establish convergence rates that, not surprisingly,  coincide with the best known rates for SVMs with offset.  We further conduct various experiments that investigate both the run time behavior and the performed iterations of the new training algorithm. It turns out, that the new algorithm needs significantly less iterations and also runs substantially faster  than standard training algorithms for SVMs with offset.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/steinwart11a/steinwart11a.pdf</url></Article><Article><id>771</id><title> Logistic Stick-Breaking Process</title><author>Lu Ren, Lan Du, Lawrence Carin, David Dunson</author><abstract>

A logistic stick-breaking process (LSBP) is proposed for non-parametric clustering of general spatially- or temporally-dependent data, imposing the belief that proximate data are more likely to be clustered together. The sticks in the LSBP are realized via multiple logistic regression functions, with shrinkage priors employed to favor contiguous and spatially localized segments. The LSBP is also extended for the simultaneous processing of multiple data sets, yielding a hierarchical logistic stick-breaking process (H-LSBP). The model parameters (atoms) within the H-LSBP are shared across the multiple learning tasks.  Efficient variational Bayesian inference is derived, and comparisons are made to related techniques in the literature.  Experimental analysis is performed for audio waveforms and images, and it is demonstrated that for segmentation applications the LSBP yields generally homogeneous segments with sharp boundaries.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ren11a/ren11a.pdf</url></Article><Article><id>772</id><title> Online Learning in Case of Unbounded Losses Using Follow the Perturbed Leader Algorithm</title><author>Vladimir V. V'yugin</author><abstract>

In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modification of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled fluctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled fluctuations of one-step losses of experts of the pool tend to zero.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/vyugin11a/vyugin11a.pdf</url></Article><Article><id>773</id><title> A Bayesian Approximation Method for Online Ranking</title><author>Ruby C. Weng, Chih-Jen Lin</author><abstract>

This paper describes a Bayesian approximation method to obtain online ranking algorithms for games with multiple teams and multiple players.  Recently for Internet games large online ranking systems are much needed.  We consider game models in which a &lt;i&gt;k&lt;/i&gt;-team game is treated as several two-team games.  By approximating the expectation of teams' (or players') performances, we derive simple analytic update rules.  These update rules, without numerical integrations, are very easy to interpret and implement.  Experiments on game data show that the accuracy of our approach is competitive with state of the art systems such as TrueSkill, but the running time as well as the code is much shorter.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/weng11a/weng11a.pdf</url></Article><Article><id>774</id><title> Cumulative Distribution Networks and the Derivative-sum-product Algorithm: Models and Inference for Cumulative Distribution Functions on Graphs</title><author>Jim C. Huang, Brendan J. Frey</author><abstract>

We present a class of graphical models for directly representing the joint cumulative distribution function (CDF) of many random variables, called  &lt;i&gt;cumulative distribution networks&lt;/i&gt; (CDNs).  Unlike graphs for probability density and mass functions, for CDFs the marginal probabilities for any subset of variables are obtained by computing limits of functions in the model, and conditional probabilities correspond to computing mixed derivatives.  We will show that the conditional independence properties in a CDN are distinct from the conditional independence properties of directed, undirected and factor graphs, but include the conditional independence properties of bi-directed graphs.  In order to perform inference in such models, we describe the `derivative-sum-product' (DSP) message-passing algorithm in which messages correspond to derivatives of the joint CDF.  We will then apply CDNs to the problem of learning to rank players in multiplayer team-based games and suggest several future directions for research.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/huang11a/huang11a.pdf</url></Article><Article><id>775</id><title> Models of Cooperative Teaching and Learning </title><author>Sandra Zilles, Steffen Lange, Robert Holte, Martin Zinkevich</author><abstract>

While most supervised machine learning models assume that training examples are sampled at random or adversarially, this article is concerned with models of learning from a cooperative teacher that selects "helpful" training examples. The number of training examples a learner needs for identifying a concept in a given class &lt;i&gt;C&lt;/i&gt; of possible target concepts (sample complexity of &lt;i&gt;C&lt;/i&gt;) is lower in models assuming such teachers, that is, "helpful" examples can speed up the learning process.
&lt;br&gt;
The problem of how a teacher and a learner can cooperate in order to reduce the sample complexity, yet without using "coding tricks", has been widely addressed. Nevertheless, the resulting teaching and learning protocols do not seem to make the teacher select intuitively "helpful" examples. The two models introduced in this paper are built on what we call &lt;i&gt;subset teaching sets&lt;/i&gt; and &lt;i&gt;recursive teaching sets&lt;/i&gt;. They extend previous models of teaching by letting both the teacher and the learner exploit &lt;i&gt;knowing&lt;/i&gt; that the partner is cooperative. For this purpose, we introduce a new notion of "coding trick"/"collusion". 
&lt;br&gt;
We show how both resulting sample complexity measures (the &lt;i&gt;subset teaching dimension&lt;/i&gt; and the &lt;i&gt;recursive teaching dimension&lt;/i&gt;) can be arbitrarily lower than the classic teaching dimension and known variants thereof, without using coding tricks. For instance, monomials can be taught with only two examples independent of the number of variables.
&lt;br&gt;
The subset teaching dimension turns out to be nonmonotonic with respect to subclasses of concept classes. We discuss why this nonmonotonicity might be inherent in many interesting cooperative teaching and learning scenarios. 


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zilles11a/zilles11a.pdf</url></Article><Article><id>776</id><title> Operator Norm Convergence of Spectral Clustering on Level Sets </title><author>Bruno Pelletier, Pierre Pudlo</author><abstract>

Following Hartigan (1975), a cluster is defined as a connected component of the &lt;i&gt;t&lt;/i&gt;-level set of the underlying density, that is, the set of points for which the density is greater than &lt;i&gt;t&lt;/i&gt;.  A clustering algorithm which combines a density estimate with spectral clustering techniques is proposed.  Our algorithm is composed of two steps.  First, a nonparametric density estimate is used to extract the data points for which the estimated density takes a value greater than &lt;i&gt;t&lt;/i&gt;.  Next, the extracted points are clustered based on the eigenvectors of a graph Laplacian matrix.  Under mild assumptions, we prove the almost sure convergence in operator norm of the empirical graph Laplacian operator associated with the algorithm.  Furthermore, we give the typical behavior of the representation of the data set into the feature space, which establishes the strong consistency of our proposed algorithm.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/pelletier11a/pelletier11a.pdf</url></Article><Article><id>777</id><title> Approximate Marginals in Latent Gaussian Models </title><author>Botond Cseke, Tom Heskes</author><abstract>

We consider the problem of improving the Gaussian approximate posterior marginals computed by expectation propagation and the Laplace method in latent Gaussian models and propose methods that are similar in spirit to the Laplace approximation of Tierney and Kadane (1986).  We show that in the case of sparse Gaussian models, the computational complexity of expectation propagation can be made comparable to that of the Laplace method by using a parallel updating scheme. In some cases, expectation propagation gives excellent estimates where the Laplace approximation fails. Inspired by bounds on the correct marginals, we arrive at factorized approximations, which can be applied on top of both expectation propagation and the Laplace method. The factorized approximations can give nearly indistinguishable results from the non-factorized approximations and their computational complexity scales linearly with the number of variables.  We experienced that the expectation propagation based marginal approximations we introduce are typically more  accurate than the methods of similar complexity proposed by Rue et al. (2009).


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/cseke11a/cseke11a.pdf</url></Article><Article><id>778</id><title> Posterior Sparsity in Unsupervised Dependency Parsing </title><author>Jennifer Gillenwater, Kuzman Ganchev, Jo&amp;#227;o Gra&amp;#231;a, Fernando Pereira, Ben Taskar</author><abstract>

A strong inductive bias is essential in unsupervised grammar induction.  In this paper, we explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types.  We use part-of-speech (POS) tags to group dependencies by parent-child types and investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Gra&amp;#231;a et al. (2007). In experiments with 12 different languages, we achieve significant gains in directed attachment accuracy over the standard expectation maximization (EM) baseline, with an average accuracy improvement of 6.5%, outperforming EM by at least 1% for 9 out of 12 languages. Furthermore, the new method outperforms models based on standard Bayesian sparsity-inducing parameter priors with an average improvement of 5% and positive gains of at least 1% for 9 out of 12 languages. On English text in particular, we show that our approach improves performance over other state-of-the-art techniques.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/gillenwater11a/gillenwater11a.pdf</url></Article><Article><id>779</id><title> Learning Multi-modal Similarity </title><author>Brian McFee, Gert Lanckriet</author><abstract>

In many applications involving multi-media data, the definition of similarity between items is integral to several key tasks, including nearest-neighbor retrieval, classification, and recommendation.  Data in such regimes typically exhibits multiple modalities, such as acoustic and visual content of video.  Integrating such heterogeneous data to form a holistic similarity space is therefore a key challenge to be overcome in many real-world applications.
&lt;br&gt;
We present a novel multiple kernel learning technique for integrating heterogeneous data into a single, unified similarity space.  Our algorithm learns an optimal ensemble of kernel transformations which conform to measurements of human perceptual similarity, as expressed by relative comparisons.  To cope with the ubiquitous problems of subjectivity and inconsistency in multi-media similarity, we develop graph-based techniques to filter similarity measurements, resulting in a simplified and robust training procedure.  


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/mcfee11a/mcfee11a.pdf</url></Article><Article><id>780</id><title> Minimum Description Length Penalization for Group and Multi-Task Sparse Learning </title><author>Paramveer S. Dhillon, Dean Foster, Lyle H. Ungar</author><abstract>

We propose a framework MIC (Multiple Inclusion Criterion) for learning sparse models based on the information theoretic Minimum Description Length (MDL) principle. MIC provides an elegant way of incorporating arbitrary sparsity patterns in the feature space by using  two-part MDL coding schemes. We present MIC based models for the problems of grouped feature selection (MIC-GROUP)  and multi-task feature selection (MIC-MULTI). MIC-GROUP assumes that the features are divided into groups and induces two level sparsity, selecting a subset of the feature groups, and also selecting features within each selected group.  MIC-MULTI applies when there are multiple related tasks that share the same set of potentially predictive features. It also induces two level sparsity, selecting a subset of the features, and then selecting which of the tasks each feature should be added to.  Lastly, we propose a model, TRANSFEAT, that can be used to transfer knowledge from a set of previously learned tasks to a new task that is expected to share similar features.  All three methods are designed for selecting a small set of predictive features from a large pool of candidate features. We demonstrate the effectiveness of our approach with experimental results on data from genomics and from word sense disambiguation problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/dhillon11a/dhillon11a.pdf</url></Article><Article><id>781</id><title> Variable Sparsity Kernel Learning </title><author>Jonathan Aflalo, Aharon Ben-Tal, Chiranjib Bhattacharyya, Jagarlapudi Saketha Nath, Sankaran Raman</author><abstract>

This paper presents novel algorithms and applications for a particular class of mixed-norm regularization based Multiple Kernel Learning (MKL) formulations. The formulations assume that the given kernels are grouped and employ &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; norm regularization for promoting sparsity within RKHS norms of each group and &lt;i&gt;l&lt;sub&gt;s&lt;/sub&gt;, s&amp;#8805;2&lt;/i&gt; norm regularization for promoting non-sparse combinations across groups. Various sparsity levels in combining the kernels can be achieved by varying the grouping of kernels---hence we name the formulations as Variable Sparsity Kernel Learning (VSKL) formulations. While previous attempts have a non-convex formulation, here we present a convex formulation which admits efficient Mirror-Descent (MD) based solving techniques. The proposed MD based algorithm optimizes over product of simplices and has a computational complexity of &lt;i&gt;O(m&lt;sup&gt;2&lt;/sup&gt;n&lt;sub&gt;tot&lt;/sub&gt; log n&lt;sub&gt;max&lt;/sub&gt;/&amp;#949;&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; where &lt;i&gt;m&lt;/i&gt; is no. training data points, &lt;i&gt;n&lt;sub&gt;max&lt;/sub&gt;,n&lt;sub&gt;tot&lt;/sub&gt;&lt;/i&gt; are the maximum no. kernels in any group, total no. kernels respectively and &lt;i&gt;&amp;#949;&lt;/i&gt; is the error in approximating the objective. A detailed proof of convergence of the algorithm is also presented. Experimental results show that the VSKL formulations are well-suited for multi-modal learning tasks like object categorization. Results also show that the MD based algorithm outperforms state-of-the-art MKL solvers in terms of computational efficiency.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/aflalo11a/aflalo11a.pdf</url></Article><Article><id>782</id><title> Regression on Fixed-Rank Positive Semidefinite Matrices: A Riemannian Approach </title><author>Gilles Meyer, Silv&amp;#232;re Bonnabel, Rodolphe Sepulchre</author><abstract>

The paper addresses the problem of learning a regression model parameterized by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of gradient descent algorithms adapted to the Riemannian geometry that underlies the set of fixed-rank positive semidefinite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semidefinite matrix. Good performance is observed on classical benchmarks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/meyer11a/meyer11a.pdf</url></Article><Article><id>783</id><title> Parameter Screening and Optimisation for ILP using Designed Experiments </title><author>Ashwin Srinivasan, Ganesh Ramakrishnan</author><abstract>

Reports of experiments conducted with an Inductive Logic Programming system rarely describe how specific values of parameters of the system are arrived at when constructing models. Usually, no attempt is made to identify sensitive parameters, and those that are used are often given "factory-supplied" default values, or values obtained from some non-systematic exploratory analysis. The immediate consequence of this is, of course, that it is not clear if better models could have been obtained if some form of parameter selection and optimisation had been performed.  Questions follow inevitably on the experiments themselves: specifically, are all algorithms being treated fairly, and is the exploratory phase sufficiently well-defined to allow the experiments to be replicated? In this paper, we investigate the use of parameter selection and optimisation techniques grouped under the study of experimental design.  Screening and response surface methods determine, in turn, sensitive parameters and good values for these parameters. Screening is done here by constructing a stepwise regression model relating the utility of an ILP system's hypothesis to its input parameters, using systematic combinations of values of input parameters (technically speaking, we use a two-level fractional factorial design of the input parameters).  The parameters used by the regression model are taken to be the sensitive parameters for the system for that application. We then seek an assignment of values to these sensitive parameters that maximise the utility of the ILP model. This is done using the technique of constructing a local "response surface". The parameters are then changed following the path of steepest ascent until a locally optimal value is reached.  This combined use of parameter selection and response surface-driven optimisation has a long history of application in industrial engineering, and its role in ILP is demonstrated using well-known benchmarks. The results suggest that computational overheads from this preliminary phase are not substantial, and that much can be gained, both on improving system performance and on enabling controlled experimentation, by adopting well-established procedures such as the ones proposed here.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/srinivasan11a/srinivasan11a.pdf</url></Article><Article><id>784</id><title> Efficient Structure Learning of Bayesian Networks using Constraints </title><author>Cassio P. de Campos, Qiang Ji</author><abstract>

This paper addresses the problem of learning Bayesian network structures from data based on score functions that are decomposable.  It describes properties that strongly reduce the time and memory costs of many known methods without losing global optimality guarantees.  These properties are derived for different score criteria such as Minimum Description Length (or Bayesian Information Criterion), Akaike Information Criterion and Bayesian Dirichlet Criterion.  Then a branch-and-bound algorithm is presented that integrates structural constraints with data in a way to guarantee global optimality.  As an example, structural constraints are used to map the problem of structure learning in Dynamic Bayesian networks into a corresponding augmented Bayesian network.  Finally, we show empirically the benefits of using the properties with state-of-the-art methods and with the new algorithm, which is able to handle larger data sets than before.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/decampos11a/decampos11a.pdf</url></Article><Article><id>785</id><title> Inverse Reinforcement Learning in Partially Observable Environments </title><author>Jaedeug Choi, Kee-Eung Kim</author><abstract>

Inverse reinforcement learning (IRL) is the problem of recovering the underlying reward function from the behavior of an expert. Most of the existing IRL algorithms assume that the environment is modeled as a Markov decision process (MDP), although it is desirable to handle partially observable settings in order to handle more realistic scenarios. In this paper, we present IRL algorithms for partially observable environments that can be modeled as a partially observable Markov decision process (POMDP). We deal with two cases according to the representation of the given expert's behavior, namely the case in which the expert's policy is explicitly given, and the case in which the expert's trajectories are available instead.  The IRL in POMDPs poses a greater challenge than in MDPs since it is not only ill-posed due to the nature of IRL, but also computationally intractable due to the hardness in solving POMDPs. To overcome these obstacles, we present algorithms that exploit some of the classical results from the POMDP literature. Experimental results on several benchmark POMDP domains show that our work is useful for partially observable settings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/choi11a/choi11a.pdf</url></Article><Article><id>786</id><title> Information, Divergence and Risk for Binary Experiments </title><author>Mark D. Reid, Robert C. Williamson</author><abstract>

We unify &lt;i&gt;f&lt;/i&gt;-divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information.  We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives  which all are related to cost-sensitive binary classification.  As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating &lt;i&gt;f&lt;/i&gt;-divergences to variational divergence.  The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/reid11a/reid11a.pdf</url></Article><Article><id>787</id><title> Learning Transformation Models for Ranking and Survival Analysis </title><author>Vanya Van Belle, Kristiaan Pelckmans, Johan A. K. Suykens, Sabine Van Huffel</author><abstract>

This paper studies the task of learning transformation models for ranking problems, ordinal regression and survival analysis.  The present contribution describes a machine learning approach termed MINLIP. The key insight is to relate ranking criteria as the Area Under the Curve to monotone transformation functions.  Consequently, the notion of a Lipschitz smoothness constant is found to be useful for complexity control for learning transformation models, much in a similar vein as the 'margin' is for Support Vector Machines for classification. The use of this model structure in the context of high dimensional data, as well as for estimating non-linear, and additive models based on primal-dual kernel machines,  and for sparse models is indicated.  Given &lt;i&gt;n&lt;/i&gt; observations, the present method solves a quadratic program existing of &lt;i&gt;O(n)&lt;/i&gt; constraints and &lt;i&gt;O(n)&lt;/i&gt; unknowns, where most existing risk minimization approaches to ranking problems typically result in algorithms with &lt;i&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; constraints or unknowns. We specify the MINLIP method for three different cases: the first one concerns the preference learning problem. Secondly it is specified how to adapt the method to ordinal regression with a finite set of ordered outcomes. Finally, it is shown how the method can be used in the context of survival analysis where one models failure times, typically subject to censoring. The current approach is found to be particularly useful in this context as it can handle, in contrast with the standard statistical model for analyzing survival data, all types of censoring in a straightforward way, and because of the explicit relation with the Proportional Hazard and Accelerated Failure Time models. The advantage of the current method is illustrated on different benchmark data sets, as well as for estimating a model for cancer survival based on different micro-array and clinical data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/vanbelle11a/vanbelle11a.pdf</url></Article><Article><id>788</id><title> Sparse Linear Identifiable Multivariate Modeling </title><author>Ricardo Henao, Ole Winther</author><abstract>

In this paper we consider sparse and identifiable linear latent variable (factor) and linear Bayesian network models for parsimonious analysis of multivariate data. We propose a computationally efficient method for joint parameter and model inference, and model comparison. It consists of a fully Bayesian hierarchy for sparse models using slab and spike priors (two-component &lt;i&gt;&amp;#948;&lt;/i&gt;-function and continuous mixtures), non-Gaussian latent factors and a stochastic search over the ordering of the variables. The framework, which we call SLIM (Sparse Linear Identifiable Multivariate modeling), is validated and bench-marked on artificial and real biological data sets. SLIM is closest in spirit to LiNGAM (Shimizu et al., 2006), but differs substantially in inference, Bayesian network structure learning and model comparison. Experimentally, SLIM performs equally well or better than LiNGAM with comparable computational complexity. We attribute this mainly to the stochastic search strategy used, and to parsimony (sparsity and identifiability), which is an explicit part of the model. We propose two extensions to the basic i.i.d. linear framework: non-linear dependence on observed variables, called SNIM (Sparse Non-linear Identifiable Multivariate modeling) and allowing for correlations between latent variables, called CSLIM (Correlated SLIM), for the temporal and/or spatial data. The source code and scripts are available from http://cogsys.imm.dtu.dk/slim/.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/henao11a/henao11a.pdf</url></Article><Article><id>789</id><title> Forest Density Estimation </title><author>Han Liu, Min Xu, Haijie Gu, Anupam Gupta, John Lafferty, Larry Wasserman</author><abstract>

We study graph estimation and density estimation in high dimensions, using a family of density estimators based on forest structured undirected graphical models.  For density estimation, we do not assume the true distribution corresponds to a forest; rather, we form kernel density estimates of the bivariate and univariate marginals, and apply Kruskal's algorithm to estimate the optimal forest on held out data.  We prove an oracle inequality on the excess risk of the resulting estimator relative to the risk of the best forest.  For graph estimation, we consider the problem of estimating forests with restricted tree sizes.  We prove that finding a maximum weight spanning forest with restricted tree size is NP-hard, and develop an approximation algorithm for this problem.  Viewing the tree size as a complexity parameter, we then select a forest using data splitting, and prove bounds on excess risk and structure selection consistency of the procedure.  Experiments with simulated data and microarray data indicate that the methods are a practical alternative to Gaussian graphical models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/liu11a/liu11a.pdf</url></Article><Article><id>790</id><title> &lt;i&gt;l&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-Norm Multiple Kernel Learning </title><author>Marius Kloft, Ulf Brefeld, S&amp;#246;ren Sonnenburg, Alexander Zien</author><abstract>

Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown. Previous approaches to multiple kernel learning (MKL) promote sparse kernel combinations to support interpretability and scalability.  Unfortunately, this &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm MKL is rarely observed to outperform trivial baselines in practical applications. To allow for robust kernel mixtures that generalize well, we extend MKL to arbitrary norms. We devise new insights on the connection between several existing MKL formulations and develop two efficient &lt;i&gt;interleaved&lt;/i&gt; optimization strategies for arbitrary norms, that is &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-norms with &lt;i&gt;p &amp;#8805; 1&lt;/i&gt;. This interleaved optimization is much faster than the commonly used wrapper approaches, as demonstrated on several data sets.  A theoretical analysis and an experiment on controlled artificial data shed light on the appropriateness of sparse, non-sparse and &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;&amp;#8734;&lt;/sub&gt;&lt;/i&gt;-norm MKL in various scenarios.  Importantly, empirical applications of &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-norm MKL to three real-world problems from computational biology show that non-sparse MKL achieves accuracies that surpass the state-of-the-art.
&lt;br&gt;
Data sets, source code to reproduce the experiments, implementations of the algorithms, and further information are available at http://doc.ml.tu-berlin.de/nonsparse_mkl/.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/kloft11a/kloft11a.pdf</url></Article><Article><id>791</id><title> Unsupervised Similarity-Based Risk Stratification for Cardiovascular Events Using Long-Term Time-Series Data </title><author>Zeeshan Syed, John Guttag</author><abstract>

In medicine, one often bases decisions upon a comparative analysis of patient data. In this paper, we build upon this observation and describe similarity-based algorithms to risk stratify patients for major adverse cardiac events. We evolve the traditional approach of comparing patient data in two ways. First, we propose similarity-based algorithms that compare patients in terms of their long-term physiological monitoring data. Symbolic mismatch identifies functional units in long-term signals and measures changes in the morphology and frequency of these units across patients. Second, we describe similarity-based algorithms that are unsupervised and do not require comparisons to patients with known outcomes for risk stratification. This is achieved by using an anomaly detection framework to identify patients who are unlike other patients in a population and may potentially be at an elevated risk. We demonstrate the potential utility of our approach by showing how symbolic mismatch-based algorithms can be used to classify patients as being at high or low risk of major adverse cardiac events by comparing their long-term electrocardiograms to that of a large population. We describe how symbolic mismatch can be used in three different existing methods: one-class support vector machines, nearest neighbor analysis, and hierarchical clustering. When evaluated on a population of 686 patients with available long-term electrocardiographic data, symbolic mismatch-based comparative approaches were able to identify patients at roughly a two-fold increased risk of major adverse cardiac events in the 90 days following acute coronary syndrome. These results were consistent even after adjusting for other clinical risk variables.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/syed11a/syed11a.pdf</url></Article><Article><id>792</id><title> Two Distributed-State Models For Generating High-Dimensional Time Series </title><author>Graham W. Taylor, Geoffrey E. Hinton, Sam T. Roweis</author><abstract>

In this paper we develop a class of nonlinear generative models for high-dimensional time series.  We first propose a model based on the restricted Boltzmann machine (RBM) that uses an undirected model with binary latent variables and real-valued "visible" variables. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. This "conditional" RBM (CRBM) makes on-line inference efficient and allows us to use a simple approximate learning procedure. We demonstrate the power of our approach by synthesizing various sequences from a model trained on motion capture data and by performing on-line filling in of data lost during capture.
&lt;br&gt;
We extend the CRBM in a way that preserves its most important computational properties and introduces multiplicative three-way interactions that allow the effective interaction weight between two variables to be modulated by the dynamic state of a third variable. We introduce a factoring of the implied three-way weight tensor to permit a more compact parameterization. The resulting model can capture diverse styles of motion with a single set of parameters, and the three-way interactions greatly improve its ability to blend motion styles or to transition smoothly among them.
&lt;br&gt;
Videos and source code can be found at http://www.cs.nyu.edu/~gwtaylor/publications/jmlr2011.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/taylor11a/taylor11a.pdf</url></Article><Article><id>793</id><title> Differentially Private Empirical Risk Minimization </title><author>Kamalika Chaudhuri, Claire Monteleoni, Anand D. Sarwate</author><abstract>

Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or financial records, are analyzed.  We provide general techniques to produce privacy-preserving approximations of classifiers learned via (regularized) empirical risk minimization (ERM).  These algorithms are private under the &lt;i&gt;&lt;i&gt;&amp;#949;&lt;/i&gt;-differential privacy&lt;/i&gt; definition due to Dwork et al. (2006).  First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classification.  Then we propose a new method, &lt;i&gt;objective perturbation&lt;/i&gt;, for privacy-preserving machine learning algorithm design.  This method entails perturbing the objective function before optimizing over classifiers.  If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels.  We further present a privacy-preserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines.  We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets.  Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/chaudhuri11a/chaudhuri11a.pdf</url></Article><Article><id>794</id><title> Anechoic Blind Source Separation Using Wigner Marginals </title><author>Lars Omlor, Martin A. Giese</author><abstract>

Blind source separation problems emerge in many applications, where signals can be modeled as superpositions of multiple sources. Many popular applications of blind source separation are based on linear instantaneous mixture models. If specific invariance properties are known about the sources, for example, translation or rotation invariance, the simple linear model can be extended by inclusion of the corresponding transformations.  When the sources are invariant against translations (spatial displacements or time shifts) the resulting model is called an anechoic mixing model. We present a new algorithmic framework for the solution of anechoic problems in arbitrary dimensions. This framework is derived from stochastic time-frequency analysis in general, and the marginal properties of the Wigner-Ville spectrum in particular. The method reduces the general anechoic problem to a set of anechoic problems with non-negativity constraints and a phase retrieval problem. The first type of subproblem can be solved by existing algorithms, for example by an appropriate modification of non-negative matrix factorization (NMF). The second subproblem is solved by established phase retrieval methods. We discuss and compare implementations of this new algorithmic framework for several example problems with synthetic and real-world data, including music streams, natural 2D images, human motion trajectories and two-dimensional shapes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/omlor11a/omlor11a.pdf</url></Article><Article><id>795</id><title> Laplacian Support Vector Machines  Trained in the Primal </title><author>Stefano Melacci, Mikhail Belkin</author><abstract>

In the last few years, due to the growing ubiquity of unlabeled data, much effort has been spent by the machine learning community to develop better understanding and improve the quality of classifiers exploiting unlabeled data.  Following the manifold regularization approach, Laplacian Support Vector Machines (LapSVMs) have shown the state of the art performance in semi-supervised classification.  In this paper we present two strategies to solve the &lt;i&gt;primal&lt;/i&gt; LapSVM problem, in order to overcome some issues of the original &lt;i&gt;dual&lt;/i&gt; formulation.  In particular, training a LapSVM in the primal can be efficiently performed with preconditioned conjugate gradient.  We speed up training by using an early stopping strategy based on the prediction on unlabeled data or, if available, on labeled validation examples. This allows the algorithm to quickly compute approximate solutions with roughly the same classification accuracy as the optimal ones, considerably reducing the training time.  The computational complexity of the training algorithm is reduced from &lt;i&gt;O(n&lt;sup&gt;3&lt;/sup&gt;)&lt;/i&gt; to &lt;i&gt;O(kn&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt;, where &lt;i&gt;n&lt;/i&gt; is the combined number of labeled and unlabeled examples and &lt;i&gt;k&lt;/i&gt; is empirically evaluated to be significantly smaller than &lt;i&gt;n&lt;/i&gt;.  Due to its simplicity, training LapSVM in the primal can be the starting point for  additional enhancements of the original LapSVM formulation, such as those for dealing with large data sets.  We present an extensive experimental evaluation on real world data showing the benefits of the proposed approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/melacci11a/melacci11a.pdf</url></Article><Article><id>796</id><title> The Indian Buffet Process: An Introduction and Review </title><author>Thomas L. Griffiths, Zoubin Ghahramani</author><abstract>

The Indian buffet process is a stochastic process defining a probability distribution over equivalence classes of sparse binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features, or that involve bipartite graphs in which the size of at least one class of nodes is unknown. We give a detailed derivation of this distribution, and illustrate its use as a prior in an infinite latent feature model. We then review recent applications of the Indian buffet process in machine learning, discuss its extensions, and summarize its connections to other stochastic processes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/griffiths11a/griffiths11a.pdf</url></Article><Article><id>797</id><title> DirectLiNGAM: A Direct Method for Learning a Linear Non-Gaussian Structural Equation Model </title><author>Shohei Shimizu, Takanori Inazumi, Yasuhiro Sogawa, Aapo Hyv&amp;#228;rinen, Yoshinobu Kawahara, Takashi Washio, Patrik O. Hoyer, Kenneth Bollen</author><abstract>

Structural equation models and Bayesian networks have been widely used to analyze causal relations between continuous variables. In such frameworks, linear acyclic models are typically used to model the data-generating process of variables.  Recently, it was shown that use of non-Gaussianity identifies the full structure of a linear acyclic model, that is, a causal ordering of variables and their connection strengths, without using any prior knowledge on the network structure, which is not the case with conventional methods.  However, existing estimation methods are based on iterative search algorithms and may not converge to a correct solution in a finite number of steps.  In this paper, we propose a new direct method to estimate a causal ordering and connection strengths based on non-Gaussianity.  In contrast to the previous methods, our algorithm requires no algorithmic parameters and is guaranteed to converge to the right solution within a small fixed number of steps if the data strictly follows the model, that is, if all the model assumptions are met and the sample size is infinite.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/shimizu11a/shimizu11a.pdf</url></Article><Article><id>798</id><title> Locally Defined Principal Curves and Surfaces </title><author>Umut Ozertem, Deniz Erdogmus</author><abstract>

Principal curves are defined as self-consistent &lt;i&gt;smooth&lt;/i&gt; curves passing through the &lt;i&gt;middle&lt;/i&gt; of the data, and they have been used in many applications of machine learning as a generalization, dimensionality reduction and a feature extraction tool. We redefine principal curves and surfaces in terms of the gradient and the Hessian of the probability density estimate. This provides a geometric understanding of the principal curves and surfaces, as well as a unifying view for clustering, principal curve fitting and manifold learning by regarding those as principal manifolds of different intrinsic dimensionalities. The theory does not impose any particular density estimation method can be used with any density estimator that gives continuous first and second derivatives. Therefore, we first present our principal curve/surface definition without assuming any particular density estimation method. Afterwards, we develop practical algorithms for the commonly used kernel density estimation (KDE) and Gaussian mixture models (GMM). Results of these algorithms are presented in notional data sets as well as real applications with comparisons to other approaches in the principal curve literature. All in all, we present a novel theoretical understanding of principal curves and surfaces, practical algorithms as general purpose machine learning tools, and applications of these algorithms to several practical problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ozertem11a/ozertem11a.pdf</url></Article><Article><id>799</id><title> Better Algorithms for Benign Bandits </title><author>Elad Hazan, Satyen Kale</author><abstract>

The online multi-armed bandit problem and its generalizations are repeated decision making problems, where the goal is to select one of several possible decisions in every round, and incur a cost associated with the decision, in such a way that the total cost incurred over all iterations is close to the cost of the best fixed decision in hindsight. The difference in these costs is known as the &lt;i&gt;regret&lt;/i&gt; of the algorithm. The term &lt;i&gt;bandit&lt;/i&gt; refers to the setting where one only obtains the cost of the decision used in a given iteration and no other information.
&lt;br&gt;
A very general form of this problem is the non-stochastic bandit linear optimization problem, where the set of decisions is a convex set in some Euclidean space, and the cost functions are linear. Only recently an efficient algorithm attaining &lt;i&gt;&amp;#213;(&amp;#8730;T)&lt;/i&gt; regret was discovered in this setting.
&lt;br&gt;
In this paper we propose a new algorithm for the bandit linear optimization problem which obtains a tighter regret bound of &lt;i&gt;&amp;#213;(&amp;#8730;Q)&lt;/i&gt;, where &lt;i&gt;Q&lt;/i&gt; is the total variation in the cost functions. This regret bound, previously conjectured to hold in the full information case, shows that it is possible to incur much less regret in a slowly changing environment even in the bandit setting. Our algorithm is efficient and applies several new ideas to bandit optimization such as reservoir sampling.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/hazan11a/hazan11a.pdf</url></Article><Article><id>800</id><title> A Family of Simple Non-Parametric Kernel Learning Algorithms </title><author>Jinfeng Zhuang, Ivor W. Tsang, Steven C.H. Hoi</author><abstract>

Previous studies of &lt;i&gt;Non-Parametric Kernel Learning&lt;/i&gt; (NPKL) usually formulate the learning task as a Semi-Definite Programming (SDP) problem that is often solved by some general purpose SDP solvers. However, for &lt;i&gt;N&lt;/i&gt; data examples, the time complexity of NPKL using a standard interior-point SDP solver could be as high as &lt;i&gt;O(N&lt;sup&gt;6.5&lt;/sup&gt;)&lt;/i&gt;, which prohibits NPKL methods applicable to real applications, even for data sets of moderate size. In this paper, we present a family of efficient NPKL algorithms, termed "&lt;b&gt;SimpleNPKL&lt;/b&gt;", which can learn non-parametric kernels from a large set of pairwise constraints efficiently. In particular, we propose two efficient SimpleNPKL algorithms. One is SimpleNPKL algorithm with linear loss, which enjoys a &lt;i&gt;closed-form&lt;/i&gt; solution that can be efficiently computed by the &lt;i&gt;Lanczos&lt;/i&gt; sparse eigen decomposition technique. Another one is SimpleNPKL algorithm with other loss functions (including square hinge loss, hinge loss, square loss) that can be re-formulated as a saddle-point optimization problem, which can be further resolved by a fast iterative algorithm. In contrast to the previous NPKL approaches, our empirical results show that the proposed new technique, maintaining the same accuracy, is significantly more efficient and scalable. Finally, we also demonstrate that the proposed new technique is also applicable to speed up many kernel learning tasks, including &lt;i&gt;colored maximum variance unfolding&lt;/i&gt;, &lt;i&gt;minimum volume embedding&lt;/i&gt;, and &lt;i&gt;structure preserving embedding&lt;/i&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zhuang11a/zhuang11a.pdf</url></Article><Article><id>801</id><title> Faster Algorithms for Max-Product Message-Passing </title><author>Julian J. McAuley, Tib&amp;#233;rio S. Caetano</author><abstract>

&lt;i&gt;Maximum A Posteriori&lt;/i&gt; inference in graphical models is often solved via message-passing algorithms, such as the junction-tree algorithm or loopy belief-propagation. The exact solution to this problem is well-known to be exponential in the size of the maximal cliques of the triangulated model, while approximate inference is typically exponential in the size of the model's factors. In this paper, we take advantage of the fact that many models have maximal cliques that are larger than their constituent factors, and also of the fact that many factors consist only of latent variables (i.e., they do not depend on an observation). This is a common case in a wide variety of applications that deal with grid-, tree-, and ring-structured models. In such cases, we are able to decrease the exponent of complexity for message-passing by &lt;i&gt;0.5&lt;/i&gt; for both exact &lt;i&gt;and&lt;/i&gt; approximate inference. We demonstrate that message-passing operations in such models are equivalent to some variant of matrix multiplication in the tropical semiring, for which we offer an &lt;i&gt;O(N&lt;sup&gt;2.5&lt;/sup&gt;)&lt;/i&gt; &lt;i&gt;expected-case&lt;/i&gt; solution.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/mcauley11a/mcauley11a.pdf</url></Article><Article><id>802</id><title> Clustering Algorithms for Chains </title><author>Antti Ukkonen</author><abstract>

We consider the problem of clustering a set of chains to &lt;i&gt;k&lt;/i&gt; clusters.  A chain is a totally ordered subset of a finite set of items.  Chains are an intuitive way to express preferences over a set of alternatives, as well as a useful representation of ratings in situations where the item-specific scores are either difficult to obtain, too noisy due to measurement error, or simply not as relevant as the order that they induce over the items.  First we adapt the classical &lt;i&gt;k&lt;/i&gt;-means for chains by proposing a suitable distance function and a centroid structure.  We also present two different approaches for mapping chains to a vector space.  The first one is related to the planted partition model, while the second one has an intuitive geometrical interpretation.  Finally we discuss a randomization test for assessing the significance of a clustering.  To this end we present an MCMC algorithm for sampling random sets of chains that share certain properties with the original data.  The methods are studied in a series of experiments using real and artificial data.  Results indicate that the methods produce interesting clusterings, and for certain types of inputs improve upon previous work on clustering algorithms for orders.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ukkonen11a/ukkonen11a.pdf</url></Article><Article><id>803</id><title> Introduction to the Special Topic on Grammar Induction, Representation of Language and Language Learning </title><author>Dorota G&amp;#322;owacka, John Shawe-Taylor, Alex Clark, Colin de la Higuera, Mark Johnson</author><abstract>

Grammar induction refers to the process of learning grammars and languages from data; this finds a variety of applications in syntactic pattern recognition, the modeling of natural language acquisition, data mining and machine translation. This special topic contains several papers presenting some of recent developments in the area of grammar induction and language learning, as applied to various problems in Natural Language Processing, including supervised and unsupervised parsing and statistical machine translation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/glowacka11a/glowacka11a.pdf</url></Article><Article><id>804</id><title> Learning a Robust Relevance Model for Search Using Kernel Methods </title><author>Wei Wu, Jun Xu, Hang Li, Satoshi Oyama</author><abstract>

This paper points out that many search relevance models in information retrieval, such as the Vector Space Model, BM25 and Language Models for Information Retrieval, can be viewed as a similarity function between pairs of objects of different types, referred to as an S-function. An S-function is specifically defined as the dot product between the images of two objects in a Hilbert space mapped from two different input spaces. One advantage of taking this view is that one can take a unified and principled approach to address the issues with regard to search relevance. The paper then proposes employing a kernel method to learn a robust relevance model as an S-function, which can effectively deal with the term mismatch problem, one of the biggest challenges in search.  The kernel method exploits a positive semi-definite kernel referred to as an S-kernel. The paper shows that when using an S-kernel the model learned by the kernel method is guaranteed to be an S-function. The paper then gives more general principles for constructing S-kernels. A specific implementation of the kernel method is proposed using the Ranking SVM techniques and click-through data. The proposed approach is employed to learn a relevance model as an extension of BM25, referred to as Robust BM25.  Experimental results on web search and enterprise search data show that Robust BM25 significantly outperforms baseline methods and can successfully tackle the term mismatch problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/wu11a/wu11a.pdf</url></Article><Article><id>805</id><title> Computationally Efficient Convolved Multiple Output Gaussian Processes </title><author>Mauricio A. &amp;#193;lvarez, Neil D. Lawrence</author><abstract>

Recently there has been an increasing interest in regression methods that deal with multiple outputs. This has been motivated partly by frameworks like multitask learning, multisensor networks or structured output data. From a Gaussian processes perspective, the problem reduces to specifying an appropriate covariance function that, whilst being positive semi-definite, captures the dependencies between all the data points and across all the outputs. One approach to account for non-trivial correlations between outputs employs convolution processes. Under a latent function interpretation of the convolution transform we establish dependencies between output variables. The main drawbacks of this approach are the associated computational and storage demands.  In this paper we address these issues. We present different efficient approximations for dependent output Gaussian processes constructed through the convolution formalism. We exploit the conditional independencies present naturally in the model. This leads to a form of the covariance similar in spirit to the so called PITC and FITC approximations for a single output. We show experimental results with synthetic and real data, in particular, we show results in school exams score prediction, pollution prediction and gene expression data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/alvarez11a/alvarez11a.pdf</url></Article><Article><id>806</id><title> Learning from Partial Labels </title><author>Timothee Cour, Ben Sapp, Ben Taskar</author><abstract>

We address the problem of partially-labeled multiclass classification, where instead of a single label per instance, the algorithm is given a candidate set of labels, only one of which is correct.  Our setting is motivated by a common scenario in many image and video collections, where only partial access to labels is available.  The goal is to learn a classifier that can disambiguate the partially-labeled training instances, and generalize to unseen data.  We define an intuitive property of the data distribution that sharply characterizes the ability to learn in this setting and show that effective learning is possible even when all the data is only partially labeled.  Exploiting this property of the data, we propose a convex learning formulation based on minimization of a loss function appropriate for the partial label setting.  We analyze the conditions under which our loss function is asymptotically consistent, as well as its generalization and transductive performance.  We apply our framework to identifying faces culled from web news sources and to naming characters in TV series and movies; in particular, we annotated and experimented on a very large video data set and achieve &lt;i&gt;6%&lt;/i&gt; error for character naming on 16 episodes of the TV series &lt;i&gt;Lost&lt;/i&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/cour11a/cour11a.pdf</url></Article><Article><id>807</id><title> Super-Linear Convergence of Dual Augmented Lagrangian Algorithm for Sparsity Regularized Estimation </title><author>Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama</author><abstract>

We analyze the convergence behaviour of a recently proposed algorithm for regularized estimation called Dual Augmented Lagrangian (DAL).  Our analysis is based on a new interpretation of DAL as a proximal minimization algorithm.  We theoretically show under some conditions that DAL converges super-linearly in a non-asymptotic and global sense. Due to a special modelling of sparse estimation problems in the context of machine learning, the assumptions we make are milder and more natural than those made in conventional analysis of augmented Lagrangian algorithms.  In addition, the new interpretation enables us to generalize DAL to wide varieties of sparse estimation problems.  We experimentally confirm our analysis in  a large scale &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-regularized logistic regression problem and   extensively compare the efficiency of DAL algorithm to previously  proposed algorithms on both synthetic and benchmark data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/tomioka11a/tomioka11a.pdf</url></Article><Article><id>808</id><title> Double Updating Online Learning </title><author>Peilin Zhao, Steven C.H. Hoi, Rong Jin</author><abstract>

In most kernel based online learning algorithms, when an incoming instance is misclassified, it will be added into the pool of support vectors and assigned with a weight, which often remains unchanged during the rest of the learning process. This is clearly insufficient since when a new support vector is added, we generally expect the weights of the other existing support vectors to be updated in order to reflect the influence of the added support vector. In this paper, we propose a new online learning method, termed &lt;b&gt;Double Updating Online Learning&lt;/b&gt;, or &lt;b&gt;DUOL&lt;/b&gt; for short, that explicitly addresses this problem. Instead of only assigning a fixed weight to the misclassified example received at the current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be improved by the proposed online learning method. We conduct an extensive set of empirical evaluations for both binary and multi-class online learning tasks. The experimental results show that the proposed technique is considerably more effective than the state-of-the-art online learning algorithms. The source code is available to public at http://www.cais.ntu.edu.sg/~chhoi/DUOL/.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zhao11a/zhao11a.pdf</url></Article><Article><id>809</id><title> Learning High-Dimensional Markov Forest Distributions: Analysis of Error Rates </title><author>Vincent Y.F. Tan, Animashree Anandkumar, Alan S. Willsky</author><abstract>

The problem of learning forest-structured discrete graphical models from i.i.d. samples is considered. An  algorithm based on pruning of the Chow-Liu tree through adaptive thresholding is proposed.   It is shown that this algorithm is both  structurally consistent and risk consistent and  the error probability of structure learning decays faster than any polynomial in the number of samples   under fixed model size.  For the  high-dimensional scenario where the size of the  model &lt;i&gt;d&lt;/i&gt; and the number of edges &lt;i&gt;k&lt;/i&gt; scale with the number of samples &lt;i&gt;n&lt;/i&gt;,  sufficient conditions on &lt;i&gt;(n,d,k)&lt;/i&gt; are given for  the algorithm to satisfy structural and risk consistencies. In addition, the extremal structures for learning are identified; we prove that the independent (resp., tree) model is the hardest (resp., easiest) to learn using the proposed algorithm in terms of error rates for structure learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/tan11a/tan11a.pdf</url></Article><Article><id>810</id><title> &lt;i&gt;X&lt;/i&gt;-Armed Bandits </title><author>S&amp;#233;bastien Bubeck, R&amp;#233;mi Munos, Gilles Stoltz, Csaba Szepesv&amp;#225;ri</author><abstract>

We consider a generalization of stochastic bandits where the set of arms, &lt;i&gt;X&lt;/i&gt;, is allowed to be a generic measurable space and the mean-payoff function is "locally Lipschitz" with respect to a dissimilarity function that is known to the decision maker.  Under this condition we construct an arm selection policy, called HOO (hierarchical optimistic optimization), with improved regret bounds compared to previous results for a large class of problems.  In particular, our results imply that if &lt;i&gt;X&lt;/i&gt; is the unit hypercube in a Euclidean space and the mean-payoff function has a finite number of global maxima around which the behavior of the function is locally continuous with a known smoothness degree, then the expected regret of HOO is bounded up to a logarithmic factor by &lt;i&gt;&amp;#8730;n&lt;/i&gt;, that is, the rate of growth of the regret is independent of the dimension of the space.  We also prove the minimax optimality of our algorithm when the dissimilarity is a metric.  Our basic strategy has quadratic computational complexity as a function of the number of time steps and does not rely on the doubling trick.  We also introduce a modified strategy, which relies on the doubling trick but runs in linearithmic time.  Both results are improvements with respect to previous approaches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/bubeck11a/bubeck11a.pdf</url></Article><Article><id>811</id><title> Domain Decomposition Approach for Fast Gaussian Process Regression of Large Spatial Data Sets </title><author>Chiwoo Park, Jianhua Z. Huang, Yu Ding</author><abstract>

Gaussian process regression is a flexible and powerful tool for machine learning, but the high computational complexity hinders its broader applications. In this paper, we propose a new approach for fast computation of Gaussian process regression with a focus on large spatial data sets. The approach decomposes the domain of a regression function into small subdomains and infers a local piece of the regression function for each subdomain. We explicitly address the mismatch problem of the local pieces on the boundaries of neighboring subdomains by imposing continuity constraints. The new approach has comparable or better computation complexity as other competing methods, but it is easier to be parallelized for faster computation. Moreover, the method can be adaptive to non-stationary features because of its local nature and, in particular, its use of different hyperparameters of the covariance function for different local regions. We illustrate application of the method and demonstrate its advantages over existing methods using two synthetic data sets and two real spatial data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/park11a/park11a.pdf</url></Article><Article><id>812</id><title> A Bayesian Approach for Learning and Planning in Partially Observable Markov Decision Processes </title><author>St&amp;#233;phane Ross, Joelle Pineau, Brahim Chaib-draa, Pierre Kreitmann</author><abstract>

Bayesian learning methods have recently been shown to provide an elegant solution to the exploration-exploitation trade-off in reinforcement learning. However most investigations of Bayesian reinforcement learning to date focus on the standard Markov Decision Processes (MDPs).  The primary focus of this paper is to extend these ideas to the case of partially observable domains, by introducing the Bayes-Adaptive Partially Observable Markov Decision Processes. This new framework can be used to simultaneously (1) learn a model of the POMDP domain through interaction with the environment, (2) track the state of the system under partial observability, and (3) plan (near-)optimal sequences of actions. An important contribution of this paper is to provide theoretical results showing how the model can be finitely approximated while preserving good learning performance. We present approximate algorithms for belief tracking and planning in this model, as well as empirical results that illustrate how the model estimate and agent's return improve as a function of experience.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ross11a/ross11a.pdf</url></Article><Article><id>813</id><title> Learning Latent Tree Graphical Models </title><author>Myung Jin Choi, Vincent Y.F. Tan, Animashree Anandkumar, Alan S. Willsky</author><abstract>

We study the problem of learning a latent tree graphical model where samples are available only from a subset of variables. We propose two consistent and computationally efficient algorithms for learning &lt;i&gt;minimal&lt;/i&gt; latent trees, that is, trees without any redundant hidden nodes. Unlike many existing methods, the observed nodes (or variables) are not constrained to be leaf nodes. Our algorithms can be applied to both discrete and Gaussian random variables and our learned models are such that all  the observed and latent variables have  the same domain (state space). Our first algorithm, &lt;i&gt;recursive grouping&lt;/i&gt;, builds the latent tree recursively by identifying sibling groups using   so-called information distances. One of the main contributions of this work is our second algorithm, which we refer to as &lt;i&gt;CLGrouping&lt;/i&gt;. CLGrouping starts with a pre-processing procedure in which a tree over the observed variables is constructed. This global step groups the observed nodes that are likely to be close to each other in the true latent tree, thereby guiding subsequent recursive grouping (or   equivalent procedures such as neighbor-joining) on much smaller subsets of variables. This results in more accurate and efficient learning of latent trees. We also present regularized versions of our algorithms that learn latent tree approximations of arbitrary distributions. We compare the proposed algorithms to other methods by  performing extensive numerical experiments on various latent tree graphical models such as hidden Markov models and star graphs.  In addition, we demonstrate the applicability of our methods on real-world data sets by modeling the dependency structure of monthly stock returns in the S&amp;P index and of the words in the 20 newsgroups data set.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/choi11b/choi11b.pdf</url></Article><Article><id>814</id><title> Hyper-Sparse Optimal Aggregation </title><author>St&amp;#233;phane Ga&amp;#239;ffas, Guillaume Lecu&amp;#233;</author><abstract>

Given a finite set &lt;i&gt;F&lt;/i&gt; of functions and a learning sample, the aim of an aggregation procedure is to have a risk as close as possible to risk of the best function in &lt;i&gt;F&lt;/i&gt;. Up to now, optimal aggregation procedures are convex combinations of every elements of &lt;i&gt;F&lt;/i&gt;. In this paper, we prove that optimal aggregation procedures combining only two functions in &lt;i&gt;F&lt;/i&gt; exist. Such algorithms are of particular interest when &lt;i&gt;F&lt;/i&gt; contains many irrelevant functions that should not appear in the aggregation procedure. Since selectors are suboptimal aggregation procedures, this proves that two is the minimal number of elements of &lt;i&gt;F&lt;/i&gt; required for the construction of an optimal aggregation procedure in every situations. Then, we perform a numerical study for the problem of selection of the regularization parameters of the Lasso and the Elastic-net estimators. We compare on simulated examples our aggregation algorithms to aggregation with exponential weights, to Mallow's &lt;i&gt;C&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; and to cross-validation selection procedures.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/gaiffas11a/gaiffas11a.pdf</url></Article><Article><id>815</id><title> A Refined Margin Analysis for Boosting Algorithms via Equilibrium Margin </title><author>Liwei Wang, Masashi Sugiyama, Zhaoxiang Jing, Cheng Yang, Zhi-Hua Zhou, Jufu Feng</author><abstract>

Much attention has been paid to the theoretical explanation of the empirical success of AdaBoost. The most influential work is the margin theory, which is essentially an upper bound for the generalization error of any voting classifier in terms of the margin distribution over the training data. However, important questions were raised about the margin explanation. Breiman (1999) proved a bound in terms of the minimum margin, which is sharper than the margin distribution bound. He argued that the minimum margin would be better in predicting the generalization error.  Grove and Schuurmans (1998) developed an algorithm called LP-AdaBoost which maximizes the minimum margin while keeping all other factors the same as AdaBoost. In experiments however, LP-AdaBoost usually performs worse than AdaBoost, putting the margin explanation into serious doubt. In this paper, we make a refined analysis of the margin theory. We prove a bound in terms of a new margin measure called the &lt;i&gt;Equilibrium margin (Emargin)&lt;/i&gt;. The Emargin bound is uniformly sharper than Breiman's minimum margin bound. Thus our result suggests that the minimum margin may be not crucial for the generalization error. We also show that a large Emargin and a small empirical error at Emargin imply a smaller bound of the generalization error. Experimental results on benchmark data sets demonstrate that AdaBoost usually has a larger Emargin and a smaller test error than LP-AdaBoost, which agrees well with our theory.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/wang11a/wang11a.pdf</url></Article><Article><id>816</id><title> Stochastic Methods for &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;-regularized Loss Minimization </title><author>Shai Shalev-Shwartz, Ambuj Tewari</author><abstract>

We describe and analyze two stochastic methods for &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; regularized loss minimization problems, such as the Lasso.  The first method updates the weight of a single feature at each iteration while the second method updates the entire weight vector but only uses a single training example at each iteration.  In both methods, the choice of feature or example is uniformly at random. Our theoretical runtime analysis suggests that the stochastic methods should outperform state-of-the-art deterministic approaches, including their deterministic counterparts, when the size of the problem is large. We demonstrate the advantage of stochastic methods by experimenting with synthetic and natural data sets.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/shalev-shwartz11a/shalev-shwartz11a.pdf</url></Article><Article><id>817</id><title> Internal Regret with Partial Monitoring: Calibration-Based Optimal Algorithms </title><author>Vianney Perchet</author><abstract>

We provide consistent random algorithms for sequential decision under partial monitoring, when the decision maker does not observe the outcomes but receives instead random feedback signals. Those algorithms have no internal regret in the sense that, on the set of stages  where the decision maker chose his action according to a given law, the average payoff could not have been improved in average by using any other fixed law.  &lt;br&gt; They are based on a generalization of calibration, no longer defined in terms of  a Vorono&amp;#239; diagram but instead of a Laguerre diagram (a more general concept). This allows us to bound, for the first time in this general framework,  the expected average internal, as well as the usual external, regret at stage &lt;i&gt;n&lt;/i&gt; by &lt;i&gt;O(n&lt;sup&gt;-1/3&lt;/sup&gt;)&lt;/i&gt;, which is known to be optimal.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/perchet11a/perchet11a.pdf</url></Article><Article><id>818</id><title> Dirichlet Process Mixtures of Generalized Linear Models </title><author>Lauren A. Hannah, David M. Blei, Warren B. Powell</author><abstract>

We propose Dirichlet Process mixtures of Generalized Linear Models (DP-GLM), a new class of methods for nonparametric regression.  Given a data set of input-response pairs, the DP-GLM produces a global model of the joint distribution through a mixture of local generalized linear models.  DP-GLMs allow both continuous and categorical inputs, and can model the same class of responses that can be modeled with a generalized linear model.  We study the properties of the DP-GLM, and show why it provides better predictions and density estimates than existing Dirichlet process mixture regression models.  We give conditions for weak consistency of the joint distribution and pointwise consistency of the regression estimate.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/hannah11a/hannah11a.pdf</url></Article><Article><id>819</id><title> Kernel Regression in the Presence of Correlated Errors </title><author>Kris De Brabanter, Jos De Brabanter, Johan A.K. Suykens, Bart De Moor</author><abstract>

It is a well-known problem that obtaining a correct bandwidth and/or smoothing parameter in nonparametric regression is difficult in the presence of correlated errors. There exist a wide variety of methods coping with this problem, but they all critically depend on a tuning procedure which requires accurate information about the correlation structure. We propose a bandwidth selection procedure based on bimodal kernels which successfully removes the correlation without requiring any prior knowledge about its structure and its parameters. Further, we show that the form of the kernel is very important when errors are correlated which is in contrast to the independent and identically distributed (i.i.d.) case. Finally, some extensions are proposed to use the proposed criterion in support vector machines and least squares support vector machines for regression.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/debrabanter11a/debrabanter11a.pdf</url></Article><Article><id>820</id><title> Generalized TD Learning </title><author>Tsuyoshi Ueno, Shin-ichi Maeda, Motoaki Kawanabe, Shin Ishii</author><abstract>

Since the invention of temporal difference (TD) learning (Sutton, 1988), many new algorithms for model-free policy evaluation have been proposed.  Although they have brought much progress in practical applications of reinforcement learning (RL), there still remain fundamental problems concerning statistical properties of the value function estimation.  To solve these problems, we introduce a new framework, &lt;i&gt;semiparametric statistical inference&lt;/i&gt;, to model-free policy evaluation.  This framework generalizes TD learning and its extensions, and allows us to investigate statistical properties of both of batch and online learning procedures for the value function estimation in a unified way in terms of &lt;i&gt;estimating functions&lt;/i&gt;.  Furthermore, based on this framework, we derive an optimal estimating function with the &lt;i&gt;minimum asymptotic variance&lt;/i&gt; and propose batch and online learning algorithms  which achieve the optimality.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ueno11a/ueno11a.pdf</url></Article><Article><id>821</id><title> The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Data Sets </title><author>Michael Hahsler, Sudheer Chelluboina, Kurt Hornik, Christian Buchta</author><abstract>

This paper describes the ecosystem of R add-on packages developed around the infrastructure provided by the package &lt;b&gt;arules&lt;/b&gt;. The packages provide comprehensive functionality for analyzing interesting patterns including frequent itemsets, association rules, frequent sequences and for building applications like associative classification. After discussing the ecosystem's design we illustrate the ease of mining and visualizing rules with a short example.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/hahsler11a/hahsler11a.pdf</url></Article><Article><id>822</id><title> A Cure for Variance Inflation in High Dimensional Kernel Principal Component Analysis </title><author>Trine Julie Abrahamsen, Lars Kai Hansen</author><abstract>

Small sample high-dimensional principal component analysis (PCA) suffers from variance inflation and lack of generalizability. It has earlier been pointed out that a simple leave-one-out variance renormalization scheme can cure the problem. In this paper we generalize the cure in two directions: First, we propose a computationally less intensive approximate leave-one-out estimator, secondly, we show that variance inflation is also present in kernel principal component analysis (kPCA) and we provide a non-parametric renormalization scheme which can quite efficiently restore generalizability in kPCA. As for PCA our analysis also suggests a simplified approximate expression.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/abrahamsen11a/abrahamsen11a.pdf</url></Article><Article><id>823</id><title> Exploiting Best-Match Equations for Efficient Reinforcement Learning </title><author>Harm van Seijen, Shimon Whiteson, Hado van Hasselt, Marco Wiering</author><abstract>

This article presents and evaluates &lt;i&gt;best-match learning&lt;/i&gt;, a new approach to reinforcement learning that  trades off the sample efficiency of model-based methods with the space efficiency of model-free methods.  Best-match learning works by approximating the solution to a set of &lt;i&gt;best-match equations&lt;/i&gt;, which combine a sparse model with a model-free Q-value function constructed from samples not used by the model.  We prove that, unlike regular sparse model-based methods, best-match learning is guaranteed to converge to the optimal Q-values in the tabular case.  Empirical results demonstrate that best-match learning can substantially outperform regular sparse model-based methods, as well as several model-free methods that strive to improve the sample efficiency of temporal-difference methods. In addition, we demonstrate that best-match learning can be successfully combined with function approximation.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/vanseijen11a/vanseijen11a.pdf</url></Article><Article><id>824</id><title> Information Rates of Nonparametric Gaussian Process Methods </title><author>Aad van der Vaart, Harry van Zanten</author><abstract>

We consider the quality of learning a response function by a nonparametric Bayesian approach using a Gaussian process (GP) prior on the response function. We upper bound the quadratic risk of the learning procedure, which in turn is an upper bound on the Kullback-Leibler information between the predictive and true data distribution. The upper bound is expressed in small ball probabilities and concentration measures of the GP prior.  We illustrate the computation of the upper bound for the Mat&amp;#233;rn  and squared exponential kernels.  For these priors the risk, and hence the information criterion, tends to zero for all continuous response functions. However, the rate at which this happens depends on the combination of true response function and Gaussian prior, and is expressible in a certain concentration function. In particular, the results show that for good performance, the regularity of the GP prior should match the regularity of the unknown response function.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/vandervaart11a/vandervaart11a.pdf</url></Article><Article><id>825</id><title> Adaptive Subgradient Methods for Online Learning and Stochastic Optimization </title><author>John Duchi, Elad Hazan, Yoram Singer</author><abstract>

We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf</url></Article><Article><id>826</id><title> On the Relation between Realizable and Nonrealizable Cases of the Sequence Prediction Problem </title><author>Daniil Ryabko</author><abstract>

A sequence &lt;i&gt;x&lt;sub&gt;1&lt;/sub&gt;,...,x&lt;sub&gt;n&lt;/sub&gt;,...&lt;/i&gt; of discrete-valued observations is generated according to some unknown probabilistic law (measure) &lt;i&gt;&amp;#956;&lt;/i&gt;.  After observing each outcome, one is required to give  conditional probabilities of the next observation.  The realizable case is when the  measure  &lt;i&gt;&amp;#956;&lt;/i&gt; belongs to an arbitrary but known class &lt;i&gt;C&lt;/i&gt;  of  process measures.  The non-realizable case is when &lt;i&gt;&amp;#956;&lt;/i&gt; is completely arbitrary, but the prediction performance is measured with respect to a given set &lt;i&gt;C&lt;/i&gt; of process measures.  We are interested in the relations between these problems and between their solutions, as well as in characterizing the cases when a solution exists and finding these solutions.  We show that if the quality of prediction is measured using the total variation distance, then these problems coincide, while if it is measured using the expected average KL divergence, then they are different. For some of the formalizations we also show that when a solution exists it can be obtained as a Bayes mixture over a countable subset of &lt;i&gt;C&lt;/i&gt;.  We also obtain several characterization of those sets &lt;i&gt;C&lt;/i&gt; for which solutions to the considered problems exist.  As an illustration to the general results obtained, we show that a solution to the non-realizable case of the sequence prediction problem exists for the set of all finite-memory processes, but does not exist for the set of all stationary processes.  It should be emphasized that the framework  is completely general: the  processes measures considered are not required to be i.i.d., mixing, stationary, or to belong to any parametric family.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ryabko11a/ryabko11a.pdf</url></Article><Article><id>827</id><title> Discriminative Learning of Bayesian Networks via Factorized Conditional Log-Likelihood </title><author>Alexandra M. Carvalho, Teemu Roos, Arlindo L. Oliveira, Petri Myllym&amp;#228;ki</author><abstract>

We propose an efficient and parameter-free scoring criterion, the factorized conditional log-likelihood (f&amp;#770;CLL), for learning Bayesian network classifiers. The proposed score is an approximation of the conditional log-likelihood criterion. The approximation is devised in order to guarantee decomposability over the network structure, as well as efficient estimation of the optimal parameters, achieving the same time and space complexity as the traditional log-likelihood scoring criterion.  The resulting criterion has an information-theoretic interpretation based on interaction information, which exhibits its discriminative nature. To evaluate the performance of the proposed criterion, we present an empirical comparison with state-of-the-art classifiers. Results on a large suite of benchmark data sets from the UCI repository show that f&amp;#770;CLL-trained classifiers achieve at least as good accuracy as the best compared classifiers, using significantly less computational resources.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/carvalho11a/carvalho11a.pdf</url></Article><Article><id>828</id><title> Multiple Kernel Learning Algorithms </title><author>Mehmet G&amp;#246;nen, Ethem Alpayd&amp;#305;n</author><abstract>

In recent years, several methods have been proposed to combine multiple kernels instead of using a single one. These different kernels may correspond to using different notions of similarity or may be using information coming from multiple sources (different representations or different feature subsets). In trying to organize and highlight the similarities and differences between them, we give a taxonomy of and review several multiple kernel learning algorithms. We perform experiments on real data sets for better illustration and comparison of existing algorithms. We see that though there may not be large differences in terms of accuracy, there is difference between them in complexity as given by the number of stored support vectors, the sparsity of the solution as given by the number of used kernels, and training time complexity. We see that overall, using multiple kernels instead of a single one is useful and believe that combining kernels in a nonlinear or data-dependent way seems more promising than linear combination in fusing information provided by simple linear kernels, whereas linear methods are more reasonable when combining complex Gaussian kernels.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/gonen11a/gonen11a.pdf</url></Article><Article><id>829</id><title> Smoothness, Disagreement Coefficient, and the Label Complexity of Agnostic Active Learning </title><author>Liwei Wang</author><abstract>

We study pool-based active learning in the presence of noise, that is, the agnostic setting. It is known that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have an advantage. Previous works have shown that the label complexity of active learning relies on the &lt;i&gt;disagreement coefficient&lt;/i&gt; which often characterizes the intrinsic difficulty of the learning problem. In this paper, we study the disagreement coefficient of classification problems for which the classification boundary is smooth and the data distribution has a density that can be bounded by a smooth function.  We prove upper and lower bounds for the disagreement coefficients of both finitely and infinitely smooth problems. Combining with existing results, it shows that active learning is superior to passive supervised learning for smooth problems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/wang11b/wang11b.pdf</url></Article><Article><id>830</id><title> MSVMpack: A Multi-Class Support Vector Machine Package </title><author>Fabien Lauer, Yann Guermeur</author><abstract>

This paper describes MSVMpack, an open source software package dedicated to our generic model of &lt;i&gt;multi-class&lt;/i&gt; support vector machine.  All four multi-class support vector machines (M-SVMs) proposed so far in the literature appear as instances of this model. MSVMpack provides for them the first unified implementation and offers a convenient basis to develop other instances.  This is also the first parallel implementation for M-SVMs.  The package consists in a set of command-line tools with a callable library.  The documentation includes a tutorial, a user's guide and a developer's guide. 

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/lauer11a/lauer11a.pdf</url></Article><Article><id>831</id><title> Proximal Methods for Hierarchical Sparse Coding </title><author>Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, Francis Bach</author><abstract>

Sparse coding consists in representing signals as sparse linear combinations of atoms selected from a dictionary.  We consider an extension of this framework where the atoms are further assumed to be embedded in a tree. This is achieved using a recently introduced tree-structured sparse regularization norm, which has proven useful in several applications. This norm leads to regularized problems that are difficult to optimize, and in this paper, we propose efficient algorithms for solving them.  More precisely, we show that the proximal operator associated with this norm is computable exactly via a dual approach that can be viewed as the composition of elementary proximal operators.  Our procedure has a complexity linear, or close to linear, in the number of atoms, and allows the use of accelerated gradient techniques to solve the tree-structured sparse approximation problem at the same computational cost as traditional ones using the &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm.  Our method is efficient and scales gracefully to millions of variables, which we illustrate in two types of applications: first, we consider &lt;i&gt;fixed&lt;/i&gt; hierarchical dictionaries of wavelets to denoise natural images.  Then, we apply our optimization tools in the context of &lt;i&gt;dictionary learning&lt;/i&gt;, where learned dictionary elements naturally self-organize in a prespecified arborescent structure, leading to better performance in reconstruction of natural image patches.  When applied to text documents, our method learns hierarchies of topics, thus providing a competitive alternative to probabilistic topic models.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/jenatton11a/jenatton11a.pdf</url></Article><Article><id>832</id><title> Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models </title><author>Sharon Goldwater, Thomas L. Griffiths, Mark Johnson</author><abstract>

Standard statistical models of language fail to capture one of the most striking properties of natural languages: the power-law distribution in the frequencies of word tokens. We present a framework for developing statistical models that can generically produce power laws, breaking generative models into two stages. The first stage, the generator, can be any standard probabilistic model, while the second stage, the adaptor, transforms the word frequencies of this model to provide a closer match to natural language. We show that two commonly used Bayesian models, the Dirichlet-multinomial model and the Dirichlet process, can be viewed as special cases of our framework.  We discuss two stochastic processes---the Chinese restaurant process and its two-parameter generalization based on the Pitman-Yor process---that can be used as adaptors in our framework to produce power-law distributions over word frequencies.  We show that these adaptors justify common estimation procedures based on logarithmic or inverse-power transformations of empirical frequencies.  In addition, taking the Pitman-Yor Chinese restaurant process as an adaptor justifies the appearance of type frequencies in formal analyses of natural language and improves the performance of a model for unsupervised learning of morphology.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/goldwater11a/goldwater11a.pdf</url></Article><Article><id>833</id><title> &lt;i&gt;Waffles&lt;/i&gt;: A Machine Learning Toolkit </title><author>Michael Gashler</author><abstract>

We present a breadth-oriented collection of cross-platform command-line tools for researchers in machine learning called &lt;i&gt;Waffles&lt;/i&gt;. The &lt;i&gt;Waffles&lt;/i&gt; tools are designed to offer a broad spectrum of functionality in a manner that is friendly for scripted automation. All functionality is also available in a C++ class library. &lt;i&gt;Waffles&lt;/i&gt; is available under the GNU Lesser General Public License.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/gashler11a/gashler11a.pdf</url></Article><Article><id>834</id><title> Universality, Characteristic Kernels and RKHS Embedding of Measures </title><author>Bharath K. Sriperumbudur, Kenji Fukumizu, Gert R.G. Lanckriet</author><abstract>

Over the last few years, two different notions of positive definite (pd) kernels---universal and characteristic---have been developing in parallel in machine learning: universal kernels are proposed in the context of achieving the Bayes risk by kernel-based classification/regression algorithms while characteristic kernels are introduced in the context of distinguishing probability measures by embedding them into a reproducing kernel Hilbert space (RKHS). However, the relation between these two notions is not well understood. The main contribution of this paper is to clarify the relation between universal and characteristic kernels by presenting a unifying study relating them to RKHS embedding of measures, in addition to clarifying their relation to other common notions of strictly pd, conditionally strictly pd and &lt;i&gt;integrally strictly pd&lt;/i&gt; kernels. For &lt;i&gt;radial&lt;/i&gt; kernels on &lt;i&gt;&amp;#8476;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;, all these notions are shown to be equivalent.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/sriperumbudur11a/sriperumbudur11a.pdf</url></Article><Article><id>835</id><title> MULAN: A Java Library for Multi-Label Learning </title><author>Grigorios Tsoumakas, Eleftherios Spyromitros-Xioufis, Jozef Vilcek, Ioannis Vlahavas</author><abstract>

MULAN is a Java library for learning from multi-label data. It offers a variety of classification, ranking, thresholding and dimensionality reduction algorithms, as well as algorithms for learning from hierarchically structured labels. In addition, it contains an evaluation framework that calculates a rich variety of performance measures.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/tsoumakas11a/tsoumakas11a.pdf</url></Article><Article><id>836</id><title> Union Support Recovery in Multi-task Learning </title><author>Mladen Kolar, John Lafferty, Larry Wasserman</author><abstract>

We sharply characterize the performance of different penalization schemes for the problem of selecting the relevant variables in the multi-task setting.  Previous work focuses on the regression problem where conditions on the design matrix complicate the analysis.  A clearer and simpler picture emerges by studying the Normal means model.  This model, often used in the field of statistics, is a simplified model that provides a laboratory for studying complex procedures.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/kolar11a/kolar11a.pdf</url></Article><Article><id>837</id><title> Parallel Algorithm for Learning Optimal Bayesian Network Structure </title><author>Yoshinori Tamada, Seiya Imoto, Satoru Miyano</author><abstract>

We present a parallel algorithm for the score-based optimal structure search of Bayesian networks.  This algorithm is based on a dynamic programming (DP) algorithm having &lt;i&gt;O(n &amp;#8901; 2&lt;sup&gt;n&lt;/sup&gt;)&lt;/i&gt; time and space complexity, which is known to be the fastest algorithm for the optimal structure search of networks with &lt;i&gt;n&lt;/i&gt; nodes.  The bottleneck of the problem is the memory requirement, and therefore, the algorithm is currently applicable for up to a few tens of nodes.  While the recently proposed algorithm overcomes this limitation by a space-time trade-off, our proposed algorithm realizes direct parallelization of the original DP algorithm with &lt;i&gt;O(n&lt;sup&gt;&amp;#963;&lt;/sup&gt;)&lt;/i&gt; time and space overhead calculations, where &lt;i&gt;&amp;#963;&gt;0&lt;/i&gt; controls the communication-space trade-off.  The overall time and space complexity is &lt;i&gt;O(n&lt;sup&gt;&amp;#963;+1&lt;/sup&gt; 2&lt;sup&gt;n&lt;/sup&gt;)&lt;/i&gt;.  This algorithm splits the search space so that the required communication between independent calculations is minimal.  Because of this advantage, our algorithm can run on distributed memory supercomputers.  Through computational experiments, we confirmed that our algorithm can run in parallel using up to 256 processors with a parallelization efficiency of 0.74, compared to the original DP algorithm with a single processor.  We also demonstrate optimal structure search for a 32-node network without any constraints, which is the largest network search presented in literature.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/tamada11a/tamada11a.pdf</url></Article><Article><id>838</id><title> Distance Dependent Chinese Restaurant Processes </title><author>David M. Blei, Peter I. Frazier</author><abstract>

We develop the distance dependent Chinese restaurant process, a flexible class of distributions over partitions that allows for dependencies between the elements.  This class can be used to model many kinds of dependencies between data in infinite clustering models, including dependencies arising from time, space, and network connectivity.  We examine the properties of the distance dependent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs sampler for both fully observed and latent mixture settings.  We study its empirical performance with three text corpora.  We show that relaxing the assumption of exchangeability with distance dependent CRPs can provide a better fit to sequential data and network data.  We also show that the distance dependent CRP representation of the traditional CRP mixture leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/blei11a/blei11a.pdf</url></Article><Article><id>839</id><title> LPmade: Link Prediction Made Easy </title><author>Ryan N. Lichtenwalter, Nitesh V. Chawla</author><abstract>

LPmade is a complete cross-platform software solution for multi-core link prediction and related tasks and analysis. Its first principal contribution is a scalable network library supporting high-performance implementations of the most commonly employed unsupervised link prediction methods. Link prediction in longitudinal data requires a sophisticated and disciplined procedure for correct results and fair evaluation, so the second principle contribution of LPmade is a sophisticated GNU make architecture that completely automates link prediction, prediction evaluation, and network analysis. Finally, LPmade streamlines and automates the procedure for creating multivariate supervised link prediction models with a version of WEKA modified to operate effectively on extremely large data sets. With mere minutes of manual work, one may start with a raw stream of records representing a network and progress through hundreds of steps to generate plots, gigabytes or terabytes of output, and actionable or publishable results.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/lichtenwalter11a/lichtenwalter11a.pdf</url></Article><Article><id>840</id><title> Natural Language Processing (Almost) from Scratch </title><author>Ronan Collobert, Jason Weston, L&amp;#233;on Bottou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa</author><abstract>

We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling.  This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge.  Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data.  This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf</url></Article><Article><id>841</id><title> Weisfeiler-Lehman Graph Kernels </title><author>Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, Kurt Mehlhorn, Karsten M. Borgwardt</author><abstract>

In this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence.  In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime.  Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf</url></Article><Article><id>842</id><title> Kernel Analysis of Deep Networks </title><author>Gr&amp;#233;goire Montavon, Mikio L. Braun, Klaus-Robert M&amp;#252;ller</author><abstract>

When training deep networks it is common knowledge that an efficient and well generalizing representation of the problem is formed. In this paper we aim to elucidate what makes the emerging representation successful. We analyze the layer-wise evolution of the representation in a deep network by building a sequence of deeper and deeper kernels that subsume the mapping performed by more and more layers of the deep network and measuring how these increasingly complex kernels fit the learning problem. We observe that deep networks create increasingly better representations of the learning problem and that the structure of the deep network controls how fast the representation of the task is formed layer after layer.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/montavon11a/montavon11a.pdf</url></Article><Article><id>843</id><title> Theoretical Analysis of Bayesian Matrix Factorization </title><author>Shinichi Nakajima, Masashi Sugiyama</author><abstract>

Recently, &lt;i&gt;variational Bayesian&lt;/i&gt; (VB) techniques have been applied to probabilistic matrix factorization and shown to perform very well in experiments.  In this paper, we theoretically elucidate properties of the VB matrix factorization (VBMF) method.  Through finite-sample analysis of the VBMF estimator, we show that two types of shrinkage factors exist in the VBMF estimator: the &lt;i&gt;positive-part James-Stein (PJS)&lt;/i&gt; shrinkage and the &lt;i&gt;trace-norm&lt;/i&gt; shrinkage, both acting on each singular component separately for producing low-rank solutions.  The trace-norm shrinkage is simply induced by non-flat prior information, similarly to the maximum a posteriori (MAP) approach.  Thus, no trace-norm shrinkage remains when priors are non-informative.  On the other hand, we show a counter-intuitive fact that the PJS shrinkage factor is kept activated even with flat priors.  This is shown to be induced by the &lt;i&gt;non-identifiability&lt;/i&gt; of the matrix factorization model, that is, the mapping between the target matrix and factorized matrices is not one-to-one.  We call this &lt;i&gt;model-induced regularization&lt;/i&gt;.  We further extend our analysis to empirical Bayes scenarios where hyperparameters are also learned based on the VB free energy.  Throughout the paper, we assume no missing entry in the observed matrix, and therefore collaborative filtering is out of scope.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/nakajima11a/nakajima11a.pdf</url></Article><Article><id>844</id><title> Bayesian Co-Training </title><author>Shipeng Yu, Balaji Krishnapuram, R&amp;#243;mer Rosales, R. Bharat Rao</author><abstract>

Co-training (or more generally, co-regularization) has been a popular algorithm for semi-supervised learning in data with two feature representations (or views), but the fundamental assumptions underlying this type of models are still unclear. In this paper we propose a Bayesian undirected graphical model for co-training, or more generally for semi-supervised multi-view learning. This makes explicit the previously unstated assumptions of a large class of co-training type algorithms, and also clarifies the circumstances under which these assumptions fail. Building upon new insights from this model, we propose an improved method for co-training, which is a novel co-training kernel for Gaussian process classifiers. The resulting approach is convex and avoids local-maxima problems, and it can also automatically estimate how much each view should be trusted to accommodate noisy or unreliable views. The Bayesian co-training approach can also elegantly handle data samples with missing views, that is, some of the views are not available for some data points at learning time. This is further extended to an active sensing framework, in which the missing (sample, view) pairs are actively acquired to improve learning performance. The strength of active sensing model is that one actively sensed (sample, view) pair would improve the joint multi-view classification on all the samples.  Experiments on toy data and several real world data sets illustrate the benefits of this approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/yu11a/yu11a.pdf</url></Article><Article><id>845</id><title> Convex and Network Flow Optimization for Structured Sparsity </title><author>Julien Mairal, Rodolphe Jenatton, Guillaume Obozinski, Francis Bach</author><abstract>

We consider a class of learning problems regularized by a structured sparsity-inducing norm defined as the sum of &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;- or &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;&amp;#8734;&lt;/sub&gt;-norms over groups of variables. Whereas much effort has been put in developing fast optimization techniques when the groups are disjoint or embedded in a hierarchy, we address here the case of general overlapping groups.  To this end, we present two different strategies: On the one hand, we show that the proximal operator associated with a sum of &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;&amp;#8734;&lt;/sub&gt;-norms can be computed exactly in polynomial time by solving a &lt;i&gt;quadratic min-cost flow problem&lt;/i&gt;, allowing the use of accelerated proximal gradient methods.  On the other hand, we use proximal splitting techniques, and address an equivalent formulation with non-overlapping groups, but in higher dimension and with additional constraints.  We propose efficient and scalable algorithms exploiting these two strategies, which are significantly faster than alternative approaches.  We illustrate these methods with several problems such as CUR matrix factorization, multi-task learning of tree-structured dictionaries, background subtraction in video sequences, image denoising with wavelets, and topographic dictionary learning of natural image patches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/mairal11a/mairal11a.pdf</url></Article><Article><id>846</id><title> Large Margin Hierarchical Classification with Mutually Exclusive Class Membership </title><author>Huixin Wang, Xiaotong Shen, Wei Pan</author><abstract>

In hierarchical classification, class labels are structured, that is each label value corresponds to one non-root node in a tree, where the inter-class relationship for classification is specified by directed paths of the tree. In such a situation, the focus has been on how to leverage the inter-class relationship to enhance the performance of flat classification, which ignores such dependency.  This is critical when the number of classes becomes large relative to the sample size. This paper considers single-path or partial-path hierarchical classification, where only one path is permitted from the root to a leaf node. A large margin method is introduced based on a new concept of generalized margins with respect to hierarchy. For implementation, we consider support vector machines and &amp;#968;-learning. Numerical and theoretical analyses suggest that the proposed method achieves the desired objective and compares favorably against strong competitors in the literature, including its flat counterparts.  Finally, an application to gene function prediction is discussed.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/wang11c/wang11c.pdf</url></Article><Article><id>847</id><title> Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes </title><author>Elias Zavitsanos, Georgios Paliouras, George A. Vouros</author><abstract>

This paper presents hHDP, a hierarchical algorithm for representing a document collection as a hierarchy of latent topics, based on Dirichlet process priors. The hierarchical nature of the algorithm refers to the Bayesian hierarchy that it comprises, as well as to the hierarchy of the latent topics. hHDP relies on nonparametric Bayesian priors and it is able to infer a hierarchy of topics, without making any assumption about the depth of the learned hierarchy and the branching factor at each level. We evaluate the proposed method on real-world data sets in document modeling, as well as in ontology learning, and provide qualitative and quantitative evaluation results, showing that the model is robust, it models accurately the training data set and is able to generalize on held-out data.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zavitsanos11a/zavitsanos11a.pdf</url></Article><Article><id>848</id><title> Structured Variable Selection with Sparsity-Inducing Norms </title><author>Rodolphe Jenatton, Jean-Yves Audibert, Francis Bach</author><abstract>

We consider the empirical risk minimization problem for linear supervised learning, with regularization by structured sparsity-inducing norms. These are defined as sums of Euclidean norms on certain subsets of variables, extending the usual &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm and the group &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm by allowing the subsets to overlap. This leads to a specific set of allowed nonzero patterns for the solutions of such problems. We first explore the relationship between the groups defining the norm and the resulting nonzero patterns, providing both forward and backward algorithms to go back and forth from groups to patterns. This allows the design of norms adapted to specific prior knowledge expressed in terms of nonzero patterns. We also present an efficient active set algorithm, and analyze the consistency of variable selection for least-squares linear regression in low and high-dimensional settings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/jenatton11b/jenatton11b.pdf</url></Article><Article><id>849</id><title> Scikit-learn: Machine Learning in Python </title><author>Fabian Pedregosa, Ga&amp;#235;l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, &amp;#201;douard Duchesnay</author><abstract>

&lt;i&gt;Scikit-learn&lt;/i&gt; is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf</url></Article><Article><id>850</id><title> Neyman-Pearson Classification, Convexity and Stochastic Constraints </title><author>Philippe Rigollet, Xin Tong</author><abstract>

Motivated by problems of anomaly detection, this paper implements the Neyman-Pearson paradigm to deal with asymmetric errors in binary classification with a convex loss &lt;i&gt;&amp;#966;&lt;/i&gt;. Given a finite collection of classifiers, we combine them and obtain a new classifier  that satisfies simultaneously the two following properties with high probability: (i) its &lt;i&gt;&amp;#966;&lt;/i&gt;-type I error is below a pre-specified level and (ii), it has &lt;i&gt;&amp;#966;&lt;/i&gt;-type II error close to the minimum possible. The proposed classifier is obtained by minimizing an empirical convex objective with an empirical convex constraint. The novelty of the method is that the classifier output by this computationally feasible program is shown to satisfy the original constraint on type I error. New techniques to handle such problems are developed and they have consequences on chance constrained programming. We also evaluate the price to pay in terms of type II error for being conservative on type I error.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/rigollet11a/rigollet11a.pdf</url></Article><Article><id>851</id><title> Efficient Learning with Partially Observed Attributes </title><author>Nicol&amp;#242; Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</author><abstract>

We investigate three variants of budgeted learning, a setting in which the learner is allowed to access a limited number of attributes from training or test examples. In the "local budget" setting, where a constraint is imposed on the number of available attributes per training example, we design and analyze an efficient algorithm for learning linear predictors that actively samples the attributes of each training instance. Our analysis bounds the number of additional examples sufficient to compensate for the lack of full information on the training set. This result is complemented by a general lower bound for the easier "global budget" setting, where it is only the overall number of accessible training attributes that is being constrained. In the third, "prediction on a budget" setting, when the constraint is on the number of available attributes per test example, we show that there are cases in which there exists a linear predictor with zero error but it is statistically impossible to achieve arbitrary accuracy without full information on test examples. Finally, we run simple experiments on a digit recognition problem that reveal that our algorithm has a good performance against both partial information and full information baselines.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/cesa-bianchi11a/cesa-bianchi11a.pdf</url></Article><Article><id>852</id><title> Convergence Rates of Efficient Global Optimization Algorithms </title><author>Adam D. Bull</author><abstract>

In the efficient global optimization problem, we minimize an unknown function &lt;i&gt;f&lt;/i&gt;, using as few observations &lt;i&gt;f(x)&lt;/i&gt; as possible. It can be considered a continuum-armed-bandit problem, with noiseless data, and simple regret.  Expected-improvement algorithms are perhaps the most popular methods for solving the problem; in this paper, we provide theoretical results on their asymptotic behaviour.  &lt;br&gt; Implementing these algorithms requires a choice of Gaussian-process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS).  When the prior is fixed, expected improvement is known to converge on the minimum of any function in its RKHS.  We provide convergence rates for this procedure, optimal for functions of low smoothness, and describe a modified algorithm attaining optimal rates for smoother functions.  &lt;br&gt; In practice, however, priors are typically estimated sequentially from the data.  For standard estimators, we show this procedure may never find the minimum of &lt;i&gt;f&lt;/i&gt;.  We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a fixed prior.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/bull11a/bull11a.pdf</url></Article><Article><id>853</id><title> On Equivalence Relationships Between Classification and Ranking Algorithms </title><author>&amp;#350;eyda Ertekin, Cynthia Rudin</author><abstract>

We demonstrate that there are machine learning algorithms that can achieve success for two separate tasks simultaneously, namely the tasks of classification and bipartite ranking. This means that advantages gained from solving one task can be carried over to the other task, such as the ability to obtain conditional density estimates, and an order-of-magnitude reduction in computational time for training the algorithm. It also means that some algorithms are robust to the choice of evaluation metric used; they can theoretically perform well when performance is measured either by a misclassification error or by a statistic of the ROC curve (such as the area under the curve). Specifically, we provide such an equivalence relationship between a generalization of Freund et al.'s RankBoost algorithm, called the "P-Norm Push," and a particular cost-sensitive classification algorithm that generalizes AdaBoost, which we call "P-Classification." We discuss and validate the potential benefits of this equivalence relationship, and perform controlled experiments to understand P-Classification's empirical performance.  There is no established equivalence relationship for logistic regression and its ranking counterpart, so we introduce a logistic-regression-style algorithm that aims in between classification and ranking, and has promising experimental performance with respect to both tasks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/ertekin11a/ertekin11a.pdf</url></Article><Article><id>854</id><title> Hierarchical Knowledge Gradient for Sequential Sampling </title><author>Martijn R.K. Mes, Warren B. Powell, Peter I. Frazier</author><abstract>

We propose a sequential sampling policy for noisy discrete global optimization and ranking and selection, in which we aim to efficiently explore a finite set of alternatives before selecting an alternative as best when exploration stops. Each alternative may be characterized by a multi-dimensional vector of categorical and numerical attributes and has independent normal rewards. We use a Bayesian probability model for the unknown reward of each alternative and follow a fully sequential sampling policy called the knowledge-gradient policy. This policy myopically optimizes the expected increment in the value of sampling information in each time period. We propose a hierarchical aggregation technique that uses the common features shared by alternatives to learn about many alternatives from even a single measurement. This approach greatly reduces the measurement effort required, but it requires some prior knowledge on the smoothness of the function in the form of an aggregation function and computational issues limit the number of alternatives that can be easily considered to the thousands. We prove that our policy is consistent, finding a globally optimal alternative when given enough measurements, and show through simulations that it performs competitively with or significantly better than other policies.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/mes11a/mes11a.pdf</url></Article><Article><id>855</id><title> High-dimensional Covariance Estimation Based On Gaussian Graphical Models </title><author>Shuheng Zhou, Philipp R&amp;#252;timann, Min Xu, Peter B&amp;#252;hlmann</author><abstract>

Undirected graphs are often used to describe high dimensional distributions. Under sparsity conditions, the graph can be estimated using &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-penalization methods.  We propose and study the following method. We combine a multiple regression approach with ideas of thresholding and refitting: first we infer a sparse undirected graphical model structure via thresholding of each among many &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-norm penalized regression functions; we then estimate the covariance matrix and its inverse using the maximum likelihood estimator.  We show that under suitable conditions, this approach yields consistent estimation in terms of graphical structure and fast convergence rates with respect to the operator and Frobenius norm for the covariance matrix and its inverse.  We also derive an explicit bound for the Kullback Leibler divergence.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zhou11a/zhou11a.pdf</url></Article><Article><id>856</id><title> Robust Approximate Bilinear Programming for Value Function Approximation </title><author>Marek Petrik, Shlomo Zilberstein</author><abstract>

Value function approximation methods have been successfully used in many applications, but the prevailing techniques often lack useful &lt;i&gt;a priori&lt;/i&gt; error bounds. We propose a new &lt;i&gt;approximate bilinear programming&lt;/i&gt; formulation of value function approximation, which employs global optimization. The formulation provides strong a priori guarantees on both robust and expected policy loss by minimizing specific norms of the Bellman residual. Solving a bilinear program optimally is NP-hard, but this worst-case complexity is unavoidable because the Bellman-residual minimization itself is NP-hard. We describe and analyze the formulation as well as a simple approximate algorithm for solving bilinear programs. The analysis shows that this algorithm offers a &lt;i&gt;convergent&lt;/i&gt; generalization of approximate policy iteration. We also briefly analyze the behavior of bilinear programming algorithms under incomplete samples. Finally, we demonstrate that the proposed approach can consistently minimize the Bellman residual on simple benchmark problems.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/petrik11a/petrik11a.pdf</url></Article><Article><id>857</id><title> The Stationary Subspace Analysis Toolbox </title><author>Jan Saputra M&amp;#252;ller, Paul von B&amp;#252;nau, Frank C. Meinecke, Franz J. Kir&amp;#225;ly, Klaus-Robert M&amp;#252;ller</author><abstract>

The Stationary Subspace Analysis (SSA) algorithm linearly factorizes a high-dimensional time series into stationary and non-stationary components.  The SSA Toolbox is a platform-independent efficient stand-alone implementation of the SSA algorithm with a graphical user interface written in Java, that can also be invoked from the command line and from Matlab. The graphical interface guides the user through the whole process; data can be imported and exported from comma separated values (CSV) and Matlab's .mat files.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/mueller11a/mueller11a.pdf</url></Article><Article><id>858</id><title> In All Likelihood, Deep Belief Is Not Enough </title><author>Lucas Theis, Sebastian Gerwinn, Fabian Sinz, Matthias Bethge</author><abstract>

Statistical models of natural images provide an important tool for researchers in the fields of machine learning and computational neuroscience. The canonical measure to quantitatively assess and compare the performance of statistical models is given by the likelihood. One class of statistical models which has recently gained increasing popularity and has been applied to a variety of complex data is formed by deep belief networks. Analyses of these models, however, have often been limited to qualitative analyses based on samples due to the computationally intractable nature of their likelihood. Motivated by these circumstances, the present article introduces a consistent estimator for the likelihood of deep belief networks which is computationally tractable and simple to apply in practice. Using this estimator, we quantitatively investigate a deep belief network for natural image patches and compare its performance to the performance of other models for natural image patches. We find that the deep belief network is outperformed with respect to the likelihood even by very simple mixture models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/theis11a/theis11a.pdf</url></Article><Article><id>859</id><title> Efficient and Effective Visual Codebook Generation Using Additive Kernels </title><author>Jianxin Wu, Wei-Chian Tan, James M. Rehg</author><abstract>

Common visual codebook generation methods used in a bag of visual words model, for example, k-means or Gaussian Mixture Model, use the Euclidean distance to cluster features into visual code words. However, most popular visual descriptors are histograms of image measurements. It has been shown that with histogram features, the Histogram Intersection Kernel (HIK) is more effective than the Euclidean distance in supervised learning tasks. In this paper, we demonstrate that HIK can be used in an unsupervised manner to significantly improve the generation of visual codebooks. We propose a histogram kernel k-means algorithm which is easy to implement and runs almost as fast as the standard k-means. The HIK codebooks have consistently higher recognition accuracy over k-means codebooks by 2-4% in several benchmark object and scene recognition data sets. The algorithm is also generalized to arbitrary additive kernels. Its speed is thousands of times faster than a naive implementation of the kernel k-means algorithm. In addition, we propose a one-class SVM formulation to create more effective visual code words. Finally, we show that the standard k-median clustering method can be used for visual codebook generation and can act as a compromise between the HIK / additive kernel and the k-means approaches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/wu11b/wu11b.pdf</url></Article><Article><id>860</id><title> Unsupervised Supervised Learning II: Margin-Based Classification Without Labels </title><author>Krishnakumar Balasubramanian, Pinar Donmez, Guy Lebanon</author><abstract>

Many popular linear classifiers, such as logistic regression, boosting, or SVM, are trained by optimizing a margin-based risk function. Traditionally, these risk functions are computed based on a labeled data set. We develop a novel technique for estimating such risks using only unlabeled data and the marginal label distribution. We prove that the proposed risk estimator is consistent on high-dimensional data sets and demonstrate it on synthetic and real-world data. In particular, we   show how the estimate is used for evaluating classifiers in transfer   learning, and for training classifiers with no labeled data   whatsoever.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/balasubramanian11a/balasubramanian11a.pdf</url></Article><Article><id>861</id><title> Adaptive Exact Inference in Graphical Models </title><author>&amp;#214;zg&amp;#252;r S&amp;#252;mer, Umut A. Acar, Alexander T. Ihler, Ramgopal R. Mettu</author><abstract>

Many algorithms and applications involve repeatedly solving variations of the same inference problem, for example to introduce new evidence to the model or to change conditional dependencies. As the model is updated, the goal of &lt;i&gt;adaptive inference&lt;/i&gt; is to take advantage of previously computed quantities to perform inference more rapidly than from scratch.  In this paper, we present algorithms for adaptive exact inference on general graphs that can be used to efficiently compute marginals and update MAP configurations under arbitrary changes to the input factor graph and its associated elimination tree. After a linear time preprocessing step, our approach enables updates to the model and the computation of any marginal in time that is logarithmic in the size of the input model. Moreover, in contrast to max-product our approach can also be used to update MAP configurations in time that is roughly proportional to the number of updated entries, rather than the size of the input model.  To evaluate the practical effectiveness of our algorithms, we implement and test them using synthetic data as well as for two real-world computational biology applications. Our experiments show that adaptive inference can achieve substantial speedups over performing complete inference as the model undergoes small changes over time.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/sumer11a/sumer11a.pdf</url></Article><Article><id>862</id><title> Group Lasso Estimation of High-dimensional Covariance Matrices </title><author>J&amp;#233;r&amp;#233;mie Bigot, Rolando J. Biscay, Jean-Michel Loubes, Lillian Mu&amp;#241;iz-Alvarez</author><abstract>

In this paper, we consider the Group Lasso estimator of the covariance matrix of a stochastic process corrupted by an additive noise. We propose to estimate the covariance matrix in a high-dimensional setting under the assumption that the process has a sparse representation in a large dictionary of basis functions. Using a matrix regression model, we propose a new methodology for high-dimensional covariance matrix estimation based on empirical contrast regularization by a group Lasso penalty. Using such a penalty, the method selects a sparse set of basis functions in the dictionary used to approximate the process, leading to an approximation of the covariance matrix into a low dimensional space. Consistency of the estimator is studied in Frobenius and operator norms and an application to sparse PCA is proposed.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/bigot11a/bigot11a.pdf</url></Article><Article><id>863</id><title> Robust Gaussian Process Regression with a Student-&lt;i&gt;t&lt;/i&gt; Likelihood </title><author>Pasi Jyl&amp;#228;nki, Jarno Vanhatalo, Aki Vehtari</author><abstract>

This paper considers the robust and efficient implementation of Gaussian process regression with a Student-&lt;i&gt;t&lt;/i&gt; observation model, which has a non-log-concave likelihood. The challenge with the Student-&lt;i&gt;t&lt;/i&gt; model is the analytically intractable inference which is why several approximative methods have been proposed. Expectation propagation (EP) has been found to be a very accurate method in many empirical studies but the convergence of EP is known to be problematic with models containing non-log-concave site functions.  In this paper we illustrate the situations where standard EP fails to converge and review different modifications and alternative algorithms for improving the convergence. We demonstrate that convergence problems may occur during the type-II maximum a posteriori (MAP) estimation of the hyperparameters and show that standard EP may not converge in the MAP values with some difficult data sets. We present a robust implementation which relies primarily on parallel EP updates and uses a moment-matching-based double-loop algorithm with adaptively selected step size in difficult cases. The predictive performance of EP is compared with Laplace, variational Bayes, and Markov chain Monte Carlo approximations.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/jylanki11a/jylanki11a.pdf</url></Article><Article><id>864</id><title> The Sample Complexity of Dictionary Learning </title><author>Daniel Vainsencher, Shie Mannor, Alfred M. Bruckstein</author><abstract>

A large set of signals can sometimes be described sparsely using a dictionary, that is, every element can be represented as a linear combination of few elements from the dictionary.  Algorithms for various signal processing applications, including classification, denoising and signal separation, learn a dictionary from a given set of signals to be represented. Can we expect that the error in representing by such a dictionary a previously unseen signal from the same source will be of similar magnitude as those for the given examples?  We assume signals are generated from a fixed distribution, and study these questions from a statistical learning theory perspective.  &lt;br&gt; We develop generalization bounds on the quality of the learned dictionary for two types of constraints on the coefficient selection, as measured by the expected &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt; error in representation when the dictionary is used.  For the case of &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; regularized coefficient selection we provide a generalization bound of the order of &lt;i&gt;O(&amp;#8730;np ln(m&amp;#955;)/m)&lt;/i&gt;, where &lt;i&gt;n&lt;/i&gt; is the dimension, &lt;i&gt;p&lt;/i&gt; is the number of elements in the dictionary, &lt;i&gt;&amp;#955;&lt;/i&gt; is a bound on the &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; norm of the coefficient vector and &lt;i&gt;m&lt;/i&gt; is the number of samples, which complements existing results.  For the case of representing a new signal as a combination of at most &lt;i&gt;k&lt;/i&gt; dictionary elements, we provide a bound of the order &lt;i&gt;O(&amp;#8730;np ln(mk)/m)&lt;/i&gt; under an assumption on the closeness to orthogonality of the dictionary (low Babel function).  We further show that this assumption holds for &lt;i&gt;most&lt;/i&gt; dictionaries in high dimensions in a strong probabilistic sense.  Our results also include bounds that converge as &lt;i&gt;1/m&lt;/i&gt;, not previously known for this problem.  We provide similar results in a general setting using kernels with weak smoothness requirements.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/vainsencher11a/vainsencher11a.pdf</url></Article><Article><id>865</id><title> An Asymptotic Behaviour of the Marginal Likelihood for General Markov Models </title><author>Piotr Zwiernik</author><abstract>

The standard Bayesian Information Criterion (BIC) is derived under regularity conditions which are not always satisfied in the case of graphical models with hidden variables. In this paper we derive the BIC for the binary graphical tree models where all the inner nodes of a tree represent binary hidden variables. This provides an extension of a similar formula given by Rusakov and Geiger for naive Bayes models. The main tool used in this paper is the connection between the growth behavior of marginal likelihood integrals and the real log-canonical threshold.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/zwiernik11a/zwiernik11a.pdf</url></Article><Article><id>866</id><title> Semi-Supervised Learning with Measure Propagation </title><author>Amarnag Subramanya, Jeff Bilmes</author><abstract>

We describe a new objective for graph-based semi-supervised learning based on minimizing the Kullback-Leibler divergence between discrete probability measures that encode class membership probabilities. We show how the proposed objective can be efficiently optimized using alternating minimization. We prove that the alternating minimization procedure converges to the correct optimum and derive a simple test for convergence. In addition, we show how this approach can be scaled to solve the semi-supervised learning problem on very large data sets, for example, in one instance we use a data set with over &lt;i&gt;10&lt;sup&gt;8&lt;/sup&gt;&lt;/i&gt; samples.  In this context, we propose a graph node ordering algorithm that is also applicable to other graph-based semi-supervised learning approaches. We compare the proposed approach against other standard semi-supervised learning algorithms on the semi-supervised learning benchmark data sets (Chapelle et al., 2007), and other real-world tasks such as text classification on Reuters and WebKB, speech phone classification on TIMIT and Switchboard, and linguistic dialog-act tagging on Dihana and Switchboard. In each case, the proposed approach outperforms the state-of-the-art.  Lastly, we show that our objective can be generalized into a form that includes the standard squared-error loss, and we prove a geometric rate of convergence in that case.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/subramanya11a/subramanya11a.pdf</url></Article><Article><id>867</id><title> Learning with Structured Sparsity </title><author>Junzhou Huang, Tong Zhang, Dimitris Metaxas</author><abstract>

This paper investigates a learning formulation called  &lt;i&gt;structured sparsity&lt;/i&gt;, which is a natural extension of the standard sparsity concept in statistical learning and compressive sensing.  By allowing arbitrary structures on the feature set, this concept generalizes the group sparsity idea that has become popular in recent years.  A general theory is developed for learning with structured sparsity, based on the notion of coding complexity associated with the structure.  It is shown that if the coding complexity of the target signal is small, then one can achieve improved performance by using coding complexity regularization methods, which generalize the standard sparse regularization.  Moreover, a structured greedy algorithm is proposed to efficiently solve the structured sparsity problem. It is shown that the greedy algorithm approximately solves the coding complexity optimization problem under appropriate conditions.  Experiments are included to demonstrate the advantage of structured sparsity over standard sparsity on some real applications.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/huang11b/huang11b.pdf</url></Article><Article><id>868</id><title> A Simpler Approach to Matrix Completion </title><author>Benjamin Recht</author><abstract>

This paper provides the best bounds to date on the number of randomly sampled entries required to reconstruct an unknown low-rank matrix.  These results improve on prior work by Cand&amp;#232;s and Recht (2009), Cand&amp;#232;s and Tao (2009), and Keshavan et al. (2009).  The reconstruction is accomplished by minimizing the nuclear norm, or sum of the singular values, of the hidden matrix subject to agreement with the provided entries. If the underlying matrix satisfies a certain incoherence condition, then the number of entries required is equal to a quadratic logarithmic factor times the number of parameters in the singular value decomposition.  The proof of this assertion is short, self contained, and uses very elementary analysis.  The novel techniques herein are based on recent work in quantum information theory.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/recht11a/recht11a.pdf</url></Article><Article><id>869</id><title> Convergence of Distributed Asynchronous Learning Vector Quantization Algorithms </title><author>Beno&amp;#238;t Patra</author><abstract>

Motivated by the problem of effectively executing clustering algorithms on very large data sets, we address a model for large scale distributed clustering methods. To this end, we briefly recall some standards on the quantization problem and some results on the almost sure convergence of the competitive learning vector quantization (CLVQ) procedure. A general model for linear distributed asynchronous algorithms well adapted to several parallel computing architectures is also discussed. Our approach brings together this scalable model and the CLVQ algorithm, and we call the resulting technique the distributed asynchronous learning vector quantization algorithm (DALVQ). An in-depth analysis of the almost sure convergence of the DALVQ algorithm is performed. A striking result is that we prove that the multiple versions of the quantizers distributed among the processors in the parallel architecture asymptotically reach a consensus almost surely. Furthermore, we also show that these versions converge almost surely towards the same nearly optimal value for the quantization criterion.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume12/patra11a/patra11a.pdf</url></Article><Article><id>870</id><title> Distance Metric Learning with Eigenvalue Optimization </title><author>Yiming Ying, Peng Li</author><abstract>

The main theme of this paper is to develop a novel eigenvalue optimization framework for learning a Mahalanobis metric.  Within this context, we introduce a novel metric learning approach called &lt;i&gt;DML-eig&lt;/i&gt;  which is shown to be equivalent to  a well-known eigenvalue optimization problem called minimizing the maximal eigenvalue of a symmetric matrix (Overton, 1988; Lewis and Overton, 1996).  Moreover, we formulate &lt;i&gt;LMNN&lt;/i&gt; (Weinberger et al., 2005), one of the state-of-the-art metric learning methods, as a similar eigenvalue optimization problem. This novel framework not only provides new insights into metric learning but also opens new avenues  to the design of efficient metric learning algorithms.   Indeed,  first-order algorithms are developed for DML-eig and LMNN which only need the computation of the largest eigenvector of a matrix per iteration. Their convergence characteristics are rigorously established.  Various experiments on benchmark data sets show the competitive performance  of our new approaches. In addition, we report an encouraging result on a difficult and challenging face verification data set called Labeled Faces in the Wild (LFW).


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ying12a/ying12a.pdf</url></Article><Article><id>871</id><title> Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection </title><author>Gavin Brown, Adam Pocock, Ming-Jie Zhao, Mikel Luj&amp;#225;n</author><abstract>

We present a unifying framework for information theoretic feature selection, bringing almost two decades of research on heuristic filter criteria under a single theoretical interpretation.  This is in response to the question: &lt;i&gt;"what are the implicit statistical assumptions of feature selection criteria based on mutual information?"&lt;/i&gt;.  To answer this, we adopt a different strategy than is usual in the feature selection literature&amp;minus;instead of trying to &lt;i&gt;define&lt;/i&gt; a criterion, we &lt;i&gt;derive&lt;/i&gt; one, directly from a clearly specified objective function: the conditional likelihood of the training labels.  While many hand-designed heuristic criteria try to optimize a definition of feature 'relevancy' and 'redundancy', our approach leads to a probabilistic framework which naturally incorporates these concepts.  As a result we can unify the numerous criteria published over the last two decades, and show them to be low-order approximations to the exact (but intractable) optimisation problem.  The primary contribution is to show that &lt;i&gt;common heuristics for information based feature selection (including Markov Blanket algorithms as a special case) are approximate iterative maximisers of the conditional likelihood.&lt;/i&gt; A large empirical study provides strong evidence to favour certain classes of criteria, in particular those that balance the relative size of the relevancy/redundancy terms.  Overall we conclude that the JMI criterion (Yang and Moody, 1999; Meyer et al., 2008) provides the best tradeoff in terms of accuracy, stability, and flexibility with small data samples.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/brown12a/brown12a.pdf</url></Article><Article><id>872</id><title> Plug-in Approach to Active Learning </title><author>Stanislav Minsker</author><abstract>

We present a new active learning algorithm based on nonparametric estimators of the regression function.  Our investigation provides probabilistic bounds for the rates of convergence of the generalization error achievable by proposed method over a broad class of underlying distributions.  We also prove minimax lower bounds which show that the obtained rates are almost tight.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/minsker12a/minsker12a.pdf</url></Article><Article><id>873</id><title> Refinement of Operator-valued Reproducing Kernels </title><author>Haizhang Zhang, Yuesheng Xu, Qinghui Zhang</author><abstract>

This paper studies the construction of a &lt;i&gt;refinement&lt;/i&gt; kernel for a given operator-valued reproducing kernel such that the vector-valued reproducing kernel Hilbert space of the refinement kernel contains that of the given kernel as a subspace. The study is motivated from the need of updating the current operator-valued reproducing kernel in multi-task learning when underfitting or overfitting occurs. Numerical simulations confirm that the established refinement kernel method is able to meet this need.  Various characterizations are provided based on feature maps and vector-valued integral representations of operator-valued reproducing kernels. Concrete examples of refining translation invariant and finite Hilbert-Schmidt operator-valued reproducing kernels are provided. Other examples include refinement of Hessian of scalar-valued translation-invariant kernels and transformation kernels. Existence and properties of operator-valued reproducing kernels preserved during the refinement process are also investigated.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhang12a/zhang12a.pdf</url></Article><Article><id>874</id><title> An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity </title><author>Nir Ailon</author><abstract>

Given a set &lt;i&gt;V&lt;/i&gt; of  &lt;i&gt;n&lt;/i&gt; elements we wish to linearly order them given pairwise preference labels which may be non-transitive (due to irrationality or arbitrary noise).  &lt;br&gt; The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible.  Our performance is measured by two parameters:  The number of disagreements (loss) and the query complexity (number of pairwise preference labels).  Our algorithm adaptively queries  at most &lt;i&gt;O(&amp;#949;&lt;sup&gt;-6&lt;/sup&gt;n log&lt;sup&gt;5&lt;/sup&gt; n)&lt;/i&gt; preference labels for a regret of &lt;i&gt;&amp;#949;&lt;/i&gt; times the optimal loss.  As a function of &lt;i&gt;n&lt;/i&gt;, this is asymptotically better than standard (non-adaptive) learning bounds achievable for the same problem.  &lt;br&gt; Our main result takes us a step closer toward settling an open problem posed by learning-to-rank (from pairwise information) theoreticians and practitioners: What is a provably correct way to sample preference labels?  To further  show the power and practicality of our solution, we analyze a typical test case in which a large margin linear relaxation is used for efficiently solving the simpler learning problems in our decomposition.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ailon12a/ailon12a.pdf</url></Article><Article><id>875</id><title> Optimal Distributed Online Prediction Using Mini-Batches </title><author>Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, Lin Xiao</author><abstract>

Online prediction methods are typically presented as serial algorithms running on a single processor. However, in the age of web-scale prediction problems, it is increasingly common to encounter situations where a single processor cannot keep up with the high rate at which inputs arrive. In this work, we present the &lt;i&gt;distributed mini-batch&lt;/i&gt; algorithm, a method of converting many serial gradient-based online prediction algorithms into distributed algorithms.  We prove a regret bound for this method that is asymptotically optimal for smooth convex loss functions and stochastic inputs. Moreover, our analysis explicitly takes into account communication latencies between nodes in the distributed environment.  We show how our method can be used to solve the closely-related distributed stochastic optimization problem, achieving an asymptotically linear speed-up over multiple processors. Finally, we demonstrate the merits of our approach on a web-scale online prediction problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/dekel12a/dekel12a.pdf</url></Article><Article><id>876</id><title> Active Clustering of Biological Sequences </title><author>Konstantin Voevodski, Maria-Florina Balcan, Heiko R&amp;#246;glin, Shang-Hua Teng, Yu Xia</author><abstract>

Given a point set &lt;i&gt;S&lt;/i&gt; and an unknown metric &lt;i&gt;d&lt;/i&gt; on &lt;i&gt;S&lt;/i&gt;, we study the problem of efficiently partitioning &lt;i&gt;S&lt;/i&gt; into &lt;i&gt;k&lt;/i&gt; clusters while querying few distances between the points.  In our model we assume that we have access to &lt;i&gt;one versus all&lt;/i&gt; queries that given a point &lt;i&gt;s &amp;#8712; S&lt;/i&gt; return the distances between &lt;i&gt;s&lt;/i&gt; and all other points.  We show that given a natural assumption about the structure of the instance, we can efficiently find an accurate clustering using only &lt;i&gt;O(k)&lt;/i&gt; distance queries.   Our algorithm uses an &lt;i&gt;active&lt;/i&gt; selection strategy to choose a small set of points that we call landmarks, and considers only the distances between landmarks and other points to produce a clustering.  We use our procedure to cluster proteins by sequence similarity.  This setting nicely fits our model because we can use a fast sequence database search program to query a sequence against an entire data set.  We conduct an empirical study that shows that even though we query a small fraction of the distances between the points, we produce clusterings that are close to a desired clustering given by manual classification.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/voevodski12a/voevodski12a.pdf</url></Article><Article><id>877</id><title> Multi Kernel Learning with Online-Batch Optimization </title><author>Francesco Orabona, Luo Jie, Barbara Caputo</author><abstract>

In recent years there has been a lot of interest in designing principled classification algorithms over multiple cues, based on the intuitive notion that using more features should lead to better performance. In the domain of kernel methods, a principled way to use multiple features is the Multi Kernel Learning (MKL) approach.  &lt;br&gt; Here we present a MKL optimization algorithm based on stochastic gradient descent that has a guaranteed convergence rate. We directly solve the MKL problem in the primal formulation. By having a p-norm formulation of MKL, we introduce a parameter that controls the level of sparsity of the solution, while leading to an easier optimization problem.  We prove theoretically and experimentally that 1) our algorithm has a faster convergence rate as the number of kernels grows; 2) the training complexity is linear in the number of training examples; 3) very few iterations are sufficient to reach good solutions.  Experiments on standard benchmark databases support our claims.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/orabona12a/orabona12a.pdf</url></Article><Article><id>878</id><title> Active Learning via Perfect Selective Classification </title><author>Ran El-Yaniv, Yair Wiener</author><abstract>

We discover a strong relation between two known learning models: stream-based active learning and perfect selective classification (an extreme case of 'classification with a reject option').  For these models, restricted to the realizable case, we show a reduction of active learning to selective classification that preserves fast rates.  Applying this reduction to recent results for selective classification, we derive exponential target-independent label complexity speedup for actively learning general (non-homogeneous) linear classifiers when the data distribution is an arbitrary high dimensional mixture of Gaussians. Finally, we study the relation between the proposed technique and existing label complexity measures, including teaching dimension and disagreement coefficient.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/el-yaniv12a/el-yaniv12a.pdf</url></Article><Article><id>879</id><title> Random Search for Hyper-Parameter Optimization </title><author>James Bergstra, Yoshua Bengio</author><abstract>

Grid search and manual search are the most widely used strategies for hyper-parameter optimization.  This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid.  Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks.  Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time.  Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space.  Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven.  A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets.  This phenomenon makes grid search a poor choice for configuring algorithms for new data sets.  Our analysis casts some light on why recent "High Throughput" methods achieve surprising success&amp;#8722;they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much.  We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf</url></Article><Article><id>880</id><title> Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics </title><author>Michael U. Gutmann, Aapo Hyv&amp;#228;rinen</author><abstract>

We consider the task of estimating, from observed data, a probabilistic model that is parameterized by a finite number of parameters. In particular, we are considering the situation where the model probability density function is unnormalized. That is, the model is only specified up to the partition function. The partition function normalizes a model so that it integrates to one for any choice of the parameters. However, it is often impossible to obtain it in closed form. Gibbs distributions, Markov and multi-layer networks are examples of models where analytical normalization is often impossible. Maximum likelihood estimation can then not be used without resorting to numerical approximations which are often computationally expensive. We propose here a new objective function for the estimation of both normalized and unnormalized models. The basic idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise. With this approach, the normalizing partition function can be estimated like any other parameter. We prove that the new estimation method leads to a consistent (convergent) estimator of the parameters. For large noise sample sizes, the new estimator is furthermore shown to behave like the maximum likelihood estimator. In the estimation of unnormalized models, there is a trade-off between statistical and computational performance. We show that the new method strikes a competitive trade-off in comparison to other estimation methods for unnormalized models. As an application to real data, we estimate novel two-layer models of natural image statistics with spline nonlinearities.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/gutmann12a/gutmann12a.pdf</url></Article><Article><id>881</id><title> Bounding the Probability of Error for High Precision Optical Character Recognition </title><author>Gary B. Huang, Andrew Kae, Carl Doersch, Erik Learned-Miller</author><abstract>

We consider a model for which it is important, early in processing, to estimate some variables with high precision, but perhaps at relatively low recall. If some variables can be identified with near certainty, they can be conditioned upon, allowing further inference to be done efficiently.  Specifically, we consider optical character recognition (OCR) systems that can be bootstrapped by identifying a subset of correctly translated document words with very high precision. This "clean set" is subsequently used as document-specific training data.  While OCR systems produce confidence measures for the identity of each letter or word, thresholding these values still produces a significant number of errors.
&lt;br&gt;
We introduce a novel technique for identifying a set of correct words with very high precision. Rather than estimating posterior probabilities, we &lt;b&gt;bound&lt;/b&gt; the probability that any given word is incorrect using an approximate worst case analysis.  We give empirical results on a data set of difficult historical newspaper scans, demonstrating that our method for identifying correct words makes only two errors in 56 documents.  Using document-specific character models generated from this data, we are able to reduce the error over properly segmented characters by 34.1% from an initial OCR system's translation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/huang12a/huang12a.pdf</url></Article><Article><id>882</id><title> Minimax-Optimal Rates For Sparse Additive Models Over Kernel Classes Via Convex Programming </title><author>Garvesh Raskutti, Martin J. Wainwright, Bin Yu</author><abstract>

Sparse additive models are families of &lt;i&gt;d&lt;/i&gt;-variate functions with the additive decomposition &lt;i&gt;f&lt;sup&gt;*&lt;/sup&gt; = &amp;#8721;&lt;sub&gt;j &amp;#8712; S&lt;/sub&gt; f&lt;sup&gt;*&lt;/sup&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt;, where &lt;i&gt;S&lt;/i&gt; is an unknown subset of cardinality &lt;i&gt;s &lt;&lt; d&lt;/i&gt;. In this paper, we consider the case where each univariate component function &lt;i&gt;f&lt;sup&gt;*&lt;/sup&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt; lies in a reproducing kernel Hilbert space (RKHS), and analyze a method for estimating the unknown function &lt;i&gt;f&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; based on kernels combined with &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-type convex regularization.  Working within a high-dimensional framework that allows both the dimension &lt;i&gt;d&lt;/i&gt; and sparsity &lt;i&gt;s&lt;/i&gt; to increase with &lt;i&gt;n&lt;/i&gt;, we derive convergence rates in the &lt;i&gt;L&lt;sup&gt;2&lt;/sup&gt;(P)&lt;/i&gt; and &lt;i&gt;L&lt;sup&gt;2&lt;/sup&gt;(P&lt;sub&gt;n&lt;/sub&gt;)&lt;/i&gt; norms over the class &lt;i&gt; F&lt;sub&gt;d,s,H&lt;/sub&gt;&lt;/i&gt; of sparse additive models with each univariate function &lt;i&gt;f&lt;sup&gt;*&lt;/sup&gt;&lt;sub&gt;j&lt;/sub&gt;&lt;/i&gt; in the unit ball of a univariate RKHS with bounded kernel function.  We complement our upper bounds by deriving minimax lower bounds on the &lt;i&gt;L&lt;sup&gt;2&lt;/sup&gt;(P)&lt;/i&gt; error, thereby showing the optimality of our method.  Thus, we obtain optimal minimax rates for many interesting classes of sparse additive models, including polynomials, splines, and Sobolev classes.  We also show that if, in contrast to our univariate conditions, the &lt;i&gt;d&lt;/i&gt;-variate function class is assumed to be globally bounded, then much faster estimation rates are possible for any sparsity &lt;i&gt;s = &amp;#937;(&amp;#8730;n)&lt;/i&gt;, showing that global boundedness is a significant restriction in the high-dimensional setting.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/raskutti12a/raskutti12a.pdf</url></Article><Article><id>883</id><title> Online Learning in the Embedded Manifold of Low-rank Matrices </title><author>Uri Shalit, Daphna Weinshall, Gal Chechik</author><abstract>

When learning models that are represented in matrix forms, enforcing a low-rank constraint can dramatically improve the memory and run time complexity, while providing a natural regularization of the model. However, naive approaches to minimizing functions over the set of low-rank matrices are either prohibitively time consuming (repeated singular value decomposition of the matrix) or numerically unstable (optimizing a factored representation of the low-rank matrix). We build on recent advances in optimization over manifolds, and describe an iterative online learning procedure, consisting of a gradient step, followed by a &lt;i&gt;second-order retraction&lt;/i&gt; back to the manifold. While the ideal retraction is costly to compute, and so is the projection operator that approximates it, we describe another retraction that can be computed efficiently. It has run time and memory complexity of &lt;i&gt;O ( (n+m)k )&lt;/i&gt; for a rank-&lt;i&gt;k&lt;/i&gt; matrix of dimension &lt;i&gt;m&lt;/i&gt; X &lt;i&gt;n&lt;/i&gt;, when using an online procedure with rank-one gradients. We use this algorithm, LORETA, to learn a matrix-form similarity measure over pairs of documents represented as high dimensional vectors. LORETA improves the mean average precision over a passive-aggressive approach in a factorized model, and also improves over a full model trained on pre-selected features using the same memory requirements. We further adapt LORETA to learn positive semi-definite low-rank matrices, providing an online algorithm for &lt;i&gt;low-rank metric learning&lt;/i&gt;. LORETA also shows consistent improvement over standard weakly supervised methods in a large (1600 classes and 1 million images, using &lt;i&gt;ImageNet&lt;/i&gt;) multi-label image classification task.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/shalit12a/shalit12a.pdf</url></Article><Article><id>884</id><title> Multi-Assignment Clustering for Boolean Data </title><author>Mario Frank, Andreas P. Streich, David Basin, Joachim M. Buhmann</author><abstract>

We propose a probabilistic model for clustering Boolean data where an object can be simultaneously assigned to multiple clusters. By explicitly modeling the underlying generative process that combines the  individual source emissions, highly structured data are expressed with substantially fewer clusters compared to single-assignment clustering. As a consequence, such a model provides robust parameter estimators even when the number of samples is low. We extend the model with different noise processes and demonstrate that maximum-likelihood estimation with multiple assignments consistently infers source parameters more accurately than single-assignment clustering. Our model is primarily motivated by the task of role mining for role-based access control, where users of a system are assigned one or more roles. In experiments with real-world access-control data, our model exhibits better generalization performance than state-of-the-art approaches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/frank12a/frank12a.pdf</url></Article><Article><id>885</id><title> Eliminating Spammers and Ranking Annotators for Crowdsourced Labeling Tasks </title><author>Vikas C. Raykar, Shipeng Yu</author><abstract>

With the advent of crowdsourcing services it has become quite cheap and reasonably effective to get a data set labeled by multiple annotators in a short amount of time.  Various methods have been proposed to estimate the consensus labels by correcting for the bias of annotators with different kinds of expertise. Since we do not have control over the quality of the annotators, very often the annotations can be dominated by spammers, defined as annotators who assign labels randomly without actually looking at the instance.  Spammers can make the cost of acquiring labels very expensive and can potentially degrade the quality of the final consensus labels.  In this paper we propose an empirical Bayesian algorithm called SpEM that iteratively eliminates the spammers and estimates the consensus labels based only on the good annotators.  The algorithm is motivated by defining a spammer score that can be used to rank the annotators.  Experiments on simulated and real data show that the proposed approach is better than (or as good as) the earlier approaches in terms of the accuracy and uses a significantly smaller number of annotators.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/raykar12a/raykar12a.pdf</url></Article><Article><id>886</id><title> Metric and Kernel Learning Using a Linear Transformation </title><author>Prateek Jain, Brian Kulis, Jason V. Davis, Inderjit S. Dhillon</author><abstract>

Metric and kernel learning arise in several machine learning applications.  However, most existing metric learning algorithms are limited to learning metrics over low-dimensional data, while existing kernel learning algorithms are often limited to the transductive setting and do not generalize to new data points.  In this paper, we study the connections between metric learning and kernel learning that arise when studying metric learning as a linear transformation learning problem.  In particular, we propose a general optimization framework for learning metrics via linear transformations, and analyze in detail a special case of our framework---that of minimizing the LogDet divergence subject to linear constraints. We then propose a general regularized framework for learning a kernel matrix, and show it to be &lt;i&gt;equivalent&lt;/i&gt; to our metric learning framework.  Our theoretical connections between metric and kernel learning have two main consequences: 1) the learned kernel matrix parameterizes a linear transformation kernel &lt;i&gt;function&lt;/i&gt; and can be applied inductively to new data points, 2) our result yields a constructive method for kernelizing most existing Mahalanobis metric learning formulations.  We demonstrate our learning approach by applying it to large-scale real world problems in computer vision, text mining and semi-supervised kernel dimensionality reduction.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/jain12a/jain12a.pdf</url></Article><Article><id>887</id><title> MULTIBOOST: A Multi-purpose Boosting Package </title><author>Djalel Benbouzid, R&amp;#243;bert Busa-Fekete, Norman Casagrande, Fran&amp;#231;ois-David Collin, Bal&amp;#225;zs K&amp;#233;gl</author><abstract>

The MULTIBOOST package provides a fast C++ implementation of multi-class/multi-label/multi-task boosting algorithms. It is based on ADABOOST.MH but it also implements popular cascade classifiers and FILTERBOOST. The package contains common multi-class base learners (stumps, trees, products, Haar filters). Further base learners and strong learners following the boosting paradigm can be easily implemented in a flexible framework.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/benbouzid12a/benbouzid12a.pdf</url></Article><Article><id>888</id><title> ML-Flex: A Flexible Toolbox for Performing Classification Analyses In Parallel </title><author>Stephen R. Piccolo, Lewis J. Frey</author><abstract>

Motivated by a need to classify high-dimensional, heterogeneous data from the bioinformatics domain, we developed ML-Flex, a machine-learning toolbox that enables users to perform two-class and multi-class classification analyses in a systematic yet flexible manner. ML-Flex was written in Java but is capable of interfacing with third-party packages written in other programming languages. It can handle multiple input-data formats and supports a variety of customizations. ML-Flex provides implementations of various validation strategies, which can be executed in parallel across multiple computing cores, processors, and nodes. Additionally, ML-Flex supports aggregating evidence across multiple algorithms and data sets via ensemble learning. This open-source software package is freely available from http://mlflex.sourceforge.net.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/piccolo12a/piccolo12a.pdf</url></Article><Article><id>889</id><title> A Primal-Dual Convergence Analysis of Boosting </title><author>Matus Telgarsky</author><abstract>

Boosting combines weak learners into a predictor with low empirical risk.  Its dual constructs a high entropy distribution upon which weak learners and training labels are uncorrelated.  This manuscript studies this primal-dual relationship under a broad family of losses, including the exponential loss of AdaBoost and the logistic loss, revealing: &lt;br&gt; &amp;#8226; Weak learnability aids the whole loss family: for any &lt;i&gt;&amp;#949; &gt; 0&lt;/i&gt;, &lt;i&gt;O(ln(1/&amp;#949;))&lt;/i&gt; iterations suffice to produce a predictor with empirical risk &lt;i&gt;&amp;#949;&lt;/i&gt;-close to the infimum; &lt;br&gt; &amp;#8226; The circumstances granting the existence of an empirical risk minimizer may be characterized in terms of the primal and dual problems, yielding a new proof of the known rate &lt;i&gt;O(ln(1/&amp;#949;))&lt;/i&gt;; &lt;br&gt; &amp;#8226; Arbitrary instances may be decomposed into the above two, granting rate &lt;i&gt;O(1/&amp;#949;)&lt;/i&gt;, with a matching lower bound provided for the logistic loss.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/telgarsky12a/telgarsky12a.pdf</url></Article><Article><id>890</id><title> Non-Sparse Multiple Kernel Fisher Discriminant Analysis </title><author>Fei Yan, Josef Kittler, Krystian Mikolajczyk, Atif Tahir</author><abstract>

Sparsity-inducing multiple kernel Fisher discriminant analysis (MK-FDA) has been studied in the literature. Building on recent advances in non-sparse multiple kernel learning (MKL), we propose a non-sparse version of MK-FDA, which imposes a general &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; norm regularisation on the kernel weights. We formulate the associated optimisation problem as a semi-infinite program (SIP), and adapt an iterative wrapper algorithm to solve it. We then discuss, in light of latest advances in MKL optimisation techniques, several reformulations and optimisation strategies that can potentially lead to significant improvements in the efficiency and scalability of MK-FDA. We carry out extensive experiments on six datasets from various application areas, and compare closely the performance of &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; MK-FDA, fixed norm MK-FDA, and several variants of SVM-based MKL (MK-SVM). Our results demonstrate that &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; MK-FDA improves upon sparse MK-FDA in many practical situations. The results also show that on image categorisation problems, &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; MK-FDA tends to outperform its SVM counterpart. Finally, we also discuss the connection between (MK-)FDA and (MK-)SVM, under the unified framework of regularised kernel machines.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/yan12a/yan12a.pdf</url></Article><Article><id>891</id><title> Learning Algorithms for the Classification Restricted Boltzmann Machine </title><author>Hugo Larochelle, Michael Mandel, Razvan Pascanu, Yoshua Bengio</author><abstract>

Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBM only yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classifiers. We study the Classification RBM (ClassRBM), a variant on the RBM adapted to the classification setting. We study different strategies for training the ClassRBM and show that competitive classification performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classification problems, namely semi-supervised and multitask learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/larochelle12a/larochelle12a.pdf</url></Article><Article><id>892</id><title> Structured Sparsity and Generalization </title><author>Andreas Maurer, Massimiliano Pontil</author><abstract>

We present a data dependent generalization bound for a large class of regularized algorithms which implement structured sparsity constraints. The bound can be applied to standard squared-norm regularization, the Lasso, the group Lasso, some versions of the group Lasso with overlapping groups, multiple kernel learning and other regularization schemes. In all these cases competitive results are obtained. A novel feature of our bound is that it can be applied in an infinite dimensional setting such as the Lasso in a separable Hilbert space or multiple kernel learning with a countable number of kernels.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/maurer12a/maurer12a.pdf</url></Article><Article><id>893</id><title> A Case Study on Meta-Generalising: A Gaussian Processes Approach </title><author>Grigorios Skolidis, Guido Sanguinetti</author><abstract>

We propose a novel model for meta-generalisation, that is, performing prediction on novel tasks based on information from multiple different but related tasks. The model is based on two coupled Gaussian processes with structured covariance function; one model performs predictions by learning a constrained covariance function encapsulating the relations between the various training tasks, while the second model determines the similarity of new tasks to previously seen tasks. We demonstrate empirically on several real and synthetic data sets both the strengths of the approach and its limitations due to the distributional assumptions underpinning it.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/skolidis12a/skolidis12a.pdf</url></Article><Article><id>894</id><title> A Kernel Two-Sample Test </title><author>Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch&amp;#246;lkopf, Alexander Smola</author><abstract>

We propose a framework for analyzing and comparing distributions, which we use to construct statistical tests to determine if two samples are drawn from different distributions.  Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS), and is called the &lt;i&gt;maximum mean discrepancy&lt;/i&gt; (MMD).  We present two distribution-free tests based on large deviation bounds for the MMD, and a third test based on the asymptotic distribution of this statistic.  The MMD can be computed in quadratic time, although efficient linear time approximations are available.  Our statistic is an instance of an integral probability metric, and various classical metrics on distributions are obtained when alternative function classes are used in place of an RKHS.  We apply our two-sample tests  to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly.  Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf</url></Article><Article><id>895</id><title> GPLP: A Local and Parallel Computation Toolbox for Gaussian Process Regression </title><author>Chiwoo Park, Jianhua Z. Huang, Yu Ding</author><abstract>

This paper presents the &lt;i&gt;Getting-started&lt;/i&gt; style documentation for the local and parallel computation toolbox for Gaussian process regression (GPLP), an open source software package written in Matlab (but also compatible with Octave). The working environment and the usage of the software package will be presented in this paper.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/park12a/park12a.pdf</url></Article><Article><id>896</id><title> Exact Covariance Thresholding into Connected Components for Large-Scale Graphical Lasso </title><author>Rahul Mazumder,  Trevor Hastie</author><abstract>

We consider the sparse inverse covariance regularization problem or &lt;i&gt;graphical lasso&lt;/i&gt; with regularization  parameter &lt;i&gt;&amp;#955;&lt;/i&gt;.  Suppose the sample &lt;i&gt;covariance graph&lt;/i&gt; formed by thresholding the entries of the sample covariance matrix at &lt;i&gt;&amp;#955;&lt;/i&gt; is decomposed into connected components.  We show that the &lt;i&gt;vertex-partition&lt;/i&gt; induced by the connected components of the thresholded sample covariance graph (at &lt;i&gt;&amp;#955;&lt;/i&gt;) is &lt;i&gt;exactly&lt;/i&gt; equal to that induced by the connected components of the estimated concentration graph, obtained by solving the graphical lasso problem for the &lt;i&gt;same&lt;/i&gt; &lt;i&gt;&amp;#955;&lt;/i&gt;.  This characterizes a very interesting property of a path of graphical lasso solutions.  Furthermore, this simple rule, when used as a wrapper around existing algorithms for the graphical lasso, leads to enormous performance gains. For a range of values of &lt;i&gt;&amp;#955;&lt;/i&gt;, our proposal splits a large graphical lasso problem into smaller tractable problems, making it possible to solve an otherwise infeasible large-scale problem. We illustrate the graceful scalability of our proposal via synthetic and real-life microarray examples.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/mazumder12a/mazumder12a.pdf</url></Article><Article><id>897</id><title> Algorithms for Learning Kernels Based on Centered Alignment </title><author>Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh</author><abstract>

This paper presents new and effective algorithms for learning kernels. In particular, as shown by our empirical results, these algorithms consistently outperform the so-called uniform combination solution that has proven to be difficult to improve upon in the past, as well as other algorithms for learning kernels based on convex combinations of base kernels in both classification and regression.  Our algorithms are based on the notion of centered alignment which is used as a similarity measure between kernels or kernel matrices. We present a number of novel algorithmic, theoretical, and empirical results for learning kernels based on our notion of centered alignment. In particular, we describe efficient algorithms for learning a maximum alignment kernel by showing that the problem can be reduced to a simple QP and discuss a one-stage algorithm for learning both a kernel and a hypothesis based on that kernel using an alignment-based regularization.  Our theoretical results include a novel concentration bound for centered alignment between kernel matrices, the proof of the existence of effective predictors for kernels with high alignment, both for classification and for regression, and the proof of stability-based generalization bounds for a broad family of algorithms for learning kernels based on centered alignment. We also report the results of experiments with our centered alignment-based algorithms in both classification and regression.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/cortes12a/cortes12a.pdf</url></Article><Article><id>898</id><title> Causal Bounds and Observable Constraints for Non-deterministic Models </title><author>Roland R. Ramsahai</author><abstract>

Conditional independence relations involving latent variables do not necessarily imply observable independences. They may imply inequality constraints on observable parameters and causal bounds, which can be used for falsification and identification. The literature on computing such constraints often involve a deterministic underlying data generating process in a counterfactual framework. If an analyst is ignorant of the nature of the underlying mechanisms then they may wish to use a model which allows the underlying mechanisms to be probabilistic. A method of computation for a weaker model without any determinism is given here and demonstrated for the instrumental variable model, though applicable to other models. The approach is based on the analysis of mappings with convex polytopes in a decision theoretic framework and can be implemented in readily available polyhedral computation software. Well known constraints and bounds are replicated in a probabilistic model and novel ones are computed for instrumental variable models without non-deterministic versions of the randomization, exclusion restriction and monotonicity assumptions respectively.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ramsahai12a/ramsahai12a.pdf</url></Article><Article><id>899</id><title> NIMFA : A Python Library for Nonnegative Matrix Factorization </title><author>Marinka &amp;#381;itnik, Bla&amp;#382; Zupan</author><abstract>

NIMFA is an open-source Python library that provides a unified interface to nonnegative matrix factorization algorithms. It includes implementations of state-of-the-art factorization methods, initialization approaches, and quality scoring. It supports both dense and sparse matrix representation. NIMFA's component-based implementation and hierarchical design should help the users to employ already implemented techniques or design and code new strategies for matrix factorization tasks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zitnik12a/zitnik12a.pdf</url></Article><Article><id>900</id><title> Algebraic Geometric Comparison of Probability Distributions </title><author>Franz J. Kir&amp;#225;ly, Paul von B&amp;#252;nau, Frank C. Meinecke, Duncan A.J. Blythe, Klaus-Robert M&amp;#252;ller</author><abstract>

We propose a novel algebraic algorithmic framework for dealing with probability distributions represented by their cumulants such as the mean and covariance matrix. As an example, we consider the unsupervised learning problem of finding the subspace on which several probability distributions agree. Instead of minimizing an objective function involving the estimated cumulants, we show that by treating the cumulants as elements of the polynomial ring we can directly solve the problem, at a lower computational cost and with higher accuracy. Moreover, the algebraic viewpoint on probability distributions allows us to invoke the theory of algebraic geometry, which we demonstrate in a compact proof for an identifiability criterion.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kiraly12a/kiraly12a.pdf</url></Article><Article><id>901</id><title> Stability of Density-Based Clustering </title><author>Alessandro Rinaldo, Aarti Singh, Rebecca Nugent, Larry Wasserman</author><abstract>

High density clusters can be characterized by the connected components of a level set &lt;i&gt;L(&amp;#955;) = {x: p(x)&gt;&amp;#955;}&lt;/i&gt; of the underlying probability density function &lt;i&gt;p&lt;/i&gt; generating the data, at some appropriate level &lt;i&gt;&amp;#955; &amp;#8805; 0&lt;/i&gt;. The complete hierarchical clustering can be characterized by a cluster tree &lt;i&gt;T= &amp;#8746;&lt;sub&gt;&amp;#955;&lt;/sub&gt;L(&amp;#955;)&lt;/i&gt;.  In this paper, we study the behavior of a density level set estimate  &lt;i&gt;L&amp;#770;(&amp;#955;)&lt;/i&gt; and cluster tree estimate &lt;i&gt;T&amp;#770;&lt;/i&gt; based on a kernel density estimator with kernel bandwidth &lt;i&gt;h&lt;/i&gt;. We define two notions of instability to measure the variability of &lt;i&gt;L&amp;#770;(&amp;#955;)&lt;/i&gt; and &lt;i&gt;T&amp;#770;&lt;/i&gt; as a function of &lt;i&gt;h&lt;/i&gt;, and investigate the theoretical properties of these instability measures.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/rinaldo12a/rinaldo12a.pdf</url></Article><Article><id>902</id><title> Mal-ID: Automatic Malware Detection Using Common Segment Analysis and Meta-Features </title><author>Gil Tahan, Lior Rokach, Yuval Shahar</author><abstract>

This paper proposes several novel methods, based on machine learning, to detect malware in executable files without any need for preprocessing, such as unpacking or disassembling. The basic method (Mal-ID) is a new static (form-based) analysis methodology that uses common segment analysis in order to detect malware files. By using common segment analysis, Mal-ID is able to discard malware parts that originate from benign code. In addition, Mal-ID uses a new kind of feature, termed meta-feature, to better capture the properties of the analyzed segments. Rather than using the entire file, as is usually the case with machine learning based techniques, the new approach detects malware on the segment level. This study also introduces two Mal-ID extensions that improve the Mal-ID basic method in various aspects. We rigorously evaluated Mal-ID and its two extensions with more than ten performance measures, and compared them to the highly rated boosted decision tree method under identical settings. The evaluation demonstrated that Mal-ID and the two Mal-ID extensions outperformed the boosted decision tree method in almost all respects. In addition, the results indicated that by extracting meaningful features, it is sufficient to employ one simple detection rule for classifying executable files.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/tahan12a/tahan12a.pdf</url></Article><Article><id>903</id><title> Sampling Methods for the Nystr&amp;#246;m Method </title><author>Sanjiv Kumar, Mehryar Mohri, Ameet Talwalkar</author><abstract>

The Nystr&amp;#246;m method is an efficient technique to generate low-rank matrix approximations and is used in several large-scale learning applications.  A key aspect of this method is the procedure according to which columns are sampled from the original matrix.  In this work, we explore the efficacy of a variety of &lt;i&gt;fixed&lt;/i&gt; and &lt;i&gt;adaptive&lt;/i&gt; sampling schemes.  We also propose a family of &lt;i&gt;ensemble&lt;/i&gt;-based sampling algorithms for the Nystr&amp;#246;m method. We report results of extensive experiments that provide a detailed comparison of various fixed and adaptive sampling techniques, and demonstrate the performance improvement associated with the ensemble Nystr&amp;#246;m method when used in conjunction with either fixed or adaptive sampling schemes.  Corroborating these empirical findings, we present a theoretical analysis of the Nystr&amp;#246;m method, providing novel error bounds guaranteeing a better convergence rate of the ensemble Nystr&amp;#246;m method in comparison to the standard Nystr&amp;#246;m method.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kumar12a/kumar12a.pdf</url></Article><Article><id>904</id><title> Positive Semidefinite Metric Learning Using Boosting-like Algorithms </title><author>Chunhua Shen, Junae Kim, Lei Wang, Anton van den Hengel</author><abstract>

The success of many machine learning and pattern recognition methods relies heavily upon the identification of an appropriate distance metric on the input data.  It is often beneficial to learn such a metric from the input training data, instead of using a default one such as the Euclidean distance.  In this work, we propose a boosting-based technique, termed BOOSTMETRIC, for learning a quadratic Mahalanobis distance metric.  Learning a valid Mahalanobis distance metric requires enforcing the constraint that the matrix parameter to the metric remains positive semidefinite.  Semidefinite programming is often used to enforce this constraint, but does not scale well and is not easy to implement.  BOOSTMETRIC is instead based on the observation that any positive semidefinite matrix can be decomposed into a linear combination of trace-one rank-one matrices.  BOOSTMETRIC thus uses rank-one positive semidefinite matrices as weak learners within an efficient and scalable boosting-based learning process.  The resulting methods are easy to implement, efficient, and can accommodate various types of constraints.  We extend traditional boosting algorithms in that its weak learner is a positive semidefinite matrix with trace and rank being one rather than a classifier or regressor.  Experiments on various data sets demonstrate that the proposed algorithms compare favorably to those state-of-the-art methods in terms of classification accuracy and running time.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/shen12a/shen12a.pdf</url></Article><Article><id>905</id><title> Consistent Model Selection Criteria on High Dimensions </title><author>Yongdai Kim, Sunghoon Kwon, Hosik Choi</author><abstract>

Asymptotic properties of model selection criteria for high-dimensional regression models are studied where the dimension of covariates is much larger than the sample size. Several sufficient conditions for model selection consistency are provided.  Non-Gaussian error distributions are considered and it is shown that the maximal number of covariates for model selection consistency depends on the tail behavior of the error distribution. Also, sufficient conditions for model selection consistency are given when the variance of the noise is neither known nor estimated consistently.  Results of simulation studies as well as real data analysis are given to illustrate that finite sample performances of consistent model selection criteria can be quite different.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kim12a/kim12a.pdf</url></Article><Article><id>906</id><title> The huge Package for High-dimensional Undirected Graph Estimation in R </title><author>Tuo Zhao, Han Liu, Kathryn Roeder, John Lafferty, Larry Wasserman</author><abstract>

We describe an R package named  huge which provides easy-to-use functions for estimating high dimensional undirected graphs from data.  This package implements recent results in the literature, including Friedman et al. (2007), Liu et al. (2009, 2012) and Liu et al. (2010).   Compared with the existing graph estimation package glasso, the huge package provides extra features: (1) instead of using Fortan, it is written in C, which makes the code more portable and easier to modify; (2) besides fitting  Gaussian graphical models, it also provides functions for fitting high dimensional semiparametric Gaussian copula models; (3) more functions like data-dependent model selection, data generation and graph visualization; (4) a minor convergence problem of the graphical lasso algorithm is corrected; (5) the package allows the user to apply both lossless and lossy screening rules to scale up large-scale problems, making a tradeoff between computational and statistical efficiency.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhao12a/zhao12a.pdf</url></Article><Article><id>907</id><title> Analysis of a Random Forests Model </title><author>G&amp;#233;rard Biau</author><abstract>

Random forests are a scheme proposed by Leo Breiman in the 2000's for building a predictor ensemble with a set of decision trees that grow in randomly selected subspaces of data. Despite growing interest and  practical use, there has been little exploration of the statistical properties of random forests, and little is known about the mathematical forces driving the algorithm.  In this paper, we offer an in-depth analysis of a random forests model suggested by Breiman (2004), which is very close to the original algorithm. We show in particular that the procedure is consistent and adapts to sparsity, in the sense that its rate of convergence depends only on the number of strong features and not on how many noise variables are present.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/biau12a/biau12a.pdf</url></Article><Article><id>908</id><title> Towards Integrative Causal Analysis of Heterogeneous Data Sets and Studies </title><author>Ioannis Tsamardinos, Sofia Triantafillou, Vincenzo Lagani</author><abstract>

We present methods able to predict the presence and strength of conditional and unconditional dependencies (correlations) between two variables &lt;i&gt;Y&lt;/i&gt; and &lt;i&gt;Z&lt;/i&gt; &lt;i&gt;never jointly measured&lt;/i&gt; on the same samples, based on multiple data sets measuring a set of common variables. The algorithms are specializations of prior work on learning causal structures from overlapping variable sets.  This problem has also been addressed in the field of &lt;i&gt;statistical matching&lt;/i&gt;. The proposed methods are applied to a wide range of domains and are shown to accurately predict the presence of thousands of dependencies. Compared against prototypical statistical matching algorithms and within the scope of our experiments, the proposed algorithms make predictions that are better correlated with the sample estimates of the unknown parameters on test data ; this is particularly the case when the number of commonly measured variables is low.  &lt;br&gt; The enabling idea behind the methods is to induce one or all &lt;i&gt;causal&lt;/i&gt; models that are simultaneously consistent with (fit) all available data sets and prior knowledge and reason with them. This allows constraints stemming from causal assumptions (e.g., Causal Markov Condition, Faithfulness) to propagate. Several methods have been developed based on this idea, for which we propose the unifying name Integrative Causal Analysis (INCA). A contrived example is presented demonstrating the theoretical potential to develop more general methods for co-analyzing heterogeneous data sets. The computational experiments with the novel methods provide evidence that causally-inspired assumptions such as Faithfulness often hold to a good degree of approximation in many real systems and could be exploited for statistical inference. Code, scripts, and data are available at www.mensxmachina.org.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/tsamardinos12a/tsamardinos12a.pdf</url></Article><Article><id>909</id><title> Hope and Fear for Discriminative Training of Statistical Translation Models </title><author>David Chiang</author><abstract>

In machine translation, discriminative models have almost entirely supplanted the classical noisy-channel model, but are standardly trained using a method that is reliable only in low-dimensional spaces. Two strands of research have tried to adapt more scalable discriminative training methods to machine translation: the first uses log-linear probability models and either maximum likelihood or minimum risk, and the other uses linear models and large-margin methods. Here, we provide an overview of the latter. We compare several learning algorithms and describe in detail some novel extensions suited to properties of the translation task: no single correct output, a large space of structured outputs, and slow inference. We present experimental results on a large-scale Arabic-English translation task, demonstrating large gains in translation accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/chiang12a/chiang12a.pdf</url></Article><Article><id>910</id><title> A Multi-Stage Framework for Dantzig Selector and LASSO </title><author>Ji Liu, Peter Wonka, Jieping Ye</author><abstract>

We consider the following sparse signal recovery (or feature selection) problem: given a design matrix &lt;i&gt;X&amp;#8712; &amp;#8477;&lt;sup&gt;n&amp;#10005; m&lt;/sup&gt;&lt;/i&gt; &lt;i&gt;(m &gt;&gt; n)&lt;/i&gt; and a noisy observation vector &lt;i&gt;y&amp;#8712; &amp;#8477;&lt;sup&gt;n&lt;/sup&gt;&lt;/i&gt; satisfying &lt;i&gt;y=X&amp;#946;&lt;sup&gt;*&lt;/sup&gt;+&amp;#949;&lt;/i&gt; where &lt;i&gt;&amp;#949;&lt;/i&gt; is the noise vector following a Gaussian distribution &lt;i&gt;N(0,&amp;#963;&lt;sup&gt;2&lt;/sup&gt;I)&lt;/i&gt;, how to recover the signal (or parameter vector) &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; when the signal is sparse?  &lt;br&gt; The Dantzig selector has been proposed for sparse signal recovery with strong theoretical guarantees. In this paper, we propose a multi-stage Dantzig selector method, which iteratively refines the target signal &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt;. We show that if &lt;i&gt;X&lt;/i&gt; obeys a certain condition, then with a large probability the difference between the solution &lt;i&gt;&amp;#946;&amp;#770;&lt;/i&gt; estimated by the proposed method and the true solution &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; measured in terms of the &lt;i&gt;l&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; norm (&lt;i&gt;p&amp;#8805; 1&lt;/i&gt;) is bounded as &lt;br&gt; ||&amp;#946;&amp;#770;-&amp;#946;&lt;sup&gt;*&lt;/sup&gt;||&lt;sub&gt;p&lt;/sub&gt;&amp;#8804; (C(s-N)&lt;sup&gt;1/p&lt;/sup&gt;&amp;#8730;log m+&amp;#916;)&amp;#963;, &lt;br&gt; where &lt;i&gt;C&lt;/i&gt; is a constant, &lt;i&gt;s&lt;/i&gt; is the number of nonzero entries in &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt;, the risk of the oracle estimator &lt;i&gt;&amp;#916;&lt;/i&gt; is independent of &lt;i&gt;m&lt;/i&gt; and is much smaller than the first term, and &lt;i&gt;N&lt;/i&gt; is the number of entries of &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; larger than a certain value in the order of &lt;i&gt;O(&amp;#963;&amp;#8730;log m)&lt;/i&gt;. The proposed method improves the estimation bound of the standard Dantzig selector approximately from &lt;i&gt;Cs&lt;sup&gt;1/p&lt;/sup&gt;&amp;#8730;log m&amp;#963;&lt;/i&gt; to &lt;i&gt;C(s-N)&lt;sup&gt;1/p&lt;/sup&gt;&amp;#8730;log m&amp;#963;&lt;/i&gt; where the value &lt;i&gt;N&lt;/i&gt; depends on the number of large entries in &lt;i&gt;&amp;#946;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt;. When &lt;i&gt;N=s&lt;/i&gt;, the proposed algorithm achieves the oracle solution with a high probability, where the oracle solution is the projection of the observation vector &lt;i&gt;y&lt;/i&gt; onto true features. In addition, with a large probability, the proposed method can select the same number of correct features under a milder condition than the Dantzig selector.  Finally, we extend this multi-stage procedure to the LASSO case.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/liu12a/liu12a.pdf</url></Article><Article><id>911</id><title> A Geometric Approach to Sample Compression </title><author>Benjamin I.P. Rubinstein, J. Hyam Rubinstein</author><abstract>

The Sample Compression Conjecture of Littlestone &amp; Warmuth has remained unsolved for a quarter century. While maximum classes (concept classes meeting Sauer's Lemma with equality) can be compressed, the compression of general concept classes reduces to compressing maximal classes (classes that cannot be expanded without increasing VC dimension). Two promising ways forward are: embedding maximal classes into maximum classes with at most a polynomial increase to VC dimension, and compression via operating on geometric representations. This paper presents positive results on the latter approach and a first negative result on the former, through a systematic investigation of finite maximum classes.  Simple arrangements of hyperplanes in hyperbolic space are shown to represent maximum classes, generalizing the corresponding Euclidean result.  We show that sweeping a generic hyperplane across such arrangements forms an unlabeled compression scheme of size VC dimension and corresponds to a special case of peeling the one-inclusion graph, resolving a recent conjecture of Kuzmin &amp; Warmuth. A bijection between finite maximum classes and certain arrangements of piecewise-linear (PL) hyperplanes in either a ball or Euclidean space is established.  Finally we show that &lt;i&gt;d&lt;/i&gt;-maximum classes corresponding to PL-hyperplane arrangements in &lt;i&gt;&amp;#8477;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt; have cubical complexes homeomorphic to a &lt;i&gt;d&lt;/i&gt;-ball, or equivalently complexes that are manifolds with boundary.  A main result is that PL arrangements can be swept by a moving hyperplane to unlabeled &lt;i&gt;d&lt;/i&gt;-compress &lt;i&gt;any&lt;/i&gt; finite maximum class, forming a peeling scheme as conjectured by Kuzmin &amp; Warmuth. A corollary is that some &lt;i&gt;d&lt;/i&gt;-maximal classes cannot be embedded into any maximum class of VC-dimension &lt;i&gt;d+k&lt;/i&gt;, for any constant &lt;i&gt;k&lt;/i&gt;. The construction of the PL sweeping involves Pachner moves on the one-inclusion graph, corresponding to moves of a hyperplane across the intersection of &lt;i&gt;d&lt;/i&gt; other hyperplanes. This extends the well known Pachner moves for triangulations to cubical complexes.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/rubinstein12a/rubinstein12a.pdf</url></Article><Article><id>912</id><title> Minimax Manifold Estimation </title><author>Christopher Genovese, Marco Perone-Pacifico, Isabella Verdinelli, Larry Wasserman</author><abstract>

We find the minimax rate of convergence in Hausdorff distance for estimating a manifold &lt;i&gt;M&lt;/i&gt; of dimension &lt;i&gt;d&lt;/i&gt; embedded in &lt;i&gt;&amp;#8477;&lt;sup&gt;D&lt;/sup&gt;&lt;/i&gt; given a noisy sample from the manifold.  Under certain conditions, we show that the optimal rate of convergence is &lt;i&gt;n&lt;sup&gt;-2/(2+d)&lt;/sup&gt;&lt;/i&gt;.  Thus, the minimax rate depends only on the dimension of the manifold, not on the dimension of the space in which &lt;i&gt;M&lt;/i&gt; is embedded.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/genovese12a/genovese12a.pdf</url></Article><Article><id>913</id><title> Query Strategies for Evading Convex-Inducing Classifiers </title><author>Blaine Nelson, Benjamin I. P. Rubinstein, Ling Huang, Anthony D. Joseph, Steven J. Lee, Satish Rao, J. D. Tygar</author><abstract>

Classifiers are often used to detect miscreant activities. We study how an adversary can systematically query a classifier to elicit information that allows the attacker to evade detection while incurring a near-minimal cost of modifying their intended malfeasance. We generalize the theory of Lowd and Meek (2005) to the family of convex-inducing classifiers that partition their feature space into two sets, one of which is convex. We present query algorithms for this family that construct undetected instances of approximately minimal cost using only polynomially-many queries in the dimension of the space and in the level of approximation. Our results demonstrate that near-optimal evasion can be accomplished for this family without reverse engineering the classifier's decision boundary. We also consider general &lt;i&gt;l&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt; costs and show that near-optimal evasion on the family of convex-inducing classifiers is generally efficient for both positive and negative convexity for all levels of approximation if &lt;i&gt;p=1&lt;/i&gt;.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/nelson12a/nelson12a.pdf</url></Article><Article><id>914</id><title> Transfer in Reinforcement Learning via Shared Features </title><author>George Konidaris, Ilya Scheidwasser, Andrew Barto</author><abstract>

We present a framework for  transfer in reinforcement learning based on the idea that related tasks share some common features, and that transfer can be achieved via those shared features. The framework attempts to capture the notion of tasks that are related but distinct, and provides some insight into when transfer can be usefully applied to a problem sequence and when it cannot. We apply the framework to the knowledge transfer problem, and show that an agent can learn a portable shaping function from experience in a sequence of tasks to significantly improve performance in a later related task, even given a very brief training period. We also apply the framework to skill transfer, to show that agents can learn portable skills across a sequence of tasks that significantly improve performance on later related tasks, approaching the performance of agents given perfectly learned problem-specific skills.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/konidaris12a/konidaris12a.pdf</url></Article><Article><id>915</id><title> On Ranking and Generalization Bounds </title><author>Wojciech Rejchel</author><abstract>

The problem of ranking is to predict or to guess the ordering between objects on the basis of their observed features. In this paper we consider ranking estimators that minimize the empirical convex risk. We prove generalization bounds for the excess risk of such estimators with rates that are faster than &lt;i&gt;1/&amp;#8730;n.&lt;/i&gt; We apply our results to commonly used ranking algorithms, for instance boosting or support vector machines. Moreover, we study the performance of considered estimators on real data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/rejchel12a/rejchel12a.pdf</url></Article><Article><id>916</id><title> Feature Selection via Dependence Maximization </title><author>Le Song, Alex Smola, Arthur Gretton, Justin Bedo, Karsten Borgwardt</author><abstract>

We introduce a framework for feature selection based on dependence maximization between the selected features and the labels of an estimation problem, using the Hilbert-Schmidt Independence Criterion. The key idea is that good features should be highly dependent on the labels.  Our approach leads to a greedy procedure for feature selection.  We show that a number of existing feature selectors are special cases of this framework. Experiments on both artificial and real-world data show that our feature selector works well in practice.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/song12a/song12a.pdf</url></Article><Article><id>917</id><title> Structured Sparsity via Alternating Direction Methods </title><author>Zhiwei Qin, Donald Goldfarb</author><abstract>

We consider a class of sparse learning problems in high dimensional feature space regularized by a structured sparsity-inducing norm that incorporates prior knowledge of the group structure of the features.  Such problems often pose a considerable challenge to optimization algorithms due to the non-smoothness and non-separability of the regularization term.  In this paper, we focus on two commonly adopted sparsity-inducing regularization terms, the overlapping Group Lasso penalty &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;/l&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;-norm and the &lt;i&gt;l&lt;sub&gt;1&lt;/sub&gt;/l&lt;sub&gt;&amp;#8734;&lt;/sub&gt;&lt;/i&gt;-norm.  We propose a unified framework based on the augmented Lagrangian method, under which problems with both types of regularization and their variants can be efficiently solved.  As one of the core building-blocks of this framework, we develop new algorithms using a partial-linearization/splitting technique and prove that the accelerated versions of these algorithms require &lt;i&gt;O(1/&amp;#8730;&amp;#949;)&lt;/i&gt; iterations to obtain an &lt;i&gt;&amp;#949;&lt;/i&gt;-optimal solution.  We compare the performance of these algorithms against that of the alternating direction augmented Lagrangian and FISTA methods on a collection of data sets and apply them to two real-world problems to compare the relative merits of the two norms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/qin12a/qin12a.pdf</url></Article><Article><id>918</id><title> Activized Learning: Transforming Passive to Active with Improved Label Complexity </title><author>Steve Hanneke</author><abstract>

We study the theoretical advantages of active learning over passive learning.  Specifically, we prove that, in noise-free classifier learning for VC classes, any passive learning algorithm can be transformed into an active learning algorithm with asymptotically strictly superior label complexity for all nontrivial target functions and distributions.  We further provide a general characterization of the magnitudes of these improvements in terms of a novel generalization of the disagreement coefficient.  We also extend these results to active learning in the presence of label noise, and find that even under broad classes of noise distributions, we can typically guarantee strict improvements over the known results for passive learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hanneke12a/hanneke12a.pdf</url></Article><Article><id>919</id><title> A Model of the Perception of Facial Expressions of Emotion by Humans: Research Overview and Perspectives </title><author>Aleix Martinez, Shichuan Du</author><abstract>

In cognitive science and neuroscience, there have been two leading models describing how humans perceive and classify facial expressions of emotion---the continuous and the categorical model. The continuous model defines each facial expression of emotion as a feature vector in a face space. This model explains, for example, how expressions of emotion can be seen at different intensities. In contrast, the categorical model consists of &lt;i&gt;C&lt;/i&gt; classifiers, each tuned to a specific emotion category. This model explains, among other findings, why the images in a morphing sequence between a happy and a surprise face are perceived as either happy or surprise but not something in between. While the continuous model has a more difficult time justifying this latter finding, the categorical model is not as good when it comes to explaining how expressions are recognized at different intensities or modes. Most importantly, both models have problems explaining how one can recognize combinations of emotion categories such as happily surprised versus angrily surprised versus surprise. To resolve these issues, in the past several years, we have worked on a revised model that justifies the results reported in the cognitive science and neuroscience literature. This model consists of &lt;i&gt;C&lt;/i&gt; distinct continuous spaces. Multiple (compound) emotion categories can be recognized by linearly combining these &lt;i&gt;C&lt;/i&gt; face spaces. The dimensions of these spaces are shown to be mostly configural. According to this model, the major task for the classification of facial expressions of emotion is precise, detailed detection of facial landmarks rather than recognition. We provide an overview of the literature justifying the model, show how the resulting model can be employed to build algorithms for the recognition of facial expression of emotion, and propose research directions in machine learning and computer vision researchers to keep pushing the state of the art in these areas.  We also discuss how the model can aid in studies of human perception, social interactions and disorders.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/martinez12a/martinez12a.pdf</url></Article><Article><id>920</id><title> A Unifying Probabilistic Perspective for Spectral Dimensionality Reduction: Insights and New Models </title><author>Neil D. Lawrence</author><abstract>

We introduce a new perspective on spectral dimensionality reduction which views these methods as Gaussian Markov random fields (GRFs). Our unifying perspective is based on the maximum entropy principle which is in turn inspired by maximum variance unfolding. The resulting model, which we call maximum entropy unfolding (MEU) is a nonlinear generalization of principal component analysis. We relate the model to Laplacian eigenmaps and isomap. We show that parameter fitting in the locally linear embedding (LLE) is approximate maximum likelihood MEU. We introduce a variant of LLE that performs maximum likelihood exactly: Acyclic LLE (ALLE).  We show that MEU and ALLE are competitive with the leading spectral approaches on a robot navigation visualization and a human motion capture data set. Finally the maximum likelihood perspective allows us to introduce a new approach to dimensionality reduction based on L1 regularization of the Gaussian random field via the graphical lasso.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lawrence12a/lawrence12a.pdf</url></Article><Article><id>921</id><title> Mixability is Bayes Risk Curvature Relative to Log Loss </title><author>Tim van Erven, Mark D. Reid, Robert C. Williamson</author><abstract>

Mixability of a loss characterizes fast rates in the online learning setting of prediction with expert advice. The determination of the mixability constant for binary losses is straightforward but opaque. In the binary case we make this transparent and simpler by characterising mixability in terms of the second derivative of the Bayes risk of proper losses.  We then extend this result to multiclass proper losses where there are few existing results.  We show that mixability is governed by the maximum eigenvalue of the Hessian of the Bayes risk, relative to the Hessian of the Bayes risk for log loss. We conclude by comparing our result to other work that bounds prediction performance in terms of the geometry of the Bayes risk. Although all calculations are for proper losses, we also show how to carry the results across to improper losses.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/vanerven12a/vanerven12a.pdf</url></Article><Article><id>922</id><title> Restricted Strong Convexity and Weighted Matrix Completion: Optimal Bounds with Noise </title><author>Sahand Negahban, Martin J. Wainwright</author><abstract>

We consider the matrix completion problem under a form of row/column weighted entrywise sampling, including the case of uniform entrywise sampling as a special case.  We analyze the associated random observation operator, and prove that with high probability, it satisfies a form of restricted strong convexity with respect to weighted Frobenius norm.  Using this property, we obtain as corollaries a number of error bounds on matrix completion in the weighted Frobenius norm under noisy sampling and for both exact and near low-rank matrices.  Our results are based on measures of the "spikiness" and "low-rankness" of matrices that are less restrictive than the incoherence conditions imposed in previous work.  Our technique involves an &lt;i&gt;M&lt;/i&gt;-estimator that includes controls on both the rank and spikiness of the solution, and we establish non-asymptotic error bounds in weighted Frobenius norm for recovering matrices lying with &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;q&lt;/sub&gt;&lt;/i&gt;-"balls" of bounded spikiness.  Using information-theoretic methods, we show that no algorithm can achieve better estimates (up to a logarithmic factor) over these same sets, showing that our conditions on matrices and associated rates are essentially optimal.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/negahban12a/negahban12a.pdf</url></Article><Article><id>923</id><title> glm-ie: Generalised Linear Models Inference &amp; Estimation Toolbox </title><author>Hannes Nickisch</author><abstract>

The glm-ie toolbox contains functionality for estimation and inference in generalised linear models over continuous-valued variables. Besides a variety of penalised least squares solvers for estimation, it offers inference based on (convex) variational bounds, on expectation propagation and on factorial mean field.  Scalable and efficient inference in fully-connected undirected graphical models or Markov random fields with Gaussian and non-Gaussian potentials is achieved by casting all the computations as matrix vector multiplications. We provide a wide choice of penalty functions for estimation, potential functions for inference and matrix classes with lazy evaluation for convenient modelling.  We designed the glm-ie package to be simple, generic and easily expansible. Most of the code is written in Matlab including some MEX files to be fully compatible to both Matlab 7.x and GNU Octave 3.3.x. Large scale probabilistic classification as well as sparse linear modelling can be performed in a common algorithmical framework by the glm-ie toolkit.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/nickisch12a/nickisch12a.pdf</url></Article><Article><id>924</id><title> Manifold Identification in Dual Averaging for Regularized Stochastic Online Learning </title><author>Sangkyun Lee, Stephen J. Wright</author><abstract>

Iterative methods that calculate their steps from approximate subgradient directions have proved to be useful for stochastic learning problems over large and streaming data sets. When the objective consists of a loss function plus a nonsmooth regularization term, the solution often lies on a low-dimensional manifold of parameter space along which the regularizer is smooth. (When an &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; regularizer is used to induce sparsity in the solution, for example, this manifold is defined by the set of nonzero components of the parameter vector.)  This paper shows that a regularized dual averaging algorithm can identify this manifold, with high probability, before reaching the solution. This observation motivates an algorithmic strategy in which, once an iterate is suspected of lying on an optimal or near-optimal manifold, we switch to a "local phase" that searches in this manifold, thus converging rapidly to a near-optimal point. Computational results are presented to verify the identification property and to illustrate the effectiveness of this approach.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lee12a/lee12a.pdf</url></Article><Article><id>925</id><title> Variational Multinomial Logit Gaussian Process </title><author>Kian Ming A. Chai</author><abstract>

Gaussian process prior with an appropriate likelihood function is a flexible non-parametric model for a variety of learning tasks.  One important and standard task is multi-class classification, which is the categorization of an item into one of several fixed classes.  A usual likelihood function for this is the multinomial logistic likelihood function.  However, exact inference with this model has proved to be difficult because high-dimensional integrations are required.  In this paper, we propose a variational approximation to this model, and we describe the optimization of the variational parameters.  Experiments have shown our approximation to be tight.  In addition, we provide data-independent bounds on the marginal likelihood of the model, one of which is shown to be much tighter than the existing variational mean-field bound in the experiments.  We also derive a proper lower bound on the predictive likelihood that involves the Kullback-Leibler divergence between the approximating and the true posterior.  We combine our approach with a recently proposed sparse approximation to give a variational sparse approximation to the Gaussian process multi-class  model.  We also derive criteria which can be used to select the inducing set, and we show the effectiveness of these criteria over random selection in an experiment.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/chai12a/chai12a.pdf</url></Article><Article><id>926</id><title> Entropy Search for Information-Efficient Global Optimization </title><author>Philipp Hennig, Christian J. Schuler</author><abstract>

Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hennig12a/hennig12a.pdf</url></Article><Article><id>927</id><title> Estimation and Selection via Absolute Penalized Convex Minimization And Its Multistage Adaptive Applications </title><author>Jian Huang, Cun-Hui Zhang</author><abstract>

The &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-penalized method, or the Lasso, has emerged as an important tool for the analysis of large data sets.  Many important results have been obtained for the Lasso in linear regression which have led to a deeper understanding of high-dimensional statistical problems. In this article, we consider a class of weighted &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-penalized estimators for convex loss functions of a general form, including the generalized linear models. We study  the estimation, prediction, selection and sparsity  properties of the weighted &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt;-penalized estimator in sparse, high-dimensional settings where the number of predictors &lt;i&gt;p&lt;/i&gt; can be much larger than the sample size &lt;i&gt;n&lt;/i&gt;. Adaptive Lasso is considered as a special case.  A multistage method is developed to approximate concave regularized estimation by applying an adaptive Lasso recursively.  We provide prediction and estimation oracle inequalities for single- and multi-stage estimators, a general selection consistency theorem, and an upper bound for the dimension of the Lasso estimator. Important models including the linear regression, logistic regression and log-linear models are used throughout to illustrate the applications of the general results.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/huang12b/huang12b.pdf</url></Article><Article><id>928</id><title> Regularization Techniques for Learning with Matrices </title><author>Sham M. Kakade, Shai Shalev-Shwartz, Ambuj Tewari</author><abstract>

There is growing body of learning problems for which it is natural to organize the parameters into a matrix. As a result, it becomes easy to impose sophisticated prior knowledge by appropriately regularizing the parameters under some matrix norm.  This work describes and analyzes a systematic method for constructing such matrix-based regularization techniques.  In particular, we focus on how the underlying statistical properties of a given problem can help us decide which regularization function is appropriate.  &lt;br&gt; Our methodology is based on a known duality phenomenon: a function is strongly convex with respect to some norm if and only if its conjugate function is strongly smooth with respect to the dual norm. This result has already been found to be a key component in deriving and analyzing several learning algorithms.  We demonstrate the potential of this framework by deriving novel generalization and regret bounds for multi-task learning, multi-class learning, and multiple kernel learning.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kakade12a/kakade12a.pdf</url></Article><Article><id>929</id><title> Confidence-Weighted Linear Classification for Text Categorization </title><author>Koby Crammer, Mark Dredze, Fernando Pereira</author><abstract>

Confidence-weighted online learning is a generalization of margin-based learning of linear classifiers in which the margin constraint is replaced by a probabilistic constraint based on a distribution over classifier weights that is updated online as examples are observed. The distribution captures a notion of confidence on classifier weights, and in some cases it can also be interpreted as replacing a single learning rate by adaptive per-weight rates. Confidence-weighted learning was motivated by the statistical properties of natural-language classification tasks, where most of the informative features are relatively rare.  We investigate several versions of confidence-weighted learning that use a Gaussian distribution over weight vectors, updated at each observed example to achieve high probability of correct classification for the example. Empirical evaluation on a range of text-categorization tasks show that our algorithms improve over other state-of-the-art online and batch methods, learn faster in the online setting, and lead to better classifier combination for a type of distributed training commonly used in cloud computing.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/crammer12a/crammer12a.pdf</url></Article><Article><id>930</id><title> Integrating a Partial Model into Model Free Reinforcement Learning </title><author>Aviv Tamar, Dotan Di Castro, Ron Meir</author><abstract>

In reinforcement learning an agent uses online feedback from the environment in order to adaptively select an effective policy.  Model free approaches address this task by directly mapping environmental states to actions, while model based methods attempt to construct a model of the environment, followed by a selection of optimal actions based on that model. Given the complementary advantages of both approaches, we suggest a novel procedure which augments a model free algorithm with a partial model. The resulting &lt;i&gt;hybrid&lt;/i&gt; algorithm switches between a model based and a model free mode, depending on the current state and the agent's knowledge. Our method relies on a novel definition for a partially known model, and an estimator that incorporates such knowledge in order to reduce uncertainty in stochastic approximation iterations. We prove that such an approach leads to improved policy evaluation whenever environmental knowledge is available, without compromising performance when such knowledge is absent. Numerical simulations demonstrate the effectiveness of the approach on policy gradient and Q-learning algorithms, and its usefulness in solving a call admission control problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/tamar12a/tamar12a.pdf</url></Article><Article><id>931</id><title> Jstacs: A Java Framework for Statistical Analysis and Classification of Biological Sequences </title><author>Jan Grau, Jens Keilwagen, Andr&amp;#233; Gohr, Berit Haldemann, Stefan Posch, Ivo Grosse</author><abstract>

Jstacs is an object-oriented Java library for analysing and classifying sequence data, which emerged from the need for a standardized implementation of statistical models, learning principles, classifiers, and performance measures. In Jstacs, these components can be used, combined, and extended easily, which allows for a direct comparison of different approaches and fosters the development of new components.  Jstacs is especially tailored to biological sequence data, but is also applicable to general discrete and continuous data. Jstacs is freely available at http://www.jstacs.de under the GNU GPL license including an API documentation, a cookbook, and code examples.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/grau12a/grau12a.pdf</url></Article><Article><id>932</id><title> Variable Selection in High-dimensional Varying-coefficient Models with Global Optimality </title><author>Lan Xue, Annie Qu</author><abstract>

The varying-coefficient model is flexible and powerful for modeling the dynamic changes of regression coefficients.  It is important to identify significant covariates associated with response variables, especially for high-dimensional settings where the number of covariates can be larger than the sample size.  We consider model selection in the high-dimensional setting and adopt difference convex programming to approximate the &lt;i&gt;L&lt;sub&gt;0&lt;/sub&gt;&lt;/i&gt; penalty, and we investigate the global optimality properties of the varying-coefficient estimator. The challenge of the variable selection problem here is that the dimension of the nonparametric form for the varying-coefficient modeling could be infinite, in addition to dealing with the high-dimensional linear covariates. We show that the proposed varying-coefficient estimator is consistent, enjoys the oracle property and achieves an optimal convergence rate for the non-zero nonparametric components for high-dimensional data.  Our simulations and numerical examples indicate that the difference convex algorithm is efficient using the coordinate decent algorithm, and is able to select the true model at a higher frequency than the least absolute shrinkage and selection operator (LASSO), the adaptive LASSO and the smoothly clipped absolute deviation (SCAD) approaches.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/xue12a/xue12a.pdf</url></Article><Article><id>933</id><title> An Improved GLMNET for L1-regularized Logistic Regression </title><author>Guo-Xun Yuan, Chia-Hua Ho, Chih-Jen Lin</author><abstract>

Recently, Yuan et al. (2010) conducted a comprehensive comparison on software for L1-regularized classification.  They concluded that a carefully designed coordinate descent implementation CDN is the fastest among state-of-the-art solvers.  In this paper, we point out that CDN is less competitive on loss functions that are expensive to compute.  In particular, CDN for logistic regression is much slower than CDN for SVM because the logistic loss involves expensive exp/log operations.  &lt;br&gt; In optimization, Newton methods are known to have fewer iterations although each iteration costs more.  Because solving the Newton sub-problem is independent of the loss calculation, this type of methods may surpass CDN under some circumstances.  In L1-regularized classification, GLMNET by Friedman et al. is already a Newton-type method, but experiments in Yuan et al. (2010) indicated that the existing GLMNET implementation may face difficulties for some large-scale problems.  In this paper, we propose an improved GLMNET to address some theoretical and implementation issues.  In particular, as a Newton-type method, GLMNET achieves fast local convergence, but may fail to quickly obtain a useful solution.  By a careful design to adjust the effort for each iteration, our method is efficient for both loosely or strictly solving the optimization problem.  Experiments demonstrate that our improved GLMNET is more efficient than CDN for L1-regularized logistic regression.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/yuan12a/yuan12a.pdf</url></Article><Article><id>934</id><title> EP-GIG Priors and Applications in Bayesian Sparse Learning </title><author>Zhihua Zhang, Shusen Wang, Dehua Liu, Michael I. Jordan</author><abstract>

In this paper we propose a novel framework for the construction of  sparsity-inducing priors. In particular, we define such priors as a mixture of exponential power distributions with a generalized inverse Gaussian density (EP-GIG).  EP-GIG is a  variant of generalized hyperbolic distributions, and the special cases include Gaussian scale mixtures and Laplace scale mixtures.  Furthermore, Laplace scale mixtures can subserve a Bayesian framework for sparse learning with nonconvex penalization.  The densities of EP-GIG can be explicitly expressed.  Moreover, the corresponding posterior distribution also follows a generalized inverse Gaussian distribution. We exploit these properties to develop EM algorithms for sparse empirical Bayesian learning.  We also show that these algorithms bear an interesting resemblance to iteratively reweighted &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt; or &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; methods. Finally, we present two extensions for grouped variable selection and logistic regression.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhang12b/zhang12b.pdf</url></Article><Article><id>935</id><title> Pattern for Python </title><author>Tom De Smedt, Walter Daelemans</author><abstract>

Pattern is a package for Python 2.4+ with functionality for web mining (Google + Twitter + Wikipedia, web spider, HTML DOM parser), natural language processing (tagger/chunker, n-gram search, sentiment analysis, WordNet), machine learning (vector space model, &lt;i&gt;k&lt;/i&gt;-means clustering, Naive Bayes + &lt;i&gt;k&lt;/i&gt;-NN + SVM classifiers) and network analysis (graph centrality and visualization). It is well documented and bundled with 30+ examples and 350+ unit tests. The source code is licensed under BSD and available from http://www.clips.ua.ac.be/pages/pattern.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/desmedt12a/desmedt12a.pdf</url></Article><Article><id>936</id><title> Optimistic Bayesian Sampling in Contextual-Bandit Problems </title><author>Benedict C. May, Nathan Korda, Anthony Lee, David S. Leslie</author><abstract>

In sequential decision problems in an unknown environment, the decision maker often faces a dilemma over whether to explore to discover more about the environment, or to exploit current knowledge. We address the exploration-exploitation dilemma in a general setting encompassing both standard and contextualised bandit problems. The contextual bandit problem has recently resurfaced in attempts to maximise click-through rates in web based applications, a task with significant commercial interest.  &lt;br&gt; In this article we consider an approach of Thompson (1933) which makes use of samples from the posterior distributions for the instantaneous value of each action. We extend the approach by introducing a new algorithm, Optimistic Bayesian Sampling (OBS), in which the probability of playing an action increases with the uncertainty in the estimate of the action value. This results in better directed exploratory behaviour.  &lt;br&gt; We prove that, under unrestrictive assumptions, both approaches result in optimal behaviour with respect to the average reward criterion of Yang and Zhu (2002).  We implement OBS and measure its performance in simulated Bernoulli bandit and linear regression domains, and also when tested with the task of personalised news article recommendation on a Yahoo! Front Page Today Module data set. We find that OBS performs competitively when compared to recently proposed benchmark algorithms and outperforms Thompson's method throughout.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/may12a/may12a.pdf</url></Article><Article><id>937</id><title> A Comparison of the Lasso and  Marginal Regression </title><author>Christopher R. Genovese, Jiashun Jin, Larry Wasserman, Zhigang Yao</author><abstract>

The lasso is an important method for sparse, high-dimensional regression problems, with efficient algorithms available, a long history of practical success, and a large body of theoretical results supporting and explaining its performance.  But even with the best available algorithms, finding the lasso solutions remains a computationally challenging task in cases where the number of covariates vastly exceeds the number of data points.  &lt;br&gt; Marginal regression, where each dependent variable is regressed separately on each covariate, offers a promising alternative in this case because the estimates can be computed roughly two orders faster than the lasso solutions.  The question that remains is how the statistical performance of the method compares to that of the lasso in these cases.  &lt;br&gt; In this paper, we study the relative statistical performance of the lasso and marginal regression for sparse, high-dimensional regression problems.  We consider the problem of learning which coefficients are non-zero.  Our main results are as follows: (i) we compare the conditions under which the lasso and marginal regression guarantee exact recovery in the fixed design, noise free case; (ii) we establish conditions under which marginal regression provides exact recovery with high probability in the fixed design, noise free, random coefficients case; and (iii) we derive rates of convergence for both procedures, where performance is measured by the number of coefficients with incorrect sign, and characterize the regions in the parameter space recovery is and is not possible under this metric.  &lt;br&gt; In light of the computational advantages of marginal regression in very high dimensional problems, our theoretical and simulations results suggest that the procedure merits further study.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/genovese12b/genovese12b.pdf</url></Article><Article><id>938</id><title> On the Necessity of Irrelevant Variables </title><author>David P. Helmbold, Philip M. Long</author><abstract>

This work explores the effects of relevant and irrelevant boolean variables on the accuracy of classifiers.  The analysis uses the assumption that the variables are conditionally independent given the class, and focuses on a natural family of learning algorithms for such sources when the relevant variables have a small advantage over random guessing.  The main result is that algorithms relying predominately on irrelevant variables have error probabilities that quickly go to &lt;i&gt;0&lt;/i&gt; in situations where algorithms that limit the use of irrelevant variables have errors bounded below by a positive constant.  We also show that accurate learning is possible even when there are so few examples that one cannot determine with high confidence whether or not any individual variable is relevant.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/helmbold12a/helmbold12a.pdf</url></Article><Article><id>939</id><title> DEAP: Evolutionary Algorithms Made Easy </title><author>F&amp;#233;lix-Antoine Fortin, Fran&amp;#231;ois-Michel De Rainville, Marc-Andr&amp;#233; Gardner, Marc Parizeau, Christian Gagn&amp;#233;</author><abstract>

DEAP is a novel evolutionary computation framework for rapid prototyping and testing of ideas. Its design departs from most other existing frameworks in that it seeks to make algorithms explicit and data structures transparent, as opposed to the more common black-box frameworks.  Freely available with extensive documentation at http://deap.gel.ulaval.ca, DEAP is an open source project under an LGPL license.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/fortin12a/fortin12a.pdf</url></Article><Article><id>940</id><title> An Introduction to Artificial Prediction Markets for Classification </title><author>Adrian Barbu, Nathan Lay</author><abstract>

Prediction markets are used in real life to predict outcomes of interest such as presidential elections. This paper presents a mathematical theory of artificial prediction markets for supervised learning of conditional probability estimators. The artificial prediction market is a novel method for fusing the prediction information of features or trained classifiers, where the fusion result is the contract price on the possible outcomes. The market can be trained online by updating the participants' budgets using training examples. Inspired by the real prediction markets, the equations that govern the market are derived from simple and reasonable assumptions. Efficient numerical algorithms are presented for solving these equations. The obtained artificial prediction market is shown to be a maximum likelihood estimator. It generalizes linear aggregation, existent in boosting and random forest, as well as logistic regression and some kernel methods. Furthermore, the market mechanism allows the aggregation of specialized classifiers that participate only on specific instances. Experimental comparisons show that the artificial prediction markets often outperform random forest and implicit online learning on synthetic data and real UCI data sets. Moreover, an extensive evaluation for pelvic and abdominal lymph node detection in CT data shows that the prediction market improves adaboost's detection rate from &lt;i&gt;79.6%&lt;/i&gt; to &lt;i&gt;81.2%&lt;/i&gt; at 3 false positives/volume.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/barbu12a/barbu12a.pdf</url></Article><Article><id>941</id><title> Sign Language Recognition using Sub-Units </title><author>Helen Cooper, Eng-Jon Ong, Nicolas Pugeault, Richard Bowden</author><abstract>

This paper discusses sign language recognition using linguistic sub-units.  It presents three types of sub-units for consideration; those learnt from appearance data as well as those inferred from both 2D or 3D tracking data.  These sub-units are then combined using a sign level classifier; here, two options are presented.  The first uses Markov Models to encode the temporal changes between sub-units.  The second makes use of Sequential Pattern Boosting to apply discriminative feature selection at the same time as encoding temporal information.  This approach is more robust to noise and performs well in signer independent tests, improving results from the 54% achieved by the Markov Chains to 76%.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/cooper12a/cooper12a.pdf</url></Article><Article><id>942</id><title> A Topic Modeling Toolbox Using Belief Propagation </title><author>Jia Zeng</author><abstract>

Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model for probabilistic topic modeling, which attracts worldwide interests and touches on many important applications in text mining, computer vision and computational biology.  This paper introduces a topic modeling toolbox (TMBP) based on the belief propagation (BP) algorithms.  TMBP toolbox is implemented by MEX C++/Matlab/Octave for either Windows 7 or Linux.  Compared with existing topic modeling packages, the novelty of this toolbox lies in the BP algorithms for learning LDA-based topic models.  The current version includes BP algorithms for latent Dirichlet allocation (LDA), author-topic models (ATM), relational topic models (RTM), and labeled LDA (LaLDA).  This toolbox is an ongoing project and more BP-based algorithms for various topic models will be added in the near future.  Interested users may also extend BP algorithms for learning more complicated topic models.  The source codes are freely available under the GNU General Public Licence, Version &lt;i&gt;1.0&lt;/i&gt; at https://mloss.org/software/view/399/.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zeng12a/zeng12a.pdf</url></Article><Article><id>943</id><title> MedLDA: Maximum Margin Supervised Topic Models </title><author>Jun Zhu, Amr Ahmed, Eric P. Xing</author><abstract>

A supervised topic model can use side information such as ratings or labels associated with documents or images to discover more predictive low dimensional topical representations of the data. However, existing supervised topic models predominantly employ likelihood-driven objective functions for learning and inference, leaving the popular and potentially powerful max-margin principle unexploited for seeking predictive representations of data and more discriminative topic bases for the corpus. In this paper, we propose the maximum entropy discrimination latent Dirichlet allocation (MedLDA) model, which integrates the mechanism behind the max-margin prediction models (e.g., SVMs) with the mechanism behind the hierarchical Bayesian topic models (e.g., LDA) under a unified constrained optimization framework, and yields latent topical representations that are more discriminative and more suitable for prediction tasks such as document classification or regression. The principle underlying the MedLDA formalism is quite general and can be applied for jointly max-margin and maximum likelihood learning of directed or undirected topic models when supervising side information is available. Efficient variational methods for posterior inference and parameter estimation are derived and extensive empirical studies on several real data sets are also provided. Our experimental results demonstrate qualitatively and quantitatively that MedLDA could: 1) discover sparse and highly discriminative topical representations; 2) achieve state of the art prediction performance; and 3) be more efficient than existing supervised topic models, especially for classification.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhu12a/zhu12a.pdf</url></Article><Article><id>944</id><title> Pairwise Support Vector Machines and their Application to Large Scale Problems </title><author>Carl Brunner, Andreas Fischer, Klaus Luig, Thorsten Thies</author><abstract>

Pairwise classification is the task to predict whether the examples &lt;i&gt;a,b&lt;/i&gt; of a pair &lt;i&gt;(a,b)&lt;/i&gt; belong to the same class or to different classes. In particular, interclass generalization problems can be treated in this way.  In pairwise classification, the order of the two input examples should not affect the classification result. To achieve this, particular kernels as well as the use of symmetric training sets in the framework of support vector machines were suggested. The paper discusses both approaches in a general way and establishes a strong connection between them. In addition, an efficient implementation is discussed which allows the training of several millions of pairs. The value of these contributions is confirmed by excellent results on the labeled faces in the wild benchmark.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/brunner12a/brunner12a.pdf</url></Article><Article><id>945</id><title> High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion </title><author>Animashree Anandkumar, Vincent Y.F. Tan, Furong Huang, Alan S. Willsky</author><abstract>

We consider the problem of high-dimensional Gaussian graphical model selection. We  identify a set of graphs for which an efficient estimation algorithm exists, and this algorithm is  based on thresholding of  empirical conditional covariances. Under a set of transparent conditions, we establish structural consistency (or &lt;i&gt;sparsistency&lt;/i&gt;) for the proposed algorithm, when the number of samples &lt;i&gt;n=&amp;#937;(J&lt;sub&gt;min&lt;/sub&gt;&lt;sup&gt;-2&lt;/sup&gt; log p)&lt;/i&gt;, where &lt;i&gt;p&lt;/i&gt; is the number of variables and &lt;i&gt;J&lt;sub&gt;min&lt;/sub&gt;&lt;/i&gt; is the minimum (absolute) edge potential of the graphical model. The sufficient conditions for sparsistency are based on the notion of &lt;i&gt;walk-summability&lt;/i&gt; of the model and the presence of sparse &lt;i&gt;local vertex separators&lt;/i&gt; in the underlying graph. We also derive novel non-asymptotic  necessary conditions on the number of samples required  for sparsistency.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/anandkumar12a/anandkumar12a.pdf</url></Article><Article><id>946</id><title> A Local Spectral Method for Graphs: With Applications to Improving Graph Partitions and Exploring Data Graphs Locally </title><author>Michael W. Mahoney, Lorenzo Orecchia, Nisheeth K. Vishnoi</author><abstract>

The second eigenvalue of the Laplacian matrix and its associated eigenvector are fundamental features of an undirected graph, and as such they have found widespread use in scientific computing, machine learning, and data analysis.  In many applications, however, graphs that arise have several &lt;i&gt;local&lt;/i&gt; regions of interest, and the second eigenvector will typically fail to provide information fine-tuned to each local region.  In this paper, we introduce a locally-biased analogue of the second eigenvector, and we demonstrate its usefulness at highlighting local properties of data graphs in a semi-supervised manner.  To do so, we first view the second eigenvector as the solution to a constrained optimization problem, and we incorporate the local information as an additional constraint; we then characterize the optimal solution to this new problem and show that it can be interpreted as a generalization of a Personalized PageRank vector; and finally, as a consequence, we show that the solution can be computed in nearly-linear time.  In addition, we show that this locally-biased vector can be used to compute an approximation to the best partition &lt;i&gt;near&lt;/i&gt; an input seed set in a manner analogous to the way in which the second eigenvector of the Laplacian can be used to obtain an approximation to the best partition in the entire input graph.  Such a primitive is useful for identifying and refining clusters locally, as it allows us to focus on a local region of interest in a semi-supervised manner.  Finally, we provide a detailed empirical evaluation of our method by showing how it can applied to finding locally-biased sparse cuts around an input vertex seed set in social and information networks.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/mahoney12a/mahoney12a.pdf</url></Article><Article><id>947</id><title> Multi-Target Regression with Rule Ensembles </title><author>Timo Aho, Bernard &amp;#381;enko, Sa&amp;#353;o D&amp;#382;eroski, Tapio Elomaa</author><abstract>

Methods for learning decision rules are being successfully applied to many problem domains, in particular when understanding and interpretation of the learned model is necessary. In many real life problems, we would like to predict multiple related (nominal or numeric) target attributes simultaneously. While several methods for learning rules that predict multiple targets at once exist, they are all based on the covering algorithm, which does not work well for regression problems. A better solution for regression is the rule ensemble approach that transcribes an ensemble of decision trees into a large collection of rules. An optimization procedure is then used to select the best (and much smaller) subset of these rules and to determine their respective weights.  &lt;br&gt; We introduce the FIRE algorithm for solving multi-target regression problems, which employs the rule ensembles approach. We improve the accuracy of the algorithm by adding simple linear functions to the ensemble. We also extensively evaluate the algorithm with and without linear functions. The results show that the accuracy of multi-target regression rule ensembles is high. They are more accurate than, for instance, multi-target regression trees, but not quite as accurate as multi-target random forests. The rule ensembles are significantly more concise than random forests, and it is also possible to create compact rule sets that are smaller than a single regression tree but still comparable in accuracy.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/aho12a/aho12a.pdf</url></Article><Article><id>948</id><title> Characterization and Greedy Learning of Interventional Markov Equivalence Classes of Directed Acyclic Graphs </title><author>Alain Hauser, Peter B&amp;#252;hlmann</author><abstract>

The investigation of directed acyclic graphs (DAGs) encoding the same Markov property, that is the same conditional independence relations of multivariate observational distributions, has a long tradition; many algorithms exist for model selection and structure learning in Markov equivalence classes.  In this paper, we extend the notion of Markov equivalence of DAGs to the case of interventional distributions arising from &lt;i&gt;multiple&lt;/i&gt; intervention experiments.  We show that under reasonable assumptions on the intervention experiments, interventional Markov equivalence defines a finer partitioning of DAGs than observational Markov equivalence and hence improves the identifiability of causal models.  We give a graph theoretic criterion for two DAGs being Markov equivalent under interventions and show that each interventional Markov equivalence class can, analogously to the observational case, be uniquely represented by a chain graph called &lt;i&gt;interventional essential graph&lt;/i&gt; (also known as &lt;i&gt;CPDAG&lt;/i&gt; in the observational case).  These are key insights for deriving a generalization of the Greedy Equivalence Search algorithm aimed at structure learning from interventional data.  This new algorithm is evaluated in a simulation study.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hauser12a/hauser12a.pdf</url></Article><Article><id>949</id><title> On the Convergence Rate of &lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;-Norm Multiple Kernel Learning </title><author>Marius Kloft, Gilles Blanchard</author><abstract>

We derive an upper bound on the local Rademacher complexity of &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;p&lt;/sub&gt;&lt;/i&gt;-norm multiple kernel learning, which yields a tighter excess risk bound than global approaches. Previous local approaches analyzed the case &lt;i&gt;p=1&lt;/i&gt; only while our analysis covers all cases &lt;i&gt;1&amp;#8804;p&amp;#8804;&amp;#8734;&lt;/i&gt;, assuming the different feature mappings corresponding to the different kernels to be uncorrelated.  We also show a lower bound that shows that the bound is tight, and derive consequences regarding excess loss, namely fast convergence rates of the order &lt;i&gt;O(n&lt;sup&gt;-&amp;#945;/1+&amp;#945;&lt;/sup&gt;)&lt;/i&gt;, where &lt;i&gt;&amp;#945;&lt;/i&gt; is the minimum eigenvalue decay rate of the individual kernels.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kloft12a/kloft12a.pdf</url></Article><Article><id>950</id><title> Trading Regret for Efficiency: Online Convex Optimization with Long Term Constraints </title><author>Mehrdad Mahdavi, Rong Jin, Tianbao Yang</author><abstract>

In this paper we propose efficient algorithms for solving constrained online convex optimization problems. Our motivation stems from the observation that most  algorithms proposed for online convex optimization require a projection onto the convex set &lt;i&gt;&lt;i&gt;K&lt;/i&gt;&lt;/i&gt; from which the decisions are made. While  the projection is straightforward for simple shapes (e.g., Euclidean ball), for arbitrary complex sets it is  the main computational challenge and may be inefficient in practice. In this paper, we consider an alternative online convex optimization problem. Instead of requiring that decisions belong to &lt;i&gt;&lt;i&gt;K&lt;/i&gt;&lt;/i&gt;  for all rounds, we only require that the constraints, which define the set &lt;i&gt;&lt;i&gt;K&lt;/i&gt;&lt;/i&gt;, be satisfied in the long run.  By turning the problem into an online convex-concave optimization problem, we propose an efficient algorithm which achieves &lt;i&gt;O(&amp;#8730;T)&lt;/i&gt;  regret bound and &lt;i&gt;O(T&lt;sup&gt;3/4&lt;/sup&gt;)&lt;/i&gt; bound on the violation of constraints. Then, we modify the algorithm in order to guarantee that the constraints are satisfied in the long run. This gain is achieved at the price of getting &lt;i&gt;O(T&lt;sup&gt;3/4&lt;/sup&gt;)&lt;/i&gt;  regret bound. Our second algorithm is based on the mirror prox method (Nemirovski, 2005) to solve variational inequalities which achieves &lt;i&gt;O(T&lt;sup&gt;2/3&lt;/sup&gt;)&lt;/i&gt; bound for both regret and the violation of constraints  when the domain &lt;i&gt;K&lt;/i&gt; can be described by a finite number of linear constraints. Finally, we extend the results to the setting where we only have partial access to the convex set &lt;i&gt;&lt;i&gt;K&lt;/i&gt;&lt;/i&gt; and propose a multipoint bandit feedback algorithm with the same bounds in expectation as our first algorithm.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/mahdavi12a/mahdavi12a.pdf</url></Article><Article><id>951</id><title> Robust Kernel Density Estimation </title><author>JooSeuk Kim, Clayton D. Scott</author><abstract>

We propose a method for nonparametric density estimation that exhibits robustness to contamination of the training sample. This method achieves robustness by combining a traditional kernel density estimator (KDE) with ideas from classical &lt;i&gt;M&lt;/i&gt;-estimation. We interpret the KDE based on a positive semi-definite kernel as a sample mean in the associated reproducing kernel Hilbert space. Since the sample mean is sensitive to outliers, we estimate it robustly via &lt;i&gt;M&lt;/i&gt;-estimation, yielding a robust kernel density estimator (RKDE).  &lt;br&gt; An RKDE can be computed efficiently via a kernelized iteratively re-weighted least squares (IRWLS) algorithm. Necessary and sufficient conditions are given for kernelized IRWLS to converge to the global minimizer of the &lt;i&gt;M&lt;/i&gt;-estimator objective function. The robustness of the RKDE is demonstrated with a representer theorem, the influence function, and experimental results for density estimation and anomaly detection.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kim12b/kim12b.pdf</url></Article><Article><id>952</id><title> Nonparametric Guidance of Autoencoder Representations using Label Information </title><author>Jasper Snoek, Ryan P. Adams, Hugo Larochelle</author><abstract>

While unsupervised learning has long been useful for density modeling, exploratory data analysis and visualization, it has become increasingly important for discovering features that will later be used for discriminative tasks.  Discriminative algorithms often work best with highly-informative features; remarkably, such features can often be learned without the labels.  One particularly effective way to perform such unsupervised learning has been to use autoencoder neural networks, which find latent representations that are constrained but nevertheless informative for reconstruction.  However, &lt;i&gt;pure&lt;/i&gt; unsupervised learning with autoencoders can find representations that may or may not be useful for the ultimate discriminative task.  It is a continuing challenge to guide the training of an autoencoder so that it finds features which will be useful for predicting labels.  Similarly, we often have &lt;i&gt;a priori&lt;/i&gt; information regarding what statistical variation will be irrelevant to the ultimate discriminative task, and we would like to be able to use this for guidance as well.  Although a typical strategy would be to include a parametric discriminative model as part of the autoencoder training, here we propose a nonparametric approach that uses a Gaussian process to guide the representation.  By using a nonparametric model, we can ensure that a useful discriminative function exists for a given set of features, without explicitly instantiating it.  We demonstrate the superiority of this guidance mechanism on four data sets, including a real-world application to rehabilitation research.  We also show how our proposed approach can learn to explicitly ignore statistically significant covariate information that is label-irrelevant, by evaluating on the small NORB image recognition problem in which pose and lighting labels are available.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/snoek12a/snoek12a.pdf</url></Article><Article><id>953</id><title> Finding Recurrent Patterns from Continuous Sign Language Sentences for Automated Extraction of Signs </title><author>Sunita Nayak, Kester Duncan, Sudeep Sarkar, Barbara Loeding</author><abstract>

We present a probabilistic framework to automatically learn models of recurring signs from multiple sign language video sequences containing the vocabulary of interest. We extract the parts of the signs that are present in most occurrences of the sign in context and are robust to the variations produced by adjacent signs. Each sentence video is first transformed into a multidimensional time series representation, capturing the motion and shape aspects of the sign. Skin color blobs are extracted from frames of color video sequences, and a probabilistic relational distribution is formed for each frame using the contour and edge pixels from the skin blobs. Each sentence is represented as a trajectory in a low dimensional space called the space of relational distributions. Given these time series trajectories, we extract signemes from multiple sentences concurrently using iterated conditional modes (ICM). We show results by learning single signs from a collection of sentences with one common pervading sign, multiple signs from a collection of sentences with more than one common sign, and single signs from a mixed collection of sentences. The extracted signemes demonstrate that our approach is robust to some extent to the variations produced within a sign due to different contexts. We also show results whereby these learned sign models are used for spotting signs in test sequences.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/nayak12a/nayak12a.pdf</url></Article><Article><id>954</id><title> Static Prediction Games for Adversarial Learning Problems </title><author>Michael Br&amp;#252;ckner, Christian Kanzow, Tobias Scheffer</author><abstract>

The standard assumption of identically distributed training and test data is violated when the test data are generated in response to the presence of a predictive model. This becomes apparent, for example, in the context of email spam filtering. Here, email service providers employ spam filters, and spam senders engineer campaign templates to achieve a high rate of successful deliveries despite the filters. We model the interaction between the learner and the data generator as a static game in which the cost functions of the learner and the data generator are not necessarily antagonistic. We identify conditions under which this prediction game has a unique Nash equilibrium and derive algorithms that find the equilibrial prediction model. We derive two instances, the Nash logistic regression and the Nash support vector machine, and empirically explore their properties in a case study on email spam filtering.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/brueckner12a/brueckner12a.pdf</url></Article><Article><id>955</id><title> Selective Sampling and Active Learning from Single and Multiple Teachers </title><author>Ofer Dekel, Claudio Gentile, Karthik Sridharan</author><abstract>

We present a new online learning algorithm in the selective sampling framework, where labels must be actively queried before they are revealed. We prove bounds on the regret of our algorithm and on the number of labels it queries when faced with an adaptive adversarial strategy of generating the instances. Our bounds both generalize and strictly improve over previous bounds in similar settings. Additionally, our selective sampling algorithm can be converted into an efficient statistical active learning algorithm. We extend our algorithm and analysis to the multiple-teacher setting, where the algorithm can choose which subset of teachers to query for each label. Finally, we demonstrate the effectiveness of our techniques on a real-world Internet search problem.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/dekel12b/dekel12b.pdf</url></Article><Article><id>956</id><title> PREA: Personalized Recommendation Algorithms Toolkit </title><author>Joonseok Lee, Mingxuan Sun, Guy Lebanon</author><abstract>

Recommendation systems are important business applications with significant economic impact. In recent years, a large number of algorithms have been proposed for recommendation systems. In this paper, we describe an open-source toolkit implementing many recommendation algorithms as well as popular evaluation metrics. In contrast to other packages, our toolkit implements recent state-of-the-art algorithms as well as most classic algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lee12b/lee12b.pdf</url></Article><Article><id>957</id><title> Coherence Functions with Applications in Large-Margin Classification Methods </title><author>Zhihua Zhang, Dehua Liu, Guang Dai, Michael I. Jordan</author><abstract>

Support vector machines (SVMs) naturally embody sparseness due to their use of hinge loss functions. However, SVMs can not directly estimate conditional class probabilities. In this paper we propose and study a family of &lt;i&gt;coherence functions&lt;/i&gt;, which are convex and differentiable, as surrogates of the hinge function. The coherence function is derived by using the maximum-entropy principle and is characterized by a temperature parameter. It bridges the hinge function and the logit function in logistic regression.  The limit of the coherence function at zero temperature corresponds to the hinge function, and the limit of the minimizer of its expected error is the minimizer of  the expected error of the hinge loss.  We refer to the use of the coherence function in large-margin classification as "&lt;i&gt;&lt;i&gt;C-learning&lt;/i&gt;&lt;/i&gt;," and we present efficient coordinate descent algorithms for the training of regularized &lt;i&gt;C&lt;/i&gt;-learning models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhang12c/zhang12c.pdf</url></Article><Article><id>958</id><title> Linear Regression With Random Projections </title><author>Odalric-Ambrym Maillard, R&amp;#233;mi Munos</author><abstract>

We investigate a method for regression that makes use of a randomly generated subspace &lt;i&gt;G&lt;sub&gt;P&lt;/sub&gt;&amp;#8834;F&lt;/i&gt; (of finite dimension &lt;i&gt;P&lt;/i&gt;) of a given large (possibly infinite) dimensional function space &lt;i&gt;F&lt;/i&gt;, for example, &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;([0,1]&lt;sup&gt;d&lt;/sup&gt;;&amp;#8476;)&lt;/i&gt;.  &lt;i&gt;G&lt;sub&gt;P&lt;/sub&gt;&lt;/i&gt; is defined as the span of &lt;i&gt;P&lt;/i&gt; random features  that are linear combinations of a basis functions of &lt;i&gt;F&lt;/i&gt; weighted by random Gaussian i.i.d. coefficients.  We show practical motivation for the use of this approach, detail the link that this random projections method share with RKHS and Gaussian objects theory and prove, both in deterministic and random design, approximation error bounds when searching for the best regression function in &lt;i&gt;G&lt;sub&gt;P&lt;/sub&gt;&lt;/i&gt; rather than in &lt;i&gt;F&lt;/i&gt;, and derive excess risk bounds for a specific regression algorithm (least squares regression in &lt;i&gt;G&lt;sub&gt;P&lt;/sub&gt;&lt;/i&gt;). This paper stresses the motivation to study such methods, thus the analysis developed is kept simple for explanations purpose and leaves room for future developments.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/maillard12a/maillard12a.pdf</url></Article><Article><id>959</id><title> Multi-task Regression using Minimal Penalties </title><author>Matthieu Solnon, Sylvain Arlot, Francis Bach</author><abstract>

In this paper we study the kernel  multiple ridge regression framework, which we refer to as multi-task regression, using penalization techniques. The theoretical analysis of this problem shows that the key element appearing for an optimal calibration is the covariance matrix of the noise between the different tasks. We present a new algorithm to estimate this covariance matrix, based on the concept of minimal penalty, which was previously used in the single-task regression framework to estimate the variance of the noise. We show, in a non-asymptotic setting and under mild assumptions on the target function, that this estimator converges towards the covariance matrix. Then plugging this estimator into the corresponding ideal penalty leads to an oracle inequality. We illustrate the behavior of our algorithm on synthetic examples.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/solnon12a/solnon12a.pdf</url></Article><Article><id>960</id><title> A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss </title><author>Jos&amp;#233; Hern&amp;#225;ndez-Orallo, Peter Flach, C&amp;#232;sar Ferri</author><abstract>

Many performance metrics have been introduced in the literature for the evaluation of classification performance, each of them with different origins and areas of application. These metrics include accuracy, unweighted accuracy, the area under the ROC curve or the ROC convex hull, the mean absolute error and the Brier score or mean squared error (with its decomposition into refinement and calibration). One way of understanding the relations among these metrics is by means of variable operating conditions (in the form of misclassification costs and/or class distributions). Thus, a metric may correspond to some expected loss over different operating conditions. One dimension for the analysis has been the distribution for this range of operating conditions, leading to some important connections in the area of proper scoring rules. We demonstrate in this paper that there is an equally important dimension which has so far received much less attention in the analysis of performance metrics. This dimension is given by the decision rule, which is typically implemented as a &lt;i&gt;threshold choice method&lt;/i&gt; when using scoring models. In this paper, we explore many old and new threshold choice methods: fixed, score-uniform, score-driven, rate-driven and optimal, among others. By calculating the expected loss obtained with these threshold choice methods for a uniform range of operating conditions we give clear interpretations of the 0-1 loss, the absolute error, the Brier score, the AUC and the refinement loss respectively. Our analysis provides a comprehensive view of performance metrics as well as a systematic approach to loss minimisation which can be summarised as follows: given a model, apply the threshold choice methods that correspond with the available information about the operating condition, and compare their expected losses. In order to assist in this procedure we also derive several connections between the aforementioned performance metrics, and we highlight the role of calibration in choosing the threshold choice method.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hernandez-orallo12a/hernandez-orallo12a.pdf</url></Article><Article><id>961</id><title> Local and Global Scaling Reduce Hubs in Space </title><author>Dominik Schnitzer, Arthur Flexer, Markus Schedl, Gerhard Widmer</author><abstract>

'Hubness' has recently been identified as a general problem of high dimensional data spaces, manifesting itself in the emergence of objects, so-called hubs, which tend to be among the &lt;i&gt;k&lt;/i&gt; nearest neighbors of a large number of data items. As a consequence many nearest neighbor relations in the distance space are asymmetric, that is, object &lt;i&gt;y&lt;/i&gt; is amongst the nearest neighbors of &lt;i&gt;x&lt;/i&gt; but not vice versa. The work presented here discusses two classes of methods that try to symmetrize nearest neighbor relations and investigates to what extent they can mitigate the negative effects of hubs. We evaluate local distance scaling and propose a global variant which has the advantage of being easy to approximate for large data sets and of having a probabilistic interpretation. Both local and global approaches are shown to be effective especially for high-dimensional data sets, which are affected by high hubness. Both methods lead to a strong decrease of hubness in these data sets, while at the same time improving properties like classification accuracy. We evaluate the methods on a large number of public machine learning data sets and synthetic data. Finally we present a real-world application where we are able to achieve significantly higher retrieval quality.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/schnitzer12a/schnitzer12a.pdf</url></Article><Article><id>962</id><title> Online Submodular Minimization </title><author>Elad Hazan, Satyen Kale</author><abstract>

We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efficient and are Hannan-consistent in both the full information and partial feedback settings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hazan12a/hazan12a.pdf</url></Article><Article><id>963</id><title> Efficient Methods for Robust Classification Under Uncertainty in Kernel Matrices </title><author>Aharon Ben-Tal, Sahely Bhadra, Chiranjib Bhattacharyya, Arkadi Nemirovski</author><abstract>

In this paper we study the problem of designing SVM classifiers when the kernel matrix, &lt;i&gt;&lt;b&gt;K&lt;/b&gt;&lt;/i&gt;, is affected by uncertainty. Specifically &lt;i&gt;&lt;b&gt;K&lt;/b&gt;&lt;/i&gt; is modeled as a positive affine combination of given positive semi definite kernels, with the coefficients ranging in a norm-bounded uncertainty set. We treat the problem using the Robust Optimization methodology. This reduces the uncertain SVM problem into a deterministic conic quadratic problem which can be solved in principle by a polynomial time Interior Point (IP) algorithm. However, for large-scale classification problems,  IP methods become intractable and one has to resort to first-order gradient type methods. The strategy we use here is to reformulate the robust counterpart of the uncertain SVM problem as a saddle point problem and employ a special gradient scheme which works directly on the convex-concave saddle function. The algorithm is a simplified version of a general scheme due to Juditski and Nemirovski (2011). It achieves an &lt;i&gt;O(1/T&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; reduction of the initial error after &lt;i&gt;T&lt;/i&gt; iterations. A comprehensive empirical study on both synthetic data and real-world protein structure data sets show that the proposed formulations achieve the desired robustness, and the saddle point based algorithm outperforms the IP method significantly.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ben-tal12a/ben-tal12a.pdf</url></Article><Article><id>964</id><title> Facilitating Score and Causal Inference Trees for Large Observational Studies </title><author>Xiaogang Su, Joseph Kang, Juanjuan Fan, Richard A. Levine, Xin Yan</author><abstract>

Assessing treatment effects in observational studies is a multifaceted problem that not only involves heterogeneous mechanisms of how the treatment or cause is exposed to subjects, known as propensity, but also differential causal effects across sub-populations. We introduce a concept termed the facilitating score to account for both the confounding and interacting impacts of covariates on the treatment effect. Several approaches for estimating the facilitating score are discussed. In particular, we put forward a machine learning method, called causal inference tree (CIT), to provide a piecewise constant approximation of the facilitating score. With interpretable rules, CIT splits data  in such a way that both the propensity and the treatment effect become more homogeneous within each resultant partition. Causal inference at different levels can be made on the basis of CIT.  Together with an aggregated grouping procedure, CIT stratifies data into strata where causal effects can be conveniently assessed within each. Besides, a feasible way of predicting individual causal effects (ICE) is made available by aggregating ensemble CIT models. Both the stratified results and the estimated ICE provide an assessment of heterogeneity of causal effects and can be integrated for estimating the average causal effect (ACE). Mean square consistency of CIT is also established. We evaluate the performance of proposed methods with simulations and illustrate their use with the NSW data in Dehejia and Wahba (1999) where the objective is to assess the impact of a labor training program, the National Supported Work (NSW) demonstration, on post-intervention earnings.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/su12a/su12a.pdf</url></Article><Article><id>965</id><title> Oger: Modular Learning Architectures For Large-Scale Sequential Processing </title><author>David Verstraeten, Benjamin Schrauwen, Sander Dieleman, Philemon Brakel, Pieter Buteneers, Dejan Pecevski</author><abstract>

Oger (OrGanic Environment for Reservoir computing) is a Python toolbox for building, training and evaluating modular learning architectures on large data sets. It builds on MDP for its modularity, and adds processing of sequential data sets, gradient descent training, several cross-validation schemes and parallel parameter optimization methods. Additionally, several learning algorithms are implemented, such as different reservoir implementations (both sigmoid and spiking), ridge regression, conditional restricted Boltzmann machine (CRBM) and others, including GPU accelerated versions. Oger is released under the GNU LGPL, and is available from http://organic.elis.ugent.be/oger.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/verstraeten12a/verstraeten12a.pdf</url></Article><Article><id>966</id><title> Multi-Instance Learning with Any Hypothesis Class </title><author>Sivan Sabato, Naftali Tishby</author><abstract>

In the supervised learning setting termed Multiple-Instance Learning (MIL), the examples are bags of instances, and the bag label is a function of the labels of its instances. Typically, this function is the Boolean OR. The learner observes a sample of bags and the bag labels, but not the instance labels that determine the bag labels. The learner is then required to emit a classification rule for bags based on the sample. MIL has numerous applications, and many heuristic algorithms have been used successfully on this problem, each adapted to specific settings or applications.  In this work we provide a unified theoretical analysis for MIL, which holds for any underlying hypothesis class, regardless of a specific application or problem domain. We show that the sample complexity of MIL is only poly-logarithmically dependent on the size of the bag, for any underlying hypothesis class.  In addition, we introduce a new PAC-learning algorithm for MIL, which uses a regular supervised learning algorithm as an oracle. We prove that efficient PAC-learning for MIL can be generated from any efficient non-MIL supervised learning algorithm that handles one-sided error. The computational complexity of the resulting algorithm is only polynomially dependent on the bag size.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/sabato12a/sabato12a.pdf</url></Article><Article><id>967</id><title> Finite-Sample Analysis of Least-Squares Policy Iteration </title><author>Alessandro Lazaric, Mohammad Ghavamzadeh, R&amp;#233;mi Munos</author><abstract>

In this paper, we report a performance bound for the widely used least-squares policy iteration (LSPI) algorithm. We first consider the problem of policy evaluation in reinforcement learning, that is, learning the value function of a fixed policy, using the least-squares temporal-difference (LSTD) learning method, and report finite-sample analysis for this algorithm. To do so, we first derive a bound on the performance of the LSTD solution evaluated at the states generated by the Markov chain and used by the algorithm to learn an estimate of the value function. This result is general in the sense that no assumption is made on the existence of a stationary distribution for the Markov chain. We then derive generalization bounds in the case when the Markov chain possesses a stationary distribution and is &lt;i&gt;&amp;#946;&lt;/i&gt;-mixing. Finally, we analyze how the error at each policy evaluation step is propagated through the iterations of a policy iteration method, and derive a performance bound for the LSPI algorithm.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lazaric12a/lazaric12a.pdf</url></Article><Article><id>968</id><title> Discriminative Hierarchical Part-based Models for Human Parsing and Action Recognition </title><author>Yang Wang, Duan Tran, Zicheng Liao, David Forsyth</author><abstract>

We consider the problem of parsing human poses and recognizing their actions in static images with part-based models. Most previous work in part-based models only considers rigid parts (e.g., torso, head, half limbs) guided by human anatomy. We argue that this representation of parts is not necessarily appropriate. In this paper, we introduce hierarchical poselets---a new representation for modeling the pose configuration of human bodies. Hierarchical poselets can be rigid parts, but they can also be parts that cover large portions of human bodies (e.g., torso + left arm). In the extreme case, they can be the whole bodies. The hierarchical poselets are organized in a hierarchical way via a structured model. Human parsing can be achieved by inferring the optimal labeling of this hierarchical model. The pose information captured by this hierarchical model can also be used as a intermediate representation for other high-level tasks. We demonstrate it in action recognition from static images.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/wang12a/wang12a.pdf</url></Article><Article><id>969</id><title> Breaking the Curse of Kernelization: Budgeted Stochastic Gradient Descent for Large-Scale SVM Training </title><author>Zhuang Wang, Koby Crammer, Slobodan Vucetic</author><abstract>

Online algorithms that process one example at a time are advantageous when dealing with very large data or with data streams. Stochastic Gradient Descent (SGD) is such an algorithm and it is an attractive choice for online Support Vector Machine (SVM) training due to its simplicity and effectiveness. When equipped with kernel functions, similarly to other SVM learning algorithms, SGD is susceptible to the curse of kernelization that causes unbounded linear growth in model size and update time with data size. This may render SGD inapplicable to large data sets. We address this issue by presenting a class of Budgeted SGD (BSGD) algorithms for large-scale kernel SVM training which have constant space and constant time complexity per update. Specifically, BSGD keeps the number of support vectors bounded during training through several budget maintenance strategies. We treat the budget maintenance as a source of the gradient error, and show that the gap between the BSGD and the optimal SVM solutions depends on the model degradation due to budget maintenance. To minimize the gap, we study greedy budget maintenance methods based on removal, projection, and merging of support vectors. We propose budgeted versions of several popular online SVM algorithms that belong to the SGD family. We further derive BSGD algorithms for multi-class SVM training. Comprehensive empirical results show that BSGD achieves higher accuracy than the state-of-the-art budgeted online algorithms and comparable to non-budget algorithms, while achieving impressive computational efficiency both in time and space during training and prediction.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/wang12b/wang12b.pdf</url></Article><Article><id>970</id><title> Bayesian Mixed-Effects Inference on Classification Performance in Hierarchical Data Sets </title><author>Kay H. Brodersen, Christoph Mathys, Justin R. Chumbley, Jean Daunizeau, Cheng Soon Ong, Joachim M. Buhmann, Klaas E. Stephan</author><abstract>

Classification algorithms are frequently used on data with a natural hierarchical structure. For instance, classifiers are often trained and tested on trial-wise measurements, separately for each subject within a group. One important question is how classification outcomes observed in individual subjects can be generalized to the population from which the group was sampled. To address this question, this paper introduces novel statistical models that are guided by three desiderata. First, all models explicitly respect the hierarchical nature of the data, that is, they are mixed-effects models that simultaneously account for within-subjects (fixed-effects) and across-subjects (random-effects) variance components. Second, maximum-likelihood estimation is replaced by full Bayesian inference in order to enable natural regularization of the estimation problem and to afford conclusions in terms of posterior probability statements. Third, inference on classification accuracy is complemented by inference on the balanced accuracy, which avoids inflated accuracy estimates for imbalanced data sets. We introduce hierarchical models that satisfy these criteria and demonstrate their advantages over conventional methods using MCMC implementations for model inversion and model selection on both synthetic and empirical data. We envisage that our approach will improve the sensitivity and validity of statistical inference in future hierarchical classification studies.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/brodersen12a/brodersen12a.pdf</url></Article><Article><id>971</id><title> Quantum Set Intersection and its Application to Associative Memory </title><author>Tamer Salman, Yoram Baram</author><abstract>

We describe a quantum algorithm for computing the intersection of two sets and its application to associative memory. The algorithm is based on a modification of Grover's quantum search algorithm (Grover, 1996). We present algorithms for pattern retrieval, pattern completion, and pattern correction. We show that the quantum associative memory can store an exponential number of memories and retrieve them in sub-exponential time. We prove that this model has advantages over known classical associative memories as well as previously proposed quantum models.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/salman12a/salman12a.pdf</url></Article><Article><id>972</id><title> Dynamic Policy Programming </title><author>Mohammad Gheshlaghi Azar, Vicen&amp;#231; G&amp;#243;mez, Hilbert J. Kappen</author><abstract>

In this paper, we propose a novel policy iteration method, called dynamic policy programming (DPP), to estimate the optimal policy in the infinite-horizon Markov decision processes.  DPP is an incremental algorithm that forces a gradual change in policy update.  This allows us to prove finite-iteration and asymptotic  &lt;i&gt;&lt;i&gt;l&lt;/i&gt;&lt;sub&gt;&amp;#8734;&lt;/sub&gt;&lt;/i&gt;-norm performance-loss bounds in the presence of approximation/estimation error which depend on the average accumulated error as opposed to the standard bounds which are expressed in terms of  the supremum of the errors.  The dependency on the average error is important in problems with limited number of samples per iteration, for which the average of the errors can be significantly smaller in size than the supremum of the errors. Based on these theoretical results, we prove that a sampling-based variant of DPP (DPP-RL) asymptotically converges to the optimal policy. Finally, we illustrate numerically the applicability of these results on some benchmark problems and compare the performance of the approximate variants of DPP with some existing reinforcement learning (RL) methods.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/azar12a/azar12a.pdf</url></Article><Article><id>973</id><title> Sally: A Tool for Embedding Strings in Vector Spaces </title><author>Konrad Rieck, Christian Wressnegger, Alexander Bikadorov</author><abstract>

Strings and sequences are ubiquitous in many areas of data analysis. However, only few learning methods can be directly applied to this form of data.  We present Sally, a tool for embedding strings in vector spaces that allows for applying a wide range of learning methods to string data.  Sally implements a generalized form of the bag-of-words model, where strings are mapped to a vector space that is spanned by a set of string features, such as words or n-grams of words. The implementation of Sally builds on efficient string algorithms and enables processing millions of strings and features. The tool supports several data formats and is capable of interfacing with common learning environments, such as Weka, Shogun, Matlab, or Pylab. Sally has been successfully applied for learning with natural language text, DNA sequences and monitored program behavior.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/rieck12a/rieck12a.pdf</url></Article><Article><id>974</id><title> Linear Fitted-Q Iteration with Multiple Reward Functions </title><author>Daniel J. Lizotte, Michael Bowling, Susan A. Murphy</author><abstract>

We present a general and detailed development of an algorithm for finite-horizon fitted-Q iteration with an arbitrary number of reward signals and linear value function approximation using an arbitrary number of state features. This includes a detailed treatment of the 3-reward function case using triangulation primitives from computational geometry and a method for identifying globally dominated actions.  We also present an example of how our methods can be used to construct a real-world decision aid by considering symptom reduction, weight gain, and quality of life in sequential treatments for schizophrenia. Finally, we discuss future directions in which to take this work that will further enable our methods to make a positive impact on the field of evidence-based clinical decision support.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lizotte12a/lizotte12a.pdf</url></Article><Article><id>975</id><title> Human Gesture Recognition on Product Manifolds </title><author>Yui Man Lui</author><abstract>

Action videos are multidimensional data and can be naturally represented as data tensors.  While tensor computing is widely used in computer vision, the geometry of tensor space is often ignored. The aim of this paper is to demonstrate the importance of the intrinsic geometry of tensor space which yields a very discriminating structure for action recognition. We characterize data tensors as points on a product manifold and model it statistically using least squares regression. To this aim, we factorize a data tensor relating to each order of the tensor using Higher Order Singular Value Decomposition (HOSVD) and then impose each factorized element on a Grassmann manifold. Furthermore, we account for underlying geometry on manifolds and formulate least squares regression as a composite function. This gives a natural extension from Euclidean space to manifolds. Consequently, classification is performed using geodesic distance on a product manifold where each factor manifold is Grassmannian.  Our method exploits appearance and motion without explicitly modeling the shapes and dynamics. We assess the proposed method using three gesture databases, namely the Cambridge hand-gesture, the UMD Keck body-gesture, and the CHALEARN gesture challenge data sets. Experimental results reveal that not only does the proposed method perform well on the standard benchmark data sets, but also it generalizes well on the one-shot-learning gesture challenge. Furthermore, it is based on a simple statistical model and the intrinsic geometry of tensor space.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lui12a/lui12a.pdf</url></Article><Article><id>976</id><title> Large-scale Linear Support Vector Regression </title><author>Chia-Hua Ho, Chih-Jen Lin</author><abstract>

Support vector regression (SVR) and support vector classification (SVC) are popular learning techniques, but their use with kernels is often time consuming.  Recently, linear SVC without kernels has been shown to give competitive accuracy for some applications, but enjoys much faster training/testing.  However, few studies have focused on linear SVR.  In this paper, we extend state-of-the-art training methods for linear SVC to linear SVR.  We show that the extension is straightforward for some methods, but is not trivial for some others.  Our experiments demonstrate that for some problems, the proposed linear-SVR training methods can very efficiently produce models that are as good as kernel SVR.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ho12a/ho12a.pdf</url></Article><Article><id>977</id><title> Sparse and Unique Nonnegative Matrix Factorization Through Data Preprocessing </title><author>Nicolas Gillis</author><abstract>

Nonnegative matrix factorization (NMF) has become a very popular technique in machine learning because it automatically extracts meaningful features through a sparse and part-based representation. However, NMF has the drawback of being highly ill-posed, that is, there typically exist many different but equivalent factorizations.  In this paper, we introduce a completely new way to obtaining more well-posed NMF problems whose solutions are sparser. Our technique is based on the preprocessing of the nonnegative input data matrix, and relies on the theory of M-matrices and the geometric interpretation of NMF.  This approach provably leads to optimal and sparse solutions under the separability assumption of Donoho and Stodden (2003), and, for rank-three matrices, makes the number of exact factorizations finite. We illustrate the effectiveness of our technique on several image data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/gillis12a/gillis12a.pdf</url></Article><Article><id>978</id><title> Learning Linear Cyclic Causal Models with Latent Variables </title><author>Antti Hyttinen, Frederick Eberhardt, Patrik O. Hoyer</author><abstract>

Identifying cause-effect relationships between variables of interest is a central problem in science. Given a set of experiments we describe a procedure that identifies linear models that may contain cycles and latent variables. We provide a detailed description of the model family, full proofs of the necessary and sufficient conditions for identifiability, a search algorithm that is complete, and a discussion of what can be done when the identifiability conditions are not satisfied. The algorithm is comprehensively tested in simulations, comparing it to competing algorithms in the literature. Furthermore, we adapt the procedure to the problem of cellular network inference, applying it to the biologically realistic data of the DREAM challenges. The paper provides a full theoretical foundation for the causal discovery procedure first presented by Eberhardt et al. (2010) and Hyttinen et al. (2010).


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/hyttinen12a/hyttinen12a.pdf</url></Article><Article><id>979</id><title> Iterative Reweighted Algorithms for Matrix Rank Minimization </title><author>Karthik Mohan, Maryam Fazel</author><abstract>

The problem of minimizing the rank of a matrix subject to affine constraints has applications in several areas including machine learning, and is known to be NP-hard. A tractable relaxation for this problem is nuclear norm (or trace norm) minimization, which is guaranteed to find the minimum rank matrix under suitable assumptions.  In this paper, we propose a family of Iterative Reweighted Least Squares algorithms IRLS-&lt;i&gt;p&lt;/i&gt; (with &lt;i&gt;0 &amp;#8804; p &amp;#8804; 1&lt;/i&gt;), as a computationally efficient way to improve over the performance of nuclear norm minimization. The algorithms can be viewed as (locally) minimizing certain smooth approximations to the rank function. When &lt;i&gt;p=1&lt;/i&gt;, we give theoretical guarantees similar to those for nuclear norm minimization, that is, recovery of low-rank matrices under certain assumptions on the operator defining the constraints. For &lt;i&gt;p &lt; 1&lt;/i&gt;, IRLS-&lt;i&gt;p&lt;/i&gt; shows better empirical performance in terms of recovering low-rank matrices than nuclear norm minimization.  We provide an efficient implementation for IRLS-&lt;i&gt;p&lt;/i&gt;, and also present a related family of algorithms, sIRLS-&lt;i&gt;p&lt;/i&gt;. These algorithms exhibit competitive run times and improved recovery when compared to existing algorithms for random instances of the matrix completion problem, as well as on the MovieLens movie recommendation data set.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/mohan12a/mohan12a.pdf</url></Article><Article><id>980</id><title> Fast Approximation of Matrix Coherence and Statistical Leverage </title><author>Petros Drineas, Malik Magdon-Ismail, Michael W. Mahoney, David P. Woodruff</author><abstract>

The &lt;i&gt;statistical leverage scores&lt;/i&gt; of a matrix &lt;i&gt;A&lt;/i&gt; are the squared row-norms of the matrix containing its (top) left singular vectors and the &lt;i&gt;coherence&lt;/i&gt; is the largest leverage score.  These quantities are of interest in recently-popular problems such as matrix completion and Nystr&amp;#246;m-based low-rank matrix approximation as well as in large-scale statistical data analysis applications more generally; moreover, they are of interest since they define the key structural nonuniformity that must be dealt with in developing fast randomized matrix algorithms.  Our main result is a randomized algorithm that takes as input an arbitrary &lt;i&gt;n &amp;#215; d&lt;/i&gt; matrix &lt;i&gt;A&lt;/i&gt;, with &lt;i&gt;n &amp;#62;&amp;#62; d&lt;/i&gt;, and that returns as output relative-error approximations to &lt;i&gt;all&lt;/i&gt; &lt;i&gt;n&lt;/i&gt; of the statistical leverage scores. The proposed algorithm runs (under assumptions on the precise values of &lt;i&gt;n&lt;/i&gt; and &lt;i&gt;d&lt;/i&gt;) in &lt;i&gt;O(n d log n)&lt;/i&gt;  time, as opposed to the &lt;i&gt;O(nd&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; time required by the na&amp;#239;ve algorithm that involves computing an orthogonal basis for the range of &lt;i&gt;A&lt;/i&gt;. Our analysis may be viewed in terms of computing a relative-error approximation to an &lt;i&gt;under&lt;/i&gt;constrained least-squares approximation problem, or, relatedly, it may be viewed as an application of Johnson-Lindenstrauss type ideas. Several practically-important extensions of our basic result are also described, including the approximation of so-called cross-leverage scores, the extension of these ideas to matrices with &lt;i&gt;n &amp;#8776; d&lt;/i&gt;, and the extension to streaming environments.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/drineas12a/drineas12a.pdf</url></Article><Article><id>981</id><title> PAC-Bayes Bounds with Data Dependent Priors </title><author>Emilio Parrado-Hern&amp;#225;ndez, Amiran Ambroladze, John Shawe-Taylor, Shiliang Sun</author><abstract>

This paper presents the prior PAC-Bayes bound and explores its capabilities as a tool to provide tight predictions of SVMs' generalization. The computation of the bound involves estimating a prior of the distribution of classifiers from the available data, and then manipulating this prior in the usual PAC-Bayes generalization bound. We explore two alternatives: to learn the prior from a separate data set, or to consider an expectation prior that does not need this separate data set. The prior PAC-Bayes bound motivates two SVM-like classification algorithms, prior SVM and &lt;i&gt;&amp;#951;&lt;/i&gt;-prior SVM, whose regularization term  pushes towards the minimization of the prior PAC-Bayes bound. The experimental work illustrates that the new bounds can be significantly tighter than the original PAC-Bayes bound when applied to SVMs, and among them the combination of the prior PAC-Bayes bound and the prior SVM algorithm gives the tightest bound.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/parrado12a/parrado12a.pdf</url></Article><Article><id>982</id><title> DARWIN: A Framework for Machine Learning and Computer Vision Research and Development </title><author>Stephen Gould</author><abstract>

We present an open-source platform-independent C++ framework for machine learning and computer vision research. The framework includes a wide range of standard machine learning and graphical models algorithms as well as reference implementations for many machine learning and computer vision applications. The framework contains Matlab wrappers for core components of the library and an experimental graphical user interface for developing and visualizing machine learning data flows.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/gould12a/gould12a.pdf</url></Article><Article><id>983</id><title> Regularized Bundle Methods for Convex and Non-Convex Risks </title><author>Trinh Minh Tri Do, Thierry Arti&amp;#232;res</author><abstract>

Machine learning is most often cast as an optimization problem. Ideally, one expects a convex objective function to rely on efficient convex optimizers with nice guarantees such as no local optima. Yet, non-convexity is very frequent in practice and it may sometimes be inappropriate to look for convexity at any price. Alternatively one can decide not to limit &lt;i&gt;a priori&lt;/i&gt; the modeling expressivity to models whose learning may be solved by convex optimization and rely on non-convex optimization algorithms. The main motivation of this work is to provide efficient and scalable algorithms for non-convex optimization. We focus on regularized unconstrained optimization problems which cover a large number of modern machine learning problems such as logistic regression, conditional random fields, large margin estimation, etc. We propose a novel algorithm for minimizing a regularized objective that is able to handle convex and non-convex, smooth and non-smooth risks. The algorithm is based on the cutting plane technique and on the idea of exploiting the regularization term in the objective function. It may be thought as a limited memory extension of convex regularized bundle methods for dealing with convex and non convex risks. In case the risk is convex the algorithm is proved to converge to a stationary solution with accuracy &lt;i&gt;&amp;#949;&lt;/i&gt; with a rate &lt;i&gt;O(1/&amp;#955;&amp;#949;)&lt;/i&gt; where &lt;i&gt;&amp;#955;&lt;/i&gt; is the regularization parameter of the objective function under the assumption of a Lipschitz empirical risk. In case the risk is not convex getting such a proof is more difficult and requires a stronger and more disputable assumption. Yet we provide experimental results on artificial test problems, and on five standard and difficult machine learning problems that are cast as convex and non-convex optimization problems that show how our algorithm compares well in practice with state of the art optimization algorithms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/do12a/do12a.pdf</url></Article><Article><id>984</id><title> Learning Symbolic Representations of Hybrid Dynamical Systems </title><author>Daniel L. Ly, Hod Lipson</author><abstract>

A hybrid dynamical system is a mathematical model suitable for describing an extensive spectrum of multi-modal, time-series behaviors, ranging from bouncing balls to air traffic controllers. This paper describes multi-modal symbolic regression (MMSR): a learning algorithm to construct non-linear symbolic representations of discrete dynamical systems with continuous mappings from unlabeled, time-series data. MMSR consists of two subalgorithms---clustered symbolic regression, a method to simultaneously identify distinct behaviors while formulating their mathematical expressions, and transition modeling, an algorithm to infer symbolic inequalities that describe binary classification boundaries. These subalgorithms are combined to infer hybrid dynamical systems as a collection of apt, mathematical expressions. MMSR is evaluated on a collection of four synthetic data sets and outperforms other multi-modal machine learning approaches in both accuracy and interpretability, even in the presence of noise. Furthermore, the versatility of MMSR is demonstrated by identifying and inferring classical expressions of transistor modes from recorded measurements.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/ly12a/ly12a.pdf</url></Article><Article><id>985</id><title> SVDFeature: A Toolkit for Feature-based Collaborative Filtering </title><author>Tianqi Chen, Weinan Zhang, Qiuxia Lu, Kailong Chen, Zhao Zheng, Yong Yu</author><abstract>

In this paper we introduce SVDFeature, a machine learning toolkit for feature-based collaborative filtering. SVDFeature is designed to efficiently solve the feature-based matrix factorization. The feature-based setting allows us to build factorization models incorporating side information such as temporal dynamics, neighborhood relationship, and hierarchical information.  The toolkit is capable of both rate prediction and collaborative ranking, and is carefully designed for efficient training on large-scale data set. Using this toolkit, we built solutions to win KDD Cup for two consecutive  years.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/chen12a/chen12a.pdf</url></Article><Article><id>986</id><title> Smoothing Multivariate Performance Measures </title><author>Xinhua Zhang, Ankan Saha, S.V.N. Vishwanathan</author><abstract>

Optimizing multivariate performance measure is an important task in Machine Learning.  Joachims (2005) introduced a Support Vector Method whose underlying optimization problem is commonly solved by cutting plane methods (CPMs) such as SVM-Perf and BMRM.  It can be shown that CPMs converge to an &lt;i&gt;&amp;#949;&lt;/i&gt; accurate solution in &lt;i&gt;O(1/&amp;#955; &amp;#949;)&lt;/i&gt; iterations, where &lt;i&gt;&amp;#955;&lt;/i&gt; is the trade-off parameter between the regularizer and the loss function.  Motivated by the impressive convergence rate of CPM on a number of practical problems, it was conjectured that these rates can be further improved.  We disprove this conjecture in this paper by constructing counter examples.  However, surprisingly, we further discover that these problems are not inherently hard, and we develop a novel smoothing strategy, which in conjunction with Nesterov's accelerated gradient method, can find an &lt;i&gt;&amp;#949;&lt;/i&gt; accurate solution in &lt;i&gt;O&lt;sup&gt;*&lt;/sup&gt; (min {1/&amp;#949;, 1/&amp;#8730;&amp;#955;&amp;#949;})&lt;/i&gt; iterations.  Computationally, our smoothing technique is also particularly advantageous for optimizing multivariate performance scores such as precision/recall break-even point and ROCArea; the cost per iteration remains the same as that of CPMs.  Empirical evaluation on some of the largest publicly available data sets shows that our method converges significantly faster than CPMs without sacrificing generalization ability.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/zhang12d/zhang12d.pdf</url></Article><Article><id>987</id><title> Security Analysis of Online Centroid Anomaly Detection </title><author>Marius Kloft, Pavel Laskov</author><abstract>

Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution, we analyze the performance of a particular method---online centroid anomaly detection---in the presence of adversarial noise.  Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efficiency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker's full or limited control over the traffic and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difficult (a strict upper bound on the attacker's gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit traffic, confirms the tightness of our theoretical bounds and the practicality of our protection mechanisms.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/kloft12b/kloft12b.pdf</url></Article><Article><id>988</id><title> Exploration in Relational Domains for Model-based Reinforcement Learning </title><author>Tobias Lang, Marc Toussaint, Kristian Kersting</author><abstract>

A fundamental problem in reinforcement learning is balancing exploration and exploitation. We address this problem in the context of model-based reinforcement learning in large stochastic relational domains by developing relational extensions of the concepts of the &lt;i&gt;E&lt;sup&gt;3&lt;/sup&gt;&lt;/i&gt; and R-MAX algorithms. Efficient exploration in exponentially large state spaces needs to exploit the generalization of the learned model: what in a propositional setting would be considered a novel situation and worth exploration may in the relational setting be a well-known context in which exploitation is promising. To address this we introduce relational count functions which generalize the classical notion of state and action visitation counts. We provide guarantees on the exploration efficiency of our framework using count functions under the assumption that we had a relational KWIK learner and a near-optimal planner. We propose a concrete exploration algorithm which integrates a practically efficient probabilistic rule learner and a relational planner (for which there are no guarantees, however) and employs the contexts of learned relational rules as features to model the novelty of states and actions. Our results in noisy 3D simulated robot manipulation problems and in domains of the international planning competition demonstrate that our approach is more effective than existing propositional and factored exploration techniques.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume13/lang12a/lang12a.pdf</url></Article><Article><id>989</id><title> Global Analytic Solution of Fully-observed Variational Bayesian Matrix Factorization </title><author>Shinichi Nakajima, Masashi Sugiyama, S. Derin Babacan, Ryota Tomioka</author><abstract>

The variational Bayesian (VB) approximation is known to be a promising approach to  Bayesian estimation, when the rigorous calculation of the Bayes posterior is intractable.  The VB approximation has been successfully applied to  &lt;i&gt;matrix factorization&lt;/i&gt; (MF), offering automatic dimensionality selection for principal component analysis.  Generally, finding the VB solution is a non-convex problem, and most methods rely on  a local search algorithm derived through a standard procedure for the VB approximation.  In this paper, we show that a better option is available for fully-observed VBMF---the global solution can be &lt;i&gt;analytically&lt;/i&gt; computed.  More specifically, the global solution is a reweighted SVD of the observed matrix, and each weight can be obtained by solving a quartic equation with its coefficients being functions of the observed singular value.  We further show that the global optimal solution of &lt;i&gt;empirical&lt;/i&gt; VBMF (where hyperparameters are also learned from data) can also be analytically computed.  We illustrate the usefulness of our results through experiments in multi-variate analysis.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/nakajima13a/nakajima13a.pdf</url></Article><Article><id>990</id><title> Ranking Forests </title><author>St&amp;#233;phan Cl&amp;#233;men&amp;#231;on, Marine Depecker, Nicolas Vayatis</author><abstract>

The present paper examines how the aggregation and feature randomization principles underlying the algorithm RANDOM FOREST (Breiman, 2001) can be adapted to &lt;i&gt;bipartite ranking&lt;/i&gt;. The approach taken here is based on nonparametric scoring and ROC curve optimization in the sense of the AUC criterion. In this problem, aggregation is used to increase the performance of scoring rules produced by ranking trees, as those developed in Cl&amp;#233;men&amp;#231;on and Vayatis (2009c). The present work describes the principles for building median scoring rules based on concepts from rank aggregation. Consistency results are derived for these aggregated scoring rules and an algorithm called RANKING FOREST is presented. Furthermore, various strategies for feature randomization are explored through a series of numerical experiments on artificial data sets.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/clemencon13a/clemencon13a.pdf</url></Article><Article><id>991</id><title> Nested Expectation Propagation for Gaussian Process Classification with a Multinomial Probit Likelihood </title><author>Jaakko Riihim&amp;#228;ki, Pasi Jyl&amp;#228;nki, Aki Vehtari</author><abstract>

This paper considers probabilistic multinomial probit classification using Gaussian process (GP) priors.  Challenges with multiclass GP classification are the integration over the non-Gaussian posterior distribution, and the increase of the number of unknown latent variables as the number of target classes grows.  Expectation propagation (EP) has proven to be a very accurate method for approximate inference but the existing EP approaches for the multinomial probit GP classification rely on numerical quadratures, or independence assumptions between the latent values associated with different classes, to facilitate the computations.  In this paper we propose a novel nested EP approach which does not require numerical quadratures, and approximates accurately all between-class posterior dependencies of the latent values, but still scales linearly in the number of classes.  The predictive accuracy of the nested EP approach is compared to Laplace, variational Bayes, and Markov chain Monte Carlo (MCMC) approximations with various benchmark data sets.  In the experiments nested EP was the most consistent method compared to MCMC sampling, but in terms of classification accuracy the differences between all the methods were small from a practical point of view.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/riihimaki13a/riihimaki13a.pdf</url></Article><Article><id>992</id><title> Pairwise Likelihood Ratios for Estimation of Non-Gaussian Structural Equation Models </title><author>Aapo Hyv&amp;#228;rinen, Stephen M. Smith</author><abstract>

We present new measures of the causal direction, or direction of effect, between two non-Gaussian random variables. They are based on the likelihood ratio under the linear non-Gaussian acyclic model (LiNGAM).  We also develop simple first-order approximations of the likelihood ratio and analyze them based on related cumulant-based measures, which can be shown to find the correct causal directions. We show how to apply these measures to estimate LiNGAM for more than two variables, and even in the case of more variables than observations. We further extend the method to cyclic and nonlinear models. The proposed framework is statistically at least as good as existing ones in the cases of few data points or noisy data, and it is computationally and conceptually very simple. Results on simulated fMRI data indicate that the method may be useful in neuroimaging where the number of time points is typically quite small.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/hyvarinen13a/hyvarinen13a.pdf</url></Article><Article><id>993</id><title> Universal Consistency of Localized Versions of Regularized Kernel Methods </title><author>Robert Hable</author><abstract>

In supervised learning problems, global and local learning algorithms are used. In contrast to global learning algorithms, the prediction of a local learning algorithm in a testing point is only based on training data which are close to the testing point.  Every global algorithm such as support vector machines (SVM) can be localized in the following way: in every testing point, the (global) learning algorithm is not applied to the whole training data but only to the &lt;i&gt;k&lt;/i&gt; nearest neighbors (kNN) of the testing point. In case of support vector machines, the success of such mixtures of SVM and kNN (called SVM-KNN) has been shown in extensive simulation studies and also for real data sets but only little has been known on theoretical properties so far. In the present article, it is shown how a large class of regularized kernel methods (including SVM) can be localized in order to get a universally consistent learning algorithm.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/hable13a/hable13a.pdf</url></Article><Article><id>994</id><title> Lower Bounds and Selectivity of Weak-Consistent Policies in Stochastic Multi-Armed Bandit Problem </title><author>Antoine Salomon, Jean-Yves Audibert, Issam El Alaoui</author><abstract>

This paper is devoted to regret lower bounds in the classical model of stochastic multi-armed bandit.  A well-known result of Lai and Robbins, which has then been extended by Burnetas and Katehakis, has established the presence of a logarithmic bound for all consistent policies. We relax the notion of consistency, and exhibit a generalisation of the bound. We also study the existence of logarithmic bounds in general and in the case of Hannan consistency. Moreover, we prove that it is impossible to design an adaptive policy that would select the best of two algorithms by taking advantage of the properties of the environment. To get these results, we study variants of popular Upper Confidence Bounds (UCB) policies.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/salomon13a/salomon13a.pdf</url></Article><Article><id>995</id><title> MAGIC Summoning:  Towards Automatic Suggesting and Testing of Gestures With Low Probability of False Positives During Use </title><author>Daniel Kyu Hwa Kohlsdorf, Thad E. Starner</author><abstract>

Gestures for interfaces should be short, pleasing, intuitive, and easily recognized by a computer.  However, it is a challenge for interface designers to create gestures easily distinguishable from users' normal movements.  Our tool MAGIC Summoning addresses this problem.  Given a specific platform and task, we gather a large database of unlabeled sensor data captured in the environments in which the system will be used (an "Everyday Gesture Library" or EGL).  The EGL is quantized and indexed via multi-dimensional Symbolic Aggregate approXimation (SAX) to enable quick searching.  MAGIC exploits the SAX representation of the EGL to suggest gestures with a low likelihood of false triggering.  Suggested gestures are ordered according to brevity and simplicity, freeing the interface designer to focus on the user experience.  Once a gesture is selected, MAGIC can output synthetic examples of the gesture to train a chosen classifier (for example, with a hidden Markov model).  If the interface designer suggests his own gesture and provides several examples, MAGIC estimates how accurately that gesture can be recognized and estimates its false positive rate by comparing it against the natural movements in the EGL.  We demonstrate MAGIC's effectiveness in gesture selection and helpfulness in creating accurate gesture recognizers.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/kohlsdorf13a/kohlsdorf13a.pdf</url></Article><Article><id>996</id><title> Sparse Single-Index Model </title><author>Pierre Alquier, G&amp;#233;rard Biau</author><abstract>

Let &lt;i&gt;(&lt;b&gt;X&lt;/b&gt;, Y)&lt;/i&gt; be a random pair taking values in &lt;i&gt;&amp;#8477;&lt;sup&gt;p&lt;/sup&gt; &amp;#215; &amp;#8477;&lt;/i&gt;. In the so-called single-index model, one has &lt;i&gt;Y=f&lt;sup&gt;*&lt;/sup&gt;(&amp;#952;&lt;sup&gt;* T&lt;/sup&gt;&lt;b&gt;X&lt;/b&gt;)+&lt;b&gt;W&lt;/b&gt;&lt;/i&gt;, where &lt;i&gt;f&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; is an unknown univariate measurable function, &lt;i&gt;&amp;#952;&lt;sup&gt;*&lt;/sup&gt;&lt;/i&gt; is an unknown vector in &lt;i&gt;&amp;#8477;&lt;sup&gt;d&lt;/sup&gt;&lt;/i&gt;, and &lt;i&gt;W&lt;/i&gt; denotes a random noise satisfying &lt;i&gt; E[&lt;b&gt;W&lt;/b&gt;|&lt;b&gt;X&lt;/b&gt;]=0&lt;/i&gt;. The single-index model is known to offer a flexible way to model a variety of high-dimensional real-world phenomena. However, despite its relative simplicity, this dimension reduction scheme is faced with severe complications as soon as the underlying dimension becomes larger than the number of observations ("&lt;i&gt;p&lt;/i&gt; larger than &lt;i&gt;n&lt;/i&gt;" paradigm).  To circumvent this difficulty, we consider the single-index model estimation problem from a sparsity perspective using a PAC-Bayesian approach. On the theoretical side, we offer a sharp oracle inequality, which is more powerful than the best known oracle inequalities for other common procedures of single-index recovery. The proposed method is implemented by means of the reversible jump Markov chain Monte Carlo technique and its performance is compared with that of standard procedures.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/alquier13a/alquier13a.pdf</url></Article><Article><id>997</id><title> Derivative Estimation with Local Polynomial Fitting </title><author>Kris De Brabanter, Jos De Brabanter, Bart De Moor, Ir&amp;#232;ne Gijbels</author><abstract>

We present a fully automated framework to estimate derivatives nonparametrically without estimating the regression function. Derivative estimation plays an important role in the exploration of structures in curves (jump detection and discontinuities), comparison of regression curves, analysis of human growth data, etc. Hence, the study of estimating derivatives is equally important as regression estimation itself. Via empirical derivatives we approximate the &lt;i&gt;q&lt;/i&gt;th order derivative and create a new data set which can be smoothed by any nonparametric regression estimator. We derive &lt;i&gt;L&lt;sub&gt;1&lt;/sub&gt;&lt;/i&gt; and &lt;i&gt;L&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt; rates and establish consistency of the estimator. The new data sets created by this technique are no longer independent and identically distributed (i.i.d.) random variables anymore. As a consequence, automated model selection criteria (data-driven procedures) break down. Therefore, we propose a simple factor method, based on bimodal kernels, to effectively deal with correlated data in the local polynomial regression framework.


</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/debrabanter13a/debrabanter13a.pdf</url></Article><Article><id>998</id><title> Using Symmetry and Evolutionary Search to Minimize Sorting Networks </title><author>Vinod K. Valsalam, Risto Miikkulainen</author><abstract>

  Sorting networks are an interesting class of parallel sorting
  algorithms with applications in multiprocessor computers and
  switching networks. They are built by cascading a series of
  comparison-exchange units called comparators.  Minimizing the number
  of comparators for a given number of inputs is a challenging
  optimization problem.  This paper presents a two-pronged approach
  called Symmetry and Evolution based Network Sort Optimization
  (SENSO) that makes it possible to scale the solutions to networks
  with a larger number of inputs than previously possible.  First, it
  uses the symmetry of the problem to decompose the minimization
  goal into subgoals that are easier to solve.  Second, it minimizes
  the resulting greedy solutions further by using an evolutionary
  algorithm to learn the statistical distribution of comparators in
  minimal networks.  The final solutions improve upon half-century of
  results published in patents, books, and peer-reviewed literature,
  demonstrating the potential of the SENSO approach for solving
  difficult combinatorial problems.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/valsalam13a/valsalam13a.pdf</url></Article><Article><id>999</id><title> A Framework for Evaluating Approximation Methods for Gaussian Process Regression </title><author>Krzysztof Chalupka, Christopher K. I. Williams, Iain Murray</author><abstract>

  Gaussian process (GP) predictors are an important component of many
  Bayesian approaches to machine learning. However, even a
  straightforward implementation of Gaussian process regression (GPR)
  requires &lt;i&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/i&gt; space and &lt;i&gt;O(n&lt;sup&gt;3&lt;/sup&gt;)&lt;/i&gt; time for a data set of &lt;i&gt;n&lt;/i&gt;
  examples. Several approximation methods have been proposed, but
  there is a lack of understanding of the relative merits of the
  different approximations, and in what situations they are most
  useful.  We recommend assessing the quality of the predictions
  obtained as a function of the compute time taken, and comparing to
  standard baselines (e.g., Subset of Data and FITC).
  We empirically investigate four different approximation algorithms on
  four different prediction problems, and make our code available to
  encourage future comparisons.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/chalupka13a/chalupka13a.pdf</url></Article><Article><id>1000</id><title> Risk Bounds of Learning Processes for L&amp;eacute;vy Processes </title><author>Chao Zhang, Dacheng Tao</author><abstract>

L&amp;eacute;vy processes refer to a class of stochastic processes, for example, Poisson processes and Brownian motions, and play an important role in stochastic processes and machine learning. Therefore, it is essential to study risk bounds of the learning process for time-dependent samples drawn from a L&amp;eacute;vy process (or briefly called learning process for L&amp;eacute;vy process). It is noteworthy that samples in this learning process are not independently and identically distributed (i.i.d.). Therefore, results in traditional statistical learning theory are not applicable (or at least cannot be applied directly), because they are obtained under the sample-i.i.d. assumption. In this paper, we study risk bounds of the learning process for time-dependent samples drawn from a L&amp;eacute;vy process, and then analyze the asymptotical behavior of the learning process. In particular, we first develop the deviation inequalities and the symmetrization inequality for the learning process. By using the resultant inequalities, we then obtain the risk bounds based on the covering number. Finally, based on the resulting risk bounds, we study the asymptotic convergence and the rate of convergence of the learning process for L&amp;eacute;vy process.
Meanwhile, we also give a comparison to the related results under the sample-i.i.d. assumption.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/zhang13a/zhang13a.pdf</url></Article><Article><id>1001</id><title> Learning Theory Approach to Minimum Error Entropy Criterion </title><author>Ting Hu, Jun Fan, Qiang Wu, Ding-Xuan Zhou</author><abstract>

We consider the minimum error entropy (MEE) criterion and an empirical risk minimization learning algorithm when an
approximation of R&amp;eacute;nyi's entropy (of order &lt;i&gt;2&lt;/i&gt;) by Parzen windowing is minimized. This learning algorithm involves a
Parzen windowing scaling parameter. We present a learning theory approach for this MEE algorithm in a regression setting
when the scaling parameter is large. Consistency and explicit convergence rates are provided in terms of the approximation
ability and capacity of the involved hypothesis space. Novel analysis is carried out for the generalization error
associated with R&amp;eacute;nyi's entropy and a Parzen windowing function, to overcome technical difficulties arising from the
essential differences between the classical least squares problems and the MEE setting. An involved symmetrized least
squares error is introduced and analyzed, which is related to some ranking algorithms.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/hu13a/hu13a.pdf</url></Article><Article><id>1002</id><title> Ranked Bandits in Metric Spaces: Learning Diverse Rankings over Large Document Collections</title><author>Aleksandrs Slivkins, Filip Radlinski, Sreenivas Gollapudi</author><abstract>

Most learning to rank research has assumed that the utility of different documents is independent, which results in learned ranking functions that return redundant results. The few approaches that avoid this have rather unsatisfyingly lacked theoretical foundations, or do not scale. We present a learning-to-rank formulation that optimizes the fraction of satisfied users, with several scalable algorithms that explicitly takes document similarity and ranking context into account. Our formulation is a non-trivial common generalization of two multi-armed bandit models from the literature: &lt;i&gt;ranked bandits&lt;/i&gt; (Radlinski et al., 2008) and &lt;i&gt;Lipschitz bandits&lt;/i&gt; (Kleinberg et al., 2008b). We present theoretical justifications for this approach, as well as a near-optimal algorithm. Our evaluation adds optimizations that improve empirical performance, and shows that our algorithms learn orders of magnitude more quickly than previous approaches.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/slivkins13a/slivkins13a.pdf</url></Article><Article><id>1003</id><title> A Theory of Multiclass Boosting </title><author>Indraneel Mukherjee, Robert E. Schapire</author><abstract>

     Boosting combines weak classifiers to form highly accurate
  predictors. Although the case of binary classification is well
  understood, in the multiclass setting, the &amp;ldquo;correct&amp;rdquo; requirements
  on the weak classifier, or the notion of the most efficient boosting
  algorithms are missing. In this paper, we create a broad and general
  framework, within which we make precise and identify the optimal
  requirements on the weak-classifier, as well as design the most
  effective, in a certain sense, boosting algorithms that assume such
  requirements.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/mukherjee13a/mukherjee13a.pdf</url></Article><Article><id>1004</id><title> Algorithms for Discovery of Multiple Markov Boundaries </title><author>Alexander Statnikov, Nikita I. Lytkin, Jan Lemeire, Constantin F. Aliferis</author><abstract>

Algorithms for Markov boundary discovery from data constitute an important recent development in
machine learning, primarily because they offer a principled solution to the variable/feature selection
problem and give insight on local causal structure. Over the last decade many sound algorithms have
been proposed to identify a single Markov boundary of the response variable. Even though faithful
distributions  and, more broadly, distributions  that satisfy  the  intersection property always have a
single Markov boundary, other distributions/data sets may have multiple Markov boundaries of the
response variable.  The latter  distributions/data sets are  common in practical data-analytic
applications, and there are several reasons why it is important to induce multiple Markov boundaries
from such data. However, there are currently no sound and efficient algorithms that can accomplish
this task. This paper describes a family of algorithms TIE* that can discover all Markov boundaries
in a distribution.  The broad applicability  as well as efficiency  of the new  algorithmic family  is
demonstrated in an extensive benchmarking study that involved comparison with 26 state-of-the-art
algorithms/variants in 15 data sets from a diversity of application domains.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/statnikov13a/statnikov13a.pdf</url></Article><Article><id>1005</id><title> Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization </title><author>Shai Shalev-Shwartz, Tong Zhang</author><abstract>

  Stochastic Gradient Descent (SGD) has become popular for solving
  large scale supervised machine learning optimization problems such
  as SVM, due to their strong theoretical guarantees.  While the
  closely related Dual Coordinate Ascent (DCA) method has been
  implemented in various software packages, it has so far lacked good
  convergence analysis.  This paper presents a new analysis of
  Stochastic Dual Coordinate Ascent (SDCA) showing that this class of
  methods enjoy strong theoretical guarantees that are comparable or
  better than SGD. This analysis justifies the effectiveness of SDCA
  for practical applications.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf</url></Article><Article><id>1006</id><title> Optimal Discovery with Probabilistic Expert Advice: Finite Time Analysis and Macroscopic Optimality </title><author>S&amp;eacute;bastien Bubeck, Damien Ernst, Aur&amp;eacute;lien Garivier</author><abstract>

We consider  an original problem that arises from the issue of security analysis of a power system and that we name optimal discovery with probabilistic expert advice. We address it with an algorithm based on the optimistic paradigm and on the Good-Turing missing mass estimator. We prove two different regret bounds on the performance of this algorithm under weak assumptions on the probabilistic experts. Under more restrictive hypotheses, we also prove a macroscopic optimality result, comparing the algorithm both with  an oracle strategy and with uniform sampling.
Finally, we provide numerical experiments illustrating these theoretical findings.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/bubeck13a/bubeck13a.pdf</url></Article><Article><id>1007</id><title> A &lt;code&gt;C++&lt;/code&gt; Template-Based Reinforcement Learning Library: Fitting the Code to the Mathematics </title><author>Herv&amp;eacute; Frezza-Buet, Matthieu Geist</author><abstract>

This paper introduces the &lt;code&gt;rllib&lt;/code&gt; as an original &lt;code&gt;C++&lt;/code&gt; template-based
library oriented toward value function estimation. Generic programming is promoted here as a way of having a good
fit between the mathematics of reinforcement learning and their implementation in a
library. The main concepts of &lt;code&gt;rllib&lt;/code&gt; are presented, as well as a short example.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/frezza-buet13a/frezza-buet13a.pdf</url></Article><Article><id>1008</id><title> CODA: High Dimensional Copula Discriminant Analysis </title><author>Fang Han, Tuo Zhao, Han Liu</author><abstract>

We propose a high dimensional classification method, named the 
&lt;i&gt;Copula Discriminant Analysis&lt;/i&gt; (CODA). The CODA generalizes the
normal-based linear discriminant analysis to the larger Gaussian
Copula models (or the nonparanormal) as proposed by Liu et al. (2009).
To simultaneously achieve estimation efficiency and robustness, the
nonparametric rank-based methods including the Spearman's rho and
Kendall's tau are exploited in estimating the covariance matrix. In
high dimensional settings, we prove that the sparsity pattern of the
discriminant features can be consistently recovered with the
parametric rate, and the expected misclassification error is
consistent to the Bayes risk. Our theory is backed up by careful
numerical experiments, which show that the extra flexibility gained
by the CODA method incurs little efficiency loss even when the data
are truly Gaussian. These results suggest that the CODA method can
be an alternative choice besides the normal-based high dimensional
linear discriminant analysis.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/han13a/han13a.pdf</url></Article><Article><id>1009</id><title> Bayesian Nonparametric Hidden Semi-Markov Models </title><author>Matthew J. Johnson, Alan S. Willsky</author><abstract>

There is much interest in the Hierarchical Dirichlet Process Hidden Markov
Model (HDP-HMM) as a natural Bayesian nonparametric extension of the ubiquitous
Hidden Markov Model for learning from sequential and time-series data. However,
in many settings the HDP-HMM's strict Markovian constraints are undesirable,
particularly if we wish to learn or encode non-geometric state durations. We
can extend the HDP-HMM to capture such structure by drawing upon
explicit-duration semi-Markov modeling, which has been developed mainly in the
parametric non-Bayesian setting, to allow construction of highly interpretable
models that admit natural prior information on state durations.

&lt;p&gt;
In this paper we introduce the explicit-duration Hierarchical Dirichlet Process
Hidden semi-Markov Model (HDP-HSMM) and develop sampling algorithms for
efficient posterior inference. The methods we introduce also provide new
methods for sampling inference in the finite Bayesian HSMM.
Our modular Gibbs sampling methods can be embedded in samplers for larger
hierarchical Bayesian models, adding semi-Markov chain modeling as another tool
in the Bayesian inference toolbox.  We demonstrate the utility of the HDP-HSMM
and our inference methods on both synthetic and real experiments.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/johnson13a/johnson13a.pdf</url></Article><Article><id>1010</id><title> Differential Privacy for Functions and Functional Data </title><author>Rob Hall, Alessandro Rinaldo, Larry Wasserman</author><abstract>

Differential privacy is a rigorous cryptographically-motivated characterization of data privacy which may be applied when
releasing summaries of a database.
Previous work has focused mainly on methods for which
the output is a finite dimensional vector, or an element of some discrete set.
We develop methods for releasing functions
while preserving differential privacy.
Specifically, we show that adding an appropriate Gaussian process
to the function of interest yields
differential privacy.  When the functions lie in the reproducing kernel Hilbert space (RKHS) generated by the covariance kernel of the
Gaussian process, then the correct noise level is established by
measuring the &amp;ldquo;sensitivity&amp;rdquo; of the function in the RKHS norm.
As examples we consider kernel density estimation,
kernel support vector machines,
and functions in RKHSs.
</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/hall13a/hall13a.pdf</url></Article><Article><id>1011</id><title>Sparsity Regret Bounds for Individual Sequences in Online Linear Regression</title><author>S&amp;#233;bastien Gerchinovitz</author><abstract>

We consider the problem of online linear regression on arbitrary deterministic sequences when the ambient dimension &lt;i&gt;d&lt;/i&gt; can be much larger than the number of time rounds &lt;i&gt;T&lt;/i&gt;. We introduce the notion of &lt;em&gt;sparsity regret bound&lt;/em&gt;, which is a deterministic online counterpart of recent risk bounds derived in the stochastic setting under a sparsity scenario. We prove such regret bounds for an online-learning algorithm called SeqSEW and based on exponential weighting and data-driven truncation. In a second part we apply a parameter-free version of this algorithm to the stochastic setting (regression model with random design). This yields risk bounds of the same flavor as in Dalalyan and Tsybakov (2012a) but which solve two questions left open therein. In particular our risk bounds are adaptive (up to a logarithmic factor) to the unknown variance of the noise if the latter is Gaussian. We also address the regression model with fixed design.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/gerchinovitz13a/gerchinovitz13a.pdf</url></Article><Article><id>1012</id><title> Semi-Supervised Learning Using Greedy Max-Cut </title><author>Jun Wang, Tony Jebara, Shih-Fu Chang</author><abstract>

Graph-based semi-supervised learning (&lt;i&gt;SSL&lt;/i&gt;) methods play an increasingly important role in practical machine learning systems, particularly in agnostic settings when no parametric information or other prior knowledge is available about the data distribution. Given the constructed graph represented by a weight matrix, transductive inference is used to propagate known labels to predict the values of all unlabeled vertices. Designing a robust label diffusion algorithm for such graphs is a widely studied problem and various methods have recently been suggested. Many of these can be formalized as regularized function estimation through the minimization of a quadratic cost. However, most existing label diffusion methods minimize a univariate cost with the classification function as the only variable of interest. Since the observed labels seed the diffusion process, such univariate frameworks are extremely sensitive to the initial label choice and any label noise. To alleviate the dependency on the initial
observed labels, this article proposes a bivariate formulation for graph-based &lt;i&gt;SSL&lt;/i&gt;, where both the binary label information and a continuous classification function are arguments of the optimization. This bivariate formulation is shown to be equivalent to a linearly constrained Max-Cut problem. Finally an efficient solution via greedy gradient Max-Cut (&lt;i&gt;GGMC&lt;/i&gt;) is derived which gradually assigns unlabeled vertices to each class with minimum connectivity. Once convergence guarantees are established, this greedy Max-Cut based &lt;i&gt;SSL&lt;/i&gt; is applied on both artificial and standard benchmark data sets where it obtains superior classification accuracy compared to existing state-of-the-art &lt;i&gt;SSL&lt;/i&gt; methods. Moreover, &lt;i&gt;GGMC&lt;/i&gt; shows robustness with respect to the graph construction method and maintains high accuracy over extensive experiments with various edge linking and weighting schemes.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/wang13a/wang13a.pdf</url></Article><Article><id>1013</id><title> MLPACK: A Scalable C++ Machine Learning Library </title><author>Ryan R. Curtin, James R. Cline, N. P. Slagle, William B. March, Parikshit Ram, Nishant A. Mehta, Alexander G. Gray</author><abstract>

MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning
library released in late 2011 offering both a simple, consistent API accessible
to novice users and high performance and flexibility to expert users by
leveraging modern features of C++.  MLPACK provides cutting-edge algorithms
whose benchmarks exhibit far better performance than other leading machine
learning libraries.  MLPACK version 1.0.3, licensed under the LGPL, is available
at &lt;a href="http://www.mlpack.org"&gt;www.mlpack.org&lt;/a&gt;.

</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/curtin13a/curtin13a.pdf</url></Article><Article><id>1014</id><title> Greedy Sparsity-Constrained Optimization </title><author>Sohail Bahmani, Bhiksha Raj, Petros T. Boufounos</author><abstract>

Sparsity-constrained optimization has wide applicability in machine
learning, statistics, and signal processing problems such as feature selection and Compressed Sensing. A vast body of work has studied the sparsity-constrained optimization from theoretical, algorithmic, and application aspects in the context of sparse estimation in linear models where the fidelity of the estimate is measured by the squared error. In contrast, relatively less effort has been made in the study of sparsity-constrained optimization in cases where nonlinear models are involved or the cost function is not quadratic. In this paper we propose a greedy algorithm, Gradient Support Pursuit (GraSP), to approximate sparse minima of cost functions of arbitrary form. Should a cost function have a Stable Restricted Hessian (SRH) or a Stable Restricted Linearization (SRL), both of which are introduced in this paper, our algorithm is guaranteed to produce a sparse vector within a bounded distance from the true sparse optimum. Our approach generalizes known results for quadratic cost functions that arise in sparse linear regression and Compressed Sensing. We also evaluate the performance of GraSP through numerical simulations on synthetic and real data, where the algorithm is employed for sparse logistic regression with and without &lt;i&gt;l&lt;sub&gt;2&lt;/sub&gt;&lt;/i&gt;-regularization.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/bahmani13a/bahmani13a.pdf</url></Article><Article><id>1015</id><title> Quasi-Newton Method: A New Direction </title><author>Philipp Hennig, Martin Kiefel</author><abstract>

Four decades after their invention, quasi-Newton methods are still
  state of the art in unconstrained numerical optimization. Although
  not usually interpreted thus, these are learning algorithms that fit
  a local quadratic approximation to the objective function. We show
  that many, including the most popular, quasi-Newton methods can be
  interpreted as approximations of Bayesian linear regression under
  varying prior assumptions. This new notion elucidates some
  shortcomings of classical algorithms, and lights the way to a novel
  nonparametric quasi-Newton method, which is able to make more
  efficient use of available information at computational cost similar
  to its predecessors.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/hennig13a/hennig13a.pdf</url></Article><Article><id>1016</id><title>A Widely Applicable Bayesian Information Criterion</title><author>Sumio Watanabe</author><abstract>

&lt;p&gt;A statistical model or a learning machine is called regular if the map taking a parameter 
to a probability distribution is one-to-one and if its Fisher information 
matrix is always positive definite. If otherwise, it is called singular.
In regular statistical models, 
the Bayes free energy, which is defined by the minus logarithm of Bayes marginal likelihood, 
can be asymptotically approximated by the 
Schwarz Bayes information criterion (BIC), whereas in singular models
such approximation does not hold. 
&lt;/p&gt;

&lt;p&gt;Recently, it was proved that the Bayes free energy of a singular model is
asymptotically given by a generalized formula
using a birational invariant, the real log canonical threshold (RLCT),
instead of half the number of parameters in BIC. 
Theoretical values of RLCTs in several statistical models are now being 
discovered based on algebraic geometrical methodology. 
However, it has been difficult to estimate the Bayes free energy using only training samples, 
because an RLCT depends on an unknown true distribution. &lt;/p&gt;

&lt;p&gt;In the present paper, we define a widely applicable Bayesian information criterion (WBIC) by 
the average log likelihood function 
over the posterior distribution with the inverse temperature &lt;i&gt;1/log n&lt;/i&gt;,
where &lt;i&gt;n&lt;/i&gt; is the number of training samples. We mathematically prove that 
WBIC has the same asymptotic expansion as the Bayes free energy, even if
a statistical model is singular for or  unrealizable by a statistical model. 
Since WBIC can be numerically calculated without any information about a true 
distribution, 
it is a generalized version of BIC onto singular statistical models.&lt;/p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf</url></Article><Article><id>1017</id><title> Truncated Power Method for Sparse Eigenvalue Problems </title><author>Xiao-Tong Yuan, Tong Zhang</author><abstract>

This paper considers the sparse eigenvalue problem, which is to
extract dominant (largest) sparse eigenvectors with at most &lt;i&gt;k&lt;/i&gt;
non-zero components. We propose a simple yet effective solution
called &lt;i&gt;truncated power method&lt;/i&gt; that can approximately solve the
underlying nonconvex optimization problem. A strong sparse recovery
result is proved for the truncated power method, and this theory is
our key motivation for developing the new algorithm. The proposed
method is tested on applications such as sparse principal component
analysis and the densest &lt;i&gt;k&lt;/i&gt;-subgraph problem. Extensive experiments
on several synthetic and real-world data sets demonstrate the
competitive empirical performance of our method.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/yuan13a/yuan13a.pdf</url></Article><Article><id>1018</id><title> Query Induction with Schema-Guided Pruning Strategies </title><author>Joachim Niehren, J&amp;#233;r&amp;#244;me Champav&amp;#232;re, Aur&amp;#233;lien Lemay, R&amp;#233;mi Gilleron</author><abstract>

Inference algorithms for tree automata that define node selecting
queries in unranked trees rely on tree pruning strategies. These
impose additional assumptions on node selection that are needed to
compensate for small numbers of annotated examples. Pruning-based
heuristics in query learning algorithms for Web information extraction
often boost the learning quality and speed up the learning process. 
We will distinguish the class of regular queries that
are stable under a given schema-guided pruning strategy, and show that
this class is learnable with polynomial time and data. Our learning
algorithm is obtained by adding pruning heuristics to the traditional
learning algorithm for tree automata from positive and negative
examples. While justified by a formal learning model, our learning
algorithm for stable queries also performs very well in practice of
&lt;b&gt;XML&lt;/b&gt; information extraction.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/niehren13a/niehren13a.pdf</url></Article><Article><id>1019</id><title> Bayesian Canonical Correlation Analysis </title><author>Arto Klami, Seppo Virtanen, Samuel Kaski</author><abstract>

Canonical correlation analysis (CCA) is a classical method for&#13;
  seeking correlations between two multivariate data sets. During the&#13;
  last ten years, it has received more and more attention in the&#13;
  machine learning community in the form of novel computational&#13;
  formulations and a plethora of applications. We review recent&#13;
  developments in Bayesian models and inference methods for CCA which&#13;
  are attractive for their potential in hierarchical extensions and&#13;
  for coping with the combination of large dimensionalities and small&#13;
  sample sizes. The existing methods have not been particularly&#13;
  successful in fulfilling the promise yet; we introduce a novel&#13;
  efficient solution that imposes group-wise sparsity to estimate the&#13;
  posterior of an extended model which not only extracts the&#13;
  statistical dependencies (correlations) between data sets but also&#13;
  decomposes the data into shared and data set-specific components. In&#13;
  statistics literature the model is known as inter-battery factor&#13;
  analysis (IBFA), for which we now provide a Bayesian treatment.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/klami13a/klami13a.pdf</url></Article><Article><id>1020</id><title> Variational Inference in Nonconjugate Models </title><author>Chong Wang, David M. Blei</author><abstract>

Mean-field variational methods are widely used for approximate
  posterior inference in many probabilistic models.  In a typical
  application, mean-field methods approximately compute the posterior
  with a coordinate-ascent optimization algorithm.  When the model is
  conditionally conjugate, the coordinate updates are easily derived
  and in closed form. However, many models of interest---like the
  correlated topic model and Bayesian logistic regression---are
  nonconjugate. In these models, mean-field methods cannot be directly
  applied and practitioners have had to develop variational algorithms
  on a case-by-case basis.  In this paper, we develop two generic
  methods for nonconjugate models, Laplace variational inference and
  delta method variational inference.  Our methods have several
  advantages: they allow for easily derived variational algorithms
  with a wide class of nonconjugate models; they extend and unify some
  of the existing algorithms that have been derived for specific
  models; and they work well on real-world data sets. We studied our
  methods on the correlated topic model, Bayesian logistic regression,
  and hierarchical Bayesian logistic regression.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/wang13b/wang13b.pdf</url></Article><Article><id>1021</id><title> Beyond Fano's Inequality: Bounds on the Optimal F-Score, BER, and Cost-Sensitive Risk and Their Implications </title><author>Ming-Jie Zhao, Narayanan Edakunni, Adam Pocock, Gavin Brown</author><abstract>

Fano's inequality lower bounds the probability of transmission error
through a communication channel.
   Applied to classification problems, it provides a lower bound on
the Bayes error rate and motivates the widely used Infomax principle.
   In modern machine learning, we are often interested in more than
just the error rate.
   In medical diagnosis, different errors incur different cost; hence,
the overall risk is cost-sensitive.
   Two other popular criteria are balanced error rate (BER) and
F-score.
   In this work, we focus on the two-class problem and use a general
definition of conditional entropy (including Shannon's as a special
case) to derive upper/lower bounds on the optimal F-score, BER and
cost-sensitive risk, extending Fano's result.
As a consequence, we show that &lt;i&gt;Infomax is not suitable for
    optimizing F-score or cost-sensitive risk&lt;/i&gt;, in that it can potentially
lead to low F-score and high risk.
   For cost-sensitive risk, we propose a new conditional entropy
formulation which avoids this inconsistency.
   In addition, we consider the common practice of using a threshold
on the posterior probability to tune performance of a classifier.
As is widely known, a threshold of &lt;i&gt;0.5&lt;/i&gt;, where the posteriors
cross, minimizes error rate---we derive similar optimal thresholds for
F-score and BER.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/zhao13a/zhao13a.pdf</url></Article><Article><id>1022</id><title> Sparse Activity and Sparse Connectivity in Supervised Learning </title><author>Markus Thom, G&amp;#252;nther Palm</author><abstract>

Sparseness is a useful regularizer for learning in a wide range of applications, in particular in neural networks.
This paper proposes a model targeted at classification tasks, where sparse activity and sparse connectivity are used to enhance classification capabilities.
The tool for achieving this is a sparseness-enforcing projection operator which finds the closest vector with a pre-defined sparseness for any given vector.
In the theoretical part of this paper, a comprehensive theory for such a projection is developed.
In conclusion, it is shown that the projection is differentiable almost everywhere and can thus be implemented as a smooth neuronal transfer function.
The entire model can hence be tuned end-to-end using gradient-based methods.
Experiments on the MNIST database of handwritten digits show that classification performance can be boosted by sparse activity or sparse connectivity.
With a combination of both, performance can be significantly better compared to classical non-sparse approaches.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/thom13a/thom13a.pdf</url></Article><Article><id>1023</id><title> Stress Functions for Nonlinear Dimension Reduction, Proximity Analysis, and Graph Drawing </title><author>Lisha Chen, Andreas Buja</author><abstract>

Multidimensional scaling (MDS) is the art of reconstructing
pointsets (embeddings) from pairwise distance data, and as such it
  is at the basis of several approaches to nonlinear dimension
  reduction and manifold learning.  At present, MDS lacks a unifying
  methodology as it consists of a discrete collection of proposals
  that differ in their optimization criteria, called ''stress
  functions''.  To correct this situation we propose (1) to embed many
  of the extant stress functions in a parametric family of stress
  functions, and (2) to replace the ad hoc choice among discrete
  proposals with a principled parameter selection method.  This
  methodology yields the following benefits and problem solutions:
  (a )It provides guidance in tailoring stress functions to a given
  data situation, responding to the fact that no single stress
  function dominates all others across all data situations; (b) the
  methodology enriches the supply of available stress functions;
  (c) it helps our understanding of stress functions by replacing the
  comparison of discrete proposals with a characterization of the
  effect of parameters on embeddings; (d) it builds a bridge to graph
  drawing, which is the related but not identical art of constructing
  embeddings from graphs.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/chen13a/chen13a.pdf</url></Article><Article><id>1024</id><title> GPstuff: Bayesian Modeling with Gaussian Processes </title><author>Jarno Vanhatalo, Jaakko Riihim&amp;#228;ki, Jouni Hartikainen, Pasi Jyl&amp;#228;nki, Ville Tolvanen, Aki Vehtari</author><abstract>

The GPstuff toolbox is a versatile collection of Gaussian process&#13;
  models and computational tools required for Bayesian inference. The tools&#13;
  include, among others, various inference methods, sparse&#13;
  approximations and model assessment methods.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/vanhatalo13a/vanhatalo13a.pdf</url></Article><Article><id>1025</id><title> Performance Bounds for &amp;#955; Policy Iteration and Application to the Game of Tetris </title><author>Bruno Scherrer</author><abstract>

We consider the discrete-time infinite-horizon optimal control
  problem formalized by Markov decision processes
  (Puterman, 1994; Bertsekas and Tsitsiklis, 1996).  We revisit the work of Bertsekas
  and Ioffe (1996), that
  introduced &amp;#955; policy iteration---a family of algorithms parametrized by a
  parameter &amp;#955;---that generalizes the standard algorithms
  value and policy iteration, and has some deep connections
  with the temporal-difference algorithms described by
  Sutton and Barto (1998). We deepen the original theory developed by the
  authors by providing convergence rate bounds which generalize
  standard bounds for value iteration described for instance by
  Puterman (1994).  Then, the main contribution of this paper is to
  develop the theory of this algorithm when it is used in an
  approximate form. We extend and unify the separate analyzes
  developed by Munos for approximate value iteration (Munos, 2007)
  and approximate policy iteration (Munos, 2003), and provide
  performance bounds in the discounted and the undiscounted
  situations. Finally, we revisit the use of this algorithm in the
  training of a Tetris playing controller as originally done by
  Bertsekas and Ioffe (1996).  Our empirical results are different from those of
  Bertsekas and Ioffe (which were originally qualified as
  ''paradoxical'' and ''intriguing''). We track down the reason to be
  a minor implementation error of the algorithm, which suggests that,
  in practice, &amp;#955; policy iteration may be more stable than previously thought.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://www.jmlr.org/papers/volume14/scherrer13a/scherrer13a.pdf</url></Article><Article><id>1026</id><title> Manifold Regularization and Semi-supervised Learning: Some Theoretical Analyses </title><author>Partha Niyogi</author><abstract>

Manifold regularization (Belkin et al., 2006) is a geometrically
motivated framework for machine learning within which several
semi- supervised algorithms have been constructed. Here we try
to provide some theoretical understanding of this approach. Our
main result is to expose the natural structure of a class of
problems on which manifold regularization methods are helpful.
We show that for such problems, no supervised learner can learn
effectively. On the other hand, a manifold based learner (that
knows the manifold or â€œlearnsâ€� it from unlabeled examples) can
learn with relatively few labeled examples. Our analysis follows
a minimax style with an emphasis on finite sample results (in
terms of $n$: the number of labeled examples). These results
allow us to properly interpret manifold regularization and
related spectral and geometric algorithms in terms of their
potential use in semi-supervised learning.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/niyogi13a/niyogi13a.pdf</url></Article><Article><id>1027</id><title> Random Spanning Trees and the Prediction of Weighted Graphs </title><author>NicolÃ² Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella</author><abstract>

We investigate the problem of sequentially predicting the binary
labels on the nodes of an arbitrary weighted graph. We show
that, under a suitable parametrization of the problem, the
optimal number of prediction mistakes can be characterized (up
to logarithmic factors) by the cutsize of a random spanning tree
of the graph. The cutsize is induced by the unknown adversarial
labeling of the graph nodes. In deriving our characterization,
we obtain a simple randomized algorithm achieving in expectation
the optimal mistake bound on any polynomially connected weighted
graph. Our algorithm draws a random spanning tree of the
original graph and then predicts the nodes of this tree in
constant expected amortized time and linear space. Experiments
on real-world data sets show that our method compares well to
both global (Perceptron) and local (label propagation) methods,
while being generally faster in practice.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/cesa-bianchi13a/cesa-bianchi13a.pdf</url></Article><Article><id>1028</id><title> Regularization-Free Principal Curve Estimation </title><author>Samuel Gerber, Ross Whitaker</author><abstract>

Principal curves and manifolds provide a framework to formulate
manifold learning within a statistical context. Principal curves
define the notion of a curve passing through the middle of a
distribution. While the intuition is clear, the formal
definition leads to some technical and practical difficulties.
In particular, principal curves are saddle points of the mean-
squared projection distance, which poses severe challenges for
estimation and model selection. This paper demonstrates that the
difficulties in model selection associated with the saddle point
property of principal curves are intrinsically tied to the
minimization of the mean-squared projection distance. We
introduce a new objective function, facilitated through a
modification of the principal curve estimation approach, for
which all critical points are principal curves and minima. Thus,
the new formulation removes the fundamental issue for model
selection in principal curve estimation. A gradient-descent-
based estimator demonstrates the effectiveness of the new
formulation for controlling model complexity on numerical
experiments with synthetic and real data.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/gerber13a/gerber13a.pdf</url></Article><Article><id>1029</id><title> Stochastic Variational Inference </title><author>Matthew D. Hoffman, David M. Blei, Chong Wang, John Paisley</author><abstract>

We develop stochastic variational inference, a scalable
algorithm for approximating posterior distributions. We develop
this technique for a large class of probabilistic models and we
demonstrate it with two probabilistic topic models, latent
Dirichlet allocation and the hierarchical Dirichlet process
topic model. Using stochastic variational inference, we analyze
several large collections of documents: 300K articles from
&lt;i&gt;Nature&lt;/i&gt;, 1.8M articles from &lt;i&gt;The New York Times&lt;/i&gt;, and
3.8M articles from &lt;i&gt;Wikipedia&lt;/i&gt;. Stochastic inference can
easily handle data sets of this size and outperforms traditional
variational inference, which can only handle a smaller subset.
(We also show that the Bayesian nonparametric topic model
outperforms its parametric counterpart.) Stochastic variational
inference lets us apply complex Bayesian models to massive data
sets.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf</url></Article><Article><id>1030</id><title> Multicategory Large-Margin Unified Machines </title><author>Chong Zhang, Yufeng Liu</author><abstract>

Hard and soft classifiers are two important groups of techniques
for classification problems. Logistic regression and Support
Vector Machines are typical examples of soft and hard
classifiers respectively. The essential difference between these
two groups is whether one needs to estimate the class
conditional probability for the classification task or not. In
particular, soft classifiers predict the label based on the
obtained class conditional probabilities, while hard classifiers
bypass the estimation of probabilities and focus on the decision
boundary. In practice, for the goal of accurate classification,
it is unclear which one to use in a given situation. To tackle
this problem, the Large-margin Unified Machine (LUM) was
recently proposed as a unified family to embrace both groups.
The LUM family enables one to study the behavior change from
soft to hard binary classifiers. For multicategory cases,
however, the concept of soft and hard classification becomes
less clear. In that case, class probability estimation becomes
more involved as it requires estimation of a probability vector.
In this paper, we propose a new Multicategory LUM (MLUM)
framework to investigate the behavior of soft versus hard
classification under multicategory settings. Our theoretical and
numerical results help to shed some light on the nature of
multicategory classification and its transition behavior from
soft to hard classifiers. The numerical results suggest that the
proposed tuned MLUM yields very competitive performance.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/liu13a/liu13a.pdf</url></Article><Article><id>1031</id><title> Finding Optimal Bayesian Networks Using Precedence Constraints </title><author>Pekka Parviainen, Mikko Koivisto</author><abstract>

We consider the problem of finding a directed acyclic graph
(DAG) that optimizes a decomposable Bayesian network score.
While in a favorable case an optimal DAG can be found in
polynomial time, in the worst case the fastest known algorithms
rely on dynamic programming across the node subsets, taking time
and space $2^n$, to within a factor polynomial in the number of
nodes $n$. In practice, these algorithms are feasible to
networks of at most around 30 nodes, mainly due to the large
space requirement. Here, we generalize the dynamic programming
approach to enhance its feasibility in three dimensions: first,
the user may trade space against time; second, the proposed
algorithms easily and efficiently parallelize onto thousands of
processors; third, the algorithms can exploit any prior
knowledge about the precedence relation on the nodes. Underlying
all these results is the key observation that, given a partial
order $P$ on the nodes, an optimal DAG compatible with $P$ can
be found in time and space roughly proportional to the number of
ideals of $P$, which can be significantly less than $2^n$.
Considering sufficiently many carefully chosen partial orders
guarantees that a globally optimal DAG will be found. Aside from
the generic scheme, we present and analyze concrete tradeoff
schemes based on parallel bucket orders.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/parviainen13a/parviainen13a.pdf</url></Article><Article><id>1032</id><title> JKernelMachines: A Simple Framework for Kernel Machines </title><author>David Picard, Nicolas Thome, Matthieu Cord</author><abstract>

&lt;i&gt;JKernelMachines&lt;/i&gt; is a Java library for learning with
kernels. It is primarily designed to deal with custom kernels
that are not easily found in standard libraries, such as kernels
on structured data. These types of kernels are often used in
computer vision or bioinformatics applications. We provide
several kernels leading to state of the art classification
performances in computer vision, as well as various kernels on
sets. The main focus of the library is to be easily extended
with new kernels. Standard SVM optimization algorithms are
available, but also more sophisticated learning-based kernel
combination methods such as Multiple Kernel Learning (MKL), and
a recently published algorithm to learn powered products of
similarities (Product Kernel Learning).</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/picard13a/picard13a.pdf</url></Article><Article><id>1033</id><title> Asymptotic Results on Adaptive False Discovery Rate Controlling Procedures Based on Kernel Estimators </title><author>Pierre Neuvial</author><abstract>

The False Discovery Rate (FDR) is a commonly used type I error
rate in multiple testing problems. It is defined as the expected
False Discovery Proportion (FDP), that is, the expected fraction
of false positives among rejected hypotheses. When the
hypotheses are independent, the Benjamini-Hochberg procedure
achieves FDR control at any pre-specified level. By
construction, FDR control offers no guarantee in terms of power,
or type II error. A number of alternative procedures have been
developed, including plug-in procedures that aim at gaining
power by incorporating an estimate of the proportion of true
null hypotheses. In this paper, we study the asymptotic behavior
of a class of plug-in procedures based on kernel estimators of
the density of the $p$-values, as the number $m$ of tested
hypotheses grows to infinity. In a setting where the hypotheses
tested are independent, we prove that these procedures are
asymptotically more powerful in two respects: (i) a tighter
asymptotic FDR control for any target FDR level and (ii) a
broader range of target levels yielding positive asymptotic
power. We also show that this increased asymptotic power comes
at the price of slower, non-parametric convergence rates for the
FDP. These rates are of the form $m^{-k/(2k+1)}$, where $k$ is
determined by the regularity of the density of the $p$-value
distribution, or, equivalently, of the test statistics
distribution. These results are applied to one- and two-sided
tests statistics for Gaussian and Laplace location models, and
for the Student model.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/neuvial13a/neuvial13a.pdf</url></Article><Article><id>1034</id><title> Conjugate Relation between Loss Functions and Uncertainty Sets in Classification Problems </title><author>Takafumi Kanamori, Akiko Takeda, Taiji Suzuki</author><abstract>

There are two main approaches to binary classification problems:
the loss function approach and the uncertainty set approach. The
loss function approach is widely used in real-world data
analysis. Statistical decision theory has been used to elucidate
its properties such as statistical consistency. Conditional
probabilities can also be estimated by using the minimum
solution of the loss function. In the uncertainty set approach,
an uncertainty set is defined for each binary label from
training samples. The best separating hyperplane between the two
uncertainty sets is used as the decision function. Although the
uncertainty set approach provides an intuitive understanding of
learning algorithms, its statistical properties have not been
sufficiently studied. In this paper, we show that the
uncertainty set is deeply connected with the convex conjugate of
a loss function. On the basis of the conjugate relation, we
propose a way of revising the uncertainty set approach so that
it will have good statistical properties such as statistical
consistency. We also introduce statistical models corresponding
to uncertainty sets in order to estimate conditional
probabilities. Finally, we present numerical experiments,
verifying that the learning with revised uncertainty sets
improves the prediction accuracy.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/kanamori13a/kanamori13a.pdf</url></Article><Article><id>1035</id><title> A Risk Comparison of Ordinary Least Squares vs Ridge Regression </title><author>Paramveer S. Dhillon, Dean P.  Foster, Sham M.  Kakade, Lyle H. Ungar</author><abstract>

We compare the risk of ridge regression to a simple variant of
ordinary least squares, in which one simply projects the data
onto a finite dimensional subspace (as specified by a principal
component analysis) and then performs an ordinary (un-
regularized) least squares regression in this subspace. This
note shows that the risk of this ordinary least squares method
(PCA-OLS) is within a constant factor (namely 4) of the risk of
ridge regression (RR).</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/dhillon13a/dhillon13a.pdf</url></Article><Article><id>1036</id><title> On the Learnability of Shuffle Ideals </title><author>Dana Angluin, James Aspnes, Sarah Eisenstat, Aryeh Kontorovich</author><abstract>

PAC learning of unrestricted regular languages is long known to
be a difficult problem. The class of shuffle ideals is a very
restricted subclass of regular languages, where the shuffle
ideal generated by a string $u$ is the collection of all strings
containing $u$ as a subsequence. This fundamental language
family is of theoretical interest in its own right and provides
the building blocks for other important language families.
Despite its apparent simplicity, the class of shuffle ideals
appears quite difficult to learn. In particular, just as for
unrestricted regular languages, the class is not properly PAC
learnable in polynomial time if RP $\neq$ NP, and PAC learning
the class improperly in polynomial time would imply polynomial
time algorithms for certain fundamental problems in
cryptography. In the positive direction, we give an efficient
algorithm for properly learning shuffle ideals in the
statistical query (and therefore also PAC) model under the
uniform distribution.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/angluin13a/angluin13a.pdf</url></Article><Article><id>1037</id><title> Fast Generalized Subset Scan for Anomalous Pattern Detection </title><author>Edward McFowland III, Skyler Speakman, Daniel B. Neill</author><abstract>

We propose Fast Generalized Subset Scan (FGSS), a new method for
detecting anomalous patterns in general categorical data sets.
We frame the pattern detection problem as a search over subsets
of data records and attributes, maximizing a nonparametric scan
statistic over all such subsets. We prove that the nonparametric
scan statistics possess a novel property that allows for
efficient optimization over the exponentially many subsets of
the data without an exhaustive search, enabling FGSS to scale to
massive and high-dimensional data sets. We evaluate the
performance of FGSS in three real-world application domains
(customs monitoring, disease surveillance, and network intrusion
detection), and demonstrate that FGSS can successfully detect
and characterize relevant patterns in each domain. As compared
to three other recently proposed detection algorithms, FGSS
substantially decreased run time and improved detection power
for massive multivariate data sets.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/mcfowland13a/mcfowland13a.pdf</url></Article><Article><id>1038</id><title> Sub-Local Constraint-Based Learning of Bayesian Networks Using A Joint Dependence Criterion </title><author>Rami Mahdi, Jason Mezey</author><abstract>

Constraint-based learning of Bayesian networks (BN) from limited
data can lead to multiple testing problems when recovering dense
areas of the skeleton and to conflicting results in the
orientation of edges. In this paper, we present a new
constraint-based algorithm, light mutual min (LMM) for improved
accuracy of BN learning from small sample data. LMM improves the
assessment of candidate edges by using a ranking criterion that
considers conditional independence on neighboring variables at
both sides of an edge simultaneously. The algorithm also employs
an adaptive relaxation of constraints that, selectively, allows
some nodes not to condition on some neighbors. This relaxation
aims at reducing the incorrect rejection of true edges
connecting high degree nodes due to multiple testing. LMM
additionally incorporates a new criterion for ranking
v-structures that is used to recover the completed partially
directed acyclic graph (CPDAG) and to resolve conflicting
v-structures, a common problem in small sample constraint-based
learning. Using simulated data, each of these components of LMM
is shown to significantly improve network inference compared to
commonly applied methods when learning from limited data,
including more accurate recovery of skeletons and CPDAGs
compared to the PC, MaxMin, and MaxMin hill climbing algorithms.
A proof of asymptotic correctness is also provided for LMM for
recovering the correct skeleton and CPDAG.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/mahdi13a/mahdi13a.pdf</url></Article><Article><id>1039</id><title> Dimension Independent Similarity Computation </title><author>Reza Bosagh Zadeh, Ashish Goel</author><abstract>

We present a suite of algorithms for Dimension Independent
Similarity Computation (DISCO) to compute all pairwise
similarities between very high-dimensional sparse vectors. All
of our results are provably independent of dimension, meaning
that apart from the initial cost of trivially reading in the
data, all subsequent operations are independent of the
dimension; thus the dimension can be very large. We study
Cosine, Dice, Overlap, and the Jaccard similarity measures. For
Jaccard similarity we include an improved version of MinHash.
Our results are geared toward the MapReduce framework. We
empirically validate our theorems with large scale experiments
using data from the social networking site Twitter. At time of
writing, our algorithms are live in production at twitter.com.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/bosagh-zadeh13a/bosagh-zadeh13a.pdf</url></Article><Article><id>1040</id><title> Dynamic Affine-Invariant Shape-Appearance Handshape Features and Classification in Sign Language Videos </title><author>Anastasios Roussos, Stavros Theodorakis, Vassilis Pitsikalis, Petros Maragos</author><abstract>

We propose the novel approach of dynamic affine-invariant shape-
appearance model (Aff-SAM) and employ it for handshape
classification and sign recognition in sign language (SL)
videos. Aff-SAM offers a compact and descriptive representation
of hand configurations as well as regularized model-fitting,
assisting hand tracking and extracting handshape features. We
construct SA images representing the hand's shape and appearance
&lt;i&gt;without&lt;/i&gt; landmark points. We model the variation of the
images by linear combinations of eigenimages followed by affine
transformations, accounting for 3D hand pose changes and
improving model's compactness. We also incorporate static and
dynamic handshape priors, offering robustness in occlusions,
which occur often in signing. The approach includes an &lt;i&gt;affine
signer adaptation&lt;/i&gt; component at the visual level, without
requiring training from scratch a new singer-specific model. We
rather employ a short development data set to adapt the models
for a new signer. Experiments on the Boston- University-400
continuous SL corpus demonstrate improvements on handshape
classification when compared to other feature extraction
approaches. Supplementary evaluations of sign recognition
experiments, are conducted on a multi-signer, 100-sign data set,
from the Greek sign language lemmas corpus. These explore the
fusion with movement cues as well as signer adaptation of Aff-
SAM to multiple signers providing promising results.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/roussos13a/roussos13a.pdf</url></Article><Article><id>1041</id><title> Nonparametric Sparsity and Regularization </title><author>Lorenzo Rosasco, Silvia Villa, Sofia Mosci, Matteo Santoro, Alessandro Verri</author><abstract>

In this work we are interested in the problems of supervised
learning and variable selection when the input-output dependence
is described by a nonlinear function depending on a few
variables. Our goal is to consider a sparse nonparametric model,
hence avoiding linear or additive models. The key idea is to
measure the importance of each variable in the model by making
use of partial derivatives. Based on this intuition we propose a
new notion of nonparametric sparsity and a corresponding least
squares regularization scheme. Using concepts and results from
the theory of reproducing kernel Hilbert spaces and proximal
methods, we show that the proposed learning algorithm
corresponds to a minimization problem which can be provably
solved by an iterative procedure. The consistency properties of
the obtained estimator are studied both in terms of prediction
and selection performance. An extensive empirical analysis shows
that the proposed method performs favorably with respect to the
state-of-the-art methods.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/rosasco13a/rosasco13a.pdf</url></Article><Article><id>1042</id><title> Similarity-based Clustering by Left-Stochastic Matrix Factorization </title><author>Raman Arora, Maya R. Gupta, Amol Kapila, Maryam Fazel</author><abstract>

For similarity-based clustering, we propose modeling the entries
of a given similarity matrix as the inner products of the
unknown cluster probabilities. To estimate the cluster
probabilities from the given similarity matrix, we introduce a
left-stochastic non-negative matrix factorization problem. A
rotation-based algorithm is proposed for the matrix
factorization. Conditions for unique matrix factorizations and
clusterings are given, and an error bound is provided. The
algorithm is particularly efficient for the case of two
clusters, which motivates a hierarchical variant for cases where
the number of desired clusters is large. Experiments show that
the proposed left-stochastic decomposition clustering model
produces relatively high within-cluster similarity on most data
sets and can match given class labels, and that the efficient
hierarchical variant performs surprisingly well.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/arora13a/arora13a.pdf</url></Article><Article><id>1043</id><title> On the Convergence of Maximum Variance Unfolding </title><author>Ery Arias-Castro, Bruno Pelletier</author><abstract>

Maximum Variance Unfolding is one of the main methods for
(nonlinear) dimensionality reduction. We study its large sample
limit, providing specific rates of convergence under standard
assumptions. We find that it is consistent when the underlying
submanifold is isometric to a convex subset, and we provide some
simple examples where it fails to be consistent.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/arias-castro13a/arias-castro13a.pdf</url></Article><Article><id>1044</id><title> Variable Selection in High-Dimension with Random Designs and Orthogonal Matching Pursuit </title><author>Antony Joseph</author><abstract>

The performance of orthogonal matching pursuit (OMP) for
variable selection is analyzed for random designs. When
contrasted with the deterministic case, since the performance is
here measured after averaging over the distribution of the
design matrix, one can have far less stringent sparsity
constraints on the coefficient vector. We demonstrate that for
exact sparse vectors, the performance of the OMP is similar to
known results on the Lasso algorithm (Wainwright, 2009).
Moreover, variable selection under a more relaxed sparsity
assumption on the coefficient vector, whereby one has only
control on the $\ell_1$ norm of the smaller coefficients, is
also analyzed. As consequence of these results, we also show
that the coefficient estimate satisfies strong oracle type
inequalities.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/joseph13a/joseph13a.pdf</url></Article><Article><id>1045</id><title> Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs </title><author>Matthew J. Urry, Peter Sollich</author><abstract>

We consider learning on graphs, guided by kernels that encode
similarity between vertices. Our focus is on random walk
kernels, the analogues of squared exponential kernels in
Euclidean spaces. We show that on large, locally treelike graphs
these have some counter-intuitive properties, specifically in
the limit of large kernel lengthscales. We consider using these
kernels as covariance functions of Gaussian processes. In this
situation one typically scales the prior globally to normalise
the average of the prior variance across vertices. We
demonstrate that, in contrast to the Euclidean case, this
generically leads to significant variation in the prior variance
across vertices, which is undesirable from a probabilistic
modelling point of view. We suggest the random walk kernel
should be normalised locally, so that each vertex has the same
prior variance, and analyse the consequences of this by studying
learning curves for Gaussian process regression. Numerical
calculations as well as novel theoretical predictions for the
learning curves using belief propagation show that one obtains
distinctly different probabilistic models depending on the
choice of normalisation. Our method for predicting the learning
curves using belief propagation is significantly more accurate
than previous approximations and should become exact in the
limit of large random graphs.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/urry13a/urry13a.pdf</url></Article><Article><id>1046</id><title> Distributions of Angles in Random Packing on Spheres </title><author>Tony Cai, Jianqing Fan, Tiefeng Jiang</author><abstract>

This paper studies the asymptotic behaviors of the pairwise
angles among $n$ randomly and uniformly distributed unit vectors
in $\mathbb{R}^p$ as the number of points $n\rightarrow \infty$,
while the dimension $p$ is either fixed or growing with $n$. For
both settings, we derive the limiting empirical distribution of
the random angles and the limiting distributions of the extreme
angles. The results reveal interesting differences in the two
settings and provide a precise characterization of the folklore
that â€œall high-dimensional random vectors are almost always
nearly orthogonal to each other". Applications to statistics and
machine learning and connections with some open problems in
physics and mathematics are also discussed.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/cai13a/cai13a.pdf</url></Article><Article><id>1047</id><title> Cluster Analysis: Unsupervised Learning via Supervised Learning with a Non-convex Penalty </title><author>Wei Pan, Xiaotong Shen, Binghui Liu</author><abstract>

Clustering analysis is widely used in many fields. Traditionally
clustering is regarded as unsupervised learning for its lack of
a class label or a quantitative response variable, which in
contrast is present in supervised learning such as
classification and regression. Here we formulate clustering as
penalized regression with grouping pursuit. In addition to the
novel use of a non-convex group penalty and its associated
unique operating characteristics in the proposed clustering
method, a main advantage of this formulation is its allowing
borrowing some well established results in classification and
regression, such as model selection criteria to select the
number of clusters, a difficult problem in clustering analysis.
In particular, we propose using the generalized cross-validation
(GCV) based on generalized degrees of freedom (GDF) to select
the number of clusters. We use a few simple numerical examples
to compare our proposed method with some existing approaches,
demonstrating our method's promising performance.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/pan13a/pan13a.pdf</url></Article><Article><id>1048</id><title> Generalized Spike-and-Slab Priors for Bayesian Group Feature Selection Using Expectation Propagation </title><author>Daniel HernÃ¡ndez-Lobato, JosÃ© Miguel HernÃ¡ndez-Lobato, Pierre Dupont</author><abstract>

We describe a Bayesian method for group feature selection in
linear regression problems. The method is based on a generalized
version of the standard spike-and-slab prior distribution which
is often used for individual feature selection. Exact Bayesian
inference under the prior considered is infeasible for typical
regression problems. However, approximate inference can be
carried out efficiently using Expectation Propagation (EP). A
detailed analysis of the generalized spike-and-slab prior shows
that it is well suited for regression problems that are sparse
at the group level. Furthermore, this prior can be used to
introduce prior knowledge about specific groups of features that
are &lt;em&gt;a priori&lt;/em&gt; believed to be more relevant. An
experimental evaluation compares the performance of the proposed
method with those of group LASSO, Bayesian group LASSO,
automatic relevance determination and additional variants used
for group feature selection. The results of these experiments
show that a model based on the generalized spike-and-slab prior
and the EP algorithm has state-of-the-art prediction performance
in the problems analyzed. Furthermore, this model is also very
useful to carry out sequential experimental design (also known
as active learning), where the data instances that are most
informative are iteratively included in the training set,
reducing the number of instances needed to obtain a particular
level of prediction accuracy.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/hernandez-lobato13a/hernandez-lobato13a.pdf</url></Article><Article><id>1049</id><title> Alleviating Naive Bayes Attribute Independence Assumption by Attribute Weighting </title><author>Nayyar A. Zaidi, JesÃºs Cerquides, Mark J. Carman, Geoffrey I. Webb</author><abstract>

Despite the simplicity of the Naive Bayes classifier, it has
continued to perform well against more sophisticated newcomers
and has remained, therefore, of great interest to the machine
learning community. Of numerous approaches to refining the naive
Bayes classifier, attribute weighting has received less
attention than it warrants. Most approaches, perhaps influenced
by attribute weighting in other machine learning algorithms, use
weighting to place more emphasis on highly predictive attributes
than those that are less predictive. In this paper, we argue
that for naive Bayes attribute weighting should instead be used
to alleviate the conditional independence assumption. Based on
this premise, we propose a weighted naive Bayes algorithm,
called WANBIA, that selects weights to minimize either the
negative conditional log likelihood or the mean squared error
objective functions. We perform extensive evaluations and find
that WANBIA is a competitive alternative to state of the art
classifiers like Random Forest, Logistic Regression and A1DE.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/zaidi13a/zaidi13a.pdf</url></Article><Article><id>1050</id><title> Machine Learning with Operational Costs </title><author>Theja Tulabandhula, Cynthia Rudin</author><abstract>

This work proposes a way to align statistical modeling with
decision making. We provide a method that propagates the
uncertainty in predictive modeling to the uncertainty in
operational cost, where operational cost is the amount spent by
the practitioner in solving the problem. The method allows us to
explore the range of operational costs associated with the set
of reasonable statistical models, so as to provide a useful way
for practitioners to understand uncertainty. To do this, the
operational cost is cast as a regularization term in a learning
algorithm's objective function, allowing either an optimistic or
pessimistic view of possible costs, depending on the
regularization parameter. From another perspective, if we have
prior knowledge about the operational cost, for instance that it
should be low, this knowledge can help to restrict the
hypothesis space, and can help with generalization. We provide a
theoretical generalization bound for this scenario. We also show
that learning with operational costs is related to robust
optimization.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/tulabandhula13a/tulabandhula13a.pdf</url></Article><Article><id>1051</id><title> Approximating the Permanent with Fractional Belief Propagation </title><author>Michael Chertkov, Adam B. Yedidia</author><abstract>

We discuss schemes for exact and approximate computations of
permanents, and compare them with each other. Specifically, we
analyze the belief propagation (BP) approach and its fractional
belief propagation (FBP) generalization for computing the
permanent of a non-negative matrix. Known bounds and Conjectures
are verified in experiments, and some new theoretical relations,
bounds and Conjectures are proposed. The fractional free energy
(FFE) function is parameterized by a scalar parameter
$\gamma\in[-1;1]$, where $\gamma=-1$ corresponds to the BP limit
and $\gamma=1$ corresponds to the exclusion principle (but
ignoring perfect matching constraints) mean-field (MF) limit.
FFE shows monotonicity and continuity with respect to $\gamma$.
For every non-negative matrix, we define its special value
$\gamma_*\in[-1;0]$ to be the $\gamma$ for which the minimum of
the $\gamma$-parameterized FFE function is equal to the
permanent of the matrix, where the lower and upper bounds of the
$\gamma$-interval corresponds to respective bounds for the
permanent. Our experimental analysis suggests that the
distribution of $\gamma_*$ varies for different ensembles but
$\gamma_*$ always lies within the $[-1;-1/2]$ interval.
Moreover, for all ensembles considered, the behavior of
$\gamma_*$ is highly distinctive, offering an empirical
practical guidance for estimating permanents of non-negative
matrices via the FFE approach.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/chertkov13a/chertkov13a.pdf</url></Article><Article><id>1052</id><title> Construction of Approximation Spaces for Reinforcement Learning </title><author>Wendelin BÃ¶hmer, Steffen GrÃ¼newÃ¤lder, Yun Shen, Marek Musial, Klaus Obermayer</author><abstract>

Linear &lt;em&gt;reinforcement learning&lt;/em&gt; (RL) algorithms like &lt;em&gt;
least-squares temporal difference learning&lt;/em&gt; (LSTD) require
&lt;em&gt; basis functions&lt;/em&gt; that span &lt;em&gt;approximation
spaces&lt;/em&gt; of potential value functions. This article
investigates methods to construct these bases from samples. We
hypothesize that an ideal approximation spaces should encode
&lt;em&gt;diffusion distances&lt;/em&gt; and that &lt;em&gt;slow feature
analysis&lt;/em&gt; (SFA) constructs such spaces. To validate our
hypothesis we provide theoretical statements about the LSTD
value approximation error and induced metric of approximation
spaces constructed by SFA and the state-of-the-art methods
&lt;em&gt;Krylov bases&lt;/em&gt; and &lt;em&gt;proto-value functions&lt;/em&gt; (PVF).
In particular, we prove that SFA minimizes the average (over all
tasks in the same environment) bound on the above approximation
error. Compared to other methods, SFA is very sensitive to
sampling and can sometimes fail to encode the whole state space.
We derive a novel &lt;em&gt;importance sampling&lt;/em&gt; modification to
compensate for this effect. Finally, the LSTD and &lt;em&gt;least
squares policy iteration&lt;/em&gt; (LSPI) performance of
approximation spaces constructed by Krylov bases, PVF, SFA and
PCA is compared in benchmark tasks and a visual robot navigation
experiment (both in a realistic simulation and with a robot).
The results support our hypothesis and suggest that (i) SFA
provides &lt;em&gt;subspace-invariant&lt;/em&gt; features for MDPs with &lt;em&gt;
self-adjoint&lt;/em&gt; transition operators, which allows strong
guarantees on the approximation error, (ii) the modified SFA
algorithm is best suited for LSPI in both discrete and
continuous state spaces and (iii) approximation spaces encoding
diffusion distances facilitate LSPI performance.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/boehmer13a/boehmer13a.pdf</url></Article><Article><id>1053</id><title> Distribution-Dependent Sample Complexity of Large Margin Learning </title><author>Sivan Sabato, Nathan Srebro, Naftali Tishby</author><abstract>

We obtain a tight distribution-specific characterization of the
sample complexity of large-margin classification with $L_2$
regularization: We introduce the &lt;em&gt;margin-adapted
dimension&lt;/em&gt;, which is a simple function of the second order
statistics of the data distribution, and show distribution-
specific upper  &lt;em&gt;and&lt;/em&gt; lower bounds on the sample
complexity, both governed by the margin-adapted dimension of the
data distribution. The upper bounds are universal, and the lower
bounds hold for the rich family of sub- Gaussian distributions
with independent features. We conclude that this new quantity
tightly characterizes the true sample complexity of large-margin
classification. To prove the lower bound, we develop several new
tools of independent interest. These include new connections
between shattering and hardness of learning, new properties of
shattering with linear classifiers, and a new lower bound on the
smallest eigenvalue of a random Gram matrix generated by sub-
Gaussian variables. Our results can be used to quantitatively
compare large margin learning to other learning rules, and to
improve the effectiveness of methods that use sample complexity
bounds, such as active learning.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/sabato13a/sabato13a.pdf</url></Article><Article><id>1054</id><title> Convex and Scalable Weakly Labeled SVMs </title><author>Yu-Feng Li, Ivor W. Tsang, James T. Kwok, Zhi-Hua Zhou</author><abstract>

In this paper, we study the problem of learning from &lt;em&gt;weakly
labeled data&lt;/em&gt;, where labels of the training examples are
incomplete. This includes, for example, (i) semi- supervised
learning where labels are partially known; (ii) multi-instance
learning where labels are implicitly known; and (iii) clustering
where labels are completely unknown. Unlike supervised learning,
learning with weak labels involves a difficult Mixed-Integer
Programming (MIP) problem. Therefore, it can suffer from poor
scalability and may also get stuck in local minimum. In this
paper, we focus on SVMs and propose the WELLSVM via a novel
&lt;em&gt;label generation&lt;/em&gt; strategy. This leads to a convex
relaxation of the original MIP, which is at least as tight as
existing convex Semi-Definite Programming (SDP) relaxations.
Moreover, the WELLSVM can be solved via a sequence of SVM
subproblems that are much more scalable than previous convex SDP
relaxations. Experiments on three weakly labeled learning tasks,
namely, (i) semi-supervised learning; (ii) multi-instance
learning for locating regions of interest in content-based
information retrieval; and (iii) clustering, clearly demonstrate
improved performance, and WELLSVM is also readily applicable on
large data sets.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/li13a/li13a.pdf</url></Article><Article><id>1055</id><title> Language-Motivated Approaches to Action Recognition </title><author>Manavender R. Malgireddy, Ifeoma Nwogu, Venu Govindaraju</author><abstract>

We present language-motivated approaches to detecting,
localizing and classifying activities and gestures in videos. In
order to obtain statistical insight into the underlying patterns
of motions in activities, we develop a dynamic, hierarchical
Bayesian model which connects low-level visual features in
videos with poses, motion patterns and classes of activities.
This process is somewhat analogous to the method of detecting
topics or categories from documents based on the word content of
the documents, except that our documents are dynamic. The
proposed generative model harnesses both the temporal ordering
power of dynamic Bayesian networks such as hidden Markov models
(HMMs) and the automatic clustering power of hierarchical
Bayesian models such as the latent Dirichlet allocation (LDA)
model. We also introduce a probabilistic framework for detecting
and localizing pre-specified activities (or gestures) in a video
sequence, analogous to the use of filler models for keyword
detection in speech processing. We demonstrate the robustness of
our classification model and our spotting framework by
recognizing activities in unconstrained real-life video
sequences and by spotting gestures via a one-shot-learning
approach.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/malgireddy13a/malgireddy13a.pdf</url></Article><Article><id>1056</id><title> Segregating Event Streams and Noise with a Markov Renewal Process Model </title><author>Dan Stowell, Mark D. Plumbley</author><abstract>

We describe an inference task in which a set of timestamped
event observations must be clustered into an unknown number of
temporal sequences with independent and varying rates of
observations. Various existing approaches to multi-object
tracking assume a fixed number of sources and/or a fixed
observation rate; we develop an approach to inferring structure
in timestamped data produced by a mixture of an unknown and
varying number of similar Markov renewal processes, plus
independent clutter noise. The inference simultaneously
distinguishes signal from noise as well as clustering signal
observations into separate source streams. We illustrate the
technique via synthetic experiments as well as an experiment to
track a mixture of singing birds. Source code is available.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/stowell13a/stowell13a.pdf</url></Article><Article><id>1057</id><title> Gaussian Kullback-Leibler Approximate Inference </title><author>Edward Challis, David Barber</author><abstract>

We investigate Gaussian Kullback-Leibler (G-KL) variational
approximate inference techniques for Bayesian generalised linear
models and various extensions. In particular we make the
following novel contributions: sufficient conditions for which
the G-KL objective is differentiable and convex are described;
constrained parameterisations of Gaussian covariance that make
G-KL methods fast and scalable are provided; the lower bound to
the normalisation constant provided by G-KL methods is proven to
dominate those provided by local lower bounding methods;
complexity and model applicability issues of G-KL versus other
Gaussian approximate inference methods are discussed. Numerical
results comparing G-KL and other deterministic Gaussian
approximate inference methods are presented for: robust Gaussian
process regression models with either Student-$t$ or Laplace
likelihoods, large scale Bayesian binary logistic regression
models, and Bayesian sparse linear models for sequential
experimental design.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/challis13a/challis13a.pdf</url></Article><Article><id>1058</id><title> Message-Passing Algorithms for Quadratic Minimization </title><author>Nicholas Ruozzi, Sekhar Tatikonda</author><abstract>

Gaussian belief propagation (GaBP) is an iterative algorithm for
computing the mean (and variances) of a multivariate Gaussian
distribution, or equivalently, the minimum of a multivariate
positive definite quadratic function. Sufficient conditions,
such as walk-summability, that guarantee the convergence and
correctness of GaBP are known, but GaBP may fail to converge to
the correct solution given an arbitrary positive definite
covariance matrix. As was observed by Malioutov et al. (2006),
the GaBP algorithm fails to converge if the computation trees
produced by the algorithm are not positive definite. In this
work, we will show that the failure modes of the GaBP algorithm
can be understood via graph covers, and we prove that a
parameterized generalization of the min-sum algorithm can be
used to ensure that the computation trees remain positive
definite whenever the input matrix is positive definite. We
demonstrate that the resulting algorithm is closely related to
other iterative schemes for quadratic minimization such as the
Gauss-Seidel and Jacobi algorithms. Finally, we observe,
empirically, that there always exists a choice of parameters
such that the above generalization of the GaBP algorithm
converges.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/ruozzi13a/ruozzi13a.pdf</url></Article><Article><id>1059</id><title> The Rate of Convergence of AdaBoost </title><author>Indraneel Mukherjee, Cynthia Rudin, Robert E. Schapire</author><abstract>

The AdaBoost algorithm was designed to combine many â€œweakâ€�
hypotheses that perform slightly better than random guessing
into a â€œstrongâ€� hypothesis that has very low error. We study the
rate at which AdaBoost iteratively converges to the minimum of
the â€œexponential lossâ€�. Unlike previous work, our proofs do not
require a weak-learning assumption, nor do they require that
minimizers of the exponential loss are finite. Our first result
shows that the exponential loss of AdaBoost's computed parameter
vector will be at most $\varepsilon$ more than that of any
parameter vector of $\ell_1$-norm bounded by $B$ in a number of
rounds that is at most a polynomial in $B$ and $1/\varepsilon$.
We also provide lower bounds showing that a polynomial
dependence is necessary. Our second result is that within
$C/\varepsilon$ iterations, AdaBoost achieves a value of the
exponential loss that is at most $\varepsilon$ more than the
best possible value, where $C$ depends on the data set. We show
that this dependence of the rate on $\varepsilon$ is optimal up
to constant factors, that is, at least $\Omega(1/\varepsilon)$
rounds are necessary to achieve within $\varepsilon$ of the
optimal exponential loss.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/mukherjee13b/mukherjee13b.pdf</url></Article><Article><id>1060</id><title> Orange: Data Mining Toolbox in Python </title><author>Janez DemÅ¡ar, TomaÅ¾ Curk, AleÅ¡ Erjavec, ÄŒrt Gorup, TomaÅ¾ HoÄ�evar, Mitar MilutinoviÄ�, Martin MoÅ¾ina, Matija Polajnar, Marko Toplak, AnÅ¾e StariÄ�, Miha Å tajdohar, Lan Umek, Lan Å½agar, Jure Å½bontar, Marinka Å½itnik, BlaÅ¾ Zupan</author><abstract>

Orange is a machine learning and data mining suite for data
analysis through Python scripting and visual programming. Here
we report on the scripting part, which features interactive data
analysis and component-based assembly of data mining procedures.
In the selection and design of components, we focus on the
flexibility of their reuse: our principal intention is to let
the user write simple and clear scripts in Python, which build
upon C$++$ implementations of computationally-intensive tasks.
Orange is intended both for experienced users and programmers,
as well as for students of data mining.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/demsar13a/demsar13a.pdf</url></Article><Article><id>1061</id><title> Tapkee: An Efficient Dimension Reduction Library </title><author>Sergey Lisitsyn, Christian Widmer, Fernando J. Iglesias Garcia</author><abstract>

We present &lt;i&gt;Tapkee&lt;/i&gt;, a C++ template library that provides
efficient implementations of more than $20$ widely used
dimensionality reduction techniques ranging from &lt;i&gt;Locally
Linear Embedding&lt;/i&gt; (Roweis and Saul, 2000) and Isomap (de
Silva and Tenenbaum, 2002) to the recently introduced &lt;i&gt;Barnes-
Hut-SNE&lt;/i&gt; (van der Maaten, 2013). Our library was designed
with a focus on performance and flexibility. For performance, we
combine efficient multi-core algorithms, modern data structures
and state-of-the-art low-level libraries. To achieve
flexibility, we designed a clean interface for applying methods
to user data and provide a callback API that facilitates
integration with the library. The library is freely available as
open-source software and is distributed under the permissive
&lt;i&gt;BSD 3-clause&lt;/i&gt; license. We encourage the integration of
&lt;i&gt;Tapkee&lt;/i&gt; into other open-source toolboxes and libraries.
For example, &lt;i&gt;Tapkee&lt;/i&gt; has been integrated into the codebase
of the &lt;i&gt;Shogun&lt;/i&gt; toolbox (Sonnenburg et al., 2010), giving
us access to a rich set of kernels, distance measures and
bindings to common programming languages including Python,
Octave, Matlab, R, Java, C#, Ruby, Perl and Lua. Source code,
examples and documentation are available at &lt;a
href="http://tapkee.lisitsyn.me"&gt;http://tapkee.lisitsyn.me&lt;/a&gt;.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/lisitsyn13a/lisitsyn13a.pdf</url></Article><Article><id>1062</id><title> On the Mutual Nearest Neighbors Estimate in Regression </title><author>Arnaud Guyader, Nick Hengartner</author><abstract>

Motivated by promising experimental results, this paper
investigates the theoretical properties of a recently proposed
nonparametric estimator, called the Mutual Nearest Neighbors
rule, which estimates the regression function
$m(\mathbf{x})=\mathbb E[Y|\mathbf{X}=\mathbf{x}]$ as follows:
first identify the $k$ nearest neighbors of $\mathbf{x}$ in the
sample $\mathcal{D}_n$, then keep only those for which
$\mathbf{x}$ is itself one of the $k$ nearest neighbors, and
finally take the average over the corresponding response
variables. We prove that this estimator is consistent and that
its rate of convergence is optimal. Since the estimate with the
optimal rate of convergence depends on the unknown distribution
of the observations, we also present adaptation results by data-
splitting.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/guyader13a/guyader13a.pdf</url></Article><Article><id>1063</id><title> Distance Preserving Embeddings for General n-Dimensional Manifolds </title><author>Nakul Verma</author><abstract>

Low dimensional embeddings of manifold data have gained
popularity in the last decade. However, a systematic finite
sample analysis of manifold embedding algorithms largely eludes
researchers. Here we present two algorithms that embed a general
$n$-dimensional manifold into $\R^d$ (where $d$ only depends on
some key manifold properties such as its intrinsic dimension,
volume and curvature) that &lt;em&gt;guarantee&lt;/em&gt; to
approximately preserve all interpoint geodesic distances.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/verma13a/verma13a.pdf</url></Article><Article><id>1064</id><title> Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows </title><author>Julien Mairal, Bin Yu</author><abstract>

We consider supervised learning problems where the features are
embedded in a graph, such as gene expressions in a gene network.
In this context, it is of much interest to automatically select
a subgraph with few connected components; by exploiting prior
knowledge, one can indeed improve the prediction performance or
obtain results that are easier to interpret. Regularization or
penalty functions for selecting features in graphs have recently
been proposed, but they raise new algorithmic challenges. For
example, they typically require solving a combinatorially hard
selection problem among all connected subgraphs. In this paper,
we propose computationally feasible strategies to select a
sparse and well-connected subset of features sitting on a
directed acyclic graph (DAG). We introduce structured sparsity
penalties over paths on a DAG called â€œpath codingâ€� penalties.
Unlike existing regularization functions that model long-range
interactions between features in a graph, path coding penalties
are tractable. The penalties and their proximal operators
involve path selection problems, which we efficiently solve by
leveraging network flow optimization. We experimentally show on
synthetic, image, and genomic data that our approach is scalable
and leads to more connected subgraphs than other regularization
functions for graphs.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/mairal13a/mairal13a.pdf</url></Article><Article><id>1065</id><title> Greedy Feature Selection for Subspace Clustering </title><author>Eva L. Dyer, Aswin C. Sankaranarayanan, Richard G. Baraniuk</author><abstract>

Unions of subspaces provide a powerful generalization of single
subspace models for collections of high-dimensional data;
however, learning multiple subspaces from data is challenging
due to the fact that segmentation---the identification of points
that live in the same subspace---and subspace estimation must be
performed simultaneously. Recently, sparse recovery methods were
shown to provide a provable and robust strategy for &lt;em&gt;exact
feature selection&lt;/em&gt; (EFS)---recovering subsets of points from
the ensemble that live in the same subspace. In parallel with
recent studies of EFS with $\ell_1$-minimization, in this paper,
we develop sufficient conditions for EFS with a greedy method
for sparse signal recovery known as orthogonal matching pursuit
(OMP). Following our analysis, we provide an empirical study of
feature selection strategies for signals living on unions of
subspaces and characterize the gap between sparse recovery
methods and nearest neighbor (NN)-based approaches. In
particular, we demonstrate that sparse recovery methods provide
significant advantages over NN methods and that the gap between
the two approaches is particularly pronounced when the sampling
of subspaces in the data set is sparse. Our results suggest that
OMP may be employed to reliably recover exact feature sets in a
number of regimes where NN approaches fail to reveal the
subspace membership of points in the ensemble.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/dyer13a/dyer13a.pdf</url></Article><Article><id>1066</id><title> Learning Bilinear Model for Matching Queries and Documents </title><author>Wei Wu, Zhengdong  Lu, Hang Li</author><abstract>

The task of matching data from two heterogeneous domains
naturally arises in various areas such as web search,
collaborative filtering, and drug design. In web search,
existing work has designed relevance models to match queries and
documents by exploiting either user clicks or content of queries
and documents. To the best of our knowledge, however, there has
been little work on principled approaches to leveraging both
clicks and content to learn a matching model for search. In this
paper, we propose a framework for learning to match
heterogeneous objects. The framework learns two linear mappings
for two objects respectively, and matches them via the dot
product of their images after mapping. Moreover, when different
regularizations are enforced, the framework renders a rich
family of matching models. With orthonormal constraints on
mapping functions, the framework subsumes Partial Least Squares
(PLS) as a special case. Alternatively, with a $\ell_1$+$\ell_2$
regularization, we obtain a new model called &lt;em&gt;Regularized
Mapping to Latent Structures&lt;/em&gt; (RMLS). RMLS enjoys many
advantages over PLS, including lower time complexity and easy
parallelization. To further understand the matching framework,
we conduct generalization analysis and apply the result to both
PLS and RMLS. We apply the framework to web search and implement
both PLS and RMLS using a click-through bipartite with metadata
representing features of queries and documents. We test the
efficacy and scalability of RMLS and PLS on large scale web
search problems. The results show that both PLS and RMLS can
significantly outperform baseline methods, while RMLS
substantially speeds up the learning process.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/wu13a/wu13a.pdf</url></Article><Article><id>1067</id><title> One-shot Learning Gesture Recognition from RGB-D Data Using Bag of Features </title><author>Jun Wan, Qiuqi Ruan, Wei Li, Shuang Deng</author><abstract>

For one-shot learning gesture recognition, two important
challenges are: how to extract distinctive features and how to
learn a discriminative model from only one training sample per
gesture class. For feature extraction, a new spatio-temporal
feature representation called 3D enhanced motion scale-invariant
feature transform (3D EMoSIFT) is proposed, which fuses RGB-D
data. Compared with other features, the new feature set is
invariant to scale and rotation, and has more compact and richer
visual representations. For learning a discriminative model, all
features extracted from training samples are clustered with the
k-means algorithm to learn a visual codebook. Then, unlike the
traditional bag of feature (BoF) models using vector
quantization (VQ) to map each feature into a certain visual
codeword, a sparse coding method named simulation orthogonal
matching pursuit (SOMP) is applied and thus each feature can be
represented by some linear combination of a small number of
codewords. Compared with VQ, SOMP leads to a much lower
reconstruction error and achieves better performance. The
proposed approach has been evaluated on ChaLearn gesture
database and the result has been ranked amongst the top best
performing techniques on ChaLearn gesture challenge (round 2).</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/wan13a/wan13a.pdf</url></Article><Article><id>1068</id><title> Efficient Active Learning of Halfspaces: An Aggressive Approach </title><author>Alon Gonen, Sivan Sabato, Shai Shalev-Shwartz</author><abstract>

We study pool-based active learning of half-spaces. We revisit
the aggressive approach for active learning in the realizable
case, and show that it can be made efficient and practical,
while also having theoretical guarantees under reasonable
assumptions. We further show, both theoretically and
experimentally, that it can be preferable to mellow approaches.
Our efficient aggressive active learner of half-spaces has
formal approximation guarantees that hold when the pool is
separable with a margin. While our analysis is focused on the
realizable setting, we show that a simple heuristic allows using
the same algorithm successfully for pools with low error as
well. We further compare the aggressive approach to the mellow
approach, and prove that there are cases in which the aggressive
approach results in significantly better label complexity
compared to the mellow approach. We demonstrate experimentally
that substantial improvements in label complexity can be
achieved using the aggressive approach, for both realizable and
low-error settings.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/gonen13a/gonen13a.pdf</url></Article><Article><id>1069</id><title> Keep It Simple And Sparse: Real-Time Action Recognition </title><author>Sean Ryan Fanello, Ilaria Gori, Giorgio Metta, Francesca Odone</author><abstract>

Sparsity has been showed to be one of the most important
properties for visual recognition purposes. In this paper we
show that sparse representation plays a fundamental role in
achieving one-shot learning and real-time recognition of
actions. We start off from RGBD images, combine motion and
appearance cues and extract state-of-the-art features in a
computationally efficient way. The proposed method relies on
descriptors based on 3D Histograms of Scene Flow (3DHOFs) and
Global Histograms of Oriented Gradient (GHOGs); adaptive sparse
coding is applied to capture high-level patterns from data. We
then propose a simultaneous on-line video segmentation and
recognition of actions using linear SVMs. The main contribution
of the paper is an effective real-time system for one-shot
action modeling and recognition; the paper highlights the
effectiveness of sparse coding techniques to represent 3D
actions. We obtain very good results on three different data
sets: a benchmark data set for one-shot action learning (the
ChaLearn Gesture Data Set), an in-house data set acquired by a
Kinect sensor including complex actions and gestures differing
by small details, and a data set created for human-robot
interaction purposes. Finally we demonstrate that our system is
effective also in a human-robot interaction setting and propose
a memory game, â€œAll Gestures You Canâ€�, to be played against a
humanoid robot.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/fanello13a/fanello13a.pdf</url></Article><Article><id>1070</id><title> Maximum Volume Clustering: A New Discriminative Clustering Approach </title><author>Gang Niu, Bo Dai, Lin Shang, Masashi Sugiyama</author><abstract>

The &lt;em&gt;large volume principle&lt;/em&gt; proposed by Vladimir
Vapnik, which advocates that hypotheses lying in an equivalence
class with a larger volume are more preferable, is a useful
alternative to the &lt;em&gt;large margin principle&lt;/em&gt;. In this
paper, we introduce a new discriminative clustering model based
on the large volume principle called &lt;em&gt;maximum volume
clustering&lt;/em&gt; (MVC), and then propose two approximation
schemes to solve this MVC model: A soft-label MVC method using
&lt;em&gt;sequential quadratic programming&lt;/em&gt; and a hard-label
MVC method using &lt;em&gt; semi-definite programming&lt;/em&gt;,
respectively. The proposed MVC is theoretically advantageous for
three reasons. The optimization involved in hard-label MVC is
convex, and under mild conditions, the optimization involved in
soft-label MVC is akin to a convex one in terms of the resulting
clusters. Secondly, the soft-label MVC method possesses a
&lt;em&gt;clustering error bound&lt;/em&gt;. Thirdly, MVC includes the
optimization problems of a spectral clustering, two relaxed
$k$-means clustering and an information-maximization clustering
as &lt;em&gt;special limit cases&lt;/em&gt; when its regularization
parameter goes to infinity. Experiments on several artificial
and benchmark data sets demonstrate that the proposed MVC
compares favorably with state-of-the-art clustering methods.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/niu13a/niu13a.pdf</url></Article><Article><id>1071</id><title> Sparse/Robust Estimation and Kalman Smoothing with Nonsmooth Log-Concave Densities: Modeling, Computation, and Theory </title><author>Aleksandr Y. Aravkin, James V. Burke, Gianluigi Pillonetto</author><abstract>

&lt;p&gt;We introduce a new class of quadratic support (QS) functions,
many of which already play a crucial role in a variety of
applications, including machine learning, robust statistical
inference, sparsity promotion, and inverse problems such as
Kalman smoothing. Well known examples of QS penalties include
the $\ell_2$, Huber, $\ell_1$ and Vapnik losses. We build on a
dual representation for QS functions, using it to characterize
conditions necessary to interpret these functions as negative
logs of true probability densities. This interpretation
establishes the foundation for statistical modeling with both
known and new QS loss functions, and enables construction of
non-smooth multivariate distributions with specified means and
variances from simple scalar building blocks.&lt;/p&gt; &lt;p&gt;The main
contribution of this paper is a flexible statistical modeling
framework for a variety of learning applications, together with
a toolbox of efficient numerical methods for estimation. In
particular, a broad subclass of QS loss functions known as
piecewise linear quadratic (PLQ) penalties has a dual
representation that can be exploited to design interior point
(IP) methods. IP methods solve nonsmooth optimization problems
by working directly with smooth systems of equations
characterizing their optimality. We provide several numerical
examples, along with a code that can be used to solve general
PLQ problems.&lt;/p&gt; &lt;p&gt;The efficiency of the IP approach depends
on the structure of particular applications. We consider the
class of dynamic inverse problems using Kalman smoothing. This
class comprises a wide variety of applications, where the aim is
to reconstruct the state of a dynamical system with known
process and measurement models starting from noisy output
samples. In the classical case, Gaussian errors are assumed both
in the process and measurement models for such problems. We show
that the extended framework allows arbitrary PLQ densities to be
used, and that the proposed IP approach solves the generalized
Kalman smoothing problem while maintaining the linear complexity
in the size of the time series, just as in the Gaussian case.
This extends the computational efficiency of the Mayne-Fraser
and Rauch-Tung- Striebel algorithms to a much broader nonsmooth
setting, and includes many recently proposed robust and sparse
smoothers as special cases.&lt;/p&gt;</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/aravkin13a/aravkin13a.pdf</url></Article><Article><id>1072</id><title> Improving CUR Matrix Decomposition and the Nystrom Approximation via Adaptive Sampling </title><author>Shusen Wang, Zhihua Zhang</author><abstract>

The CUR matrix decomposition and the Nystrom approximation are
two important low-rank matrix approximation techniques. The
Nystrom method approximates a symmetric positive semidefinite
matrix in terms of a small number of its columns, while CUR
approximates an arbitrary data matrix by a small number of its
columns and rows. Thus, CUR decomposition can be regarded as an
extension of the Nystrom approximation. In this paper we
establish a more general error bound for the adaptive column/row
sampling algorithm, based on which we propose more accurate CUR
and Nystrom algorithms with expected relative-error bounds. The
proposed CUR and Nystrom algorithms also have low time
complexity and can avoid maintaining the whole data matrix in
RAM. In addition, we give theoretical analysis for the lower
error bounds of the standard Nystrom method and the ensemble
Nystrom method. The main theoretical results established in this
paper are novel, and our analysis makes no special assumption on
the data matrices.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/wang13c/wang13c.pdf</url></Article><Article><id>1073</id><title> Training Energy-Based Models for Time-Series Imputation </title><author>PhilÃ©mon Brakel, Dirk Stroobandt, Benjamin Schrauwen</author><abstract>

Imputing missing values in high dimensional time-series is a
difficult problem. This paper presents a strategy for training
energy-based graphical models for imputation directly, bypassing
difficulties probabilistic approaches would face. The training
strategy is inspired by recent work on optimization-based
learning (Domke, 2012) and allows complex neural models with
convolutional and recurrent structures to be trained for
imputation tasks. In this work, we use this training strategy to
derive learning rules for three substantially different neural
architectures. Inference in these models is done by either
truncated gradient descent or variational mean-field iterations.
In our experiments, we found that the training methods
outperform the Contrastive Divergence learning algorithm.
Moreover, the training methods can easily handle missing values
in the training data itself during learning. We demonstrate the
performance of this learning scheme and the three models we
introduce on one artificial and two real-world data sets.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/brakel13a/brakel13a.pdf</url></Article><Article><id>1074</id><title> Belief Propagation for Continuous State Spaces: Stochastic Message-Passing with Quantitative Guarantees </title><author>Nima Noorshams, Martin J. Wainwright</author><abstract>

The sum-product or belief propagation (BP) algorithm is a widely
used message-passing technique for computing approximate
marginals in graphical models. We introduce a new technique,
called stochastic orthogonal series message-passing (SOSMP), for
computing the BP fixed point in models with continuous random
variables. It is based on a deterministic approximation of the
messages via orthogonal series basis expansion, and a stochastic
estimation of the basis coefficients via Monte Carlo techniques
and damped updates. We prove that the SOSMP iterates converge to
a $\delta$-neighborhood of the unique BP fixed point for any
tree-structured graph, and for any graphs with cycles in which
the BP updates satisfy a contractivity condition. In addition,
we demonstrate how to choose the number of basis coefficients as
a function of the desired approximation accuracy $\delta$ and
smoothness of the compatibility functions. We illustrate our
theory with both simulated examples and in application to
optical flow estimation.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/noorshams13a/noorshams13a.pdf</url></Article><Article><id>1075</id><title> A Binary-Classification-Based Metric between Time-Series Distributions and Its Use in Statistical and Learning Problems </title><author>Daniil Ryabko, JÃ©rÃ©mie Mary</author><abstract>

A metric between time-series distributions is proposed that can
be evaluated using binary classification methods, which were
originally developed to work on i.i.d. data. It is shown how
this metric can be used for solving statistical problems that
are seemingly unrelated to classification and concern highly
dependent time series. Specifically, the problems of time-series
clustering, homogeneity testing and the three-sample problem are
addressed. Universal consistency of the resulting algorithms is
proven under most general assumptions. The theoretical results
are illustrated with experiments on synthetic and real-world
data.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/ryabko13a/ryabko13a.pdf</url></Article><Article><id>1076</id><title> Perturbative Corrections for Approximate Inference in Gaussian Latent Variable Models </title><author>Manfred Opper, Ulrich Paquet, Ole Winther</author><abstract>

Expectation Propagation (EP) provides a framework for
approximate inference. When the model under consideration is
over a latent Gaussian field, with the approximation being
Gaussian, we show how these approximations can systematically be
corrected. A perturbative expansion is made of the exact but
intractable correction, and can be applied to the model's
partition function and other moments of interest. The correction
is expressed over the higher-order cumulants which are neglected
by EP's local matching of moments. Through the expansion, we see
that EP is correct to first order. By considering higher orders,
corrections of increasing polynomial complexity can be applied
to the approximation. The second order provides a correction in
quadratic time, which we apply to an array of Gaussian process
and Ising models. The corrections generalize to arbitrarily
complex approximating families, which we illustrate on tree-
structured Ising model approximations. Furthermore, they provide
a polynomial-time assessment of the approximation error. We also
provide both theoretical and practical insights on the exactness
of the EP solution.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/opper13a/opper13a.pdf</url></Article><Article><id>1077</id><title> The CAM Software for Nonnegative Blind Source Separation in R-Java </title><author>Niya Wang, Fan Meng, Li Chen, Subha Madhavan, Robert Clarke, Eric P. Hoffman, Jianhua Xuan, Yue Wang</author><abstract>

We describe a &lt;code&gt;R-Java CAM&lt;/code&gt; (convex analysis of
mixtures) package that provides comprehensive analytic functions
and a graphic user interface (&lt;code&gt;GUI&lt;/code&gt;) for blindly
separating mixed nonnegative sources. This open-source
multiplatform software implements recent and classic algorithms
in the literature including Chan et al. (2008), Wang et al.
(2010), Chen et al. (2011a) and Chen et al. (2011b). The
&lt;code&gt;CAM&lt;/code&gt; package offers several attractive features: (1)
instead of using proprietary  &lt;code&gt;MATLAB&lt;/code&gt;, its analytic
functions are written in &lt;code&gt;R&lt;/code&gt;, which makes the codes
more portable and easier to modify; (2) besides producing and
plotting results in &lt;code&gt;R&lt;/code&gt;, it also provides a
&lt;code&gt;Java GUI&lt;/code&gt; for automatic progress update and
convenient visual monitoring; (3) multi-thread interactions
between the &lt;code&gt;R&lt;/code&gt; and &lt;code&gt;Java&lt;/code&gt; modules are
driven and integrated by a &lt;code&gt;Java GUI&lt;/code&gt;, assuring that
the whole &lt;code&gt;CAM&lt;/code&gt; software runs responsively; (4) the
package offers a simple mechanism to allow others to plug-in
additional &lt;code&gt;R&lt;/code&gt;-functions.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/wang13d/wang13d.pdf</url></Article><Article><id>1078</id><title> A Near-Optimal Algorithm for Differentially-Private Principal Components </title><author>Kamalika Chaudhuri, Anand D. Sarwate, Kaushik Sinha</author><abstract>

The principal components analysis (PCA) algorithm is a standard
tool for identifying good low-dimensional approximations to
high-dimensional data. Many data sets of interest contain
private or sensitive information about individuals. Algorithms
which operate on such data should be sensitive to the privacy
risks in publishing their outputs. Differential privacy is a
framework for developing tradeoffs between privacy and the
utility of these outputs. In this paper we investigate the
theory and empirical performance of differentially private
approximations to PCA and propose a new method which explicitly
optimizes the utility of the output. We show that the sample
complexity of the proposed method differs from the existing
procedure in the scaling with the data dimension, and that our
method is nearly optimal in terms of this scaling. We
furthermore illustrate our results, showing that on real data
there is a large performance gap between the existing method and
our method.</abstract><venue>Journal of Machine Learning Research (JMLR)</venue><url>http://jmlr.org/papers/volume14/chaudhuri13a/chaudhuri13a.pdf</url></Article></articles>